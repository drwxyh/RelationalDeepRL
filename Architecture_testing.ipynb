{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Deep Reinforcement Learning\n",
    "\n",
    "**Plan:**\n",
    "1. Architecture\n",
    "2. Agent\n",
    "3. Environment\n",
    "4. Training cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational architecture\n",
    "\n",
    "**Input: (b,n,n,1)** = (batch length, linear size, linear size, greyscale)\n",
    "\n",
    "**Extract entities: (b,n,n,1) -> (b, m, m, 2k)** \n",
    "* embedding layer: vocab_size = MAX_PIXELS+1, embedding_dim = n_dim\n",
    "* convolutional_layer1(kernel_size = (2,2), input_filters = n_dim, output_filters = k, stride = 1, pad = (1,1))\n",
    "* convolutional_layer2(kernel_size = (2,2), input_filters = k, output_filters = 2k, stride = 1, pad = (1,1))\n",
    "\n",
    "**Relational block: (b, m, m, 2k) -> (b,d_m)**\n",
    "* Positional Encoding: (b, m, m, 2k) -> (b, m^2, d_m)\n",
    "* N Multi-Headed Attention blocks: (b, m^2, d_m) -> (b, m^2, d_m)\n",
    "\n",
    "**Feature-wise max pooling: (b, m^2, d_m) -> (b, d_m)**\n",
    "\n",
    "**Multi-Layer Perceptron: (b, d_m) -> (b, d_m)**\n",
    "* 4 fully connected layers (d_m,d_m) with ReLUs (TODO: add skip-connections)\n",
    "\n",
    "**Actor output: (b,d_m) -> (b,a)** [a = number of possible actions]\n",
    "* Single linear layer with softmax at the end\n",
    "\n",
    "**Critic output: (b,d_m) -> (b,1)** \n",
    "* Single linear layer without activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control architecture\n",
    "\n",
    "**Input: (b,n,n,1)** = (batch length, linear size, linear size, greyscale)\n",
    "\n",
    "**Extract entities: (b,n,n,1) -> (b, m, m, 2k)** \n",
    "* embedding layer: vocab_size = MAX_PIXELS+1, embedding_dim = n_dim\n",
    "* convolutional_layer1(kernel_size = (2,2), input_filters = n_dim, output_filters = k, stride = 1, pad = (1,1))\n",
    "* convolutional_layer2(kernel_size = (2,2), input_filters = k, output_filters = 2k, stride = 1, pad = (1,1))\n",
    "\n",
    "**1D Convolutional block: (b, m, m, 2k) -> (b, m^2, d_m)**\n",
    "* Positional Encoding: (b, m, m, 2k) -> (b, m^2, d_m)\n",
    "* 2 1D convolutional blocks with ReLUs: (b, m^2, d_m) -> (b, m^2, d_m) - pixel-wise\n",
    "\n",
    "**Feature-wise max pooling: (b, m^2, d_m) -> (b, d_m)**\n",
    "\n",
    "**Multi-Layer Perceptron: (b, d_m) -> (b, d_m)**\n",
    "* 4 fully connected layers (d_m,d_m) with ReLUs - feature-wise\n",
    "* (TODO: add skip-connections)\n",
    "\n",
    "**Actor output: (b,d_m) -> (b,a)** [a = number of possible actions]\n",
    "* Single linear layer with softmax at the end\n",
    "\n",
    "**Critic output: (b,d_m) -> (b,1)** \n",
    "* Single linear layer without activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RelationalModule import RelationalNetworks as rnet\n",
    "from RelationalModule import ControlNetworks as cnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.ControlNetworks' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/ControlNetworks.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(rnet)\n",
    "reload(cnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 256\n",
    "n_dim = 3\n",
    "embed = nn.Embedding(vocab_size, n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_zeros.shape:  torch.Size([10, 10, 3])\n",
      "tensor([[0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030],\n",
      "        [0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030, 0.9030,\n",
      "         0.9030]], grad_fn=<SelectBackward>)\n",
      "tensor([[0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922],\n",
      "        [0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922, 0.3922,\n",
      "         0.3922]], grad_fn=<SelectBackward>)\n",
      "tensor([[-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286],\n",
      "        [-1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286, -1.1286,\n",
      "         -1.1286, -1.1286]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros((10,10), dtype=int)\n",
    "y_zeros = embed(zeros)\n",
    "print(\"y_zeros.shape: \", y_zeros.shape)\n",
    "print(y_zeros[:,:,0])\n",
    "print(y_zeros[:,:,1])\n",
    "print(y_zeros[:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same integer values get mapped to same vectors, as it should be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcf93e93ed0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eye = torch.eye(10, dtype=int)\n",
    "y_eye = embed(eye).detach()\n",
    "plt.imshow(y_eye.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the embedding works, since each integer value is associated to a particular vector (in this case 3D vector, that can be represented as RGB color once clipped)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_in = 1\n",
    "k_out = 24\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "padding = 0\n",
    "\n",
    "layers = []\n",
    "layers.append(nn.Conv2d(n_dim*k_in, k_out//2, kernel_size, stride, padding))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Conv2d(k_out//2, k_out, kernel_size, stride, padding))\n",
    "#layers.append(nn.ReLU())\n",
    "net = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_slices(x, axes):\n",
    "    return x.squeeze().sum(axis=axes).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (before embed):  torch.Size([1, 1, 14, 14])\n",
      "x.shape (after embed):  torch.Size([1, 1, 14, 14, 3])\n",
      "x.sum in slices:  tensor([ 176.9918,   76.8794, -221.1962])\n",
      "x.shape:  torch.Size([1, 1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 3, 14, 14])\n",
      "y.shape:  torch.Size([1, 24, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1,14,14), dtype=int) # this is the structure of the state retrieved by the game\n",
    "if len(x.shape) <= 3:\n",
    "    x = x.unsqueeze(0)\n",
    "print(\"x.shape (before embed): \", x.shape)\n",
    "x = embed(x)\n",
    "print(\"x.shape (after embed): \", x.shape)\n",
    "print(\"x.sum in slices: \", sum_slices(x,(0,1)))\n",
    "x = x.transpose(-1,-3)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(-1,-2).reshape(x.shape[0],-1,x.shape[-2],x.shape[-1])\n",
    "print(\"x.shape: \", x.shape)\n",
    "y = net(x)\n",
    "print(\"y.shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-35.3239,  -9.3927,  35.7545, -21.0438,  13.3046,  16.2250,  25.0224,\n",
      "         34.7849, -32.5136, -44.9192, -31.9720, -20.1204, -45.4257,  18.9467,\n",
      "        -32.3886,  -9.5785, -18.5796,   7.8179,  34.8244, -29.5308,   0.6400,\n",
      "         17.0077, -13.3558, -25.9338])\n",
      "y[0,:,:]:  tensor([[-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453],\n",
      "        [-0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453, -0.2453,\n",
      "         -0.2453, -0.2453, -0.2453, -0.2453]])\n"
     ]
    }
   ],
   "source": [
    "y = y.squeeze().detach()\n",
    "print(sum_slices(y,(1,2)))\n",
    "print(\"y[0,:,:]: \", y[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically each layer is uniform thanks to the input and how convolution works (each slice is the result of the convolution from the same kernel of the same input). All the zeros that can be seen are due to the ReLU activations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_encoding2D(x):\n",
    "    x_ax = x.shape[-2]\n",
    "    y_ax = x.shape[-1]\n",
    "\n",
    "    x_lin = torch.linspace(-1,1,x_ax)\n",
    "    xx = x_lin.repeat(x.shape[0],y_ax,1).view(-1, 1, y_ax, x_ax).transpose(3,2)\n",
    "\n",
    "    y_lin = torch.linspace(-1,1,y_ax).view(-1,1)\n",
    "    yy = y_lin.repeat(x.shape[0],1,x_ax).view(-1, 1, y_ax, x_ax).transpose(3,2)\n",
    "\n",
    "    x = torch.cat((x,xx,yy), axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (before embed):  torch.Size([1, 1, 14, 14])\n",
      "x.shape (after embed):  torch.Size([1, 1, 14, 14, 3])\n",
      "x.sum in slices:  tensor([ 176.9918,   76.8794, -221.1962])\n",
      "x.shape:  torch.Size([1, 1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 3, 14, 14])\n",
      "y.shape:  torch.Size([1, 24, 12, 12])\n",
      "y_enc.shape:  torch.Size([1, 26, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1,14,14), dtype=int) # this is the structure of the state retrieved by the game\n",
    "if len(x.shape) <= 3:\n",
    "    x = x.unsqueeze(0)\n",
    "print(\"x.shape (before embed): \", x.shape)\n",
    "x = embed(x)\n",
    "print(\"x.shape (after embed): \", x.shape)\n",
    "print(\"x.sum in slices: \", sum_slices(x,(0,1)))\n",
    "x = x.transpose(-1,-3)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(-1,-2).reshape(x.shape[0],-1,x.shape[-2],x.shape[-1])\n",
    "print(\"x.shape: \", x.shape)\n",
    "y = net(x)\n",
    "print(\"y.shape: \", y.shape)\n",
    "y_enc = add_encoding2D(y)\n",
    "print(\"y_enc.shape: \", y_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the last 2 layers have a positional encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_tmp.shape:  torch.Size([26, 12, 12])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_tmp = y_enc.squeeze().detach()\n",
    "print(\"y_tmp.shape: \", y_tmp.shape)\n",
    "plt.imshow(y_tmp[-2])\n",
    "plt.show()\n",
    "plt.imshow(y_tmp[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different approach would be to sum these two layers pixel-wise to all other features. Probably it would amplify the importance of the position, at the risk that if the magnitude is too high we would lose data.\n",
    "\n",
    "Also more complicated encodings are possible; this one is the one I think they used in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection from 26 to n_features (default 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 256\n",
    "projection = nn.Linear(k_out + 2, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (before embed):  torch.Size([1, 1, 14, 14])\n",
      "x.shape (after embed):  torch.Size([1, 1, 14, 14, 3])\n",
      "x.sum in slices:  tensor([ 176.9918,   76.8794, -221.1962])\n",
      "x.shape:  torch.Size([1, 1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 24, 12, 12])\n",
      "x.shape:  torch.Size([1, 26, 12, 12])\n",
      "x.shape:  torch.Size([1, 26, 144])\n",
      "x.shape:  torch.Size([1, 144, 26])\n",
      "x.shape:  torch.Size([1, 144, 256])\n",
      "x.shape:  torch.Size([144, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1,14,14), dtype=int) # this is the structure of the state retrieved by the game\n",
    "if len(x.shape) <= 3:\n",
    "    x = x.unsqueeze(0)\n",
    "print(\"x.shape (before embed): \", x.shape)\n",
    "x = embed(x)\n",
    "print(\"x.shape (after embed): \", x.shape)\n",
    "print(\"x.sum in slices: \", sum_slices(x,(0,1)))\n",
    "x = x.transpose(-1,-3)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(-1,-2).reshape(x.shape[0],-1,x.shape[-2],x.shape[-1])\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = net(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x= add_encoding2D(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.view(x.shape[0], x.shape[1],-1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(2,1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = projection(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(1,0)\n",
    "print(\"x.shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here everything seems clean. Let's see if there is some trace of the positional encoding left. Ideally thanks to the projection now each feature potentially has a positional encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANYklEQVR4nO3db4jcB53H8c9nZxPbpLV/rl7QJFzyoPQIwlFZpFqQo+lBPcX44DhaqPREyJOrVhEk3pM+9YGIPhAh1GrA0nLEgkWKtVRFDo6c27ScTaLXUr02NW3Sptm02d2ZndnvPdgJ5Jbspc7vO/Mb7vt+QdmZ2eE7n+z2s7/5t991RAjA/38zbQcAMBmUHSiCsgNFUHagCMoOFDE7yRu76cZO7Nq5qfGcvlYT0kiDpFciVhJ/Zg4iZ9ZKdFLmDJQzp5/078qak/V1lqTBalYmN57RfeO8VhYWLztoomXftXOT/uOpnY3nvD1YTEgjnV3N+aFxZnB1yhxJemt1a8qcM/33p8w5278mZc6bKzlzzvW3pMw528uZI0nne1flzOk2n/Of9x/a8HPcjQeKoOxAEZQdKIKyA0U0Krvtu2z/3vZLtg9khQKQb+Sy2+5I+q6kT0raI+ke23uyggHI1eTI/lFJL0XEyxHRk/SYpH05sQBka1L27ZJeveT8yeFl/4vt/bbnbc+feWvQ4OYANDH2J+gi4mBEzEXE3Af+IufdWAD+fE3K/pqkS98Ot2N4GYAp1KTsv5F0s+3dtjdLulvSEzmxAGQb+b3xEdG3fb+kpyR1JD0cEcfSkgFI1egXYSLiSUlPJmUBMEa8gw4ogrIDRVB2oIiJLq9YjlX918qFxnOylkW8NchZqJC1KEKSzg5ylle8uXJtypxzKzlf67eTlkVkLYp4p/e+lDmStNjdnDJnqZuwxWmw8XtZOLIDRVB2oAjKDhRB2YEiKDtQBGUHiqDsQBGUHSiCsgNFUHagCMoOFEHZgSIoO1AEZQeKoOxAEZQdKIKyA0VMeFPNrI73tjWeczppM8zb/aytMDkbbyTp3ErORpeFlZyNLgvdnE01767kbHN5dzlnw0y3l/e//ko3Z9Zqt/lfTIqBN/wcR3agCMoOFEHZgSIoO1AEZQeKGLnstnfa/qXt47aP2X4gMxiAXE1eM+hL+mpEHLV9raRnbT8dEceTsgFINPKRPSJORcTR4el3JJ2QtD0rGIBcKY/Zbe+SdKukIxnzAORrXHbb10j6saQvR8T5y3x+v+152/MLZ/tNbw7AiBqV3fYmrRX9kYh4/HLXiYiDETEXEXPX3TjRd+cCuESTZ+Mt6fuSTkTEt/IiARiHJkf22yV9TtIdtp8f/vf3SbkAJBv5fnVE/JukjX/FBsBU4R10QBGUHSiCsgNFTPS1sKXVzTq+1PxNdm/3c7a5nO3lbKrJ2gojSQu9pM0wvZzNMBe6OXO63U0pc7K2wkTCVpiL3M05Zna6CU+BsakGAGUHiqDsQBGUHSiCsgNFUHagCMoOFEHZgSIoO1AEZQeKoOxAEZQdKIKyA0VQdqAIyg4UQdmBIig7UARlB4qY6Fqq7uqsXlz8y8ZzFno5a6CyVkBdSFoBJWWugcr51vanbA3UVK2AGprp5czqLDef48HGn+PIDhRB2YEiKDtQBGUHiqDsQBGNy267Y/s52z/NCARgPDKO7A9IOpEwB8AYNSq77R2SPiXpoZw4AMal6ZH925K+Jml1oyvY3m973vb88rnlhjcHYFQjl932pyWdjohn/6/rRcTBiJiLiLmrrs/7A4gA/jxNjuy3S/qM7T9KekzSHbZ/lJIKQLqRyx4RX4+IHRGxS9Ldkn4REfemJQOQitfZgSJSfqUpIn4l6VcZswCMB0d2oAjKDhRB2YEiJr6p5pV3b2g8553u+xLSSEu9TSlzuss5cySp38vZ6BLLSZthekmbYZaT5vRSxqRshbloJi1T8xlsqgFA2YEqKDtQBGUHiqDsQBGUHSiCsgNFUHagCMoOFEHZgSIoO1AEZQeKoOxAEZQdKIKyA0VQdqAIyg4UMdFNNf3BjN44f23jOVmbYQZTthVGktzL2aAym7QZJm8LS86/K29TTc4cSep0I2dOQqYZNtUAoOxAEZQdKIKyA0VQdqCIRmW3fb3tw7Z/Z/uE7Y9lBQOQq+lLb9+R9LOI+AfbmyVtScgEYAxGLrvt6yR9QtI/SVJE9CQlvQoKIFuTu/G7JZ2R9APbz9l+yPbW9Veyvd/2vO35/vnFBjcHoIkmZZ+V9BFJ34uIWyVdkHRg/ZUi4mBEzEXE3Oz7uZcPtKVJ2U9KOhkRR4bnD2ut/ACm0Mhlj4jXJb1q+5bhRXslHU9JBSBd02fjvyjpkeEz8S9L+nzzSADGoVHZI+J5SXNJWQCMEe+gA4qg7EARlB0oYqKbalYHM7qwcFXzQd2czTDu5vysm+3mbGGRpJluzpxOUqZOWp6kOctJW2GS8kjSbFKm2e5q4xkebJyFIztQBGUHiqDsQBGUHSiCsgNFUHagCMoOFEHZgSIoO1AEZQeKoOxAEZQdKIKyA0VQdqAIyg4UQdmBIig7UMREN9VoYM0sbGo8ZmbKtrBk5ZGmbzNM1haW6cvTfCvMRbNLObM6S4PGM2b6bKoByqPsQBGUHSiCsgNFUHagiEZlt/0V28dsv2D7UdsJS+EBjMPIZbe9XdKXJM1FxIcldSTdnRUMQK6md+NnJV1te1bSFkl/ah4JwDiMXPaIeE3SNyW9IumUpIWI+Pn669neb3ve9vzg3QujJwXQSJO78TdI2idpt6QPSdpq+97114uIgxExFxFznWu2jp4UQCNN7sbfKekPEXEmIlYkPS7p4zmxAGRrUvZXJN1me4ttS9or6UROLADZmjxmPyLpsKSjkn47nHUwKReAZI1+6y0iHpT0YFIWAGPEO+iAIig7UARlB4qY6KYaD6RNC81/vkzbNpesOZLUmbrNMDlbWKZtw0xnsZ8yR5I6yzmzZhZ7jWe4v/HXhyM7UARlB4qg7EARlB0ogrIDRVB2oAjKDhRB2YEiKDtQBGUHiqDsQBGUHSiCsgNFUHagCMoOFEHZgSIoO1AEZQeKmPhaqs3nm8/pLDefIUmdbs6qpKyVS1JipqWkNVDLg5Q5s0s5c2aWV3LmJKyAushLOTvA4sJS8yH9jb/OHNmBIig7UARlB4qg7EARVyy77Ydtn7b9wiWX3Wj7adsvDj/eMN6YAJp6L0f2H0q6a91lByQ9ExE3S3pmeB7AFLti2SPi15LOrrt4n6RDw9OHJH02OReAZKM+Zt8WEaeGp1+XtC0pD4AxafwEXUSEpA3fwWF7v+152/ODxQtNbw7AiEYt+xu2PyhJw4+nN7piRByMiLmImOts2TrizQFoatSyPyHpvuHp+yT9JCcOgHF5Ly+9PSrp3yXdYvuk7S9I+oakv7P9oqQ7h+cBTLEr/iJMRNyzwaf2JmcBMEa8gw4ogrIDRVB2oAjKDhQx+U0155pvUMnaDDObthVmNWWOJHWWc2Z1lvopc2ay5izmbHPxctZWmMWUOZK0upiwYUbS6mLzTBEbf784sgNFUHagCMoOFEHZgSIoO1AEZQeKoOxAEZQdKIKyA0VQdqAIyg4UQdmBIig7UARlB4qg7EARlB0ogrIDRXjtrzdN6MbsM5L++wpXu0nSmxOI816R58qmLVPlPH8VER+43CcmWvb3wvZ8RMy1neMi8lzZtGUiz+VxNx4ogrIDRUxj2Q+2HWAd8lzZtGUiz2VM3WN2AOMxjUd2AGNA2YEipqbstu+y/XvbL9k+MAV5dtr+pe3jto/ZfqDtTJJku2P7Ods/nYIs19s+bPt3tk/Y/ljLeb4y/F69YPtR21e1kOFh26dtv3DJZTfaftr2i8OPN0w6lzQlZbfdkfRdSZ+UtEfSPbb3tJtKfUlfjYg9km6T9M9TkEmSHpB0ou0QQ9+R9LOI+GtJf6MWc9neLulLkuYi4sOSOpLubiHKDyXdte6yA5KeiYibJT0zPD9xU1F2SR+V9FJEvBwRPUmPSdrXZqCIOBURR4en39Ha/8jb28xke4ekT0l6qM0cwyzXSfqEpO9LUkT0IuJcu6k0K+lq27OStkj606QDRMSvJZ1dd/E+SYeGpw9J+uxEQw1NS9m3S3r1kvMn1XKxLmV7l6RbJR1pN4m+LelrkvL+kuTodks6I+kHw4cVD9ne2laYiHhN0jclvSLplKSFiPh5W3nW2RYRp4anX5e0rY0Q01L2qWX7Gkk/lvTliDjfYo5PSzodEc+2lWGdWUkfkfS9iLhV0gW1dPdUkoaPg/dp7YfQhyRttX1vW3k2Emuvdbfyeve0lP01STsvOb9jeFmrbG/SWtEfiYjHW45zu6TP2P6j1h7m3GH7Ry3mOSnpZERcvLdzWGvlb8udkv4QEWciYkXS45I+3mKeS71h+4OSNPx4uo0Q01L230i62fZu25u19sTKE20Gsm2tPR49ERHfajOLJEXE1yNiR0Ts0trX5xcR0dqRKyJel/Sq7VuGF+2VdLytPFq7+36b7S3D791eTc8TmU9Ium94+j5JP2kjxGwbN7peRPRt3y/pKa09i/pwRBxrOdbtkj4n6be2nx9e9i8R8WSLmabNFyU9MvwB/bKkz7cVJCKO2D4s6ajWXkl5Ti28TdX2o5L+VtJNtk9KelDSNyT9q+0vaO1XvP9x0rkk3i4LlDEtd+MBjBllB4qg7EARlB0ogrIDRVB2oAjKDhTxP+l8mJYZJKpQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_tmp = x.squeeze().detach().view(12,12,256)\n",
    "plt.imshow(x_tmp[:,:,0])\n",
    "plt.show()\n",
    "plt.imshow(x_tmp[:,:,128])\n",
    "plt.show()\n",
    "plt.imshow(x_tmp[:,:,-2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again everything seems fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Block \n",
    "Implements the relational block, composed by a Multi-Headed Dot-Product Attention layer followed by a Position-wise Feed-Forward layer. I implement here the former one, whereas I just import the latter from the module, since it's very basic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "dropout = 0\n",
    "n_heads = 4\n",
    "\n",
    "norm = nn.LayerNorm(n_features)\n",
    "drop = nn.Dropout(dropout) # disabled\n",
    "attn = nn.MultiheadAttention(n_features, n_heads, dropout)\n",
    "ff = rnet.PositionwiseFeedForward(n_features, hidden_dim, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (before embed):  torch.Size([1, 1, 14, 14])\n",
      "x.shape (after embed):  torch.Size([1, 1, 14, 14, 3])\n",
      "x.sum in slices:  tensor([ 176.9918,   76.8794, -221.1962])\n",
      "x.shape:  torch.Size([1, 1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 24, 12, 12])\n",
      "x.shape:  torch.Size([1, 26, 12, 12])\n",
      "x.shape:  torch.Size([1, 26, 144])\n",
      "x.shape:  torch.Size([1, 144, 26])\n",
      "x.shape:  torch.Size([1, 144, 256])\n",
      "x.shape:  torch.Size([144, 1, 256])\n",
      "attn_output.shape:  torch.Size([144, 1, 256])\n",
      "x_add.shape:  torch.Size([144, 1, 256])\n",
      "x_norm.shape:  torch.Size([144, 1, 256])\n",
      "x_ff.shape:  torch.Size([144, 1, 256])\n",
      "x.shape:  torch.Size([144, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1,14,14), dtype=int) # this is the structure of the state retrieved by the game\n",
    "if len(x.shape) <= 3:\n",
    "    x = x.unsqueeze(0)\n",
    "print(\"x.shape (before embed): \", x.shape)\n",
    "x = embed(x)\n",
    "print(\"x.shape (after embed): \", x.shape)\n",
    "print(\"x.sum in slices: \", sum_slices(x,(0,1)))\n",
    "x = x.transpose(-1,-3)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(-1,-2).reshape(x.shape[0],-1,x.shape[-2],x.shape[-1])\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = net(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x= add_encoding2D(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.view(x.shape[0], x.shape[1],-1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(2,1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = projection(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(1,0)\n",
    "print(\"x.shape: \", x.shape)\n",
    "\n",
    "x_tmp = x # save it for plotting\n",
    "\n",
    "# From here it has always the same shape\n",
    "attn_output, attn_output_weights =  attn(x,x,x, key_padding_mask=None) # MHA step\n",
    "print(\"attn_output.shape: \", attn_output.shape)\n",
    "x_add = attn_output + x\n",
    "print(\"x_add.shape: \", x_add.shape)\n",
    "x_norm = drop(norm(x_add))\n",
    "print(\"x_norm.shape: \", x_norm.shape)\n",
    "x_ff = ff(x_norm)\n",
    "print(\"x_ff.shape: \", x_ff.shape)\n",
    "x = drop(norm(x_ff))\n",
    "print(\"x.shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can nonetheless follow the transformation of a single feature along the attention block, to see if something strange happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer(x, layer=0):\n",
    "    x = x.squeeze().detach()[:,layer]\n",
    "    plt.imshow(x.view(12,12))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention output\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input + attention\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After LayerNorm\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After position-wise FF\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After LayerNorm\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Input\")\n",
    "plot_layer(x_tmp)\n",
    "print(\"Attention output\")\n",
    "plot_layer(attn_output)\n",
    "print(\"Input + attention\")\n",
    "plot_layer(x_add)\n",
    "print(\"After LayerNorm\")\n",
    "plot_layer(x_norm)\n",
    "print(\"After position-wise FF\")\n",
    "plot_layer(x_ff)\n",
    "print(\"After LayerNorm\")\n",
    "plot_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we didn't see anything suspicious, with the attention layer not doing much and the only real change happening during the positionwise feed forward, in which we make a convolution of the 256 features to obtain new ones, so of course after that we are looking at a different feature plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LayerNorm formula**\n",
    "$$y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:  tensor(-0.0122, grad_fn=<MeanBackward0>)\n",
      "V:  tensor(0.0493, grad_fn=<VarBackward0>)\n",
      "LayerNorm by hand: \n",
      " tensor([ 0.0284,  1.2157, -1.1573,  0.0688,  0.7310,  0.6031,  0.6676,  1.3835,\n",
      "         0.9950,  1.2959, -0.6308,  1.8772, -0.9499, -0.3141,  1.6242,  0.7809,\n",
      "        -0.1059, -0.3799,  1.3805, -0.6039, -1.3889,  1.2424,  0.4985,  0.7495,\n",
      "         0.7886,  1.9311, -0.6990,  0.4695,  0.1626, -0.4700,  1.2492, -0.2175,\n",
      "        -0.4678, -0.1953,  0.4560, -1.4421, -0.6232, -0.0535, -1.5531, -0.4257,\n",
      "         0.2913, -1.1472, -0.5887,  0.6002,  0.4235,  2.0421,  0.7562, -0.2007,\n",
      "        -0.1215, -0.2481, -1.3256,  1.0848,  0.3430,  0.1390,  0.3757,  0.0451,\n",
      "        -0.7191,  0.6880,  0.4480, -1.5937,  0.4631,  2.0827,  2.0120, -1.4430,\n",
      "         0.1889,  0.7064, -0.6214,  1.0987, -1.6761,  0.5927,  1.3023, -0.6014,\n",
      "         0.0991,  0.2188,  0.5064, -1.1640,  0.3713, -0.6570, -0.5317,  0.1632,\n",
      "        -0.5617,  0.2554, -1.7161, -0.1190, -0.7513,  0.7122,  0.1694, -0.5682,\n",
      "        -1.1030, -1.7633,  1.8225,  0.6666, -0.0743, -0.5638, -0.4150, -1.6814,\n",
      "        -2.0115,  0.0744, -0.8668,  1.3567, -2.1959,  0.6451,  0.2918,  0.3711,\n",
      "        -2.1710, -2.4223, -0.0900,  0.4871,  1.4879, -0.2318, -0.8327, -1.6577,\n",
      "         1.3382,  1.3713, -0.7301, -1.1395,  0.1001,  0.1172,  1.2803,  0.6048,\n",
      "        -1.3390,  0.1222, -0.2058, -0.7597,  1.0593,  0.2987, -0.8467, -1.6432,\n",
      "         0.9460, -0.1942,  0.0308, -1.0530,  0.4171,  0.7168, -0.2404, -0.4735,\n",
      "        -0.2435,  0.7524,  0.7630,  1.3504,  0.6079, -1.0866, -0.5406, -0.4108,\n",
      "         0.8731, -0.3597,  1.2551,  0.4157,  0.7524,  0.0884, -1.3896,  0.4474,\n",
      "        -0.3275,  1.6835, -0.7185, -0.5379, -0.7251, -0.5232, -0.6280, -0.6037,\n",
      "         2.1334, -0.3787, -1.4207,  0.9220, -0.6052, -1.6538,  0.3611, -0.6639,\n",
      "        -0.1332,  1.5398,  1.7272, -0.2689, -0.6406, -0.3183,  0.8851, -1.0095,\n",
      "         0.2590, -1.5697,  1.1777,  1.9412,  0.9545, -1.2996, -0.8257, -1.7603,\n",
      "         0.6024, -0.1671,  0.9581, -0.6505, -0.2864,  0.2900,  0.6487, -0.2617,\n",
      "         0.4438,  1.4356, -1.4566, -0.2845, -0.1078,  1.6545,  1.1492, -1.0416,\n",
      "         0.2684,  0.5595, -0.8422, -0.6773,  0.9721, -0.6101,  0.6987, -0.4246,\n",
      "        -1.9818,  3.3396, -1.5406,  0.4651, -0.8517, -0.3173, -1.2953, -1.1015,\n",
      "         0.8501, -0.0801, -0.3988, -0.8699, -0.8417, -1.3814, -0.1618,  0.6010,\n",
      "         0.7891,  1.3574, -1.2191, -0.2442, -1.5655,  1.3477,  1.2060,  0.7657,\n",
      "        -2.0925,  0.0608, -0.4502, -1.1913,  0.7706,  1.4309,  1.4961,  0.5415,\n",
      "         0.6756, -0.4853, -0.5103,  1.1933,  1.7221, -0.5304, -0.5244,  0.6086,\n",
      "         0.1270,  0.1624,  0.1419,  0.5481, -0.4780, -0.3685, -0.4097, -1.6735],\n",
      "       grad_fn=<DivBackward0>)\n",
      "LayerNorm: \n",
      " tensor([ 0.0284,  1.2181, -1.1596,  0.0690,  0.7324,  0.6043,  0.6689,  1.3863,\n",
      "         0.9970,  1.2985, -0.6321,  1.8809, -0.9518, -0.3147,  1.6274,  0.7824,\n",
      "        -0.1061, -0.3806,  1.3832, -0.6051, -1.3916,  1.2448,  0.4995,  0.7510,\n",
      "         0.7901,  1.9348, -0.7004,  0.4704,  0.1629, -0.4710,  1.2516, -0.2180,\n",
      "        -0.4687, -0.1957,  0.4569, -1.4449, -0.6244, -0.0536, -1.5562, -0.4265,\n",
      "         0.2919, -1.1495, -0.5898,  0.6014,  0.4243,  2.0461,  0.7576, -0.2011,\n",
      "        -0.1218, -0.2486, -1.3282,  1.0869,  0.3436,  0.1393,  0.3765,  0.0451,\n",
      "        -0.7205,  0.6893,  0.4489, -1.5968,  0.4640,  2.0868,  2.0159, -1.4458,\n",
      "         0.1893,  0.7077, -0.6226,  1.1008, -1.6793,  0.5939,  1.3048, -0.6026,\n",
      "         0.0993,  0.2193,  0.5074, -1.1663,  0.3720, -0.6583, -0.5327,  0.1635,\n",
      "        -0.5628,  0.2559, -1.7195, -0.1192, -0.7528,  0.7136,  0.1698, -0.5693,\n",
      "        -1.1051, -1.7667,  1.8260,  0.6679, -0.0744, -0.5649, -0.4158, -1.6847,\n",
      "        -2.0154,  0.0746, -0.8685,  1.3594, -2.2002,  0.6464,  0.2923,  0.3718,\n",
      "        -2.1753, -2.4270, -0.0902,  0.4881,  1.4908, -0.2322, -0.8343, -1.6609,\n",
      "         1.3408,  1.3740, -0.7315, -1.1417,  0.1003,  0.1175,  1.2828,  0.6060,\n",
      "        -1.3416,  0.1224, -0.2062, -0.7612,  1.0614,  0.2993, -0.8483, -1.6464,\n",
      "         0.9478, -0.1945,  0.0309, -1.0550,  0.4179,  0.7182, -0.2409, -0.4745,\n",
      "        -0.2440,  0.7539,  0.7645,  1.3531,  0.6091, -1.0887, -0.5417, -0.4116,\n",
      "         0.8748, -0.3604,  1.2576,  0.4165,  0.7539,  0.0886, -1.3923,  0.4483,\n",
      "        -0.3281,  1.6868, -0.7199, -0.5390, -0.7265, -0.5242, -0.6292, -0.6049,\n",
      "         2.1376, -0.3794, -1.4235,  0.9238, -0.6064, -1.6570,  0.3618, -0.6652,\n",
      "        -0.1335,  1.5428,  1.7306, -0.2694, -0.6419, -0.3189,  0.8869, -1.0115,\n",
      "         0.2595, -1.5728,  1.1800,  1.9451,  0.9564, -1.3021, -0.8273, -1.7638,\n",
      "         0.6036, -0.1674,  0.9600, -0.6517, -0.2870,  0.2906,  0.6500, -0.2622,\n",
      "         0.4447,  1.4384, -1.4595, -0.2850, -0.1080,  1.6578,  1.1514, -1.0437,\n",
      "         0.2690,  0.5606, -0.8439, -0.6786,  0.9740, -0.6113,  0.7000, -0.4254,\n",
      "        -1.9857,  3.3462, -1.5436,  0.4660, -0.8534, -0.3180, -1.2978, -1.1037,\n",
      "         0.8518, -0.0803, -0.3996, -0.8717, -0.8433, -1.3841, -0.1621,  0.6021,\n",
      "         0.7907,  1.3601, -1.2215, -0.2447, -1.5685,  1.3503,  1.2083,  0.7672,\n",
      "        -2.0966,  0.0609, -0.4511, -1.1936,  0.7722,  1.4337,  1.4991,  0.5426,\n",
      "         0.6770, -0.4863, -0.5113,  1.1956,  1.7254, -0.5315, -0.5255,  0.6098,\n",
      "         0.1273,  0.1627,  0.1422,  0.5491, -0.4789, -0.3692, -0.4105, -1.6768],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# What LayerNorm does\n",
    "\n",
    "E = x_add[0,0,:].mean()\n",
    "print(\"E: \", E)\n",
    "V = x_add[0,0,:].var()\n",
    "print(\"V: \", V)\n",
    "y = (x_add[0,0,:]-E)/torch.sqrt(V+1e-5)\n",
    "print(\"LayerNorm by hand: \\n\", y)\n",
    "print(\"LayerNorm: \\n\", x_norm[0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurewise MaxPooling\n",
    "\n",
    "For each feature, take the maximum value among the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (before embed):  torch.Size([1, 1, 14, 14])\n",
      "x.shape (after embed):  torch.Size([1, 1, 14, 14, 3])\n",
      "x.sum in slices:  tensor([-298.4777,  -25.8635,  142.6594])\n",
      "x.shape:  torch.Size([1, 1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 24, 12, 12])\n",
      "x.shape:  torch.Size([1, 26, 12, 12])\n",
      "x.shape:  torch.Size([1, 26, 144])\n",
      "x.shape:  torch.Size([1, 144, 26])\n",
      "x.shape:  torch.Size([1, 144, 256])\n",
      "x.shape:  torch.Size([144, 1, 256])\n",
      "attn_output.shape:  torch.Size([144, 1, 256])\n",
      "x_add.shape:  torch.Size([144, 1, 256])\n",
      "x_norm.shape:  torch.Size([144, 1, 256])\n",
      "x_ff.shape:  torch.Size([144, 1, 256])\n",
      "x.shape:  torch.Size([144, 1, 256])\n",
      "x.shape:  torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1,14,14), dtype=int) # this is the structure of the state retrieved by the game\n",
    "if len(x.shape) <= 3:\n",
    "    x = x.unsqueeze(0)\n",
    "print(\"x.shape (before embed): \", x.shape)\n",
    "x = embed(x)\n",
    "print(\"x.shape (after embed): \", x.shape)\n",
    "print(\"x.sum in slices: \", sum_slices(x,(0,1)))\n",
    "x = x.transpose(-1,-3)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(-1,-2).reshape(x.shape[0],-1,x.shape[-2],x.shape[-1])\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = net(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x= add_encoding2D(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.view(x.shape[0], x.shape[1],-1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(2,1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = projection(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(1,0)\n",
    "print(\"x.shape: \", x.shape)\n",
    "\n",
    "x_tmp = x # save it for plotting\n",
    "\n",
    "# From here it has always the same shape\n",
    "attn_output, attn_output_weights =  attn(x,x,x, key_padding_mask=None) # MHA step\n",
    "print(\"attn_output.shape: \", attn_output.shape)\n",
    "x_add = attn_output + x\n",
    "print(\"x_add.shape: \", x_add.shape)\n",
    "x_norm = drop(norm(x_add))\n",
    "print(\"x_norm.shape: \", x_norm.shape)\n",
    "x_ff = ff(x_norm)\n",
    "print(\"x_ff.shape: \", x_ff.shape)\n",
    "x = drop(norm(x_ff))\n",
    "print(\"x.shape: \", x.shape)\n",
    "# Max pooling feature-wise\n",
    "x, _ = torch.max(x, axis=0)\n",
    "print(\"x.shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing much to control here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative to max pooling - Linear projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.RelationalNetworks' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/RelationalNetworks.py'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_proj = nn.Linear(144,1) # needs to know how many pixels there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (before embed):  torch.Size([1, 1, 14, 14])\n",
      "x.shape (after embed):  torch.Size([1, 1, 14, 14, 3])\n",
      "x.sum in slices:  tensor([ 176.9918,   76.8794, -221.1962])\n",
      "x.shape:  torch.Size([1, 1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 3, 14, 14])\n",
      "x.shape:  torch.Size([1, 24, 12, 12])\n",
      "x.shape:  torch.Size([1, 26, 12, 12])\n",
      "x.shape:  torch.Size([1, 26, 144])\n",
      "x.shape:  torch.Size([1, 144, 26])\n",
      "x.shape:  torch.Size([1, 144, 256])\n",
      "x.shape:  torch.Size([144, 1, 256])\n",
      "attn_output.shape:  torch.Size([144, 1, 256])\n",
      "x_add.shape:  torch.Size([144, 1, 256])\n",
      "x_norm.shape:  torch.Size([144, 1, 256])\n",
      "x_ff.shape:  torch.Size([144, 1, 256])\n",
      "x.shape:  torch.Size([144, 1, 256])\n",
      "x.shape (before linear):  torch.Size([256, 1, 144])\n",
      "x.shape:  torch.Size([256, 1])\n",
      "x.shape:  torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros((1,1,14,14), dtype=int) # this is the structure of the state retrieved by the game\n",
    "if len(x.shape) <= 3:\n",
    "    x = x.unsqueeze(0)\n",
    "print(\"x.shape (before embed): \", x.shape)\n",
    "x = embed(x)\n",
    "print(\"x.shape (after embed): \", x.shape)\n",
    "print(\"x.sum in slices: \", sum_slices(x,(0,1)))\n",
    "x = x.transpose(-1,-3)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(-1,-2).reshape(x.shape[0],-1,x.shape[-2],x.shape[-1])\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = net(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x= add_encoding2D(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.view(x.shape[0], x.shape[1],-1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(2,1)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = projection(x)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(1,0)\n",
    "print(\"x.shape: \", x.shape)\n",
    "\n",
    "x_tmp = x # save it for plotting\n",
    "\n",
    "# From here it has always the same shape\n",
    "attn_output, attn_output_weights =  attn(x,x,x, key_padding_mask=None) # MHA step\n",
    "print(\"attn_output.shape: \", attn_output.shape)\n",
    "x_add = attn_output + x\n",
    "print(\"x_add.shape: \", x_add.shape)\n",
    "x_norm = drop(norm(x_add))\n",
    "print(\"x_norm.shape: \", x_norm.shape)\n",
    "x_ff = ff(x_norm)\n",
    "print(\"x_ff.shape: \", x_ff.shape)\n",
    "x = drop(norm(x_ff))\n",
    "print(\"x.shape: \", x.shape)\n",
    "\n",
    "# Feature-wise projection\n",
    "x = x.transpose(-1,0)\n",
    "print(\"x.shape (before linear): \", x.shape)\n",
    "shape = x.shape\n",
    "x = linear_proj(x).reshape(shape[0],shape[1])\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = x.transpose(-1,0)\n",
    "print(\"x.shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Layer\n",
    "\n",
    "Here the original paper uses just a Multi-Layer Perceptron, but I thought it would be nice to have sone skip connections in order to make the architecture more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.RelationalNetworks' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/RelationalNetworks.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hiddens = 256 \n",
    "residual_layer = rnet.ResidualLayer(n_features, n_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0783e-01, -2.6816e-01, -6.9484e-03, -1.0234e-01, -2.0125e-01,\n",
       "          3.2590e-01,  3.4537e-01,  1.6676e-01, -1.4022e-01, -2.4998e-01,\n",
       "         -3.7718e-01,  3.2195e-03, -7.9302e-02, -1.0334e-01, -2.3368e-01,\n",
       "         -1.1705e-01,  2.3923e-01, -3.0261e-02, -8.2137e-02,  2.8402e-01,\n",
       "          2.4387e-01, -4.7626e-03, -1.7411e-01,  3.4484e-01, -8.5775e-02,\n",
       "          1.9343e-02, -4.7676e-02, -1.5612e-02, -1.4513e-01, -1.4677e-02,\n",
       "          4.6080e-01,  9.8367e-02, -1.8759e-01,  2.2664e-01, -3.4613e-01,\n",
       "         -1.9067e-02,  1.2845e-01, -3.5835e-01,  4.6214e-01, -2.5578e-01,\n",
       "          3.3528e-01,  5.1272e-03, -1.3390e-01, -3.3258e-02, -5.0577e-01,\n",
       "          7.5958e-02,  2.8291e-01, -1.9748e-01, -5.2432e-01, -1.7570e-01,\n",
       "         -1.8359e-01,  1.0159e-01,  3.4431e-01,  1.1114e-01, -7.7553e-02,\n",
       "         -1.7894e-01,  7.7040e-02, -5.3591e-01,  2.8884e-01,  4.7581e-02,\n",
       "         -1.4404e-01, -4.6286e-01, -4.0770e-02,  1.6806e-01, -5.2651e-01,\n",
       "          2.4428e-01,  1.6605e-01, -4.3939e-01,  2.0398e-01, -1.5335e-01,\n",
       "          1.1583e-01, -1.4338e-01, -5.5267e-02,  3.7470e-01, -2.6289e-02,\n",
       "         -9.9892e-02, -2.7954e-01,  2.1644e-01,  9.1117e-02,  1.2894e-01,\n",
       "          1.6170e-01, -2.0316e-01,  6.7740e-03, -3.1707e-01,  2.7418e-01,\n",
       "         -3.2257e-01,  4.7017e-02, -1.6046e-01, -1.8010e-01,  1.9892e-01,\n",
       "          6.8171e-01, -3.9773e-01, -2.1881e-01, -1.1713e-01,  6.3342e-02,\n",
       "         -3.7084e-01,  6.8782e-02,  1.3441e-02,  4.5441e-01, -1.4500e-01,\n",
       "          7.5457e-02, -4.0835e-01,  2.6327e-01,  2.1260e-02, -2.2495e-01,\n",
       "          1.6989e-01,  9.1699e-02, -1.1724e-01,  3.3687e-01, -1.6974e-01,\n",
       "         -4.6403e-01,  1.1718e-01,  6.1466e-03, -1.1344e-01, -2.0318e-01,\n",
       "         -4.5961e-01,  1.9854e-01,  3.7347e-01, -5.0878e-01,  5.7603e-01,\n",
       "         -4.2326e-02,  7.9775e-02, -1.6022e-01,  4.8472e-02,  1.2567e-01,\n",
       "          5.1351e-02, -4.1112e-03,  2.0943e-01, -1.2874e-01,  2.2116e-01,\n",
       "         -4.1082e-01,  1.1130e-02,  1.5943e-01,  2.6199e-04,  2.3650e-01,\n",
       "          4.9765e-01, -3.7346e-01, -1.0782e-01, -1.0931e-01, -2.0153e-01,\n",
       "          2.8904e-01, -1.6256e-01, -2.9466e-01, -6.7846e-03,  1.9911e-01,\n",
       "         -3.5937e-01, -3.2421e-02,  8.8059e-02,  4.2355e-02,  4.3486e-01,\n",
       "          8.4558e-02, -6.2520e-01, -3.5952e-02, -8.1737e-02,  2.0618e-02,\n",
       "          4.7420e-01, -1.1011e-01, -8.2249e-02,  2.6246e-01,  1.2959e-01,\n",
       "         -2.7172e-01, -1.2288e-01, -1.2766e-01,  3.0629e-03, -1.9330e-01,\n",
       "         -6.9014e-02, -1.9052e-01,  1.2398e-01, -3.4956e-01, -2.8965e-01,\n",
       "          1.9624e-02,  1.3528e-01, -2.8593e-01,  1.1487e-01, -1.1696e-01,\n",
       "          6.5597e-02,  6.6133e-02, -2.3019e-01, -2.2622e-01,  1.1622e-01,\n",
       "          1.6074e-01, -9.6498e-02,  1.4243e-01, -1.4953e-02,  7.2286e-02,\n",
       "         -9.5630e-02,  2.4320e-02, -3.3431e-01,  7.9424e-02,  5.9572e-02,\n",
       "         -9.3736e-02, -5.4637e-02,  1.8789e-01, -3.3369e-01,  4.9716e-01,\n",
       "         -2.7280e-01,  1.0795e-01, -4.2110e-01, -2.3696e-01, -1.2539e-01,\n",
       "         -2.0983e-01,  1.3645e-01, -3.2106e-01,  2.1756e-02,  9.7357e-03,\n",
       "          1.1370e-01,  1.3793e-02,  1.7356e-01,  5.4054e-01,  1.9129e-01,\n",
       "          4.0157e-02, -6.6467e-02, -6.5669e-02,  1.3808e-01, -4.0999e-01,\n",
       "         -4.7694e-01, -7.1571e-02,  4.4788e-01, -1.4519e-01,  3.9667e-02,\n",
       "         -5.6212e-01,  3.6544e-02,  3.8097e-01, -2.6702e-01, -1.9637e-01,\n",
       "         -3.7070e-01, -1.7567e-01, -1.4444e-01, -6.1568e-03, -3.8962e-01,\n",
       "         -4.1351e-02, -2.1424e-03,  2.0258e-01,  4.9083e-03,  9.7319e-02,\n",
       "         -4.1272e-01,  2.5690e-01, -2.3702e-01, -2.3697e-01, -2.1825e-01,\n",
       "          3.7229e-01,  1.8756e-01,  2.0806e-01,  3.4032e-01,  3.1425e-01,\n",
       "          1.0112e-01,  7.0072e-02,  1.8007e-01,  6.6778e-02, -2.7743e-01,\n",
       "          1.2281e-01,  1.1260e-01,  2.0223e-01,  2.3937e-02, -4.8643e-01,\n",
       "         -3.8376e-02]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_layer(x) - x # residual after ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.ControlNetworks' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/ControlNetworks.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnet)\n",
    "reload(cnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ExtractEntities(\n",
      "    (embed): Embedding(117, 3)\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 12, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(12, 24, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): RelationalModule(\n",
      "    (net): Sequential(\n",
      "      (0): PositionalEncoding(\n",
      "        (projection): Linear(in_features=26, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): FeaturewiseMaxPool()\n",
      "  (3): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (4): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (5): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (6): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "box_net = rnet.BoxWorldNet(in_channels=1, n_kernels=24, vocab_size=117, n_dim=3,\n",
    "                              n_features=256, n_attn_modules=2, n_linears=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ExtractEntities(\n",
      "    (embed): Embedding(117, 3)\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 12, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(12, 24, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): RelationalModule(\n",
      "    (net): Sequential(\n",
      "      (0): PositionalEncoding(\n",
      "        (projection): Linear(in_features=26, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): FeaturewiseProjection(\n",
      "    (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=144, out_features=1, bias=True)\n",
      "  )\n",
      "  (3): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (4): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (5): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (6): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "box_net_v1 = rnet.BoxWorldNet(in_channels=1, n_kernels=24, vocab_size=117, n_dim=3,\n",
    "                              n_features=256, n_attn_modules=2, n_linears=4, max_pool=False,\n",
    "                              linear_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_net = cnet.ControlNet(in_channels=1, n_kernels=24, vocab_size=117, n_dim=3,\n",
    "                              n_features=256, hidden_dim=64, n_control_modules=2, n_linears=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(high=116, size = (1,14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseProjection):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "y.shape:  torch.Size([1, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5390e-01, -7.0952e-01, -6.5533e-01, -2.3280e-01,  1.4070e+00,\n",
       "          1.1377e+00, -5.1626e-01,  6.7379e-01, -2.1708e+00,  4.7738e-01,\n",
       "          1.0760e-01, -8.9058e-01, -1.4046e+00, -5.7237e-01,  1.6635e-01,\n",
       "         -4.1910e-01, -1.1328e+00,  7.0878e-01, -1.7152e+00,  3.3344e-01,\n",
       "         -1.1291e+00,  4.5320e-01,  8.5595e-01,  3.1230e-01,  7.7161e-01,\n",
       "          2.0477e-01,  1.1913e+00,  2.3102e-01,  4.7967e-01,  4.4859e-01,\n",
       "          2.6376e-01, -3.8250e-01,  4.9597e-01,  1.6744e+00, -1.2098e+00,\n",
       "         -6.6775e-01, -1.4222e+00, -1.2581e+00,  5.1194e-01,  1.6870e+00,\n",
       "          6.8565e-01, -4.4087e-01, -2.5555e-01, -8.3321e-02,  9.2260e-01,\n",
       "          1.8577e-01, -3.9201e-01, -6.4735e-01,  1.1492e+00, -6.0591e-01,\n",
       "         -1.0770e+00, -6.9447e-01,  1.1757e+00, -1.4619e+00, -9.9624e-02,\n",
       "         -2.2770e-01,  7.9717e-01, -3.2119e-02,  9.6015e-01,  7.1545e-01,\n",
       "         -1.5834e+00, -1.7014e+00, -8.0918e-01,  2.4594e-02, -1.3880e+00,\n",
       "          6.1104e-01, -1.6140e-01, -1.5142e+00,  4.5374e-01,  1.0029e+00,\n",
       "         -6.8375e-01,  8.5494e-01, -9.3686e-01, -1.2916e+00, -6.3055e-01,\n",
       "         -4.6585e-01, -2.3273e-01, -1.7478e+00,  1.3190e+00,  1.2188e+00,\n",
       "          1.1399e+00,  7.0746e-01,  3.7460e-01, -1.6712e+00, -1.5899e+00,\n",
       "          5.6108e-02, -6.6798e-01,  6.3316e-01, -1.1217e+00,  4.1541e-01,\n",
       "          1.2422e+00,  9.9117e-01, -5.9803e-01,  5.3630e-01, -4.9501e-01,\n",
       "         -6.7523e-01,  4.8744e-01, -7.2168e-02,  8.9370e-01, -7.5807e-01,\n",
       "         -9.4070e-01, -3.4573e-01,  1.3184e+00,  7.7504e-02, -1.4278e-02,\n",
       "          3.6680e-01, -8.7529e-01, -7.1923e-02,  9.0720e-01, -1.1006e+00,\n",
       "          3.9289e-01, -1.1935e+00, -1.3737e+00, -9.9387e-01, -1.0551e+00,\n",
       "         -7.2320e-01,  4.7296e-01, -7.5129e-01,  1.3695e+00,  1.5897e+00,\n",
       "          1.1725e+00,  2.0908e-01,  1.7357e-01, -2.7772e-01,  7.0429e-01,\n",
       "         -6.1249e-01, -8.2956e-01, -3.6264e-01,  7.4018e-01, -1.7093e+00,\n",
       "         -1.7824e+00,  2.3303e-01, -6.3673e-01, -4.3805e-01, -3.6385e-01,\n",
       "         -1.1439e-01,  8.0589e-01,  4.0713e-01,  1.1673e+00,  3.5000e-01,\n",
       "          5.2904e-01, -5.1048e-01, -3.2420e-01, -5.4290e-02, -8.8203e-01,\n",
       "          6.3057e-01,  4.9503e-01, -9.2167e-01, -1.0007e+00, -4.7448e-01,\n",
       "         -1.6646e-01, -2.9448e-04, -3.2978e-01,  1.1968e-01,  4.5078e-01,\n",
       "         -1.2989e+00, -2.5267e-02, -1.4760e+00,  3.6959e-01, -1.2328e+00,\n",
       "         -2.8160e-01,  1.0107e+00,  2.3989e-01,  8.9568e-01, -9.6622e-01,\n",
       "         -7.6097e-01, -1.2622e+00,  1.7727e+00,  2.8790e-01,  4.5610e-01,\n",
       "         -1.1607e+00, -9.5557e-01, -1.6216e-01, -3.9887e-01, -2.2010e+00,\n",
       "          4.6440e-01,  7.2119e-01, -2.6358e-01, -2.0968e-01,  9.8142e-01,\n",
       "          3.2980e-02, -5.4627e-01, -8.2396e-01, -4.3259e-01, -5.2551e-01,\n",
       "         -3.8427e-01, -1.4203e+00, -1.6438e+00, -4.2595e-01, -8.6221e-02,\n",
       "          1.3292e+00, -7.0854e-01, -7.1617e-01, -1.2274e-01,  6.0675e-01,\n",
       "          1.2018e+00, -3.3904e-01, -6.3034e-01, -3.8836e-01,  1.1551e+00,\n",
       "         -4.7881e-01, -1.6740e-01,  1.7712e+00, -1.9414e-01,  5.9549e-01,\n",
       "          7.0060e-01,  5.3663e-01,  6.3504e-01, -9.7534e-01,  3.4964e-01,\n",
       "         -1.4800e+00, -1.0901e+00, -1.1155e+00,  1.6875e-01, -2.8115e-01,\n",
       "          4.7816e-02, -3.5647e-01,  5.3462e-01, -3.9576e-01, -4.7640e-01,\n",
       "         -1.9209e+00, -1.2598e+00,  5.6024e-01, -1.1567e+00, -7.6133e-01,\n",
       "          9.1165e-01, -3.3810e-01,  4.7798e-01,  1.9496e+00,  2.6769e-01,\n",
       "         -6.9183e-02,  7.4193e-02,  1.1802e+00,  1.2897e-01, -6.1182e-01,\n",
       "         -8.8506e-01,  3.8744e-01, -1.7249e+00,  5.0078e-01, -1.1607e-01,\n",
       "         -3.7000e-01,  6.2016e-01,  7.0790e-01, -1.4894e-01, -7.5942e-01,\n",
       "          1.3257e+00,  1.2343e-02,  1.4990e-01,  9.5381e-01,  7.2759e-01,\n",
       "         -5.3601e-01, -4.6851e-01, -8.2727e-01,  1.0327e+00, -1.0080e+00,\n",
       "          1.2947e+00]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = box_net_v1(x)\n",
    "print(\"y.shape: \", y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape:  torch.Size([1, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4898e+00,  7.7120e-02,  2.4382e-01,  6.4252e-01,  2.1385e-01,\n",
       "          3.1130e-02,  5.5482e-01,  1.6747e-01,  4.6643e-02,  1.6777e+00,\n",
       "          2.1526e+00,  1.2783e-01,  7.6233e-01,  1.9088e-01,  1.9711e-01,\n",
       "          8.4925e-02,  1.6465e-01,  4.0268e-01,  1.4540e-01,  1.5118e-01,\n",
       "          3.4683e-01,  1.6207e+00,  2.1201e-01,  1.0745e-01,  1.5318e-03,\n",
       "          1.1062e+00,  1.6899e+00,  1.3424e-01, -6.7152e-02,  6.5382e-02,\n",
       "          1.1693e-01,  1.4884e-01,  1.0919e-01,  9.0146e-01,  3.5792e-01,\n",
       "          8.5205e-01,  2.1508e-01,  1.0901e-01,  1.2527e-01,  5.7115e-01,\n",
       "          1.4628e-01,  1.0879e+00,  1.0445e+00,  1.3953e-01,  3.5668e-01,\n",
       "          4.2492e-01,  2.5978e-02,  1.3901e-01,  1.1301e+00,  1.4053e-01,\n",
       "          8.8481e-01,  1.0414e+00,  5.5296e-01,  4.3741e-01,  4.7355e-01,\n",
       "          3.6987e-01,  2.3077e-01,  4.9104e-01,  2.8129e-01,  8.3265e-02,\n",
       "          3.0584e-01,  9.3229e-01,  1.5149e-01,  2.7432e-01,  1.1416e-01,\n",
       "          7.6628e-02,  5.5852e-02,  1.3794e+00,  6.9490e-02,  5.3558e-02,\n",
       "          1.2692e-01, -1.1470e-01,  1.3475e-01,  4.1553e-01,  3.8324e-02,\n",
       "          4.6472e-01,  4.2084e-01,  4.7524e-01,  1.6834e+00,  7.2498e-02,\n",
       "          1.8119e+00,  1.3831e-01,  1.9772e-01,  1.4089e-01,  1.4217e-01,\n",
       "          8.1189e-01,  6.6907e-01,  1.1697e-01, -1.0798e-01,  3.8368e-01,\n",
       "          6.0217e-02,  5.5627e-02,  1.1025e+00,  8.7991e-01,  1.0839e-01,\n",
       "          3.0686e-01,  3.0830e-01,  3.2608e-01,  4.7724e-01,  1.1034e-01,\n",
       "          6.2290e-01,  9.6643e-01,  2.8766e-01,  6.4237e-02,  9.4512e-01,\n",
       "          1.2591e-01,  2.1018e-01,  1.1034e-01,  1.5518e-01,  2.5175e-01,\n",
       "          7.0853e-01,  2.8260e-01,  1.7625e-01,  6.7923e-01,  2.8778e-01,\n",
       "          1.5805e-01,  5.9924e-01,  4.8595e-01,  1.5849e+00,  2.1954e-01,\n",
       "          2.2103e+00,  1.0972e-02,  1.1874e+00,  3.0221e-01,  1.0278e-01,\n",
       "          7.6023e-01,  5.4951e-01,  1.3706e+00,  1.8939e-01,  3.4269e-01,\n",
       "          9.9126e-02,  8.1561e-02,  1.1967e+00,  1.9953e+00,  1.0224e+00,\n",
       "          4.3423e-02,  8.1522e-01, -3.0697e-02,  4.7234e-02,  3.8319e-02,\n",
       "          3.7037e-01,  8.4465e-02,  3.9248e-01,  1.1777e+00,  2.9095e-01,\n",
       "          8.4843e-02,  2.5477e-01, -8.2460e-02,  9.3874e-01,  1.2012e-02,\n",
       "         -8.0039e-02,  1.0280e-01, -7.8835e-02,  6.4250e-01,  1.6947e-01,\n",
       "         -2.0316e-02,  3.2613e-01,  6.9924e-01,  5.1973e-01,  2.5886e-01,\n",
       "          1.3260e-02,  3.0627e-01,  5.2134e-01,  3.7092e-02,  5.9571e-01,\n",
       "          2.5470e-01,  7.1644e-01,  1.0584e+00,  1.3832e+00,  2.2297e-03,\n",
       "          1.8725e+00, -2.1926e-02, -1.3263e-02,  6.1085e-01,  2.7734e-02,\n",
       "          2.4098e-01,  4.5899e-01, -7.6106e-02,  2.3499e+00,  4.9207e-02,\n",
       "          6.4980e-01,  4.2604e-01,  1.1126e+00, -5.8744e-02, -2.5146e-02,\n",
       "          3.9123e-03,  5.0893e-01, -4.0834e-02,  3.5782e-02, -5.4309e-03,\n",
       "         -8.1395e-02,  2.8987e-01,  1.0061e-01,  5.1476e-01,  4.4605e-01,\n",
       "          5.1156e-02,  6.6941e-02,  3.5788e-01,  1.3319e-02,  3.6307e-01,\n",
       "          4.0070e-01,  8.8359e-02,  1.1056e-01,  1.2935e-02,  2.3889e-01,\n",
       "          2.0157e-01,  1.0686e+00, -4.3138e-02,  1.0934e-01,  8.1360e-01,\n",
       "          9.1535e-02,  5.0044e-01,  3.3550e-01,  1.1092e-01,  6.5927e-03,\n",
       "          2.1665e-01,  6.9891e-01,  5.8565e-01,  1.0025e+00,  4.0845e-03,\n",
       "          2.3818e-02, -1.1253e-02,  1.3232e+00,  8.6101e-01,  6.1005e-01,\n",
       "          1.2189e+00,  6.0652e-01,  1.4391e+00,  4.7671e-02,  5.6531e-02,\n",
       "         -8.2698e-03,  8.8533e-01,  1.5818e-01, -1.4885e-02,  1.4182e+00,\n",
       "          3.5915e-01,  1.3138e-01,  8.5724e-01,  1.4025e+00, -2.5121e-02,\n",
       "          4.9772e-02,  1.4282e-01, -1.1717e-01, -7.6313e-03,  3.2364e-01,\n",
       "          6.8363e-01,  7.3172e-02,  4.8284e-02, -3.8048e-02,  2.4617e-01,\n",
       "          1.4405e+00,  3.4370e-01,  1.2833e+00,  2.3918e-01,  5.9789e-01,\n",
       "          5.3172e-01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = control_net(x)\n",
    "print(\"y.shape: \", y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-channel embedding layer test\n",
    "\n",
    "Here I just wanted to see how to embed even images with more than one channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.RelationalNetworks' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/RelationalNetworks.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entities = rnet.ExtractEntities(k_out = 24, k_in=3, n_dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(255,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(high=116, size = (3,14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24, 12, 12])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 14, 14])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.transpose(-1,-2).reshape(x.shape[0],-1,x.shape[-2],x.shape[-1])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_net = rnet.BoxWorldNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw_net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
