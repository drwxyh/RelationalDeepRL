{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Deep Reinforcement Learning\n",
    "\n",
    "**Plan:**\n",
    "1. Architecture\n",
    "2. Agent\n",
    "3. Environment\n",
    "4. Training cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "**Input: (b,n,n,3)** = (batch length, linear size, linear size, RGB)\n",
    "\n",
    "**Extract entities: (b,n,n,3) -> (b, m, m, 2k)** \n",
    "* convolutional_layer1(kernel_size = (2,2), input_filters = 3, output_filters = k, stride = 1, pad = (1,1))\n",
    "* convolutional_layer2(kernel_size = (2,2), input_filters = k, output_filters = 2k, stride = 1, pad = (1,1))\n",
    "\n",
    "**Relational block: (b, m, m, 2k) -> (b,d_m)**\n",
    "* Positional Encoding: (b, m, m, 2k) -> (b, m^2, d_m)\n",
    "* N Multi-Headed Attention blocks: (b, m^2, d_m) -> (b, m^2, d_m)\n",
    "\n",
    "**Feature-wise max pooling: (b, m^2, d_m) -> (b, d_m)**\n",
    "\n",
    "**Multi-Layer Perceptron: (b, d_m) -> (b, d_m)**\n",
    "* 4 fully connected layers (d_m,d_m) with ReLUs\n",
    "\n",
    "**Actor output: (b,2k+2) -> (b,a)** [a = number of possible actions]\n",
    "* Single linear layer with softmax at the end\n",
    "\n",
    "**Critic output: (b,2k+2) -> (b,1)** \n",
    "* Single linear layer without activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RelationalNetworks as rnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalNetworks' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalNetworks.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(rnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_entities = rnet.ExtractEntities(k_out = 24)\n",
    "pe = rnet.PositionalEncoding(24, 256)\n",
    "encoder = rnet.EncoderBlock(256, 2)\n",
    "rel = rnet.RelationalModule(24, 256, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single frame-like input\n",
    "x = torch.rand((1,3,12,12))\n",
    "\n",
    "# Convolutional pass\n",
    "y = get_entities(x)\n",
    "\n",
    "# Positional encoding\n",
    "z = pe(y)\n",
    "\n",
    "# MHA\n",
    "w = encoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2.shape:  torch.Size([100, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "# Positional encoding + multiple MHA\n",
    "w2 = rel(y)\n",
    "print(\"w2.shape: \", w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All together\n",
    "full_net = rnet.BoxWorldNet()\n",
    "out = full_net(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    pass\n",
    "\n",
    "def g(a, **k):\n",
    "    f(**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "g() got multiple values for keyword argument 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9177ba2617c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: g() got multiple values for keyword argument 'a'"
     ]
    }
   ],
   "source": [
    "d = {'a':1}\n",
    "g(a=2, **d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function log_softmax in module torch.nn.functional:\n",
      "\n",
      "log_softmax(input, dim=None, _stacklevel=3, dtype=None)\n",
      "    Applies a softmax followed by a logarithm.\n",
      "    \n",
      "    While mathematically equivalent to log(softmax(x)), doing these two\n",
      "    operations separately is slower, and numerically unstable. This function\n",
      "    uses an alternative formulation to compute the output and gradient correctly.\n",
      "    \n",
      "    See :class:`~torch.nn.LogSoftmax` for more details.\n",
      "    \n",
      "    Arguments:\n",
      "        input (Tensor): input\n",
      "        dim (int): A dimension along which log_softmax will be computed.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "          If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "          is performed. This is useful for preventing data type overflows. Default: None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(F.log_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
