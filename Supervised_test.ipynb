{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture testing with supervised learning\n",
    "\n",
    "In this notebook I want to test the well-functioning of the various architectures proposed for the actor and the critic.\n",
    "\n",
    "The setup is the following:\n",
    "1. Generate a series of states s\n",
    "2. Use optimal policy to associate them with an optimal action* a \n",
    "3. Train only the actor architecture with cross-entropy loss\n",
    "\n",
    "*one could also use the optimal probabilities if known, but anyway if done in an unbiased way, the sampling procedure will be enough to learn stochastic policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already have an optimal policy implemented for sandbox environment and all the code ready for playing episodes, we can build a training set starting from trajectories and then sample simple (s,a) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from RelationalModule import ActorCritic, ControlActorCritic, CoordActorCritic, OheActorCritic\n",
    "from RelationalModule import GatedActorCritic\n",
    "from Utils import train_agent_sandbox as train\n",
    "from Utils import test_env, utils, plot\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(test_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating data for supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_optimal(env):\n",
    "    state = env.reset(random_init = False)\n",
    "    \n",
    "    actions = []\n",
    "    states = []\n",
    "\n",
    "    while True:\n",
    "        action = env.get_optimal_action()\n",
    "        actions.append(action)\n",
    "        \n",
    "        new_state, reward, terminal, info = env.step(action) \n",
    "        states.append(new_state)\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "            \n",
    "        state = new_state\n",
    "    \n",
    "    return actions, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable parameters\n",
    "X = 5\n",
    "Y = 5\n",
    "initial = [0,0]\n",
    "goal = [2,2]\n",
    "MAX_STEPS = 100\n",
    "\n",
    "game_params = dict(x=X, y=Y, initial=initial, goal=goal, max_steps=MAX_STEPS, \n",
    "                   greyscale_state=True, return_ohe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = test_env.Sandbox(**game_params)\n",
    "actions, states = play_optimal(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_start(X=10, Y=10):\n",
    "    s1, s2 = np.random.choice(X*Y, 2, replace=False)\n",
    "    initial = [s1//X, s1%X]\n",
    "    goal = [s2//X, s2%X]\n",
    "    return initial, goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_action_state_set(game_params, size = 10000):\n",
    "    action_memory = []\n",
    "    state_memory = []\n",
    "    \n",
    "    while len(action_memory) < size:\n",
    "        \n",
    "        # Change game params\n",
    "        initial, goal = random_start(game_params[\"x\"], game_params[\"y\"])\n",
    "\n",
    "        # All game parameters\n",
    "        game_params[\"initial\"] = initial\n",
    "        game_params[\"goal\"] = goal\n",
    "        \n",
    "        env = test_env.Sandbox(**game_params)\n",
    "        \n",
    "        actions, states = play_optimal(env)\n",
    "        action_memory += actions\n",
    "        state_memory += states\n",
    "        \n",
    "        #print('len(action_memory): ',len(action_memory))\n",
    "        \n",
    "    return np.array(state_memory[:size]), np.array(action_memory[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "state_set, action_set = create_action_state_set(game_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using torch utils to create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Add description\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.data[index], self.label[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(x, label, train_perc, val_perc, train_batch_size, val_batch_size, test_batch_size):\n",
    "    \"\"\"\n",
    "    Add description\n",
    "    \"\"\"\n",
    "    \n",
    "    # training/test splitting\n",
    "    m = int(len(x)*train_perc)\n",
    "    x_train= x[:m]\n",
    "    y_train = label[:m]\n",
    "    x_test =  x[m:]\n",
    "    y_test = label[m:]\n",
    "    \n",
    "    # define custom NumpyDatasets\n",
    "    train_set = NumpyDataset(x_train, y_train)\n",
    "    test_set =  NumpyDataset(x_test, y_test)\n",
    "   \n",
    "    train_len = int(m*(1-val_perc))\n",
    "    train_sampler = SubsetRandomSampler(np.arange(train_len))\n",
    "    val_sampler = SubsetRandomSampler(np.arange(train_len,m))\n",
    "\n",
    "    train_loader = DataLoader(train_set, train_batch_size, sampler=train_sampler, drop_last=True, collate_fn=lambda x: x)\n",
    "    val_loader = DataLoader(train_set, val_batch_size, sampler=val_sampler, drop_last=True, collate_fn=lambda x: x)\n",
    "    test_loader = DataLoader(test_set, test_batch_size, drop_last=False, collate_fn=lambda x: x)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = {'train_batch_size':16, 'val_batch_size':64, 'test_batch_size':128}\n",
    "train_loader, val_loader, test_loader = prepare_dataset(state_set, action_set, 0.8, 0.2, **batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training actor net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RelationalModule import AC_networks as nets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = nets.GatedBoxWorldActor(action_space=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    x = [x[0] for x in data]\n",
    "    x = torch.tensor(x).float() #.to(device)\n",
    "    y =  [x[1] for x in data]\n",
    "    y = torch.LongTensor(y) #.to(device)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    y_pred = actor_net(x)\n",
    "    print(y_pred.shape)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(net, dataloader, loss_fn, optimizer):\n",
    "\n",
    "    # select device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    # Validation\n",
    "    net.eval() # Evaluation mode (e.g. disable dropout)\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        batch_len = np.zeros(len(dataloader))\n",
    "        batch_loss = np.zeros(len(dataloader))\n",
    "        for i, data in enumerate(dataloader,0):\n",
    "            # Extract data and move tensors to the selected device\n",
    "            x = [x[0] for x in data]\n",
    "            x = torch.tensor(x).float().to(device)\n",
    "            \n",
    "            y =  [x[1] for x in data]\n",
    "            y = torch.LongTensor(y).to(device)\n",
    "\n",
    "            y_pred = net(x)\n",
    "\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            \n",
    "            # save MSE loss and length of a batch\n",
    "            batch_len[i] = len(data)\n",
    "            batch_loss[i] = loss.item()\n",
    "    \n",
    "    # total loss\n",
    "    val_loss = (batch_loss*batch_len).sum()/batch_len.sum()\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NN(net, lr, n_epochs, train_loader, val_loader, train_log=True, verbose=True, \n",
    "                  debug=False, return_model = False):\n",
    "    \"\"\"\n",
    "    Trains a Pytorch model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Pytorch nn.Module class \n",
    "        Must have forward method\n",
    "    train_loader: torch DataLoader\n",
    "        Loads the training set\n",
    "    val_loader: torch DataLoader\n",
    "        Loads the validation set\n",
    "    verbose: bool\n",
    "        If True prints updates of the training 10 times for each epoch\n",
    "    return_model: bool\n",
    "        If True returns the trained instance of the model \n",
    "    **params: dictionary \n",
    "        Must contain all the parameters needed by the model, the optimizer and the loss\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    net (if return_model): Pytorch nn.Module class\n",
    "        Trained instance of the model \n",
    "    train_loss_log (if train_log): list\n",
    "        Training loss for each epoch\n",
    "    val_loss_log (if train_log): list\n",
    "        Validation loss for each epoch\n",
    "    val_acc_log (if train_log): list\n",
    "        Validation accuracy for each epoch\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    optimizer = optim.Adamax(net.parameters(), lr)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    \n",
    "    # define contextual print functions activated by print flags\n",
    "    verbose_print = print if verbose else lambda *a, **k: None\n",
    "    verbose_print(\"Verbose: \", verbose)\n",
    "    dprint = print if debug else lambda *a, **k: None\n",
    "    dprint(\"Debug: \", debug)\n",
    "\n",
    "    # If cuda is available set the device to GPU\n",
    "    verbose_print(\"Using cuda: \", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    # Move all the network parameters to the selected device (if they are already on that device nothing happens)\n",
    "    net.to(device)\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    epoch_time = []\n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    # lists with the history of the training\n",
    "    if (train_log == True):\n",
    "        train_loss_log = []\n",
    "        val_loss_log = []\n",
    "\n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10 # frequency of printing\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        batches_done = 0\n",
    "        net.train() # activate dropout\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            batches_done += 1\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x = [x[0] for x in data]\n",
    "            x = torch.tensor(x).float().to(device)\n",
    "            \n",
    "            y =  [x[1] for x in data]\n",
    "            y = torch.LongTensor(y).to(device)\n",
    "\n",
    "            y_pred = net(x)\n",
    "\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #Print statistics\n",
    "            running_loss += loss.item() \n",
    "            total_train_loss += loss.item()\n",
    "            #Print every 10th batch of an epoch\n",
    "            if ((i+1) % (print_every) == 0) or (i == n_batches - 1):\n",
    "                verbose_print('\\r'+\"Epoch {}, {:d}% \\t Train loss: {:.4f} took: {:.2f}s \".format(\n",
    "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / batches_done,\n",
    "                        time.time() - start_time), end=' ')\n",
    "                \n",
    "        epoch_time.append(time.time() - start_time)\n",
    "        if (train_log == True):\n",
    "            train_loss_log.append(total_train_loss/len(train_loader))\n",
    "        \n",
    "        \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        val_loss = test_epoch(net, dataloader=val_loader, loss_fn=loss_fn, optimizer=optimizer) \n",
    "        if (train_log == True):\n",
    "            val_loss_log.append(val_loss)\n",
    "            verbose_print(\"Val. loss: {:.4f}\".format(val_loss ))\n",
    "\n",
    "    verbose_print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
    "    if train_log:\n",
    "        if return_model:\n",
    "            return net, train_loss_log, val_loss_log#, val_acc_log\n",
    "        else:\n",
    "            return train_loss_log, val_loss_log#, val_acc_log  #used during cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "n_epochs = 10\n",
    "ohe_actor_net = nets.OheActor(action_space=4, map_size=5) #check mapsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_results = train_NN(ohe_actor_net, lr, n_epochs, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "n_epochs = 10\n",
    "relational_actor_net = nets.GatedBoxWorldActor(action_space=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relational_results = train_NN(relational_actor_net, lr, n_epochs, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
