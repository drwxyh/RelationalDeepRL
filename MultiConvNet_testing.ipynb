{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from Utils import test_env, utils\n",
    "from Utils import HP_tuning \n",
    "from Utils.supervised import *\n",
    "\n",
    "from RelationalModule import AC_networks as nets\n",
    "from RelationalModule.MLP_AC_networks import Actor\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters to try out and their priors, class for evaluation, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Utils.HP_tuning' from '/m/home/home9/94/dainesn1/unix/Workdir/RelationalDeepRL/Utils/HP_tuning.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(HP_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalSandboxModel():\n",
    "    def __init__(self, model, model_spec, game_params, n_epochs=50, n_samples=10000):\n",
    "        self.model = model\n",
    "        self.model_spec = model_spec\n",
    "        self.game_params = game_params\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "    def evaluate_params(self, HPs, lambdas):\n",
    "        train_V_lambda = [] \n",
    "        val_V_lambda = []\n",
    "        for lr in lambdas:\n",
    "            net = self.model(**self.model_spec, **HPs)\n",
    "            results = supervised_training(net, lr, self.n_epochs, self.n_samples, \n",
    "                                          self.game_params, get_probs=True)\n",
    "            trained_net, train_loss, val_loss, dataloader_dict, state_set, action_set, env = results\n",
    "            \n",
    "            train_V = 1-np.array(train_loss)\n",
    "            train_V_lambda.append(train_V)\n",
    "            \n",
    "            val_V = 1-np.array(val_loss)\n",
    "            val_V_lambda.append(val_V)\n",
    "            \n",
    "        return np.array(train_V_lambda), np.array(val_V_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable parameters\n",
    "X = 10\n",
    "Y = 10\n",
    "initial = [0,0]\n",
    "goal = [2,2]\n",
    "MAX_STEPS = 25\n",
    "\n",
    "game_params = dict(x=X, y=Y, initial=initial, goal=goal, max_steps=MAX_STEPS, \n",
    "                   greyscale_state=True, return_ohe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.MultiplicativeActor\n",
    "model_spec = dict(action_space=4, linear_size = X+2, in_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_instance = EvalSandboxModel(model, model_spec, game_params, 50, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_priors_dict = {'out_channels':([[6],[12],[6,12]], [1/3, 1/3, 1/3]),\n",
    "                     'max_pool_size':([2,3,4], [0.5, 0.3, 0.2]),\n",
    "                     'n_features':([16,32,64],[1/3,1/3,1/3]),\n",
    "                     'info_channels':([4,6,8],[0.2, 0.3, 0.5]),\n",
    "                     'mask_channels':([4,6,8],[0.2, 0.3, 0.5]),\n",
    "                     'hidden_channels':([6, 12, 32], [1/3, 1/3, 1/3]),\n",
    "                     'residual_hidden_dim':([16,32,64],[1/3, 1/3, 1/3]),\n",
    "                     'n_residual_layers':([1,2,3,4],[0.1, 0.3, 0.3, 0.3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_HP_tuning = HP_tuning.BayesHPTuning(value_priors_dict, eval_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]\n",
      "\tmax_pool_size :  4\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  6\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  64\n",
      "\tn_residual_layers :  4\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 10% \t Train loss: 0.2955 took: 0.18s  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/m/work/modules/automatic/anaconda/envs/aalto-ubuntu1804-generic/software/anaconda/2020-01-tf2/5a34a04a/lib/python3.7/site-packages/torch/nn/functional.py:1946: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 0.2614 took: 1.85s  Val. loss: 0.2699\n",
      "Epoch 2, 100% \t Train loss: 0.2420 took: 1.85s  Val. loss: 0.2089\n",
      "Epoch 3, 100% \t Train loss: 0.1941 took: 1.86s  Val. loss: 0.2072\n",
      "Epoch 4, 100% \t Train loss: 0.1884 took: 1.85s  Val. loss: 0.2021\n",
      "Epoch 5, 100% \t Train loss: 0.1866 took: 1.85s  Val. loss: 0.2064\n",
      "Epoch 6, 100% \t Train loss: 0.1838 took: 1.85s  Val. loss: 0.2032\n",
      "Epoch 7, 100% \t Train loss: 0.1838 took: 1.86s  Val. loss: 0.1980\n",
      "Epoch 8, 100% \t Train loss: 0.1829 took: 1.84s  Val. loss: 0.2020\n",
      "Epoch 9, 100% \t Train loss: 0.1818 took: 1.84s  Val. loss: 0.2013\n",
      "Epoch 10, 100% \t Train loss: 0.1807 took: 1.86s  Val. loss: 0.1979\n",
      "Epoch 11, 100% \t Train loss: 0.1797 took: 1.84s  Val. loss: 0.1980\n",
      "Epoch 12, 100% \t Train loss: 0.1800 took: 1.85s  Val. loss: 0.2017\n",
      "Epoch 13, 100% \t Train loss: 0.1794 took: 1.86s  Val. loss: 0.2003\n",
      "Epoch 14, 100% \t Train loss: 0.1785 took: 1.84s  Val. loss: 0.1975\n",
      "Epoch 15, 100% \t Train loss: 0.1773 took: 1.85s  Val. loss: 0.1931\n",
      "Epoch 16, 100% \t Train loss: 0.1751 took: 1.84s  Val. loss: 0.1922\n",
      "Epoch 17, 100% \t Train loss: 0.1728 took: 1.84s  Val. loss: 0.1901\n",
      "Epoch 18, 100% \t Train loss: 0.1695 took: 1.84s  Val. loss: 0.1866\n",
      "Epoch 19, 100% \t Train loss: 0.1672 took: 1.84s  Val. loss: 0.1828\n",
      "Epoch 20, 100% \t Train loss: 0.1637 took: 1.84s  Val. loss: 0.1814\n",
      "Epoch 21, 100% \t Train loss: 0.1603 took: 1.85s  Val. loss: 0.1752\n",
      "Epoch 22, 100% \t Train loss: 0.1555 took: 1.86s  Val. loss: 0.1732\n",
      "Epoch 23, 100% \t Train loss: 0.1526 took: 1.85s  Val. loss: 0.1685\n",
      "Epoch 24, 100% \t Train loss: 0.1503 took: 1.85s  Val. loss: 0.1660\n",
      "Epoch 25, 100% \t Train loss: 0.1464 took: 1.83s  Val. loss: 0.1645\n",
      "Epoch 26, 100% \t Train loss: 0.1458 took: 1.84s  Val. loss: 0.1583\n",
      "Epoch 27, 100% \t Train loss: 0.1426 took: 1.84s  Val. loss: 0.1631\n",
      "Epoch 28, 100% \t Train loss: 0.1399 took: 1.85s  Val. loss: 0.1600\n",
      "Epoch 29, 100% \t Train loss: 0.1380 took: 1.87s  Val. loss: 0.1572\n",
      "Epoch 30, 100% \t Train loss: 0.1363 took: 1.87s  Val. loss: 0.1542\n",
      "Epoch 31, 100% \t Train loss: 0.1360 took: 1.89s  Val. loss: 0.1537\n",
      "Epoch 32, 100% \t Train loss: 0.1337 took: 1.94s  Val. loss: 0.1549\n",
      "Epoch 33, 100% \t Train loss: 0.1329 took: 2.00s  Val. loss: 0.1562\n",
      "Epoch 34, 100% \t Train loss: 0.1319 took: 2.01s  Val. loss: 0.1535\n",
      "Epoch 35, 100% \t Train loss: 0.1299 took: 1.26s  Val. loss: 0.1511\n",
      "Epoch 36, 100% \t Train loss: 0.1293 took: 1.27s  Val. loss: 0.1512\n",
      "Epoch 37, 100% \t Train loss: 0.1285 took: 1.27s  Val. loss: 0.1479\n",
      "Epoch 38, 100% \t Train loss: 0.1276 took: 1.28s  Val. loss: 0.1540\n",
      "Epoch 39, 100% \t Train loss: 0.1273 took: 1.21s  Val. loss: 0.1475\n",
      "Epoch 40, 100% \t Train loss: 0.1245 took: 1.15s  Val. loss: 0.1466\n",
      "Epoch 41, 100% \t Train loss: 0.1247 took: 1.16s  Val. loss: 0.1502\n",
      "Epoch 42, 100% \t Train loss: 0.1241 took: 1.15s  Val. loss: 0.1483\n",
      "Epoch 43, 100% \t Train loss: 0.1250 took: 1.15s  Val. loss: 0.1547\n",
      "Epoch 44, 100% \t Train loss: 0.1238 took: 1.16s  Val. loss: 0.1465\n",
      "Epoch 45, 100% \t Train loss: 0.1236 took: 1.16s  Val. loss: 0.1443\n",
      "Epoch 46, 100% \t Train loss: 0.1231 took: 1.16s  Val. loss: 0.1452\n",
      "Epoch 47, 100% \t Train loss: 0.1232 took: 1.16s  Val. loss: 0.1516\n",
      "Epoch 48, 100% \t Train loss: 0.1222 took: 1.17s  Val. loss: 0.1437\n",
      "Epoch 49, 100% \t Train loss: 0.1219 took: 1.16s  Val. loss: 0.1417\n",
      "Epoch 50, 100% \t Train loss: 0.1208 took: 1.15s  Val. loss: 0.1452\n",
      "Training finished, took 93.02s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2582 took: 1.09s  Val. loss: 0.2580\n",
      "Epoch 2, 100% \t Train loss: 0.2560 took: 1.09s  Val. loss: 0.2573\n",
      "Epoch 3, 100% \t Train loss: 0.2439 took: 1.09s  Val. loss: 0.2200\n",
      "Epoch 4, 100% \t Train loss: 0.2158 took: 1.09s  Val. loss: 0.1980\n",
      "Epoch 5, 100% \t Train loss: 0.2018 took: 1.10s  Val. loss: 0.1922\n",
      "Epoch 6, 100% \t Train loss: 0.2001 took: 1.09s  Val. loss: 0.1946\n",
      "Epoch 7, 100% \t Train loss: 0.1977 took: 1.09s  Val. loss: 0.1887\n",
      "Epoch 8, 100% \t Train loss: 0.1980 took: 1.09s  Val. loss: 0.1924\n",
      "Epoch 9, 100% \t Train loss: 0.1956 took: 1.09s  Val. loss: 0.1904\n",
      "Epoch 10, 100% \t Train loss: 0.1980 took: 1.09s  Val. loss: 0.1890\n",
      "Epoch 11, 100% \t Train loss: 0.1947 took: 1.09s  Val. loss: 0.1891\n",
      "Epoch 12, 100% \t Train loss: 0.1938 took: 1.09s  Val. loss: 0.1863\n",
      "Epoch 13, 100% \t Train loss: 0.1930 took: 1.09s  Val. loss: 0.1886\n",
      "Epoch 14, 100% \t Train loss: 0.1936 took: 1.09s  Val. loss: 0.1873\n",
      "Epoch 15, 100% \t Train loss: 0.1936 took: 1.09s  Val. loss: 0.1869\n",
      "Epoch 16, 100% \t Train loss: 0.1926 took: 1.09s  Val. loss: 0.1856\n",
      "Epoch 17, 100% \t Train loss: 0.1898 took: 1.09s  Val. loss: 0.1876\n",
      "Epoch 18, 100% \t Train loss: 0.1896 took: 1.09s  Val. loss: 0.1838\n",
      "Epoch 19, 100% \t Train loss: 0.1928 took: 1.09s  Val. loss: 0.1881\n",
      "Epoch 20, 100% \t Train loss: 0.1892 took: 1.09s  Val. loss: 0.1860\n",
      "Epoch 21, 100% \t Train loss: 0.1885 took: 1.09s  Val. loss: 0.1837\n",
      "Epoch 22, 100% \t Train loss: 0.1866 took: 1.64s  Val. loss: 0.1872\n",
      "Epoch 23, 100% \t Train loss: 0.1870 took: 1.88s  Val. loss: 0.1838\n",
      "Epoch 24, 100% \t Train loss: 0.1860 took: 1.85s  Val. loss: 0.1825\n",
      "Epoch 25, 100% \t Train loss: 0.1854 took: 1.86s  Val. loss: 0.1847\n",
      "Epoch 26, 100% \t Train loss: 0.1866 took: 1.88s  Val. loss: 0.1858\n",
      "Epoch 27, 100% \t Train loss: 0.1864 took: 1.89s  Val. loss: 0.1822\n",
      "Epoch 28, 100% \t Train loss: 0.1859 took: 1.85s  Val. loss: 0.1881\n",
      "Epoch 29, 100% \t Train loss: 0.1845 took: 1.88s  Val. loss: 0.1810\n",
      "Epoch 30, 100% \t Train loss: 0.1832 took: 1.88s  Val. loss: 0.1818\n",
      "Epoch 31, 100% \t Train loss: 0.1827 took: 1.87s  Val. loss: 0.1772\n",
      "Epoch 32, 100% \t Train loss: 0.1807 took: 1.88s  Val. loss: 0.1851\n",
      "Epoch 33, 100% \t Train loss: 0.1801 took: 1.91s  Val. loss: 0.1772\n",
      "Epoch 34, 100% \t Train loss: 0.1795 took: 1.90s  Val. loss: 0.1744\n",
      "Epoch 35, 100% \t Train loss: 0.1787 took: 1.90s  Val. loss: 0.1747\n",
      "Epoch 36, 100% \t Train loss: 0.1782 took: 1.90s  Val. loss: 0.1761\n",
      "Epoch 37, 100% \t Train loss: 0.1778 took: 1.92s  Val. loss: 0.1740\n",
      "Epoch 38, 100% \t Train loss: 0.1760 took: 1.90s  Val. loss: 0.1747\n",
      "Epoch 39, 100% \t Train loss: 0.1760 took: 1.91s  Val. loss: 0.1720\n",
      "Epoch 40, 100% \t Train loss: 0.1763 took: 1.17s  Val. loss: 0.1724\n",
      "Epoch 41, 100% \t Train loss: 0.1739 took: 1.11s  Val. loss: 0.1724\n",
      "Epoch 42, 100% \t Train loss: 0.1731 took: 1.13s  Val. loss: 0.1697\n",
      "Epoch 43, 100% \t Train loss: 0.1714 took: 1.14s  Val. loss: 0.1691\n",
      "Epoch 44, 100% \t Train loss: 0.1711 took: 1.15s  Val. loss: 0.1688\n",
      "Epoch 45, 100% \t Train loss: 0.1692 took: 1.17s  Val. loss: 0.1683\n",
      "Epoch 46, 100% \t Train loss: 0.1664 took: 1.18s  Val. loss: 0.1685\n",
      "Epoch 47, 100% \t Train loss: 0.1646 took: 1.21s  Val. loss: 0.1635\n",
      "Epoch 48, 100% \t Train loss: 0.1625 took: 1.24s  Val. loss: 0.1640\n",
      "Epoch 49, 100% \t Train loss: 0.1601 took: 1.24s  Val. loss: 0.1672\n",
      "Epoch 50, 100% \t Train loss: 0.1577 took: 1.24s  Val. loss: 0.1559\n",
      "Training finished, took 78.34s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 1.85s  Val. loss: 0.2545\n",
      "Epoch 2, 100% \t Train loss: 0.2585 took: 1.85s  Val. loss: 0.2560\n",
      "Epoch 3, 100% \t Train loss: 0.2585 took: 1.86s  Val. loss: 0.2540\n",
      "Epoch 4, 100% \t Train loss: 0.2573 took: 1.88s  Val. loss: 0.2539\n",
      "Epoch 5, 100% \t Train loss: 0.2556 took: 1.87s  Val. loss: 0.2504\n",
      "Epoch 6, 100% \t Train loss: 0.2484 took: 1.88s  Val. loss: 0.2384\n",
      "Epoch 7, 100% \t Train loss: 0.2281 took: 1.87s  Val. loss: 0.2188\n",
      "Epoch 8, 100% \t Train loss: 0.2061 took: 1.86s  Val. loss: 0.2017\n",
      "Epoch 9, 100% \t Train loss: 0.2011 took: 1.87s  Val. loss: 0.2020\n",
      "Epoch 10, 100% \t Train loss: 0.2000 took: 1.87s  Val. loss: 0.1967\n",
      "Epoch 11, 100% \t Train loss: 0.1980 took: 1.86s  Val. loss: 0.1950\n",
      "Epoch 12, 100% \t Train loss: 0.1962 took: 1.87s  Val. loss: 0.1980\n",
      "Epoch 13, 100% \t Train loss: 0.1958 took: 1.88s  Val. loss: 0.2006\n",
      "Epoch 14, 100% \t Train loss: 0.1959 took: 1.86s  Val. loss: 0.1930\n",
      "Epoch 15, 100% \t Train loss: 0.1931 took: 1.87s  Val. loss: 0.1915\n",
      "Epoch 16, 100% \t Train loss: 0.1918 took: 1.89s  Val. loss: 0.1931\n",
      "Epoch 17, 100% \t Train loss: 0.1922 took: 1.87s  Val. loss: 0.1914\n",
      "Epoch 18, 100% \t Train loss: 0.1917 took: 1.86s  Val. loss: 0.1923\n",
      "Epoch 19, 100% \t Train loss: 0.1888 took: 1.87s  Val. loss: 0.1937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, 100% \t Train loss: 0.1890 took: 1.86s  Val. loss: 0.1903\n",
      "Epoch 21, 100% \t Train loss: 0.1876 took: 1.85s  Val. loss: 0.1993\n",
      "Epoch 22, 100% \t Train loss: 0.1871 took: 1.86s  Val. loss: 0.1897\n",
      "Epoch 23, 100% \t Train loss: 0.1826 took: 1.86s  Val. loss: 0.1826\n",
      "Epoch 24, 100% \t Train loss: 0.1821 took: 1.85s  Val. loss: 0.1834\n",
      "Epoch 25, 100% \t Train loss: 0.1792 took: 1.85s  Val. loss: 0.1845\n",
      "Epoch 26, 100% \t Train loss: 0.1778 took: 1.86s  Val. loss: 0.1838\n",
      "Epoch 27, 100% \t Train loss: 0.1780 took: 1.88s  Val. loss: 0.1781\n",
      "Epoch 28, 100% \t Train loss: 0.1731 took: 1.86s  Val. loss: 0.1785\n",
      "Epoch 29, 100% \t Train loss: 0.1697 took: 1.86s  Val. loss: 0.1777\n",
      "Epoch 30, 100% \t Train loss: 0.1711 took: 1.89s  Val. loss: 0.1754\n",
      "Epoch 31, 100% \t Train loss: 0.1663 took: 1.88s  Val. loss: 0.1711\n",
      "Epoch 32, 100% \t Train loss: 0.1630 took: 1.90s  Val. loss: 0.1695\n",
      "Epoch 33, 100% \t Train loss: 0.1629 took: 1.89s  Val. loss: 0.1673\n",
      "Epoch 34, 100% \t Train loss: 0.1594 took: 1.90s  Val. loss: 0.1634\n",
      "Epoch 35, 100% \t Train loss: 0.1563 took: 1.91s  Val. loss: 0.1637\n",
      "Epoch 36, 100% \t Train loss: 0.1559 took: 1.89s  Val. loss: 0.1620\n",
      "Epoch 37, 100% \t Train loss: 0.1519 took: 1.90s  Val. loss: 0.1628\n",
      "Epoch 38, 100% \t Train loss: 0.1537 took: 1.90s  Val. loss: 0.1607\n",
      "Epoch 39, 100% \t Train loss: 0.1480 took: 1.91s  Val. loss: 0.1533\n",
      "Epoch 40, 100% \t Train loss: 0.1483 took: 1.91s  Val. loss: 0.1530\n",
      "Epoch 41, 100% \t Train loss: 0.1462 took: 1.90s  Val. loss: 0.1548\n",
      "Epoch 42, 100% \t Train loss: 0.1437 took: 1.88s  Val. loss: 0.1486\n",
      "Epoch 43, 100% \t Train loss: 0.1431 took: 1.88s  Val. loss: 0.1522\n",
      "Epoch 44, 100% \t Train loss: 0.1443 took: 1.88s  Val. loss: 0.1490\n",
      "Epoch 45, 100% \t Train loss: 0.1453 took: 1.88s  Val. loss: 0.1517\n",
      "Epoch 46, 100% \t Train loss: 0.1406 took: 1.88s  Val. loss: 0.1487\n",
      "Epoch 47, 100% \t Train loss: 0.1386 took: 1.91s  Val. loss: 0.1395\n",
      "Epoch 48, 100% \t Train loss: 0.1386 took: 1.88s  Val. loss: 0.1416\n",
      "Epoch 49, 100% \t Train loss: 0.1385 took: 1.90s  Val. loss: 0.1425\n",
      "Epoch 50, 100% \t Train loss: 0.1365 took: 1.89s  Val. loss: 0.1415\n",
      "Training finished, took 106.62s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]\n",
      "\tmax_pool_size :  4\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  6\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  64\n",
      "\tn_residual_layers :  4\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.827025\n",
      "lambda: 0.0010 - V: 0.815685\n",
      "lambda: 0.0005 - V: 0.816101\n",
      "Average V: 0.819604\n",
      "Time elapsed: 281.62 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  4\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  4\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  3\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2604 took: 1.72s  Val. loss: 0.2618\n",
      "Epoch 2, 100% \t Train loss: 0.2585 took: 1.72s  Val. loss: 0.2604\n",
      "Epoch 3, 100% \t Train loss: 0.2512 took: 1.73s  Val. loss: 0.2365\n",
      "Epoch 4, 100% \t Train loss: 0.2158 took: 1.74s  Val. loss: 0.2084\n",
      "Epoch 5, 100% \t Train loss: 0.1998 took: 1.73s  Val. loss: 0.2036\n",
      "Epoch 6, 100% \t Train loss: 0.1960 took: 1.72s  Val. loss: 0.1988\n",
      "Epoch 7, 100% \t Train loss: 0.1931 took: 1.74s  Val. loss: 0.1982\n",
      "Epoch 8, 100% \t Train loss: 0.1918 took: 1.72s  Val. loss: 0.1981\n",
      "Epoch 9, 100% \t Train loss: 0.1905 took: 1.72s  Val. loss: 0.1949\n",
      "Epoch 10, 100% \t Train loss: 0.1903 took: 1.71s  Val. loss: 0.1967\n",
      "Epoch 11, 100% \t Train loss: 0.1878 took: 1.72s  Val. loss: 0.1969\n",
      "Epoch 12, 100% \t Train loss: 0.1870 took: 1.73s  Val. loss: 0.1971\n",
      "Epoch 13, 100% \t Train loss: 0.1878 took: 1.13s  Val. loss: 0.1903\n",
      "Epoch 14, 100% \t Train loss: 0.1845 took: 1.78s  Val. loss: 0.1900\n",
      "Epoch 15, 100% \t Train loss: 0.1830 took: 1.80s  Val. loss: 0.1927\n",
      "Epoch 16, 100% \t Train loss: 0.1810 took: 1.72s  Val. loss: 0.1873\n",
      "Epoch 17, 100% \t Train loss: 0.1805 took: 1.72s  Val. loss: 0.1921\n",
      "Epoch 18, 100% \t Train loss: 0.1778 took: 1.74s  Val. loss: 0.1908\n",
      "Epoch 19, 100% \t Train loss: 0.1763 took: 1.74s  Val. loss: 0.1840\n",
      "Epoch 20, 100% \t Train loss: 0.1742 took: 1.73s  Val. loss: 0.1845\n",
      "Epoch 21, 100% \t Train loss: 0.1738 took: 1.75s  Val. loss: 0.1821\n",
      "Epoch 22, 100% \t Train loss: 0.1721 took: 1.69s  Val. loss: 0.1824\n",
      "Epoch 23, 100% \t Train loss: 0.1694 took: 1.75s  Val. loss: 0.1842\n",
      "Epoch 24, 100% \t Train loss: 0.1681 took: 1.67s  Val. loss: 0.1874\n",
      "Epoch 25, 100% \t Train loss: 0.1674 took: 1.79s  Val. loss: 0.1764\n",
      "Epoch 26, 100% \t Train loss: 0.1646 took: 1.79s  Val. loss: 0.1811\n",
      "Epoch 27, 100% \t Train loss: 0.1656 took: 1.77s  Val. loss: 0.1749\n",
      "Epoch 28, 100% \t Train loss: 0.1627 took: 1.67s  Val. loss: 0.1724\n",
      "Epoch 29, 100% \t Train loss: 0.1607 took: 1.89s  Val. loss: 0.1736\n",
      "Epoch 30, 100% \t Train loss: 0.1607 took: 1.92s  Val. loss: 0.1784\n",
      "Epoch 31, 100% \t Train loss: 0.1595 took: 1.82s  Val. loss: 0.1679\n",
      "Epoch 32, 100% \t Train loss: 0.1595 took: 1.71s  Val. loss: 0.1715\n",
      "Epoch 33, 100% \t Train loss: 0.1572 took: 1.88s  Val. loss: 0.1695\n",
      "Epoch 34, 100% \t Train loss: 0.1557 took: 1.98s  Val. loss: 0.1647\n",
      "Epoch 35, 100% \t Train loss: 0.1539 took: 1.42s  Val. loss: 0.1673\n",
      "Epoch 36, 100% \t Train loss: 0.1526 took: 1.80s  Val. loss: 0.1683\n",
      "Epoch 37, 100% \t Train loss: 0.1535 took: 1.77s  Val. loss: 0.1664\n",
      "Epoch 38, 100% \t Train loss: 0.1507 took: 1.77s  Val. loss: 0.1654\n",
      "Epoch 39, 100% \t Train loss: 0.1505 took: 1.77s  Val. loss: 0.1615\n",
      "Epoch 40, 100% \t Train loss: 0.1497 took: 1.80s  Val. loss: 0.1614\n",
      "Epoch 41, 100% \t Train loss: 0.1484 took: 1.79s  Val. loss: 0.1625\n",
      "Epoch 42, 100% \t Train loss: 0.1470 took: 1.80s  Val. loss: 0.1640\n",
      "Epoch 43, 100% \t Train loss: 0.1460 took: 1.82s  Val. loss: 0.1612\n",
      "Epoch 44, 100% \t Train loss: 0.1460 took: 1.07s  Val. loss: 0.1548\n",
      "Epoch 45, 100% \t Train loss: 0.1452 took: 1.08s  Val. loss: 0.1620\n",
      "Epoch 46, 100% \t Train loss: 0.1435 took: 1.07s  Val. loss: 0.1583\n",
      "Epoch 47, 100% \t Train loss: 0.1429 took: 1.07s  Val. loss: 0.1606\n",
      "Epoch 48, 100% \t Train loss: 0.1425 took: 1.09s  Val. loss: 0.1557\n",
      "Epoch 49, 100% \t Train loss: 0.1417 took: 1.07s  Val. loss: 0.1565\n",
      "Epoch 50, 100% \t Train loss: 0.1407 took: 1.08s  Val. loss: 0.1541\n",
      "Training finished, took 93.95s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2586 took: 1.74s  Val. loss: 0.2622\n",
      "Epoch 2, 100% \t Train loss: 0.2578 took: 1.72s  Val. loss: 0.2642\n",
      "Epoch 3, 100% \t Train loss: 0.2572 took: 1.73s  Val. loss: 0.2591\n",
      "Epoch 4, 100% \t Train loss: 0.2529 took: 1.73s  Val. loss: 0.2454\n",
      "Epoch 5, 100% \t Train loss: 0.2363 took: 1.74s  Val. loss: 0.2291\n",
      "Epoch 6, 100% \t Train loss: 0.2232 took: 1.74s  Val. loss: 0.2075\n",
      "Epoch 7, 100% \t Train loss: 0.2123 took: 1.75s  Val. loss: 0.2032\n",
      "Epoch 8, 100% \t Train loss: 0.2120 took: 1.74s  Val. loss: 0.2030\n",
      "Epoch 9, 100% \t Train loss: 0.2079 took: 1.74s  Val. loss: 0.1999\n",
      "Epoch 10, 100% \t Train loss: 0.2070 took: 1.76s  Val. loss: 0.2005\n",
      "Epoch 11, 100% \t Train loss: 0.2071 took: 1.76s  Val. loss: 0.2004\n",
      "Epoch 12, 100% \t Train loss: 0.2050 took: 1.74s  Val. loss: 0.1976\n",
      "Epoch 13, 100% \t Train loss: 0.2049 took: 1.72s  Val. loss: 0.1969\n",
      "Epoch 14, 100% \t Train loss: 0.2036 took: 1.73s  Val. loss: 0.2030\n",
      "Epoch 15, 100% \t Train loss: 0.2036 took: 1.72s  Val. loss: 0.1980\n",
      "Epoch 16, 100% \t Train loss: 0.2018 took: 1.73s  Val. loss: 0.1975\n",
      "Epoch 17, 100% \t Train loss: 0.2006 took: 1.73s  Val. loss: 0.1960\n",
      "Epoch 18, 100% \t Train loss: 0.2009 took: 1.72s  Val. loss: 0.1969\n",
      "Epoch 19, 100% \t Train loss: 0.2008 took: 1.71s  Val. loss: 0.1981\n",
      "Epoch 20, 100% \t Train loss: 0.1982 took: 1.73s  Val. loss: 0.1931\n",
      "Epoch 21, 100% \t Train loss: 0.1978 took: 1.72s  Val. loss: 0.1915\n",
      "Epoch 22, 100% \t Train loss: 0.1971 took: 1.73s  Val. loss: 0.1904\n",
      "Epoch 23, 100% \t Train loss: 0.1969 took: 1.00s  Val. loss: 0.1891\n",
      "Epoch 24, 100% \t Train loss: 0.1958 took: 0.98s  Val. loss: 0.1927\n",
      "Epoch 25, 100% \t Train loss: 0.1949 took: 0.99s  Val. loss: 0.1892\n",
      "Epoch 26, 100% \t Train loss: 0.1934 took: 0.98s  Val. loss: 0.1918\n",
      "Epoch 27, 100% \t Train loss: 0.1923 took: 0.98s  Val. loss: 0.1945\n",
      "Epoch 28, 100% \t Train loss: 0.1925 took: 0.98s  Val. loss: 0.1966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.1929 took: 0.98s  Val. loss: 0.1861\n",
      "Epoch 30, 100% \t Train loss: 0.1900 took: 0.99s  Val. loss: 0.1846\n",
      "Epoch 31, 100% \t Train loss: 0.1896 took: 1.39s  Val. loss: 0.1812\n",
      "Epoch 32, 100% \t Train loss: 0.1884 took: 1.74s  Val. loss: 0.1814\n",
      "Epoch 33, 100% \t Train loss: 0.1886 took: 1.75s  Val. loss: 0.1846\n",
      "Epoch 34, 100% \t Train loss: 0.1858 took: 1.73s  Val. loss: 0.1789\n",
      "Epoch 35, 100% \t Train loss: 0.1847 took: 1.74s  Val. loss: 0.1774\n",
      "Epoch 36, 100% \t Train loss: 0.1838 took: 1.75s  Val. loss: 0.1801\n",
      "Epoch 37, 100% \t Train loss: 0.1821 took: 1.73s  Val. loss: 0.1806\n",
      "Epoch 38, 100% \t Train loss: 0.1806 took: 1.74s  Val. loss: 0.1769\n",
      "Epoch 39, 100% \t Train loss: 0.1813 took: 1.72s  Val. loss: 0.1728\n",
      "Epoch 40, 100% \t Train loss: 0.1795 took: 1.74s  Val. loss: 0.1745\n",
      "Epoch 41, 100% \t Train loss: 0.1766 took: 1.74s  Val. loss: 0.1688\n",
      "Epoch 42, 100% \t Train loss: 0.1746 took: 1.74s  Val. loss: 0.1685\n",
      "Epoch 43, 100% \t Train loss: 0.1725 took: 1.76s  Val. loss: 0.1701\n",
      "Epoch 44, 100% \t Train loss: 0.1707 took: 1.74s  Val. loss: 0.1663\n",
      "Epoch 45, 100% \t Train loss: 0.1702 took: 1.77s  Val. loss: 0.1603\n",
      "Epoch 46, 100% \t Train loss: 0.1675 took: 1.76s  Val. loss: 0.1616\n",
      "Epoch 47, 100% \t Train loss: 0.1663 took: 1.76s  Val. loss: 0.1585\n",
      "Epoch 48, 100% \t Train loss: 0.1636 took: 1.77s  Val. loss: 0.1604\n",
      "Epoch 49, 100% \t Train loss: 0.1648 took: 1.79s  Val. loss: 0.1573\n",
      "Epoch 50, 100% \t Train loss: 0.1620 took: 1.77s  Val. loss: 0.1530\n",
      "Training finished, took 91.78s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2600 took: 1.74s  Val. loss: 0.2587\n",
      "Epoch 2, 100% \t Train loss: 0.2599 took: 1.72s  Val. loss: 0.2571\n",
      "Epoch 3, 100% \t Train loss: 0.2597 took: 1.72s  Val. loss: 0.2566\n",
      "Epoch 4, 100% \t Train loss: 0.2590 took: 1.72s  Val. loss: 0.2575\n",
      "Epoch 5, 100% \t Train loss: 0.2575 took: 1.71s  Val. loss: 0.2538\n",
      "Epoch 6, 100% \t Train loss: 0.2503 took: 1.71s  Val. loss: 0.2365\n",
      "Epoch 7, 100% \t Train loss: 0.2334 took: 1.71s  Val. loss: 0.2198\n",
      "Epoch 8, 100% \t Train loss: 0.2228 took: 1.72s  Val. loss: 0.2142\n",
      "Epoch 9, 100% \t Train loss: 0.2143 took: 0.98s  Val. loss: 0.2002\n",
      "Epoch 10, 100% \t Train loss: 0.2026 took: 1.64s  Val. loss: 0.1935\n",
      "Epoch 11, 100% \t Train loss: 0.1963 took: 1.71s  Val. loss: 0.1905\n",
      "Epoch 12, 100% \t Train loss: 0.1941 took: 1.73s  Val. loss: 0.1921\n",
      "Epoch 13, 100% \t Train loss: 0.1938 took: 1.72s  Val. loss: 0.1890\n",
      "Epoch 14, 100% \t Train loss: 0.1934 took: 1.75s  Val. loss: 0.1924\n",
      "Epoch 15, 100% \t Train loss: 0.1933 took: 1.71s  Val. loss: 0.1884\n",
      "Epoch 16, 100% \t Train loss: 0.1928 took: 1.74s  Val. loss: 0.1893\n",
      "Epoch 17, 100% \t Train loss: 0.1931 took: 1.70s  Val. loss: 0.1898\n",
      "Epoch 18, 100% \t Train loss: 0.1924 took: 1.70s  Val. loss: 0.1888\n",
      "Epoch 19, 100% \t Train loss: 0.1916 took: 1.71s  Val. loss: 0.1908\n",
      "Epoch 20, 100% \t Train loss: 0.1923 took: 1.70s  Val. loss: 0.2006\n",
      "Epoch 21, 100% \t Train loss: 0.1927 took: 1.71s  Val. loss: 0.1911\n",
      "Epoch 22, 100% \t Train loss: 0.1930 took: 1.70s  Val. loss: 0.1907\n",
      "Epoch 23, 100% \t Train loss: 0.1917 took: 1.71s  Val. loss: 0.1995\n",
      "Epoch 24, 100% \t Train loss: 0.1911 took: 1.70s  Val. loss: 0.1889\n",
      "Epoch 25, 100% \t Train loss: 0.1908 took: 1.71s  Val. loss: 0.1882\n",
      "Epoch 26, 100% \t Train loss: 0.1910 took: 1.71s  Val. loss: 0.1897\n",
      "Epoch 27, 100% \t Train loss: 0.1901 took: 1.70s  Val. loss: 0.1941\n",
      "Epoch 28, 100% \t Train loss: 0.1904 took: 1.70s  Val. loss: 0.1942\n",
      "Epoch 29, 100% \t Train loss: 0.1900 took: 1.72s  Val. loss: 0.1885\n",
      "Epoch 30, 100% \t Train loss: 0.1900 took: 1.71s  Val. loss: 0.1966\n",
      "Epoch 31, 100% \t Train loss: 0.1906 took: 1.72s  Val. loss: 0.1897\n",
      "Epoch 32, 100% \t Train loss: 0.1888 took: 1.71s  Val. loss: 0.1902\n",
      "Epoch 33, 100% \t Train loss: 0.1887 took: 1.73s  Val. loss: 0.1896\n",
      "Epoch 34, 100% \t Train loss: 0.1898 took: 1.74s  Val. loss: 0.1902\n",
      "Epoch 35, 100% \t Train loss: 0.1892 took: 1.74s  Val. loss: 0.1891\n",
      "Epoch 36, 100% \t Train loss: 0.1876 took: 1.73s  Val. loss: 0.1865\n",
      "Epoch 37, 100% \t Train loss: 0.1876 took: 1.74s  Val. loss: 0.1881\n",
      "Epoch 38, 100% \t Train loss: 0.1884 took: 1.73s  Val. loss: 0.1891\n",
      "Epoch 39, 100% \t Train loss: 0.1887 took: 1.74s  Val. loss: 0.1879\n",
      "Epoch 40, 100% \t Train loss: 0.1871 took: 1.76s  Val. loss: 0.1866\n",
      "Epoch 41, 100% \t Train loss: 0.1870 took: 1.76s  Val. loss: 0.1845\n",
      "Epoch 42, 100% \t Train loss: 0.1863 took: 1.74s  Val. loss: 0.1885\n",
      "Epoch 43, 100% \t Train loss: 0.1864 took: 1.71s  Val. loss: 0.1850\n",
      "Epoch 44, 100% \t Train loss: 0.1854 took: 1.72s  Val. loss: 0.1908\n",
      "Epoch 45, 100% \t Train loss: 0.1853 took: 1.73s  Val. loss: 0.1872\n",
      "Epoch 46, 100% \t Train loss: 0.1849 took: 1.70s  Val. loss: 0.1848\n",
      "Epoch 47, 100% \t Train loss: 0.1849 took: 1.72s  Val. loss: 0.1858\n",
      "Epoch 48, 100% \t Train loss: 0.1842 took: 1.71s  Val. loss: 0.1893\n",
      "Epoch 49, 100% \t Train loss: 0.1852 took: 1.01s  Val. loss: 0.1860\n",
      "Epoch 50, 100% \t Train loss: 0.1853 took: 1.00s  Val. loss: 0.1885\n",
      "Training finished, took 95.45s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  4\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  4\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  3\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.817808\n",
      "lambda: 0.0010 - V: 0.808573\n",
      "lambda: 0.0005 - V: 0.801233\n",
      "Average V: 0.809205\n",
      "Time elapsed: 284.67 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  2\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  4\n",
      "\tmask_channels :  6\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  16\n",
      "\tn_residual_layers :  1\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2615 took: 0.98s  Val. loss: 0.2564\n",
      "Epoch 2, 100% \t Train loss: 0.2610 took: 0.96s  Val. loss: 0.2556\n",
      "Epoch 3, 100% \t Train loss: 0.2608 took: 0.97s  Val. loss: 0.2563\n",
      "Epoch 4, 100% \t Train loss: 0.2555 took: 0.96s  Val. loss: 0.2404\n",
      "Epoch 5, 100% \t Train loss: 0.1995 took: 0.96s  Val. loss: 0.1792\n",
      "Epoch 6, 100% \t Train loss: 0.1699 took: 0.98s  Val. loss: 0.1749\n",
      "Epoch 7, 100% \t Train loss: 0.1657 took: 0.96s  Val. loss: 0.1757\n",
      "Epoch 8, 100% \t Train loss: 0.1635 took: 0.97s  Val. loss: 0.1742\n",
      "Epoch 9, 100% \t Train loss: 0.1620 took: 0.96s  Val. loss: 0.1736\n",
      "Epoch 10, 100% \t Train loss: 0.1614 took: 0.97s  Val. loss: 0.1706\n",
      "Epoch 11, 100% \t Train loss: 0.1609 took: 0.98s  Val. loss: 0.1728\n",
      "Epoch 12, 100% \t Train loss: 0.1602 took: 1.01s  Val. loss: 0.1710\n",
      "Epoch 13, 100% \t Train loss: 0.1601 took: 1.68s  Val. loss: 0.1753\n",
      "Epoch 14, 100% \t Train loss: 0.1599 took: 1.51s  Val. loss: 0.1720\n",
      "Epoch 15, 100% \t Train loss: 0.1598 took: 0.98s  Val. loss: 0.1716\n",
      "Epoch 16, 100% \t Train loss: 0.1592 took: 0.97s  Val. loss: 0.1701\n",
      "Epoch 17, 100% \t Train loss: 0.1590 took: 0.97s  Val. loss: 0.1731\n",
      "Epoch 18, 100% \t Train loss: 0.1596 took: 0.97s  Val. loss: 0.1714\n",
      "Epoch 19, 100% \t Train loss: 0.1587 took: 0.97s  Val. loss: 0.1722\n",
      "Epoch 20, 100% \t Train loss: 0.1584 took: 0.97s  Val. loss: 0.1725\n",
      "Epoch 21, 100% \t Train loss: 0.1589 took: 0.97s  Val. loss: 0.1722\n",
      "Epoch 22, 100% \t Train loss: 0.1579 took: 0.97s  Val. loss: 0.1706\n",
      "Epoch 23, 100% \t Train loss: 0.1584 took: 0.97s  Val. loss: 0.1711\n",
      "Epoch 24, 100% \t Train loss: 0.1583 took: 0.97s  Val. loss: 0.1710\n",
      "Epoch 25, 100% \t Train loss: 0.1579 took: 0.97s  Val. loss: 0.1704\n",
      "Epoch 26, 100% \t Train loss: 0.1572 took: 0.98s  Val. loss: 0.1705\n",
      "Epoch 27, 100% \t Train loss: 0.1566 took: 0.98s  Val. loss: 0.1717\n",
      "Epoch 28, 100% \t Train loss: 0.1559 took: 0.99s  Val. loss: 0.1698\n",
      "Epoch 29, 100% \t Train loss: 0.1539 took: 1.16s  Val. loss: 0.1673\n",
      "Epoch 30, 100% \t Train loss: 0.1509 took: 1.26s  Val. loss: 0.1614\n",
      "Epoch 31, 100% \t Train loss: 0.1456 took: 1.75s  Val. loss: 0.1571\n",
      "Epoch 32, 100% \t Train loss: 0.1396 took: 1.76s  Val. loss: 0.1480\n",
      "Epoch 33, 100% \t Train loss: 0.1298 took: 1.85s  Val. loss: 0.1383\n",
      "Epoch 34, 100% \t Train loss: 0.1174 took: 1.88s  Val. loss: 0.1284\n",
      "Epoch 35, 100% \t Train loss: 0.1081 took: 1.92s  Val. loss: 0.1198\n",
      "Epoch 36, 100% \t Train loss: 0.1019 took: 1.89s  Val. loss: 0.1151\n",
      "Epoch 37, 100% \t Train loss: 0.0968 took: 1.89s  Val. loss: 0.1092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, 100% \t Train loss: 0.0927 took: 1.91s  Val. loss: 0.1072\n",
      "Epoch 39, 100% \t Train loss: 0.0903 took: 1.91s  Val. loss: 0.1042\n",
      "Epoch 40, 100% \t Train loss: 0.0878 took: 1.93s  Val. loss: 0.1031\n",
      "Epoch 41, 100% \t Train loss: 0.0858 took: 1.92s  Val. loss: 0.1005\n",
      "Epoch 42, 100% \t Train loss: 0.0844 took: 1.91s  Val. loss: 0.1006\n",
      "Epoch 43, 100% \t Train loss: 0.0828 took: 1.17s  Val. loss: 0.0988\n",
      "Epoch 44, 100% \t Train loss: 0.0819 took: 1.17s  Val. loss: 0.0972\n",
      "Epoch 45, 100% \t Train loss: 0.0811 took: 1.17s  Val. loss: 0.0977\n",
      "Epoch 46, 100% \t Train loss: 0.0806 took: 1.19s  Val. loss: 0.0972\n",
      "Epoch 47, 100% \t Train loss: 0.0787 took: 1.19s  Val. loss: 0.0974\n",
      "Epoch 48, 100% \t Train loss: 0.0784 took: 1.18s  Val. loss: 0.0951\n",
      "Epoch 49, 100% \t Train loss: 0.0778 took: 1.18s  Val. loss: 0.0946\n",
      "Epoch 50, 100% \t Train loss: 0.0770 took: 1.17s  Val. loss: 0.0947\n",
      "Training finished, took 71.70s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2561 took: 1.70s  Val. loss: 0.2528\n",
      "Epoch 2, 100% \t Train loss: 0.2557 took: 1.71s  Val. loss: 0.2518\n",
      "Epoch 3, 100% \t Train loss: 0.2556 took: 1.73s  Val. loss: 0.2524\n",
      "Epoch 4, 100% \t Train loss: 0.2551 took: 1.21s  Val. loss: 0.2511\n",
      "Epoch 5, 100% \t Train loss: 0.2523 took: 0.97s  Val. loss: 0.2439\n",
      "Epoch 6, 100% \t Train loss: 0.2349 took: 0.97s  Val. loss: 0.2193\n",
      "Epoch 7, 100% \t Train loss: 0.2020 took: 0.97s  Val. loss: 0.1886\n",
      "Epoch 8, 100% \t Train loss: 0.1769 took: 0.97s  Val. loss: 0.1721\n",
      "Epoch 9, 100% \t Train loss: 0.1708 took: 0.97s  Val. loss: 0.1687\n",
      "Epoch 10, 100% \t Train loss: 0.1653 took: 0.97s  Val. loss: 0.1702\n",
      "Epoch 11, 100% \t Train loss: 0.1649 took: 0.98s  Val. loss: 0.1666\n",
      "Epoch 12, 100% \t Train loss: 0.1631 took: 1.62s  Val. loss: 0.1662\n",
      "Epoch 13, 100% \t Train loss: 0.1602 took: 1.72s  Val. loss: 0.1688\n",
      "Epoch 14, 100% \t Train loss: 0.1587 took: 1.70s  Val. loss: 0.1626\n",
      "Epoch 15, 100% \t Train loss: 0.1618 took: 1.72s  Val. loss: 0.1622\n",
      "Epoch 16, 100% \t Train loss: 0.1595 took: 1.71s  Val. loss: 0.1603\n",
      "Epoch 17, 100% \t Train loss: 0.1555 took: 1.70s  Val. loss: 0.1637\n",
      "Epoch 18, 100% \t Train loss: 0.1580 took: 1.71s  Val. loss: 0.1600\n",
      "Epoch 19, 100% \t Train loss: 0.1536 took: 1.70s  Val. loss: 0.1662\n",
      "Epoch 20, 100% \t Train loss: 0.1553 took: 1.71s  Val. loss: 0.1585\n",
      "Epoch 21, 100% \t Train loss: 0.1535 took: 1.71s  Val. loss: 0.1571\n",
      "Epoch 22, 100% \t Train loss: 0.1540 took: 1.71s  Val. loss: 0.1574\n",
      "Epoch 23, 100% \t Train loss: 0.1517 took: 1.70s  Val. loss: 0.1560\n",
      "Epoch 24, 100% \t Train loss: 0.1511 took: 1.72s  Val. loss: 0.1565\n",
      "Epoch 25, 100% \t Train loss: 0.1511 took: 1.70s  Val. loss: 0.1580\n",
      "Epoch 26, 100% \t Train loss: 0.1512 took: 1.72s  Val. loss: 0.1566\n",
      "Epoch 27, 100% \t Train loss: 0.1505 took: 1.71s  Val. loss: 0.1553\n",
      "Epoch 28, 100% \t Train loss: 0.1489 took: 1.72s  Val. loss: 0.1569\n",
      "Epoch 29, 100% \t Train loss: 0.1494 took: 1.72s  Val. loss: 0.1564\n",
      "Epoch 30, 100% \t Train loss: 0.1487 took: 1.72s  Val. loss: 0.1598\n",
      "Epoch 31, 100% \t Train loss: 0.1488 took: 1.71s  Val. loss: 0.1539\n",
      "Epoch 32, 100% \t Train loss: 0.1479 took: 1.71s  Val. loss: 0.1575\n",
      "Epoch 33, 100% \t Train loss: 0.1496 took: 1.72s  Val. loss: 0.1549\n",
      "Epoch 34, 100% \t Train loss: 0.1475 took: 1.73s  Val. loss: 0.1545\n",
      "Epoch 35, 100% \t Train loss: 0.1477 took: 1.72s  Val. loss: 0.1533\n",
      "Epoch 36, 100% \t Train loss: 0.1477 took: 1.71s  Val. loss: 0.1536\n",
      "Epoch 37, 100% \t Train loss: 0.1475 took: 1.72s  Val. loss: 0.1530\n",
      "Epoch 38, 100% \t Train loss: 0.1463 took: 1.72s  Val. loss: 0.1561\n",
      "Epoch 39, 100% \t Train loss: 0.1473 took: 1.72s  Val. loss: 0.1539\n",
      "Epoch 40, 100% \t Train loss: 0.1465 took: 1.73s  Val. loss: 0.1545\n",
      "Epoch 41, 100% \t Train loss: 0.1460 took: 1.73s  Val. loss: 0.1536\n",
      "Epoch 42, 100% \t Train loss: 0.1464 took: 1.75s  Val. loss: 0.1546\n",
      "Epoch 43, 100% \t Train loss: 0.1467 took: 1.73s  Val. loss: 0.1546\n",
      "Epoch 44, 100% \t Train loss: 0.1459 took: 1.75s  Val. loss: 0.1568\n",
      "Epoch 45, 100% \t Train loss: 0.1464 took: 1.78s  Val. loss: 0.1534\n",
      "Epoch 46, 100% \t Train loss: 0.1453 took: 1.77s  Val. loss: 0.1544\n",
      "Epoch 47, 100% \t Train loss: 0.1455 took: 1.76s  Val. loss: 0.1537\n",
      "Epoch 48, 100% \t Train loss: 0.1450 took: 1.76s  Val. loss: 0.1533\n",
      "Epoch 49, 100% \t Train loss: 0.1448 took: 1.74s  Val. loss: 0.1545\n",
      "Epoch 50, 100% \t Train loss: 0.1455 took: 1.75s  Val. loss: 0.1538\n",
      "Training finished, took 92.00s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2600 took: 0.99s  Val. loss: 0.2557\n",
      "Epoch 2, 100% \t Train loss: 0.2597 took: 0.97s  Val. loss: 0.2546\n",
      "Epoch 3, 100% \t Train loss: 0.2597 took: 0.97s  Val. loss: 0.2560\n",
      "Epoch 4, 100% \t Train loss: 0.2597 took: 0.97s  Val. loss: 0.2552\n",
      "Epoch 5, 100% \t Train loss: 0.2598 took: 0.97s  Val. loss: 0.2546\n",
      "Epoch 6, 100% \t Train loss: 0.2596 took: 0.97s  Val. loss: 0.2554\n",
      "Epoch 7, 100% \t Train loss: 0.2595 took: 0.97s  Val. loss: 0.2547\n",
      "Epoch 8, 100% \t Train loss: 0.2592 took: 0.97s  Val. loss: 0.2551\n",
      "Epoch 9, 100% \t Train loss: 0.2585 took: 0.97s  Val. loss: 0.2517\n",
      "Epoch 10, 100% \t Train loss: 0.2558 took: 0.96s  Val. loss: 0.2482\n",
      "Epoch 11, 100% \t Train loss: 0.2411 took: 0.96s  Val. loss: 0.2114\n",
      "Epoch 12, 100% \t Train loss: 0.1976 took: 0.97s  Val. loss: 0.1905\n",
      "Epoch 13, 100% \t Train loss: 0.1844 took: 0.97s  Val. loss: 0.1839\n",
      "Epoch 14, 100% \t Train loss: 0.1778 took: 0.96s  Val. loss: 0.1868\n",
      "Epoch 15, 100% \t Train loss: 0.1757 took: 0.97s  Val. loss: 0.1807\n",
      "Epoch 16, 100% \t Train loss: 0.1735 took: 0.96s  Val. loss: 0.1775\n",
      "Epoch 17, 100% \t Train loss: 0.1734 took: 0.96s  Val. loss: 0.1767\n",
      "Epoch 18, 100% \t Train loss: 0.1702 took: 0.97s  Val. loss: 0.1757\n",
      "Epoch 19, 100% \t Train loss: 0.1694 took: 0.98s  Val. loss: 0.1718\n",
      "Epoch 20, 100% \t Train loss: 0.1677 took: 0.97s  Val. loss: 0.1720\n",
      "Epoch 21, 100% \t Train loss: 0.1667 took: 0.97s  Val. loss: 0.1707\n",
      "Epoch 22, 100% \t Train loss: 0.1676 took: 0.97s  Val. loss: 0.1719\n",
      "Epoch 23, 100% \t Train loss: 0.1643 took: 0.97s  Val. loss: 0.1700\n",
      "Epoch 24, 100% \t Train loss: 0.1626 took: 0.97s  Val. loss: 0.1728\n",
      "Epoch 25, 100% \t Train loss: 0.1640 took: 0.97s  Val. loss: 0.1655\n",
      "Epoch 26, 100% \t Train loss: 0.1645 took: 0.97s  Val. loss: 0.1758\n",
      "Epoch 27, 100% \t Train loss: 0.1620 took: 0.97s  Val. loss: 0.1661\n",
      "Epoch 28, 100% \t Train loss: 0.1619 took: 0.97s  Val. loss: 0.1709\n",
      "Epoch 29, 100% \t Train loss: 0.1622 took: 0.98s  Val. loss: 0.1727\n",
      "Epoch 30, 100% \t Train loss: 0.1603 took: 0.97s  Val. loss: 0.1662\n",
      "Epoch 31, 100% \t Train loss: 0.1596 took: 0.97s  Val. loss: 0.1659\n",
      "Epoch 32, 100% \t Train loss: 0.1599 took: 0.97s  Val. loss: 0.1720\n",
      "Epoch 33, 100% \t Train loss: 0.1588 took: 0.97s  Val. loss: 0.1635\n",
      "Epoch 34, 100% \t Train loss: 0.1577 took: 0.98s  Val. loss: 0.1684\n",
      "Epoch 35, 100% \t Train loss: 0.1585 took: 0.98s  Val. loss: 0.1662\n",
      "Epoch 36, 100% \t Train loss: 0.1572 took: 0.98s  Val. loss: 0.1660\n",
      "Epoch 37, 100% \t Train loss: 0.1564 took: 0.98s  Val. loss: 0.1654\n",
      "Epoch 38, 100% \t Train loss: 0.1562 took: 0.98s  Val. loss: 0.1671\n",
      "Epoch 39, 100% \t Train loss: 0.1566 took: 0.98s  Val. loss: 0.1629\n",
      "Epoch 40, 100% \t Train loss: 0.1585 took: 0.98s  Val. loss: 0.1669\n",
      "Epoch 41, 100% \t Train loss: 0.1569 took: 0.99s  Val. loss: 0.1635\n",
      "Epoch 42, 100% \t Train loss: 0.1542 took: 0.99s  Val. loss: 0.1657\n",
      "Epoch 43, 100% \t Train loss: 0.1567 took: 0.99s  Val. loss: 0.1623\n",
      "Epoch 44, 100% \t Train loss: 0.1546 took: 0.98s  Val. loss: 0.1647\n",
      "Epoch 45, 100% \t Train loss: 0.1537 took: 1.72s  Val. loss: 0.1681\n",
      "Epoch 46, 100% \t Train loss: 0.1545 took: 1.72s  Val. loss: 0.1634\n",
      "Epoch 47, 100% \t Train loss: 0.1532 took: 1.70s  Val. loss: 0.1643\n",
      "Epoch 48, 100% \t Train loss: 0.1528 took: 1.70s  Val. loss: 0.1632\n",
      "Epoch 49, 100% \t Train loss: 0.1534 took: 1.71s  Val. loss: 0.1650\n",
      "Epoch 50, 100% \t Train loss: 0.1539 took: 1.69s  Val. loss: 0.1623\n",
      "Training finished, took 60.27s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  2\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  4\n",
      "\tmask_channels :  6\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  16\n",
      "\tn_residual_layers :  1\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.846413\n",
      "lambda: 0.0010 - V: 0.830716\n",
      "lambda: 0.0005 - V: 0.812449\n",
      "Average V: 0.829859\n",
      "Time elapsed: 227.48 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  8\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  2\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2603 took: 1.74s  Val. loss: 0.2585\n",
      "Epoch 2, 100% \t Train loss: 0.2582 took: 1.74s  Val. loss: 0.2586\n",
      "Epoch 3, 100% \t Train loss: 0.2470 took: 1.73s  Val. loss: 0.2076\n",
      "Epoch 4, 100% \t Train loss: 0.1856 took: 1.00s  Val. loss: 0.1722\n",
      "Epoch 5, 100% \t Train loss: 0.1717 took: 1.00s  Val. loss: 0.1748\n",
      "Epoch 6, 100% \t Train loss: 0.1678 took: 1.00s  Val. loss: 0.1677\n",
      "Epoch 7, 100% \t Train loss: 0.1666 took: 1.00s  Val. loss: 0.1665\n",
      "Epoch 8, 100% \t Train loss: 0.1634 took: 1.00s  Val. loss: 0.1623\n",
      "Epoch 9, 100% \t Train loss: 0.1609 took: 1.00s  Val. loss: 0.1663\n",
      "Epoch 10, 100% \t Train loss: 0.1589 took: 1.00s  Val. loss: 0.1610\n",
      "Epoch 11, 100% \t Train loss: 0.1574 took: 1.00s  Val. loss: 0.1615\n",
      "Epoch 12, 100% \t Train loss: 0.1561 took: 1.00s  Val. loss: 0.1591\n",
      "Epoch 13, 100% \t Train loss: 0.1548 took: 1.00s  Val. loss: 0.1620\n",
      "Epoch 14, 100% \t Train loss: 0.1538 took: 1.00s  Val. loss: 0.1594\n",
      "Epoch 15, 100% \t Train loss: 0.1531 took: 1.00s  Val. loss: 0.1593\n",
      "Epoch 16, 100% \t Train loss: 0.1508 took: 1.00s  Val. loss: 0.1598\n",
      "Epoch 17, 100% \t Train loss: 0.1495 took: 1.00s  Val. loss: 0.1568\n",
      "Epoch 18, 100% \t Train loss: 0.1484 took: 1.00s  Val. loss: 0.1567\n",
      "Epoch 19, 100% \t Train loss: 0.1456 took: 1.00s  Val. loss: 0.1547\n",
      "Epoch 20, 100% \t Train loss: 0.1435 took: 1.00s  Val. loss: 0.1502\n",
      "Epoch 21, 100% \t Train loss: 0.1389 took: 1.00s  Val. loss: 0.1418\n",
      "Epoch 22, 100% \t Train loss: 0.1337 took: 1.00s  Val. loss: 0.1342\n",
      "Epoch 23, 100% \t Train loss: 0.1262 took: 1.00s  Val. loss: 0.1246\n",
      "Epoch 24, 100% \t Train loss: 0.1180 took: 1.00s  Val. loss: 0.1201\n",
      "Epoch 25, 100% \t Train loss: 0.1131 took: 0.99s  Val. loss: 0.1120\n",
      "Epoch 26, 100% \t Train loss: 0.1076 took: 1.00s  Val. loss: 0.1122\n",
      "Epoch 27, 100% \t Train loss: 0.1038 took: 1.00s  Val. loss: 0.1060\n",
      "Epoch 28, 100% \t Train loss: 0.1019 took: 1.00s  Val. loss: 0.1031\n",
      "Epoch 29, 100% \t Train loss: 0.0968 took: 1.00s  Val. loss: 0.1003\n",
      "Epoch 30, 100% \t Train loss: 0.0956 took: 1.00s  Val. loss: 0.1030\n",
      "Epoch 31, 100% \t Train loss: 0.0934 took: 1.00s  Val. loss: 0.0985\n",
      "Epoch 32, 100% \t Train loss: 0.0912 took: 1.06s  Val. loss: 0.0988\n",
      "Epoch 33, 100% \t Train loss: 0.0902 took: 1.19s  Val. loss: 0.1023\n",
      "Epoch 34, 100% \t Train loss: 0.0885 took: 1.24s  Val. loss: 0.0914\n",
      "Epoch 35, 100% \t Train loss: 0.0876 took: 1.24s  Val. loss: 0.0948\n",
      "Epoch 36, 100% \t Train loss: 0.0865 took: 1.26s  Val. loss: 0.0941\n",
      "Epoch 37, 100% \t Train loss: 0.0856 took: 1.27s  Val. loss: 0.0930\n",
      "Epoch 38, 100% \t Train loss: 0.0854 took: 1.27s  Val. loss: 0.0906\n",
      "Epoch 39, 100% \t Train loss: 0.0838 took: 2.03s  Val. loss: 0.0914\n",
      "Epoch 40, 100% \t Train loss: 0.0843 took: 2.01s  Val. loss: 0.0947\n",
      "Epoch 41, 100% \t Train loss: 0.0832 took: 2.03s  Val. loss: 0.0932\n",
      "Epoch 42, 100% \t Train loss: 0.0823 took: 2.03s  Val. loss: 0.0944\n",
      "Epoch 43, 100% \t Train loss: 0.0824 took: 2.02s  Val. loss: 0.0931\n",
      "Epoch 44, 100% \t Train loss: 0.0808 took: 2.03s  Val. loss: 0.0948\n",
      "Epoch 45, 100% \t Train loss: 0.0818 took: 2.03s  Val. loss: 0.0934\n",
      "Epoch 46, 100% \t Train loss: 0.0824 took: 2.02s  Val. loss: 0.0942\n",
      "Epoch 47, 100% \t Train loss: 0.0810 took: 2.01s  Val. loss: 0.0933\n",
      "Epoch 48, 100% \t Train loss: 0.0794 took: 2.01s  Val. loss: 0.0922\n",
      "Epoch 49, 100% \t Train loss: 0.0802 took: 1.99s  Val. loss: 0.0914\n",
      "Epoch 50, 100% \t Train loss: 0.0798 took: 1.93s  Val. loss: 0.0918\n",
      "Training finished, took 75.14s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 1.75s  Val. loss: 0.2506\n",
      "Epoch 2, 100% \t Train loss: 0.2563 took: 1.73s  Val. loss: 0.2506\n",
      "Epoch 3, 100% \t Train loss: 0.2556 took: 1.74s  Val. loss: 0.2480\n",
      "Epoch 4, 100% \t Train loss: 0.2454 took: 1.74s  Val. loss: 0.2203\n",
      "Epoch 5, 100% \t Train loss: 0.2100 took: 1.73s  Val. loss: 0.1909\n",
      "Epoch 6, 100% \t Train loss: 0.1849 took: 1.73s  Val. loss: 0.1638\n",
      "Epoch 7, 100% \t Train loss: 0.1773 took: 1.73s  Val. loss: 0.1621\n",
      "Epoch 8, 100% \t Train loss: 0.1771 took: 1.73s  Val. loss: 0.1617\n",
      "Epoch 9, 100% \t Train loss: 0.1758 took: 1.72s  Val. loss: 0.1594\n",
      "Epoch 10, 100% \t Train loss: 0.1733 took: 1.75s  Val. loss: 0.1589\n",
      "Epoch 11, 100% \t Train loss: 0.1727 took: 1.73s  Val. loss: 0.1629\n",
      "Epoch 12, 100% \t Train loss: 0.1714 took: 1.73s  Val. loss: 0.1600\n",
      "Epoch 13, 100% \t Train loss: 0.1707 took: 1.74s  Val. loss: 0.1556\n",
      "Epoch 14, 100% \t Train loss: 0.1685 took: 1.73s  Val. loss: 0.1595\n",
      "Epoch 15, 100% \t Train loss: 0.1674 took: 1.73s  Val. loss: 0.1544\n",
      "Epoch 16, 100% \t Train loss: 0.1667 took: 1.74s  Val. loss: 0.1531\n",
      "Epoch 17, 100% \t Train loss: 0.1667 took: 1.74s  Val. loss: 0.1589\n",
      "Epoch 18, 100% \t Train loss: 0.1631 took: 1.75s  Val. loss: 0.1494\n",
      "Epoch 19, 100% \t Train loss: 0.1611 took: 1.74s  Val. loss: 0.1483\n",
      "Epoch 20, 100% \t Train loss: 0.1635 took: 1.75s  Val. loss: 0.1522\n",
      "Epoch 21, 100% \t Train loss: 0.1639 took: 1.73s  Val. loss: 0.1543\n",
      "Epoch 22, 100% \t Train loss: 0.1644 took: 1.74s  Val. loss: 0.1528\n",
      "Epoch 23, 100% \t Train loss: 0.1611 took: 1.74s  Val. loss: 0.1485\n",
      "Epoch 24, 100% \t Train loss: 0.1614 took: 1.76s  Val. loss: 0.1478\n",
      "Epoch 25, 100% \t Train loss: 0.1606 took: 1.75s  Val. loss: 0.1513\n",
      "Epoch 26, 100% \t Train loss: 0.1625 took: 1.73s  Val. loss: 0.1490\n",
      "Epoch 27, 100% \t Train loss: 0.1607 took: 1.76s  Val. loss: 0.1483\n",
      "Epoch 28, 100% \t Train loss: 0.1601 took: 1.76s  Val. loss: 0.1496\n",
      "Epoch 29, 100% \t Train loss: 0.1584 took: 1.73s  Val. loss: 0.1509\n",
      "Epoch 30, 100% \t Train loss: 0.1605 took: 1.75s  Val. loss: 0.1527\n",
      "Epoch 31, 100% \t Train loss: 0.1611 took: 1.76s  Val. loss: 0.1485\n",
      "Epoch 32, 100% \t Train loss: 0.1588 took: 1.76s  Val. loss: 0.1442\n",
      "Epoch 33, 100% \t Train loss: 0.1576 took: 1.78s  Val. loss: 0.1480\n",
      "Epoch 34, 100% \t Train loss: 0.1588 took: 1.77s  Val. loss: 0.1493\n",
      "Epoch 35, 100% \t Train loss: 0.1586 took: 1.76s  Val. loss: 0.1492\n",
      "Epoch 36, 100% \t Train loss: 0.1587 took: 1.76s  Val. loss: 0.1501\n",
      "Epoch 37, 100% \t Train loss: 0.1576 took: 1.77s  Val. loss: 0.1455\n",
      "Epoch 38, 100% \t Train loss: 0.1570 took: 1.77s  Val. loss: 0.1470\n",
      "Epoch 39, 100% \t Train loss: 0.1600 took: 1.77s  Val. loss: 0.1484\n",
      "Epoch 40, 100% \t Train loss: 0.1571 took: 1.77s  Val. loss: 0.1450\n",
      "Epoch 41, 100% \t Train loss: 0.1568 took: 1.78s  Val. loss: 0.1466\n",
      "Epoch 42, 100% \t Train loss: 0.1567 took: 1.78s  Val. loss: 0.1440\n",
      "Epoch 43, 100% \t Train loss: 0.1559 took: 1.79s  Val. loss: 0.1458\n",
      "Epoch 44, 100% \t Train loss: 0.1567 took: 1.79s  Val. loss: 0.1493\n",
      "Epoch 45, 100% \t Train loss: 0.1571 took: 1.80s  Val. loss: 0.1475\n",
      "Epoch 46, 100% \t Train loss: 0.1568 took: 1.80s  Val. loss: 0.1469\n",
      "Epoch 47, 100% \t Train loss: 0.1554 took: 1.80s  Val. loss: 0.1480\n",
      "Epoch 48, 100% \t Train loss: 0.1576 took: 1.80s  Val. loss: 0.1485\n",
      "Epoch 49, 100% \t Train loss: 0.1555 took: 1.80s  Val. loss: 0.1474\n",
      "Epoch 50, 100% \t Train loss: 0.1553 took: 1.80s  Val. loss: 0.1456\n",
      "Training finished, took 100.14s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2612 took: 1.75s  Val. loss: 0.2544\n",
      "Epoch 2, 100% \t Train loss: 0.2601 took: 1.73s  Val. loss: 0.2549\n",
      "Epoch 3, 100% \t Train loss: 0.2600 took: 1.74s  Val. loss: 0.2535\n",
      "Epoch 4, 100% \t Train loss: 0.2600 took: 1.73s  Val. loss: 0.2527\n",
      "Epoch 5, 100% \t Train loss: 0.2600 took: 1.73s  Val. loss: 0.2538\n",
      "Epoch 6, 100% \t Train loss: 0.2600 took: 1.74s  Val. loss: 0.2543\n",
      "Epoch 7, 100% \t Train loss: 0.2599 took: 1.74s  Val. loss: 0.2543\n",
      "Epoch 8, 100% \t Train loss: 0.2601 took: 1.73s  Val. loss: 0.2544\n",
      "Epoch 9, 100% \t Train loss: 0.2600 took: 1.73s  Val. loss: 0.2533\n",
      "Epoch 10, 100% \t Train loss: 0.2600 took: 1.74s  Val. loss: 0.2535\n",
      "Epoch 11, 100% \t Train loss: 0.2599 took: 1.74s  Val. loss: 0.2534\n",
      "Epoch 12, 100% \t Train loss: 0.2597 took: 1.74s  Val. loss: 0.2534\n",
      "Epoch 13, 100% \t Train loss: 0.2592 took: 1.72s  Val. loss: 0.2528\n",
      "Epoch 14, 100% \t Train loss: 0.2581 took: 1.74s  Val. loss: 0.2510\n",
      "Epoch 15, 100% \t Train loss: 0.2540 took: 1.73s  Val. loss: 0.2431\n",
      "Epoch 16, 100% \t Train loss: 0.2389 took: 1.74s  Val. loss: 0.2207\n",
      "Epoch 17, 100% \t Train loss: 0.2173 took: 1.74s  Val. loss: 0.2058\n",
      "Epoch 18, 100% \t Train loss: 0.1995 took: 1.75s  Val. loss: 0.1815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1881 took: 1.75s  Val. loss: 0.1819\n",
      "Epoch 20, 100% \t Train loss: 0.1845 took: 1.73s  Val. loss: 0.1761\n",
      "Epoch 21, 100% \t Train loss: 0.1836 took: 1.75s  Val. loss: 0.1775\n",
      "Epoch 22, 100% \t Train loss: 0.1812 took: 1.75s  Val. loss: 0.1749\n",
      "Epoch 23, 100% \t Train loss: 0.1806 took: 1.73s  Val. loss: 0.1737\n",
      "Epoch 24, 100% \t Train loss: 0.1796 took: 1.74s  Val. loss: 0.1743\n",
      "Epoch 25, 100% \t Train loss: 0.1791 took: 1.77s  Val. loss: 0.1737\n",
      "Epoch 26, 100% \t Train loss: 0.1783 took: 1.74s  Val. loss: 0.1726\n",
      "Epoch 27, 100% \t Train loss: 0.1781 took: 1.74s  Val. loss: 0.1722\n",
      "Epoch 28, 100% \t Train loss: 0.1773 took: 1.75s  Val. loss: 0.1724\n",
      "Epoch 29, 100% \t Train loss: 0.1779 took: 1.76s  Val. loss: 0.1736\n",
      "Epoch 30, 100% \t Train loss: 0.1765 took: 1.78s  Val. loss: 0.1712\n",
      "Epoch 31, 100% \t Train loss: 0.1762 took: 1.75s  Val. loss: 0.1711\n",
      "Epoch 32, 100% \t Train loss: 0.1752 took: 1.75s  Val. loss: 0.1730\n",
      "Epoch 33, 100% \t Train loss: 0.1759 took: 1.76s  Val. loss: 0.1704\n",
      "Epoch 34, 100% \t Train loss: 0.1746 took: 1.76s  Val. loss: 0.1707\n",
      "Epoch 35, 100% \t Train loss: 0.1744 took: 1.76s  Val. loss: 0.1684\n",
      "Epoch 36, 100% \t Train loss: 0.1731 took: 1.76s  Val. loss: 0.1681\n",
      "Epoch 37, 100% \t Train loss: 0.1724 took: 1.75s  Val. loss: 0.1666\n",
      "Epoch 38, 100% \t Train loss: 0.1724 took: 1.75s  Val. loss: 0.1691\n",
      "Epoch 39, 100% \t Train loss: 0.1714 took: 1.75s  Val. loss: 0.1702\n",
      "Epoch 40, 100% \t Train loss: 0.1707 took: 1.76s  Val. loss: 0.1681\n",
      "Epoch 41, 100% \t Train loss: 0.1697 took: 1.78s  Val. loss: 0.1653\n",
      "Epoch 42, 100% \t Train loss: 0.1696 took: 1.74s  Val. loss: 0.1649\n",
      "Epoch 43, 100% \t Train loss: 0.1680 took: 1.75s  Val. loss: 0.1632\n",
      "Epoch 44, 100% \t Train loss: 0.1679 took: 1.73s  Val. loss: 0.1639\n",
      "Epoch 45, 100% \t Train loss: 0.1675 took: 1.76s  Val. loss: 0.1618\n",
      "Epoch 46, 100% \t Train loss: 0.1670 took: 1.75s  Val. loss: 0.1634\n",
      "Epoch 47, 100% \t Train loss: 0.1658 took: 1.74s  Val. loss: 0.1622\n",
      "Epoch 48, 100% \t Train loss: 0.1648 took: 1.73s  Val. loss: 0.1627\n",
      "Epoch 49, 100% \t Train loss: 0.1644 took: 1.75s  Val. loss: 0.1588\n",
      "Epoch 50, 100% \t Train loss: 0.1645 took: 1.75s  Val. loss: 0.1644\n",
      "Training finished, took 99.92s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  8\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  2\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.869727\n",
      "lambda: 0.0010 - V: 0.840595\n",
      "lambda: 0.0005 - V: 0.803578\n",
      "Average V: 0.837966\n",
      "Time elapsed: 278.66 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]\n",
      "\tmax_pool_size :  2\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  8\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  4\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2599 took: 2.77s  Val. loss: 0.2617\n",
      "Epoch 2, 100% \t Train loss: 0.2581 took: 2.77s  Val. loss: 0.2623\n",
      "Epoch 3, 100% \t Train loss: 0.2581 took: 2.76s  Val. loss: 0.2620\n",
      "Epoch 4, 100% \t Train loss: 0.2579 took: 2.81s  Val. loss: 0.2615\n",
      "Epoch 5, 100% \t Train loss: 0.2580 took: 2.78s  Val. loss: 0.2615\n",
      "Epoch 6, 100% \t Train loss: 0.2581 took: 2.78s  Val. loss: 0.2618\n",
      "Epoch 7, 100% \t Train loss: 0.2580 took: 2.78s  Val. loss: 0.2619\n",
      "Epoch 8, 100% \t Train loss: 0.2578 took: 2.83s  Val. loss: 0.2614\n",
      "Epoch 9, 100% \t Train loss: 0.2579 took: 2.80s  Val. loss: 0.2604\n",
      "Epoch 10, 100% \t Train loss: 0.2579 took: 2.77s  Val. loss: 0.2619\n",
      "Epoch 11, 100% \t Train loss: 0.2579 took: 2.79s  Val. loss: 0.2611\n",
      "Epoch 12, 100% \t Train loss: 0.2579 took: 2.78s  Val. loss: 0.2619\n",
      "Epoch 13, 100% \t Train loss: 0.2578 took: 2.78s  Val. loss: 0.2607\n",
      "Epoch 14, 100% \t Train loss: 0.2579 took: 2.80s  Val. loss: 0.2613\n",
      "Epoch 15, 100% \t Train loss: 0.2579 took: 2.77s  Val. loss: 0.2612\n",
      "Epoch 16, 100% \t Train loss: 0.2579 took: 2.77s  Val. loss: 0.2612\n",
      "Epoch 17, 100% \t Train loss: 0.2579 took: 2.78s  Val. loss: 0.2607\n",
      "Epoch 18, 100% \t Train loss: 0.2580 took: 2.76s  Val. loss: 0.2614\n",
      "Epoch 19, 100% \t Train loss: 0.2579 took: 2.79s  Val. loss: 0.2621\n",
      "Epoch 20, 100% \t Train loss: 0.2580 took: 2.78s  Val. loss: 0.2618\n",
      "Epoch 21, 100% \t Train loss: 0.2578 took: 2.79s  Val. loss: 0.2610\n",
      "Epoch 22, 100% \t Train loss: 0.2578 took: 2.80s  Val. loss: 0.2615\n",
      "Epoch 23, 100% \t Train loss: 0.2580 took: 2.78s  Val. loss: 0.2612\n",
      "Epoch 24, 100% \t Train loss: 0.2579 took: 2.80s  Val. loss: 0.2613\n",
      "Epoch 25, 100% \t Train loss: 0.2579 took: 2.76s  Val. loss: 0.2621\n",
      "Epoch 26, 100% \t Train loss: 0.2578 took: 2.77s  Val. loss: 0.2618\n",
      "Epoch 27, 100% \t Train loss: 0.2578 took: 2.76s  Val. loss: 0.2614\n",
      "Epoch 28, 100% \t Train loss: 0.2578 took: 2.80s  Val. loss: 0.2616\n",
      "Epoch 29, 100% \t Train loss: 0.2578 took: 2.84s  Val. loss: 0.2615\n",
      "Epoch 30, 100% \t Train loss: 0.2578 took: 2.86s  Val. loss: 0.2614\n",
      "Epoch 31, 100% \t Train loss: 0.2578 took: 2.87s  Val. loss: 0.2616\n",
      "Epoch 32, 100% \t Train loss: 0.2579 took: 2.95s  Val. loss: 0.2613\n",
      "Epoch 33, 100% \t Train loss: 0.2578 took: 3.35s  Val. loss: 0.2617\n",
      "Epoch 34, 100% \t Train loss: 0.2578 took: 3.58s  Val. loss: 0.2612\n",
      "Epoch 35, 100% \t Train loss: 0.2578 took: 3.70s  Val. loss: 0.2616\n",
      "Epoch 36, 100% \t Train loss: 0.2578 took: 3.49s  Val. loss: 0.2604\n",
      "Epoch 37, 100% \t Train loss: 0.2578 took: 3.46s  Val. loss: 0.2609\n",
      "Epoch 38, 100% \t Train loss: 0.2579 took: 3.45s  Val. loss: 0.2613\n",
      "Epoch 39, 100% \t Train loss: 0.2578 took: 3.26s  Val. loss: 0.2616\n",
      "Epoch 40, 100% \t Train loss: 0.2578 took: 3.17s  Val. loss: 0.2612\n",
      "Epoch 41, 100% \t Train loss: 0.2578 took: 3.20s  Val. loss: 0.2615\n",
      "Epoch 42, 100% \t Train loss: 0.2578 took: 3.24s  Val. loss: 0.2620\n",
      "Epoch 43, 100% \t Train loss: 0.2578 took: 3.43s  Val. loss: 0.2616\n",
      "Epoch 44, 100% \t Train loss: 0.2578 took: 3.28s  Val. loss: 0.2606\n",
      "Epoch 45, 100% \t Train loss: 0.2578 took: 3.30s  Val. loss: 0.2621\n",
      "Epoch 46, 100% \t Train loss: 0.2578 took: 3.33s  Val. loss: 0.2613\n",
      "Epoch 47, 100% \t Train loss: 0.2578 took: 3.81s  Val. loss: 0.2605\n",
      "Epoch 48, 100% \t Train loss: 0.2578 took: 3.96s  Val. loss: 0.2616\n",
      "Epoch 49, 100% \t Train loss: 0.2578 took: 4.05s  Val. loss: 0.2607\n",
      "Epoch 50, 100% \t Train loss: 0.2578 took: 3.76s  Val. loss: 0.2617\n",
      "Training finished, took 167.49s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 2.77s  Val. loss: 0.2574\n",
      "Epoch 2, 100% \t Train loss: 0.2559 took: 2.77s  Val. loss: 0.2573\n",
      "Epoch 3, 100% \t Train loss: 0.2562 took: 2.76s  Val. loss: 0.2565\n",
      "Epoch 4, 100% \t Train loss: 0.2559 took: 2.75s  Val. loss: 0.2558\n",
      "Epoch 5, 100% \t Train loss: 0.2558 took: 2.76s  Val. loss: 0.2563\n",
      "Epoch 6, 100% \t Train loss: 0.2561 took: 2.76s  Val. loss: 0.2583\n",
      "Epoch 7, 100% \t Train loss: 0.2562 took: 2.78s  Val. loss: 0.2573\n",
      "Epoch 8, 100% \t Train loss: 0.2560 took: 2.75s  Val. loss: 0.2574\n",
      "Epoch 9, 100% \t Train loss: 0.2561 took: 2.76s  Val. loss: 0.2573\n",
      "Epoch 10, 100% \t Train loss: 0.2559 took: 2.77s  Val. loss: 0.2571\n",
      "Epoch 11, 100% \t Train loss: 0.2558 took: 2.80s  Val. loss: 0.2570\n",
      "Epoch 12, 100% \t Train loss: 0.2559 took: 2.80s  Val. loss: 0.2566\n",
      "Epoch 13, 100% \t Train loss: 0.2559 took: 2.78s  Val. loss: 0.2572\n",
      "Epoch 14, 100% \t Train loss: 0.2559 took: 2.77s  Val. loss: 0.2575\n",
      "Epoch 15, 100% \t Train loss: 0.2559 took: 2.75s  Val. loss: 0.2571\n",
      "Epoch 16, 100% \t Train loss: 0.2560 took: 2.76s  Val. loss: 0.2564\n",
      "Epoch 17, 100% \t Train loss: 0.2558 took: 2.79s  Val. loss: 0.2568\n",
      "Epoch 18, 100% \t Train loss: 0.2559 took: 2.78s  Val. loss: 0.2567\n",
      "Epoch 19, 100% \t Train loss: 0.2558 took: 2.80s  Val. loss: 0.2570\n",
      "Epoch 20, 100% \t Train loss: 0.2560 took: 2.79s  Val. loss: 0.2575\n",
      "Epoch 21, 100% \t Train loss: 0.2560 took: 2.77s  Val. loss: 0.2571\n",
      "Epoch 22, 100% \t Train loss: 0.2558 took: 2.80s  Val. loss: 0.2574\n",
      "Epoch 23, 100% \t Train loss: 0.2558 took: 2.80s  Val. loss: 0.2568\n",
      "Epoch 24, 100% \t Train loss: 0.2558 took: 2.76s  Val. loss: 0.2586\n",
      "Epoch 25, 100% \t Train loss: 0.2559 took: 2.78s  Val. loss: 0.2564\n",
      "Epoch 26, 100% \t Train loss: 0.2559 took: 2.79s  Val. loss: 0.2569\n",
      "Epoch 27, 100% \t Train loss: 0.2558 took: 2.87s  Val. loss: 0.2577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, 100% \t Train loss: 0.2558 took: 2.92s  Val. loss: 0.2572\n",
      "Epoch 29, 100% \t Train loss: 0.2558 took: 2.90s  Val. loss: 0.2580\n",
      "Epoch 30, 100% \t Train loss: 0.2557 took: 2.93s  Val. loss: 0.2568\n",
      "Epoch 31, 100% \t Train loss: 0.2558 took: 2.96s  Val. loss: 0.2572\n",
      "Epoch 32, 100% \t Train loss: 0.2558 took: 2.95s  Val. loss: 0.2574\n",
      "Epoch 33, 100% \t Train loss: 0.2559 took: 2.98s  Val. loss: 0.2574\n",
      "Epoch 34, 100% \t Train loss: 0.2560 took: 2.96s  Val. loss: 0.2571\n",
      "Epoch 35, 100% \t Train loss: 0.2558 took: 2.99s  Val. loss: 0.2572\n",
      "Epoch 36, 100% \t Train loss: 0.2558 took: 2.99s  Val. loss: 0.2566\n",
      "Epoch 37, 100% \t Train loss: 0.2559 took: 3.02s  Val. loss: 0.2581\n",
      "Epoch 38, 100% \t Train loss: 0.2558 took: 3.04s  Val. loss: 0.2582\n",
      "Epoch 39, 100% \t Train loss: 0.2558 took: 3.07s  Val. loss: 0.2568\n",
      "Epoch 40, 100% \t Train loss: 0.2557 took: 2.52s  Val. loss: 0.2567\n",
      "Epoch 41, 100% \t Train loss: 0.2558 took: 2.05s  Val. loss: 0.2564\n",
      "Epoch 42, 100% \t Train loss: 0.2558 took: 2.04s  Val. loss: 0.2570\n",
      "Epoch 43, 100% \t Train loss: 0.2558 took: 2.08s  Val. loss: 0.2579\n",
      "Epoch 44, 100% \t Train loss: 0.2558 took: 2.13s  Val. loss: 0.2573\n",
      "Epoch 45, 100% \t Train loss: 0.2558 took: 2.10s  Val. loss: 0.2566\n",
      "Epoch 46, 100% \t Train loss: 0.2557 took: 2.09s  Val. loss: 0.2576\n",
      "Epoch 47, 100% \t Train loss: 0.2558 took: 3.17s  Val. loss: 0.2566\n",
      "Epoch 48, 100% \t Train loss: 0.2559 took: 3.18s  Val. loss: 0.2564\n",
      "Epoch 49, 100% \t Train loss: 0.2558 took: 3.20s  Val. loss: 0.2571\n",
      "Epoch 50, 100% \t Train loss: 0.2558 took: 3.21s  Val. loss: 0.2570\n",
      "Training finished, took 151.55s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2606 took: 2.86s  Val. loss: 0.2598\n",
      "Epoch 2, 100% \t Train loss: 0.2598 took: 2.83s  Val. loss: 0.2598\n",
      "Epoch 3, 100% \t Train loss: 0.2600 took: 2.85s  Val. loss: 0.2597\n",
      "Epoch 4, 100% \t Train loss: 0.2600 took: 2.84s  Val. loss: 0.2603\n",
      "Epoch 5, 100% \t Train loss: 0.2603 took: 2.83s  Val. loss: 0.2598\n",
      "Epoch 6, 100% \t Train loss: 0.2597 took: 2.84s  Val. loss: 0.2603\n",
      "Epoch 7, 100% \t Train loss: 0.2598 took: 2.86s  Val. loss: 0.2588\n",
      "Epoch 8, 100% \t Train loss: 0.2598 took: 2.83s  Val. loss: 0.2598\n",
      "Epoch 9, 100% \t Train loss: 0.2599 took: 2.85s  Val. loss: 0.2595\n",
      "Epoch 10, 100% \t Train loss: 0.2599 took: 2.85s  Val. loss: 0.2595\n",
      "Epoch 11, 100% \t Train loss: 0.2600 took: 2.83s  Val. loss: 0.2603\n",
      "Epoch 12, 100% \t Train loss: 0.2598 took: 2.84s  Val. loss: 0.2597\n",
      "Epoch 13, 100% \t Train loss: 0.2599 took: 2.81s  Val. loss: 0.2592\n",
      "Epoch 14, 100% \t Train loss: 0.2599 took: 2.85s  Val. loss: 0.2593\n",
      "Epoch 15, 100% \t Train loss: 0.2599 took: 2.85s  Val. loss: 0.2612\n",
      "Epoch 16, 100% \t Train loss: 0.2600 took: 2.86s  Val. loss: 0.2597\n",
      "Epoch 17, 100% \t Train loss: 0.2598 took: 2.85s  Val. loss: 0.2591\n",
      "Epoch 18, 100% \t Train loss: 0.2598 took: 2.76s  Val. loss: 0.2594\n",
      "Epoch 19, 100% \t Train loss: 0.2598 took: 2.69s  Val. loss: 0.2602\n",
      "Epoch 20, 100% \t Train loss: 0.2599 took: 2.71s  Val. loss: 0.2604\n",
      "Epoch 21, 100% \t Train loss: 0.2598 took: 2.72s  Val. loss: 0.2596\n",
      "Epoch 22, 100% \t Train loss: 0.2599 took: 2.70s  Val. loss: 0.2600\n",
      "Epoch 23, 100% \t Train loss: 0.2599 took: 2.69s  Val. loss: 0.2596\n",
      "Epoch 24, 100% \t Train loss: 0.2599 took: 2.70s  Val. loss: 0.2595\n",
      "Epoch 25, 100% \t Train loss: 0.2598 took: 2.70s  Val. loss: 0.2605\n",
      "Epoch 26, 100% \t Train loss: 0.2598 took: 2.71s  Val. loss: 0.2599\n",
      "Epoch 27, 100% \t Train loss: 0.2599 took: 2.73s  Val. loss: 0.2597\n",
      "Epoch 28, 100% \t Train loss: 0.2598 took: 2.76s  Val. loss: 0.2607\n",
      "Epoch 29, 100% \t Train loss: 0.2598 took: 2.77s  Val. loss: 0.2596\n",
      "Epoch 30, 100% \t Train loss: 0.2597 took: 2.77s  Val. loss: 0.2588\n",
      "Epoch 31, 100% \t Train loss: 0.2597 took: 2.78s  Val. loss: 0.2601\n",
      "Epoch 32, 100% \t Train loss: 0.2594 took: 2.81s  Val. loss: 0.2590\n",
      "Epoch 33, 100% \t Train loss: 0.2575 took: 2.80s  Val. loss: 0.2546\n",
      "Epoch 34, 100% \t Train loss: 0.2338 took: 2.81s  Val. loss: 0.2091\n",
      "Epoch 35, 100% \t Train loss: 0.1899 took: 2.81s  Val. loss: 0.1839\n",
      "Epoch 36, 100% \t Train loss: 0.1768 took: 2.84s  Val. loss: 0.1793\n",
      "Epoch 37, 100% \t Train loss: 0.1719 took: 2.83s  Val. loss: 0.1764\n",
      "Epoch 38, 100% \t Train loss: 0.1688 took: 1.83s  Val. loss: 0.1758\n",
      "Epoch 39, 100% \t Train loss: 0.1669 took: 1.88s  Val. loss: 0.1796\n",
      "Epoch 40, 100% \t Train loss: 0.1655 took: 1.89s  Val. loss: 0.1725\n",
      "Epoch 41, 100% \t Train loss: 0.1641 took: 1.89s  Val. loss: 0.1697\n",
      "Epoch 42, 100% \t Train loss: 0.1614 took: 1.91s  Val. loss: 0.1721\n",
      "Epoch 43, 100% \t Train loss: 0.1613 took: 1.92s  Val. loss: 0.1709\n",
      "Epoch 44, 100% \t Train loss: 0.1607 took: 1.91s  Val. loss: 0.1733\n",
      "Epoch 45, 100% \t Train loss: 0.1614 took: 1.93s  Val. loss: 0.1709\n",
      "Epoch 46, 100% \t Train loss: 0.1591 took: 1.93s  Val. loss: 0.1659\n",
      "Epoch 47, 100% \t Train loss: 0.1584 took: 1.93s  Val. loss: 0.1667\n",
      "Epoch 48, 100% \t Train loss: 0.1579 took: 1.95s  Val. loss: 0.1658\n",
      "Epoch 49, 100% \t Train loss: 0.1571 took: 1.97s  Val. loss: 0.1702\n",
      "Epoch 50, 100% \t Train loss: 0.1580 took: 1.99s  Val. loss: 0.1691\n",
      "Training finished, took 140.93s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]\n",
      "\tmax_pool_size :  2\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  8\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  4\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.738584\n",
      "lambda: 0.0010 - V: 0.742876\n",
      "lambda: 0.0005 - V: 0.769222\n",
      "Average V: 0.750228\n",
      "Time elapsed: 463.70 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  16\n",
      "\tinfo_channels :  8\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  32\n",
      "\tresidual_hidden_dim :  16\n",
      "\tn_residual_layers :  2\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2609 took: 1.24s  Val. loss: 0.2567\n",
      "Epoch 2, 100% \t Train loss: 0.2565 took: 1.20s  Val. loss: 0.2330\n",
      "Epoch 3, 100% \t Train loss: 0.1948 took: 1.20s  Val. loss: 0.1749\n",
      "Epoch 4, 100% \t Train loss: 0.1735 took: 1.20s  Val. loss: 0.1727\n",
      "Epoch 5, 100% \t Train loss: 0.1705 took: 1.20s  Val. loss: 0.1683\n",
      "Epoch 6, 100% \t Train loss: 0.1668 took: 1.20s  Val. loss: 0.1635\n",
      "Epoch 7, 100% \t Train loss: 0.1617 took: 1.20s  Val. loss: 0.1608\n",
      "Epoch 8, 100% \t Train loss: 0.1595 took: 1.20s  Val. loss: 0.1578\n",
      "Epoch 9, 100% \t Train loss: 0.1574 took: 1.20s  Val. loss: 0.1585\n",
      "Epoch 10, 100% \t Train loss: 0.1562 took: 1.20s  Val. loss: 0.1564\n",
      "Epoch 11, 100% \t Train loss: 0.1545 took: 1.20s  Val. loss: 0.1564\n",
      "Epoch 12, 100% \t Train loss: 0.1520 took: 1.20s  Val. loss: 0.1531\n",
      "Epoch 13, 100% \t Train loss: 0.1498 took: 1.20s  Val. loss: 0.1519\n",
      "Epoch 14, 100% \t Train loss: 0.1466 took: 1.20s  Val. loss: 0.1480\n",
      "Epoch 15, 100% \t Train loss: 0.1427 took: 1.20s  Val. loss: 0.1459\n",
      "Epoch 16, 100% \t Train loss: 0.1387 took: 1.20s  Val. loss: 0.1414\n",
      "Epoch 17, 100% \t Train loss: 0.1345 took: 1.20s  Val. loss: 0.1340\n",
      "Epoch 18, 100% \t Train loss: 0.1301 took: 1.20s  Val. loss: 0.1267\n",
      "Epoch 19, 100% \t Train loss: 0.1237 took: 2.02s  Val. loss: 0.1232\n",
      "Epoch 20, 100% \t Train loss: 0.1183 took: 2.00s  Val. loss: 0.1177\n",
      "Epoch 21, 100% \t Train loss: 0.1119 took: 2.01s  Val. loss: 0.1115\n",
      "Epoch 22, 100% \t Train loss: 0.1076 took: 2.01s  Val. loss: 0.1099\n",
      "Epoch 23, 100% \t Train loss: 0.1042 took: 2.00s  Val. loss: 0.1062\n",
      "Epoch 24, 100% \t Train loss: 0.1029 took: 2.00s  Val. loss: 0.1048\n",
      "Epoch 25, 100% \t Train loss: 0.1003 took: 2.03s  Val. loss: 0.1056\n",
      "Epoch 26, 100% \t Train loss: 0.1001 took: 1.20s  Val. loss: 0.1055\n",
      "Epoch 27, 100% \t Train loss: 0.0970 took: 1.20s  Val. loss: 0.1020\n",
      "Epoch 28, 100% \t Train loss: 0.0945 took: 1.21s  Val. loss: 0.1006\n",
      "Epoch 29, 100% \t Train loss: 0.0930 took: 1.22s  Val. loss: 0.0985\n",
      "Epoch 30, 100% \t Train loss: 0.0928 took: 1.23s  Val. loss: 0.0991\n",
      "Epoch 31, 100% \t Train loss: 0.0918 took: 1.26s  Val. loss: 0.1010\n",
      "Epoch 32, 100% \t Train loss: 0.0923 took: 1.47s  Val. loss: 0.1012\n",
      "Epoch 33, 100% \t Train loss: 0.0901 took: 1.86s  Val. loss: 0.1019\n",
      "Epoch 34, 100% \t Train loss: 0.0899 took: 1.93s  Val. loss: 0.0987\n",
      "Epoch 35, 100% \t Train loss: 0.0894 took: 1.95s  Val. loss: 0.0987\n",
      "Epoch 36, 100% \t Train loss: 0.0882 took: 1.97s  Val. loss: 0.0973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, 100% \t Train loss: 0.0872 took: 2.00s  Val. loss: 0.0970\n",
      "Epoch 38, 100% \t Train loss: 0.0873 took: 2.09s  Val. loss: 0.0947\n",
      "Epoch 39, 100% \t Train loss: 0.0877 took: 2.07s  Val. loss: 0.0948\n",
      "Epoch 40, 100% \t Train loss: 0.0860 took: 2.68s  Val. loss: 0.0922\n",
      "Epoch 41, 100% \t Train loss: 0.0846 took: 2.62s  Val. loss: 0.0962\n",
      "Epoch 42, 100% \t Train loss: 0.0855 took: 1.84s  Val. loss: 0.0941\n",
      "Epoch 43, 100% \t Train loss: 0.0850 took: 1.85s  Val. loss: 0.0973\n",
      "Epoch 44, 100% \t Train loss: 0.0859 took: 1.88s  Val. loss: 0.0936\n",
      "Epoch 45, 100% \t Train loss: 0.0845 took: 1.91s  Val. loss: 0.0918\n",
      "Epoch 46, 100% \t Train loss: 0.0834 took: 1.94s  Val. loss: 0.0910\n",
      "Epoch 47, 100% \t Train loss: 0.0834 took: 2.27s  Val. loss: 0.0933\n",
      "Epoch 48, 100% \t Train loss: 0.0830 took: 2.78s  Val. loss: 0.0925\n",
      "Epoch 49, 100% \t Train loss: 0.0830 took: 2.79s  Val. loss: 0.0922\n",
      "Epoch 50, 100% \t Train loss: 0.0817 took: 2.82s  Val. loss: 0.0919\n",
      "Training finished, took 95.20s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2558 took: 2.03s  Val. loss: 0.2597\n",
      "Epoch 2, 100% \t Train loss: 0.2556 took: 2.02s  Val. loss: 0.2609\n",
      "Epoch 3, 100% \t Train loss: 0.2555 took: 2.02s  Val. loss: 0.2597\n",
      "Epoch 4, 100% \t Train loss: 0.2554 took: 2.04s  Val. loss: 0.2599\n",
      "Epoch 5, 100% \t Train loss: 0.2554 took: 2.04s  Val. loss: 0.2596\n",
      "Epoch 6, 100% \t Train loss: 0.2552 took: 2.03s  Val. loss: 0.2591\n",
      "Epoch 7, 100% \t Train loss: 0.2539 took: 2.02s  Val. loss: 0.2557\n",
      "Epoch 8, 100% \t Train loss: 0.2457 took: 2.04s  Val. loss: 0.2373\n",
      "Epoch 9, 100% \t Train loss: 0.2203 took: 2.04s  Val. loss: 0.2122\n",
      "Epoch 10, 100% \t Train loss: 0.1983 took: 2.04s  Val. loss: 0.1930\n",
      "Epoch 11, 100% \t Train loss: 0.1860 took: 2.02s  Val. loss: 0.1855\n",
      "Epoch 12, 100% \t Train loss: 0.1809 took: 2.05s  Val. loss: 0.1812\n",
      "Epoch 13, 100% \t Train loss: 0.1795 took: 2.03s  Val. loss: 0.1816\n",
      "Epoch 14, 100% \t Train loss: 0.1791 took: 2.01s  Val. loss: 0.1821\n",
      "Epoch 15, 100% \t Train loss: 0.1774 took: 2.03s  Val. loss: 0.1830\n",
      "Epoch 16, 100% \t Train loss: 0.1766 took: 2.00s  Val. loss: 0.1855\n",
      "Epoch 17, 100% \t Train loss: 0.1759 took: 2.00s  Val. loss: 0.1790\n",
      "Epoch 18, 100% \t Train loss: 0.1743 took: 2.02s  Val. loss: 0.1789\n",
      "Epoch 19, 100% \t Train loss: 0.1747 took: 2.03s  Val. loss: 0.1779\n",
      "Epoch 20, 100% \t Train loss: 0.1731 took: 2.04s  Val. loss: 0.1793\n",
      "Epoch 21, 100% \t Train loss: 0.1725 took: 2.06s  Val. loss: 0.1759\n",
      "Epoch 22, 100% \t Train loss: 0.1709 took: 2.02s  Val. loss: 0.1753\n",
      "Epoch 23, 100% \t Train loss: 0.1706 took: 2.01s  Val. loss: 0.1761\n",
      "Epoch 24, 100% \t Train loss: 0.1691 took: 2.01s  Val. loss: 0.1733\n",
      "Epoch 25, 100% \t Train loss: 0.1687 took: 2.02s  Val. loss: 0.1721\n",
      "Epoch 26, 100% \t Train loss: 0.1690 took: 2.03s  Val. loss: 0.1718\n",
      "Epoch 27, 100% \t Train loss: 0.1675 took: 2.04s  Val. loss: 0.1744\n",
      "Epoch 28, 100% \t Train loss: 0.1664 took: 2.04s  Val. loss: 0.1743\n",
      "Epoch 29, 100% \t Train loss: 0.1655 took: 2.05s  Val. loss: 0.1725\n",
      "Epoch 30, 100% \t Train loss: 0.1651 took: 2.07s  Val. loss: 0.1724\n",
      "Epoch 31, 100% \t Train loss: 0.1643 took: 2.10s  Val. loss: 0.1710\n",
      "Epoch 32, 100% \t Train loss: 0.1645 took: 2.21s  Val. loss: 0.1712\n",
      "Epoch 33, 100% \t Train loss: 0.1630 took: 2.24s  Val. loss: 0.1707\n",
      "Epoch 34, 100% \t Train loss: 0.1628 took: 2.24s  Val. loss: 0.1695\n",
      "Epoch 35, 100% \t Train loss: 0.1629 took: 2.29s  Val. loss: 0.1692\n",
      "Epoch 36, 100% \t Train loss: 0.1622 took: 2.36s  Val. loss: 0.1720\n",
      "Epoch 37, 100% \t Train loss: 0.1619 took: 2.40s  Val. loss: 0.1700\n",
      "Epoch 38, 100% \t Train loss: 0.1613 took: 2.41s  Val. loss: 0.1694\n",
      "Epoch 39, 100% \t Train loss: 0.1611 took: 2.43s  Val. loss: 0.1706\n",
      "Epoch 40, 100% \t Train loss: 0.1613 took: 2.45s  Val. loss: 0.1690\n",
      "Epoch 41, 100% \t Train loss: 0.1609 took: 2.50s  Val. loss: 0.1693\n",
      "Epoch 42, 100% \t Train loss: 0.1610 took: 1.76s  Val. loss: 0.1729\n",
      "Epoch 43, 100% \t Train loss: 0.1608 took: 1.85s  Val. loss: 0.1684\n",
      "Epoch 44, 100% \t Train loss: 0.1603 took: 1.90s  Val. loss: 0.1695\n",
      "Epoch 45, 100% \t Train loss: 0.1592 took: 1.92s  Val. loss: 0.1705\n",
      "Epoch 46, 100% \t Train loss: 0.1599 took: 2.00s  Val. loss: 0.1668\n",
      "Epoch 47, 100% \t Train loss: 0.1591 took: 2.90s  Val. loss: 0.1723\n",
      "Epoch 48, 100% \t Train loss: 0.1597 took: 2.97s  Val. loss: 0.1696\n",
      "Epoch 49, 100% \t Train loss: 0.1580 took: 2.93s  Val. loss: 0.1702\n",
      "Epoch 50, 100% \t Train loss: 0.1580 took: 2.95s  Val. loss: 0.1701\n",
      "Training finished, took 121.18s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2619 took: 2.04s  Val. loss: 0.2582\n",
      "Epoch 2, 100% \t Train loss: 0.2604 took: 2.03s  Val. loss: 0.2583\n",
      "Epoch 3, 100% \t Train loss: 0.2603 took: 2.01s  Val. loss: 0.2590\n",
      "Epoch 4, 100% \t Train loss: 0.2602 took: 2.03s  Val. loss: 0.2593\n",
      "Epoch 5, 100% \t Train loss: 0.2601 took: 2.02s  Val. loss: 0.2593\n",
      "Epoch 6, 100% \t Train loss: 0.2600 took: 2.03s  Val. loss: 0.2586\n",
      "Epoch 7, 100% \t Train loss: 0.2596 took: 2.02s  Val. loss: 0.2586\n",
      "Epoch 8, 100% \t Train loss: 0.2588 took: 2.01s  Val. loss: 0.2573\n",
      "Epoch 9, 100% \t Train loss: 0.2565 took: 2.04s  Val. loss: 0.2549\n",
      "Epoch 10, 100% \t Train loss: 0.2506 took: 2.02s  Val. loss: 0.2477\n",
      "Epoch 11, 100% \t Train loss: 0.2403 took: 2.03s  Val. loss: 0.2323\n",
      "Epoch 12, 100% \t Train loss: 0.2274 took: 2.03s  Val. loss: 0.2206\n",
      "Epoch 13, 100% \t Train loss: 0.2140 took: 2.02s  Val. loss: 0.2041\n",
      "Epoch 14, 100% \t Train loss: 0.2026 took: 2.04s  Val. loss: 0.1944\n",
      "Epoch 15, 100% \t Train loss: 0.1944 took: 2.01s  Val. loss: 0.1916\n",
      "Epoch 16, 100% \t Train loss: 0.1894 took: 2.04s  Val. loss: 0.1872\n",
      "Epoch 17, 100% \t Train loss: 0.1864 took: 2.02s  Val. loss: 0.1882\n",
      "Epoch 18, 100% \t Train loss: 0.1843 took: 2.03s  Val. loss: 0.1840\n",
      "Epoch 19, 100% \t Train loss: 0.1837 took: 1.22s  Val. loss: 0.1858\n",
      "Epoch 20, 100% \t Train loss: 0.1819 took: 1.28s  Val. loss: 0.1849\n",
      "Epoch 21, 100% \t Train loss: 0.1812 took: 1.20s  Val. loss: 0.1848\n",
      "Epoch 22, 100% \t Train loss: 0.1791 took: 1.97s  Val. loss: 0.1820\n",
      "Epoch 23, 100% \t Train loss: 0.1780 took: 2.03s  Val. loss: 0.1814\n",
      "Epoch 24, 100% \t Train loss: 0.1774 took: 2.01s  Val. loss: 0.1803\n",
      "Epoch 25, 100% \t Train loss: 0.1777 took: 2.00s  Val. loss: 0.1841\n",
      "Epoch 26, 100% \t Train loss: 0.1758 took: 2.04s  Val. loss: 0.1762\n",
      "Epoch 27, 100% \t Train loss: 0.1740 took: 1.22s  Val. loss: 0.1752\n",
      "Epoch 28, 100% \t Train loss: 0.1726 took: 1.22s  Val. loss: 0.1734\n",
      "Epoch 29, 100% \t Train loss: 0.1723 took: 1.24s  Val. loss: 0.1770\n",
      "Epoch 30, 100% \t Train loss: 0.1717 took: 1.27s  Val. loss: 0.1759\n",
      "Epoch 31, 100% \t Train loss: 0.1713 took: 1.30s  Val. loss: 0.1733\n",
      "Epoch 32, 100% \t Train loss: 0.1703 took: 1.33s  Val. loss: 0.1702\n",
      "Epoch 33, 100% \t Train loss: 0.1705 took: 1.33s  Val. loss: 0.1692\n",
      "Epoch 34, 100% \t Train loss: 0.1697 took: 1.34s  Val. loss: 0.1724\n",
      "Epoch 35, 100% \t Train loss: 0.1691 took: 1.34s  Val. loss: 0.1703\n",
      "Epoch 36, 100% \t Train loss: 0.1690 took: 1.35s  Val. loss: 0.1705\n",
      "Epoch 37, 100% \t Train loss: 0.1684 took: 1.36s  Val. loss: 0.1715\n",
      "Epoch 38, 100% \t Train loss: 0.1675 took: 1.35s  Val. loss: 0.1691\n",
      "Epoch 39, 100% \t Train loss: 0.1678 took: 1.34s  Val. loss: 0.1681\n",
      "Epoch 40, 100% \t Train loss: 0.1660 took: 1.34s  Val. loss: 0.1664\n",
      "Epoch 41, 100% \t Train loss: 0.1661 took: 1.34s  Val. loss: 0.1664\n",
      "Epoch 42, 100% \t Train loss: 0.1677 took: 1.34s  Val. loss: 0.1677\n",
      "Epoch 43, 100% \t Train loss: 0.1661 took: 1.35s  Val. loss: 0.1671\n",
      "Epoch 44, 100% \t Train loss: 0.1661 took: 1.38s  Val. loss: 0.1672\n",
      "Epoch 45, 100% \t Train loss: 0.1656 took: 1.40s  Val. loss: 0.1672\n",
      "Epoch 46, 100% \t Train loss: 0.1652 took: 1.42s  Val. loss: 0.1729\n",
      "Epoch 47, 100% \t Train loss: 0.1645 took: 1.46s  Val. loss: 0.1684\n",
      "Epoch 48, 100% \t Train loss: 0.1649 took: 1.50s  Val. loss: 0.1715\n",
      "Epoch 49, 100% \t Train loss: 0.1637 took: 1.53s  Val. loss: 0.1664\n",
      "Epoch 50, 100% \t Train loss: 0.1644 took: 1.54s  Val. loss: 0.1666\n",
      "Training finished, took 92.88s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  16\n",
      "\tinfo_channels :  8\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  32\n",
      "\tresidual_hidden_dim :  16\n",
      "\tn_residual_layers :  2\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.876883\n",
      "lambda: 0.0010 - V: 0.811771\n",
      "lambda: 0.0005 - V: 0.805665\n",
      "Average V: 0.831440\n",
      "Time elapsed: 313.04 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]\n",
      "\tmax_pool_size :  4\n",
      "\tn_features :  16\n",
      "\tinfo_channels :  6\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  12\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  4\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2595 took: 1.91s  Val. loss: 0.2516\n",
      "Epoch 2, 100% \t Train loss: 0.2587 took: 1.93s  Val. loss: 0.2519\n",
      "Epoch 3, 100% \t Train loss: 0.2586 took: 1.93s  Val. loss: 0.2530\n",
      "Epoch 4, 100% \t Train loss: 0.2588 took: 1.95s  Val. loss: 0.2518\n",
      "Epoch 5, 100% \t Train loss: 0.2587 took: 1.95s  Val. loss: 0.2518\n",
      "Epoch 6, 100% \t Train loss: 0.2586 took: 1.96s  Val. loss: 0.2514\n",
      "Epoch 7, 100% \t Train loss: 0.2536 took: 1.95s  Val. loss: 0.2312\n",
      "Epoch 8, 100% \t Train loss: 0.2151 took: 1.93s  Val. loss: 0.2034\n",
      "Epoch 9, 100% \t Train loss: 0.1992 took: 1.96s  Val. loss: 0.2006\n",
      "Epoch 10, 100% \t Train loss: 0.1961 took: 1.96s  Val. loss: 0.1943\n",
      "Epoch 11, 100% \t Train loss: 0.1915 took: 1.95s  Val. loss: 0.1949\n",
      "Epoch 12, 100% \t Train loss: 0.1887 took: 1.92s  Val. loss: 0.1941\n",
      "Epoch 13, 100% \t Train loss: 0.1877 took: 1.94s  Val. loss: 0.1906\n",
      "Epoch 14, 100% \t Train loss: 0.1843 took: 1.93s  Val. loss: 0.1926\n",
      "Epoch 15, 100% \t Train loss: 0.1842 took: 1.94s  Val. loss: 0.1949\n",
      "Epoch 16, 100% \t Train loss: 0.1832 took: 1.92s  Val. loss: 0.1909\n",
      "Epoch 17, 100% \t Train loss: 0.1816 took: 1.92s  Val. loss: 0.1911\n",
      "Epoch 18, 100% \t Train loss: 0.1798 took: 1.95s  Val. loss: 0.1860\n",
      "Epoch 19, 100% \t Train loss: 0.1769 took: 1.93s  Val. loss: 0.1817\n",
      "Epoch 20, 100% \t Train loss: 0.1741 took: 1.93s  Val. loss: 0.1813\n",
      "Epoch 21, 100% \t Train loss: 0.1686 took: 1.93s  Val. loss: 0.1747\n",
      "Epoch 22, 100% \t Train loss: 0.1651 took: 1.90s  Val. loss: 0.1690\n",
      "Epoch 23, 100% \t Train loss: 0.1598 took: 1.94s  Val. loss: 0.1668\n",
      "Epoch 24, 100% \t Train loss: 0.1566 took: 1.94s  Val. loss: 0.1619\n",
      "Epoch 25, 100% \t Train loss: 0.1533 took: 1.93s  Val. loss: 0.1629\n",
      "Epoch 26, 100% \t Train loss: 0.1507 took: 1.93s  Val. loss: 0.1635\n",
      "Epoch 27, 100% \t Train loss: 0.1469 took: 1.93s  Val. loss: 0.1569\n",
      "Epoch 28, 100% \t Train loss: 0.1442 took: 1.93s  Val. loss: 0.1507\n",
      "Epoch 29, 100% \t Train loss: 0.1419 took: 1.94s  Val. loss: 0.1531\n",
      "Epoch 30, 100% \t Train loss: 0.1406 took: 1.95s  Val. loss: 0.1486\n",
      "Epoch 31, 100% \t Train loss: 0.1396 took: 1.19s  Val. loss: 0.1506\n",
      "Epoch 32, 100% \t Train loss: 0.1369 took: 1.25s  Val. loss: 0.1496\n",
      "Epoch 33, 100% \t Train loss: 0.1390 took: 1.36s  Val. loss: 0.1530\n",
      "Epoch 34, 100% \t Train loss: 0.1363 took: 2.19s  Val. loss: 0.1461\n",
      "Epoch 35, 100% \t Train loss: 0.1345 took: 2.19s  Val. loss: 0.1469\n",
      "Epoch 36, 100% \t Train loss: 0.1333 took: 1.39s  Val. loss: 0.1558\n",
      "Epoch 37, 100% \t Train loss: 0.1343 took: 1.64s  Val. loss: 0.1485\n",
      "Epoch 38, 100% \t Train loss: 0.1329 took: 2.22s  Val. loss: 0.1429\n",
      "Epoch 39, 100% \t Train loss: 0.1324 took: 2.22s  Val. loss: 0.1408\n",
      "Epoch 40, 100% \t Train loss: 0.1323 took: 2.23s  Val. loss: 0.1463\n",
      "Epoch 41, 100% \t Train loss: 0.1304 took: 2.22s  Val. loss: 0.1427\n",
      "Epoch 42, 100% \t Train loss: 0.1298 took: 2.21s  Val. loss: 0.1434\n",
      "Epoch 43, 100% \t Train loss: 0.1294 took: 2.22s  Val. loss: 0.1450\n",
      "Epoch 44, 100% \t Train loss: 0.1309 took: 2.21s  Val. loss: 0.1392\n",
      "Epoch 45, 100% \t Train loss: 0.1271 took: 2.23s  Val. loss: 0.1416\n",
      "Epoch 46, 100% \t Train loss: 0.1290 took: 2.22s  Val. loss: 0.1393\n",
      "Epoch 47, 100% \t Train loss: 0.1264 took: 2.26s  Val. loss: 0.1395\n",
      "Epoch 48, 100% \t Train loss: 0.1277 took: 2.27s  Val. loss: 0.1390\n",
      "Epoch 49, 100% \t Train loss: 0.1262 took: 2.27s  Val. loss: 0.1387\n",
      "Epoch 50, 100% \t Train loss: 0.1267 took: 2.25s  Val. loss: 0.1373\n",
      "Training finished, took 111.33s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2589 took: 1.95s  Val. loss: 0.2577\n",
      "Epoch 2, 100% \t Train loss: 0.2578 took: 1.94s  Val. loss: 0.2589\n",
      "Epoch 3, 100% \t Train loss: 0.2573 took: 1.94s  Val. loss: 0.2566\n",
      "Epoch 4, 100% \t Train loss: 0.2532 took: 1.95s  Val. loss: 0.2443\n",
      "Epoch 5, 100% \t Train loss: 0.2284 took: 1.95s  Val. loss: 0.2082\n",
      "Epoch 6, 100% \t Train loss: 0.2064 took: 1.95s  Val. loss: 0.1989\n",
      "Epoch 7, 100% \t Train loss: 0.2005 took: 1.93s  Val. loss: 0.1982\n",
      "Epoch 8, 100% \t Train loss: 0.1974 took: 1.93s  Val. loss: 0.1959\n",
      "Epoch 9, 100% \t Train loss: 0.1990 took: 1.94s  Val. loss: 0.1956\n",
      "Epoch 10, 100% \t Train loss: 0.1951 took: 1.94s  Val. loss: 0.1934\n",
      "Epoch 11, 100% \t Train loss: 0.1943 took: 1.96s  Val. loss: 0.1959\n",
      "Epoch 12, 100% \t Train loss: 0.1928 took: 1.96s  Val. loss: 0.1918\n",
      "Epoch 13, 100% \t Train loss: 0.1907 took: 1.96s  Val. loss: 0.1923\n",
      "Epoch 14, 100% \t Train loss: 0.1906 took: 1.97s  Val. loss: 0.1921\n",
      "Epoch 15, 100% \t Train loss: 0.1901 took: 1.95s  Val. loss: 0.1930\n",
      "Epoch 16, 100% \t Train loss: 0.1899 took: 1.96s  Val. loss: 0.1922\n",
      "Epoch 17, 100% \t Train loss: 0.1897 took: 1.93s  Val. loss: 0.1919\n",
      "Epoch 18, 100% \t Train loss: 0.1894 took: 1.97s  Val. loss: 0.1918\n",
      "Epoch 19, 100% \t Train loss: 0.1880 took: 1.94s  Val. loss: 0.1924\n",
      "Epoch 20, 100% \t Train loss: 0.1879 took: 1.96s  Val. loss: 0.1905\n",
      "Epoch 21, 100% \t Train loss: 0.1867 took: 1.95s  Val. loss: 0.1908\n",
      "Epoch 22, 100% \t Train loss: 0.1881 took: 1.97s  Val. loss: 0.1920\n",
      "Epoch 23, 100% \t Train loss: 0.1869 took: 1.94s  Val. loss: 0.1884\n",
      "Epoch 24, 100% \t Train loss: 0.1850 took: 1.94s  Val. loss: 0.1889\n",
      "Epoch 25, 100% \t Train loss: 0.1852 took: 1.95s  Val. loss: 0.1893\n",
      "Epoch 26, 100% \t Train loss: 0.1836 took: 1.97s  Val. loss: 0.1859\n",
      "Epoch 27, 100% \t Train loss: 0.1826 took: 1.94s  Val. loss: 0.1854\n",
      "Epoch 28, 100% \t Train loss: 0.1815 took: 1.98s  Val. loss: 0.1828\n",
      "Epoch 29, 100% \t Train loss: 0.1807 took: 1.97s  Val. loss: 0.1867\n",
      "Epoch 30, 100% \t Train loss: 0.1778 took: 1.96s  Val. loss: 0.1881\n",
      "Epoch 31, 100% \t Train loss: 0.1766 took: 1.96s  Val. loss: 0.1807\n",
      "Epoch 32, 100% \t Train loss: 0.1747 took: 1.98s  Val. loss: 0.1784\n",
      "Epoch 33, 100% \t Train loss: 0.1734 took: 2.00s  Val. loss: 0.1763\n",
      "Epoch 34, 100% \t Train loss: 0.1726 took: 1.99s  Val. loss: 0.1752\n",
      "Epoch 35, 100% \t Train loss: 0.1704 took: 1.97s  Val. loss: 0.1745\n",
      "Epoch 36, 100% \t Train loss: 0.1697 took: 1.97s  Val. loss: 0.1752\n",
      "Epoch 37, 100% \t Train loss: 0.1681 took: 2.01s  Val. loss: 0.1741\n",
      "Epoch 38, 100% \t Train loss: 0.1668 took: 1.97s  Val. loss: 0.1735\n",
      "Epoch 39, 100% \t Train loss: 0.1661 took: 2.00s  Val. loss: 0.1715\n",
      "Epoch 40, 100% \t Train loss: 0.1647 took: 1.99s  Val. loss: 0.1694\n",
      "Epoch 41, 100% \t Train loss: 0.1637 took: 1.99s  Val. loss: 0.1675\n",
      "Epoch 42, 100% \t Train loss: 0.1622 took: 2.00s  Val. loss: 0.1714\n",
      "Epoch 43, 100% \t Train loss: 0.1621 took: 2.01s  Val. loss: 0.1687\n",
      "Epoch 44, 100% \t Train loss: 0.1612 took: 1.98s  Val. loss: 0.1647\n",
      "Epoch 45, 100% \t Train loss: 0.1592 took: 1.99s  Val. loss: 0.1643\n",
      "Epoch 46, 100% \t Train loss: 0.1577 took: 1.99s  Val. loss: 0.1686\n",
      "Epoch 47, 100% \t Train loss: 0.1584 took: 2.02s  Val. loss: 0.1629\n",
      "Epoch 48, 100% \t Train loss: 0.1557 took: 2.00s  Val. loss: 0.1621\n",
      "Epoch 49, 100% \t Train loss: 0.1545 took: 2.01s  Val. loss: 0.1599\n",
      "Epoch 50, 100% \t Train loss: 0.1548 took: 2.01s  Val. loss: 0.1607\n",
      "Training finished, took 111.24s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2590 took: 1.97s  Val. loss: 0.2572\n",
      "Epoch 2, 100% \t Train loss: 0.2587 took: 1.98s  Val. loss: 0.2571\n",
      "Epoch 3, 100% \t Train loss: 0.2578 took: 1.97s  Val. loss: 0.2556\n",
      "Epoch 4, 100% \t Train loss: 0.2553 took: 1.96s  Val. loss: 0.2505\n",
      "Epoch 5, 100% \t Train loss: 0.2456 took: 1.96s  Val. loss: 0.2354\n",
      "Epoch 6, 100% \t Train loss: 0.2241 took: 1.95s  Val. loss: 0.2178\n",
      "Epoch 7, 100% \t Train loss: 0.2095 took: 1.97s  Val. loss: 0.2113\n",
      "Epoch 8, 100% \t Train loss: 0.2036 took: 1.95s  Val. loss: 0.2062\n",
      "Epoch 9, 100% \t Train loss: 0.2020 took: 1.96s  Val. loss: 0.2061\n",
      "Epoch 10, 100% \t Train loss: 0.1982 took: 1.96s  Val. loss: 0.2036\n",
      "Epoch 11, 100% \t Train loss: 0.1969 took: 1.97s  Val. loss: 0.2055\n",
      "Epoch 12, 100% \t Train loss: 0.1985 took: 1.95s  Val. loss: 0.2019\n",
      "Epoch 13, 100% \t Train loss: 0.1967 took: 1.94s  Val. loss: 0.2006\n",
      "Epoch 14, 100% \t Train loss: 0.1965 took: 1.94s  Val. loss: 0.2026\n",
      "Epoch 15, 100% \t Train loss: 0.1952 took: 1.98s  Val. loss: 0.2027\n",
      "Epoch 16, 100% \t Train loss: 0.1944 took: 1.94s  Val. loss: 0.2007\n",
      "Epoch 17, 100% \t Train loss: 0.1953 took: 1.92s  Val. loss: 0.2055\n",
      "Epoch 18, 100% \t Train loss: 0.1943 took: 1.92s  Val. loss: 0.2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1929 took: 1.96s  Val. loss: 0.2011\n",
      "Epoch 20, 100% \t Train loss: 0.1930 took: 1.93s  Val. loss: 0.2023\n",
      "Epoch 21, 100% \t Train loss: 0.1937 took: 1.95s  Val. loss: 0.1987\n",
      "Epoch 22, 100% \t Train loss: 0.1936 took: 1.95s  Val. loss: 0.2026\n",
      "Epoch 23, 100% \t Train loss: 0.1926 took: 1.96s  Val. loss: 0.1991\n",
      "Epoch 24, 100% \t Train loss: 0.1936 took: 1.97s  Val. loss: 0.1995\n",
      "Epoch 25, 100% \t Train loss: 0.1916 took: 1.96s  Val. loss: 0.1970\n",
      "Epoch 26, 100% \t Train loss: 0.1906 took: 1.96s  Val. loss: 0.1966\n",
      "Epoch 27, 100% \t Train loss: 0.1912 took: 1.96s  Val. loss: 0.1964\n",
      "Epoch 28, 100% \t Train loss: 0.1905 took: 1.97s  Val. loss: 0.1987\n",
      "Epoch 29, 100% \t Train loss: 0.1902 took: 1.97s  Val. loss: 0.1991\n",
      "Epoch 30, 100% \t Train loss: 0.1904 took: 1.96s  Val. loss: 0.1955\n",
      "Epoch 31, 100% \t Train loss: 0.1883 took: 1.97s  Val. loss: 0.1948\n",
      "Epoch 32, 100% \t Train loss: 0.1874 took: 1.96s  Val. loss: 0.1944\n",
      "Epoch 33, 100% \t Train loss: 0.1880 took: 1.97s  Val. loss: 0.1966\n",
      "Epoch 34, 100% \t Train loss: 0.1886 took: 1.95s  Val. loss: 0.1955\n",
      "Epoch 35, 100% \t Train loss: 0.1879 took: 1.96s  Val. loss: 0.1941\n",
      "Epoch 36, 100% \t Train loss: 0.1886 took: 1.96s  Val. loss: 0.1947\n",
      "Epoch 37, 100% \t Train loss: 0.1862 took: 1.95s  Val. loss: 0.1934\n",
      "Epoch 38, 100% \t Train loss: 0.1873 took: 1.96s  Val. loss: 0.1937\n",
      "Epoch 39, 100% \t Train loss: 0.1843 took: 1.96s  Val. loss: 0.1945\n",
      "Epoch 40, 100% \t Train loss: 0.1849 took: 1.97s  Val. loss: 0.2008\n",
      "Epoch 41, 100% \t Train loss: 0.1846 took: 1.95s  Val. loss: 0.1937\n",
      "Epoch 42, 100% \t Train loss: 0.1825 took: 1.96s  Val. loss: 0.1932\n",
      "Epoch 43, 100% \t Train loss: 0.1845 took: 1.96s  Val. loss: 0.1919\n",
      "Epoch 44, 100% \t Train loss: 0.1822 took: 1.94s  Val. loss: 0.1896\n",
      "Epoch 45, 100% \t Train loss: 0.1806 took: 1.95s  Val. loss: 0.1881\n",
      "Epoch 46, 100% \t Train loss: 0.1800 took: 1.97s  Val. loss: 0.1907\n",
      "Epoch 47, 100% \t Train loss: 0.1801 took: 1.96s  Val. loss: 0.1859\n",
      "Epoch 48, 100% \t Train loss: 0.1782 took: 1.98s  Val. loss: 0.1849\n",
      "Epoch 49, 100% \t Train loss: 0.1773 took: 1.97s  Val. loss: 0.1856\n",
      "Epoch 50, 100% \t Train loss: 0.1769 took: 1.15s  Val. loss: 0.1833\n",
      "Training finished, took 109.79s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]\n",
      "\tmax_pool_size :  4\n",
      "\tn_features :  16\n",
      "\tinfo_channels :  6\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  12\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  4\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.825324\n",
      "lambda: 0.0010 - V: 0.811799\n",
      "lambda: 0.0005 - V: 0.797035\n",
      "Average V: 0.811386\n",
      "Time elapsed: 335.79 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  2\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  6\n",
      "\tmask_channels :  6\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  4\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 1.89s  Val. loss: 0.2565\n",
      "Epoch 2, 100% \t Train loss: 0.2575 took: 1.90s  Val. loss: 0.2594\n",
      "Epoch 3, 100% \t Train loss: 0.2574 took: 1.89s  Val. loss: 0.2584\n",
      "Epoch 4, 100% \t Train loss: 0.2571 took: 1.91s  Val. loss: 0.2564\n",
      "Epoch 5, 100% \t Train loss: 0.2570 took: 1.90s  Val. loss: 0.2556\n",
      "Epoch 6, 100% \t Train loss: 0.2389 took: 1.88s  Val. loss: 0.2008\n",
      "Epoch 7, 100% \t Train loss: 0.1839 took: 1.88s  Val. loss: 0.1810\n",
      "Epoch 8, 100% \t Train loss: 0.1701 took: 1.88s  Val. loss: 0.1779\n",
      "Epoch 9, 100% \t Train loss: 0.1692 took: 1.87s  Val. loss: 0.1732\n",
      "Epoch 10, 100% \t Train loss: 0.1662 took: 1.89s  Val. loss: 0.1788\n",
      "Epoch 11, 100% \t Train loss: 0.1652 took: 1.87s  Val. loss: 0.1761\n",
      "Epoch 12, 100% \t Train loss: 0.1655 took: 1.87s  Val. loss: 0.1772\n",
      "Epoch 13, 100% \t Train loss: 0.1645 took: 1.87s  Val. loss: 0.1718\n",
      "Epoch 14, 100% \t Train loss: 0.1635 took: 1.87s  Val. loss: 0.1759\n",
      "Epoch 15, 100% \t Train loss: 0.1630 took: 1.87s  Val. loss: 0.1736\n",
      "Epoch 16, 100% \t Train loss: 0.1626 took: 1.87s  Val. loss: 0.1705\n",
      "Epoch 17, 100% \t Train loss: 0.1644 took: 1.89s  Val. loss: 0.1783\n",
      "Epoch 18, 100% \t Train loss: 0.1635 took: 1.89s  Val. loss: 0.1745\n",
      "Epoch 19, 100% \t Train loss: 0.1621 took: 1.91s  Val. loss: 0.1765\n",
      "Epoch 20, 100% \t Train loss: 0.1625 took: 1.90s  Val. loss: 0.1713\n",
      "Epoch 21, 100% \t Train loss: 0.1614 took: 1.89s  Val. loss: 0.1737\n",
      "Epoch 22, 100% \t Train loss: 0.1599 took: 1.89s  Val. loss: 0.1777\n",
      "Epoch 23, 100% \t Train loss: 0.1601 took: 1.90s  Val. loss: 0.1789\n",
      "Epoch 24, 100% \t Train loss: 0.1617 took: 1.90s  Val. loss: 0.1703\n",
      "Epoch 25, 100% \t Train loss: 0.1620 took: 1.91s  Val. loss: 0.1742\n",
      "Epoch 26, 100% \t Train loss: 0.1579 took: 1.94s  Val. loss: 0.1735\n",
      "Epoch 27, 100% \t Train loss: 0.1574 took: 1.93s  Val. loss: 0.1714\n",
      "Epoch 28, 100% \t Train loss: 0.1546 took: 1.89s  Val. loss: 0.1680\n",
      "Epoch 29, 100% \t Train loss: 0.1531 took: 1.89s  Val. loss: 0.1664\n",
      "Epoch 30, 100% \t Train loss: 0.1524 took: 1.93s  Val. loss: 0.1685\n",
      "Epoch 31, 100% \t Train loss: 0.1504 took: 1.92s  Val. loss: 0.1694\n",
      "Epoch 32, 100% \t Train loss: 0.1505 took: 1.91s  Val. loss: 0.1659\n",
      "Epoch 33, 100% \t Train loss: 0.1476 took: 1.95s  Val. loss: 0.1672\n",
      "Epoch 34, 100% \t Train loss: 0.1452 took: 1.95s  Val. loss: 0.1617\n",
      "Epoch 35, 100% \t Train loss: 0.1441 took: 1.94s  Val. loss: 0.1582\n",
      "Epoch 36, 100% \t Train loss: 0.1394 took: 1.93s  Val. loss: 0.1556\n",
      "Epoch 37, 100% \t Train loss: 0.1352 took: 1.94s  Val. loss: 0.1545\n",
      "Epoch 38, 100% \t Train loss: 0.1332 took: 1.96s  Val. loss: 0.1561\n",
      "Epoch 39, 100% \t Train loss: 0.1286 took: 1.95s  Val. loss: 0.1447\n",
      "Epoch 40, 100% \t Train loss: 0.1261 took: 1.95s  Val. loss: 0.1398\n",
      "Epoch 41, 100% \t Train loss: 0.1235 took: 1.94s  Val. loss: 0.1427\n",
      "Epoch 42, 100% \t Train loss: 0.1164 took: 1.95s  Val. loss: 0.1294\n",
      "Epoch 43, 100% \t Train loss: 0.1120 took: 1.95s  Val. loss: 0.1288\n",
      "Epoch 44, 100% \t Train loss: 0.1090 took: 1.93s  Val. loss: 0.1247\n",
      "Epoch 45, 100% \t Train loss: 0.1039 took: 1.95s  Val. loss: 0.1207\n",
      "Epoch 46, 100% \t Train loss: 0.1002 took: 1.94s  Val. loss: 0.1189\n",
      "Epoch 47, 100% \t Train loss: 0.0955 took: 1.94s  Val. loss: 0.1095\n",
      "Epoch 48, 100% \t Train loss: 0.0935 took: 1.93s  Val. loss: 0.1146\n",
      "Epoch 49, 100% \t Train loss: 0.0921 took: 1.92s  Val. loss: 0.1068\n",
      "Epoch 50, 100% \t Train loss: 0.0890 took: 1.92s  Val. loss: 0.1055\n",
      "Training finished, took 108.21s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2603 took: 1.88s  Val. loss: 0.2611\n",
      "Epoch 2, 100% \t Train loss: 0.2591 took: 1.86s  Val. loss: 0.2603\n",
      "Epoch 3, 100% \t Train loss: 0.2571 took: 1.90s  Val. loss: 0.2533\n",
      "Epoch 4, 100% \t Train loss: 0.2338 took: 1.87s  Val. loss: 0.2281\n",
      "Epoch 5, 100% \t Train loss: 0.2081 took: 1.87s  Val. loss: 0.2063\n",
      "Epoch 6, 100% \t Train loss: 0.1890 took: 1.86s  Val. loss: 0.1913\n",
      "Epoch 7, 100% \t Train loss: 0.1832 took: 1.88s  Val. loss: 0.1925\n",
      "Epoch 8, 100% \t Train loss: 0.1814 took: 1.89s  Val. loss: 0.1859\n",
      "Epoch 9, 100% \t Train loss: 0.1758 took: 1.88s  Val. loss: 0.1895\n",
      "Epoch 10, 100% \t Train loss: 0.1756 took: 1.87s  Val. loss: 0.1818\n",
      "Epoch 11, 100% \t Train loss: 0.1729 took: 1.85s  Val. loss: 0.1816\n",
      "Epoch 12, 100% \t Train loss: 0.1705 took: 1.87s  Val. loss: 0.1815\n",
      "Epoch 13, 100% \t Train loss: 0.1702 took: 1.85s  Val. loss: 0.1804\n",
      "Epoch 14, 100% \t Train loss: 0.1700 took: 1.89s  Val. loss: 0.1837\n",
      "Epoch 15, 100% \t Train loss: 0.1649 took: 1.87s  Val. loss: 0.1841\n",
      "Epoch 16, 100% \t Train loss: 0.1642 took: 1.86s  Val. loss: 0.1836\n",
      "Epoch 17, 100% \t Train loss: 0.1629 took: 1.88s  Val. loss: 0.1720\n",
      "Epoch 18, 100% \t Train loss: 0.1599 took: 1.88s  Val. loss: 0.1707\n",
      "Epoch 19, 100% \t Train loss: 0.1547 took: 1.88s  Val. loss: 0.1763\n",
      "Epoch 20, 100% \t Train loss: 0.1523 took: 1.88s  Val. loss: 0.1659\n",
      "Epoch 21, 100% \t Train loss: 0.1467 took: 1.88s  Val. loss: 0.1551\n",
      "Epoch 22, 100% \t Train loss: 0.1432 took: 1.88s  Val. loss: 0.1543\n",
      "Epoch 23, 100% \t Train loss: 0.1397 took: 1.89s  Val. loss: 0.1509\n",
      "Epoch 24, 100% \t Train loss: 0.1368 took: 1.89s  Val. loss: 0.1449\n",
      "Epoch 25, 100% \t Train loss: 0.1351 took: 1.90s  Val. loss: 0.1433\n",
      "Epoch 26, 100% \t Train loss: 0.1303 took: 1.91s  Val. loss: 0.1383\n",
      "Epoch 27, 100% \t Train loss: 0.1278 took: 1.88s  Val. loss: 0.1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, 100% \t Train loss: 0.1218 took: 1.88s  Val. loss: 0.1332\n",
      "Epoch 29, 100% \t Train loss: 0.1188 took: 1.41s  Val. loss: 0.1276\n",
      "Epoch 30, 100% \t Train loss: 0.1178 took: 1.89s  Val. loss: 0.1215\n",
      "Epoch 31, 100% \t Train loss: 0.1118 took: 1.91s  Val. loss: 0.1201\n",
      "Epoch 32, 100% \t Train loss: 0.1109 took: 1.91s  Val. loss: 0.1198\n",
      "Epoch 33, 100% \t Train loss: 0.1107 took: 1.91s  Val. loss: 0.1142\n",
      "Epoch 34, 100% \t Train loss: 0.1038 took: 1.95s  Val. loss: 0.1145\n",
      "Epoch 35, 100% \t Train loss: 0.1029 took: 1.96s  Val. loss: 0.1101\n",
      "Epoch 36, 100% \t Train loss: 0.1015 took: 1.95s  Val. loss: 0.1114\n",
      "Epoch 37, 100% \t Train loss: 0.0994 took: 1.96s  Val. loss: 0.1085\n",
      "Epoch 38, 100% \t Train loss: 0.0976 took: 1.98s  Val. loss: 0.1048\n",
      "Epoch 39, 100% \t Train loss: 0.0947 took: 1.97s  Val. loss: 0.1129\n",
      "Epoch 40, 100% \t Train loss: 0.0940 took: 1.99s  Val. loss: 0.1030\n",
      "Epoch 41, 100% \t Train loss: 0.0941 took: 1.99s  Val. loss: 0.1035\n",
      "Epoch 42, 100% \t Train loss: 0.0921 took: 1.20s  Val. loss: 0.1086\n",
      "Epoch 43, 100% \t Train loss: 0.0917 took: 1.20s  Val. loss: 0.1014\n",
      "Epoch 44, 100% \t Train loss: 0.0891 took: 1.21s  Val. loss: 0.1057\n",
      "Epoch 45, 100% \t Train loss: 0.0884 took: 1.22s  Val. loss: 0.1073\n",
      "Epoch 46, 100% \t Train loss: 0.0869 took: 1.22s  Val. loss: 0.0983\n",
      "Epoch 47, 100% \t Train loss: 0.0877 took: 1.22s  Val. loss: 0.0972\n",
      "Epoch 48, 100% \t Train loss: 0.0856 took: 1.24s  Val. loss: 0.1040\n",
      "Epoch 49, 100% \t Train loss: 0.0853 took: 1.23s  Val. loss: 0.0965\n",
      "Epoch 50, 100% \t Train loss: 0.0865 took: 1.24s  Val. loss: 0.0996\n",
      "Training finished, took 99.85s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2557 took: 1.90s  Val. loss: 0.2586\n",
      "Epoch 2, 100% \t Train loss: 0.2553 took: 1.92s  Val. loss: 0.2573\n",
      "Epoch 3, 100% \t Train loss: 0.2550 took: 1.92s  Val. loss: 0.2574\n",
      "Epoch 4, 100% \t Train loss: 0.2548 took: 1.10s  Val. loss: 0.2591\n",
      "Epoch 5, 100% \t Train loss: 0.2545 took: 1.11s  Val. loss: 0.2577\n",
      "Epoch 6, 100% \t Train loss: 0.2516 took: 1.10s  Val. loss: 0.2496\n",
      "Epoch 7, 100% \t Train loss: 0.2428 took: 1.11s  Val. loss: 0.2401\n",
      "Epoch 8, 100% \t Train loss: 0.2206 took: 1.90s  Val. loss: 0.2137\n",
      "Epoch 9, 100% \t Train loss: 0.2016 took: 1.89s  Val. loss: 0.1940\n",
      "Epoch 10, 100% \t Train loss: 0.1948 took: 1.88s  Val. loss: 0.1902\n",
      "Epoch 11, 100% \t Train loss: 0.1921 took: 1.91s  Val. loss: 0.1913\n",
      "Epoch 12, 100% \t Train loss: 0.1909 took: 1.89s  Val. loss: 0.1928\n",
      "Epoch 13, 100% \t Train loss: 0.1911 took: 1.89s  Val. loss: 0.1942\n",
      "Epoch 14, 100% \t Train loss: 0.1922 took: 1.90s  Val. loss: 0.1876\n",
      "Epoch 15, 100% \t Train loss: 0.1870 took: 1.90s  Val. loss: 0.1953\n",
      "Epoch 16, 100% \t Train loss: 0.1872 took: 1.91s  Val. loss: 0.1864\n",
      "Epoch 17, 100% \t Train loss: 0.1885 took: 1.91s  Val. loss: 0.2040\n",
      "Epoch 18, 100% \t Train loss: 0.1857 took: 1.90s  Val. loss: 0.1868\n",
      "Epoch 19, 100% \t Train loss: 0.1828 took: 1.91s  Val. loss: 0.1831\n",
      "Epoch 20, 100% \t Train loss: 0.1832 took: 1.87s  Val. loss: 0.1862\n",
      "Epoch 21, 100% \t Train loss: 0.1831 took: 1.88s  Val. loss: 0.1887\n",
      "Epoch 22, 100% \t Train loss: 0.1835 took: 1.88s  Val. loss: 0.1845\n",
      "Epoch 23, 100% \t Train loss: 0.1814 took: 1.10s  Val. loss: 0.1799\n",
      "Epoch 24, 100% \t Train loss: 0.1833 took: 1.10s  Val. loss: 0.1848\n",
      "Epoch 25, 100% \t Train loss: 0.1804 took: 1.10s  Val. loss: 0.1799\n",
      "Epoch 26, 100% \t Train loss: 0.1830 took: 1.10s  Val. loss: 0.1883\n",
      "Epoch 27, 100% \t Train loss: 0.1780 took: 1.10s  Val. loss: 0.1801\n",
      "Epoch 28, 100% \t Train loss: 0.1822 took: 1.11s  Val. loss: 0.1771\n",
      "Epoch 29, 100% \t Train loss: 0.1793 took: 1.11s  Val. loss: 0.1766\n",
      "Epoch 30, 100% \t Train loss: 0.1772 took: 1.12s  Val. loss: 0.1818\n",
      "Epoch 31, 100% \t Train loss: 0.1772 took: 1.12s  Val. loss: 0.1749\n",
      "Epoch 32, 100% \t Train loss: 0.1759 took: 1.12s  Val. loss: 0.1785\n",
      "Epoch 33, 100% \t Train loss: 0.1729 took: 1.11s  Val. loss: 0.1730\n",
      "Epoch 34, 100% \t Train loss: 0.1735 took: 1.12s  Val. loss: 0.1710\n",
      "Epoch 35, 100% \t Train loss: 0.1761 took: 1.12s  Val. loss: 0.1747\n",
      "Epoch 36, 100% \t Train loss: 0.1751 took: 1.12s  Val. loss: 0.1886\n",
      "Epoch 37, 100% \t Train loss: 0.1766 took: 1.13s  Val. loss: 0.1740\n",
      "Epoch 38, 100% \t Train loss: 0.1740 took: 1.13s  Val. loss: 0.1732\n",
      "Epoch 39, 100% \t Train loss: 0.1749 took: 1.13s  Val. loss: 0.1805\n",
      "Epoch 40, 100% \t Train loss: 0.1730 took: 1.35s  Val. loss: 0.1745\n",
      "Epoch 41, 100% \t Train loss: 0.1712 took: 1.91s  Val. loss: 0.1730\n",
      "Epoch 42, 100% \t Train loss: 0.1700 took: 1.91s  Val. loss: 0.1735\n",
      "Epoch 43, 100% \t Train loss: 0.1691 took: 1.91s  Val. loss: 0.1668\n",
      "Epoch 44, 100% \t Train loss: 0.1692 took: 1.92s  Val. loss: 0.1780\n",
      "Epoch 45, 100% \t Train loss: 0.1683 took: 1.91s  Val. loss: 0.1741\n",
      "Epoch 46, 100% \t Train loss: 0.1693 took: 1.93s  Val. loss: 0.1744\n",
      "Epoch 47, 100% \t Train loss: 0.1664 took: 1.93s  Val. loss: 0.1682\n",
      "Epoch 48, 100% \t Train loss: 0.1634 took: 1.91s  Val. loss: 0.1645\n",
      "Epoch 49, 100% \t Train loss: 0.1675 took: 1.92s  Val. loss: 0.1686\n",
      "Epoch 50, 100% \t Train loss: 0.1664 took: 1.94s  Val. loss: 0.1653\n",
      "Training finished, took 88.27s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  2\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  6\n",
      "\tmask_channels :  6\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  32\n",
      "\tn_residual_layers :  4\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.831176\n",
      "lambda: 0.0010 - V: 0.850408\n",
      "lambda: 0.0005 - V: 0.808465\n",
      "Average V: 0.830017\n",
      "Time elapsed: 299.81 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  16\n",
      "\tinfo_channels :  8\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  32\n",
      "\tresidual_hidden_dim :  64\n",
      "\tn_residual_layers :  2\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 2.53s  Val. loss: 0.2578\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 2.55s  Val. loss: 0.2585\n",
      "Epoch 3, 100% \t Train loss: 0.2581 took: 2.54s  Val. loss: 0.2593\n",
      "Epoch 4, 100% \t Train loss: 0.2579 took: 2.52s  Val. loss: 0.2576\n",
      "Epoch 5, 100% \t Train loss: 0.2579 took: 2.50s  Val. loss: 0.2605\n",
      "Epoch 6, 100% \t Train loss: 0.2579 took: 2.52s  Val. loss: 0.2586\n",
      "Epoch 7, 100% \t Train loss: 0.2579 took: 2.51s  Val. loss: 0.2590\n",
      "Epoch 8, 100% \t Train loss: 0.2578 took: 2.52s  Val. loss: 0.2580\n",
      "Epoch 9, 100% \t Train loss: 0.2578 took: 2.54s  Val. loss: 0.2583\n",
      "Epoch 10, 100% \t Train loss: 0.2581 took: 2.52s  Val. loss: 0.2591\n",
      "Epoch 11, 100% \t Train loss: 0.2579 took: 2.52s  Val. loss: 0.2589\n",
      "Epoch 12, 100% \t Train loss: 0.2580 took: 2.52s  Val. loss: 0.2583\n",
      "Epoch 13, 100% \t Train loss: 0.2580 took: 2.52s  Val. loss: 0.2593\n",
      "Epoch 14, 100% \t Train loss: 0.2579 took: 2.52s  Val. loss: 0.2588\n",
      "Epoch 15, 100% \t Train loss: 0.2579 took: 2.52s  Val. loss: 0.2597\n",
      "Epoch 16, 100% \t Train loss: 0.2579 took: 2.55s  Val. loss: 0.2587\n",
      "Epoch 17, 100% \t Train loss: 0.2578 took: 2.54s  Val. loss: 0.2582\n",
      "Epoch 18, 100% \t Train loss: 0.2578 took: 2.53s  Val. loss: 0.2580\n",
      "Epoch 19, 100% \t Train loss: 0.2578 took: 2.50s  Val. loss: 0.2592\n",
      "Epoch 20, 100% \t Train loss: 0.2579 took: 2.53s  Val. loss: 0.2586\n",
      "Epoch 21, 100% \t Train loss: 0.2578 took: 2.50s  Val. loss: 0.2587\n",
      "Epoch 22, 100% \t Train loss: 0.2578 took: 2.50s  Val. loss: 0.2581\n",
      "Epoch 23, 100% \t Train loss: 0.2578 took: 2.55s  Val. loss: 0.2584\n",
      "Epoch 24, 100% \t Train loss: 0.2579 took: 2.54s  Val. loss: 0.2584\n",
      "Epoch 25, 100% \t Train loss: 0.2579 took: 2.55s  Val. loss: 0.2594\n",
      "Epoch 26, 100% \t Train loss: 0.2578 took: 2.53s  Val. loss: 0.2576\n",
      "Epoch 27, 100% \t Train loss: 0.2579 took: 2.54s  Val. loss: 0.2587\n",
      "Epoch 28, 100% \t Train loss: 0.2578 took: 2.54s  Val. loss: 0.2587\n",
      "Epoch 29, 100% \t Train loss: 0.2578 took: 2.57s  Val. loss: 0.2583\n",
      "Epoch 30, 100% \t Train loss: 0.2578 took: 2.60s  Val. loss: 0.2595\n",
      "Epoch 31, 100% \t Train loss: 0.2578 took: 2.90s  Val. loss: 0.2578\n",
      "Epoch 32, 100% \t Train loss: 0.2579 took: 3.71s  Val. loss: 0.2586\n",
      "Epoch 33, 100% \t Train loss: 0.2579 took: 4.28s  Val. loss: 0.2587\n",
      "Epoch 34, 100% \t Train loss: 0.2578 took: 4.23s  Val. loss: 0.2592\n",
      "Epoch 35, 100% \t Train loss: 0.2579 took: 4.30s  Val. loss: 0.2593\n",
      "Epoch 36, 100% \t Train loss: 0.2578 took: 4.44s  Val. loss: 0.2585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, 100% \t Train loss: 0.2578 took: 4.40s  Val. loss: 0.2589\n",
      "Epoch 38, 100% \t Train loss: 0.2578 took: 4.44s  Val. loss: 0.2591\n",
      "Epoch 39, 100% \t Train loss: 0.2578 took: 4.50s  Val. loss: 0.2584\n",
      "Epoch 40, 100% \t Train loss: 0.2578 took: 4.44s  Val. loss: 0.2596\n",
      "Epoch 41, 100% \t Train loss: 0.2578 took: 4.53s  Val. loss: 0.2584\n",
      "Epoch 42, 100% \t Train loss: 0.2578 took: 4.68s  Val. loss: 0.2582\n",
      "Epoch 43, 100% \t Train loss: 0.2578 took: 4.55s  Val. loss: 0.2587\n",
      "Epoch 44, 100% \t Train loss: 0.2578 took: 4.62s  Val. loss: 0.2594\n",
      "Epoch 45, 100% \t Train loss: 0.2578 took: 4.76s  Val. loss: 0.2578\n",
      "Epoch 46, 100% \t Train loss: 0.2578 took: 4.74s  Val. loss: 0.2589\n",
      "Epoch 47, 100% \t Train loss: 0.2578 took: 4.72s  Val. loss: 0.2577\n",
      "Epoch 48, 100% \t Train loss: 0.2578 took: 4.94s  Val. loss: 0.2585\n",
      "Epoch 49, 100% \t Train loss: 0.2578 took: 4.91s  Val. loss: 0.2589\n",
      "Epoch 50, 100% \t Train loss: 0.2578 took: 5.03s  Val. loss: 0.2583\n",
      "Training finished, took 184.38s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2596 took: 2.53s  Val. loss: 0.2559\n",
      "Epoch 2, 100% \t Train loss: 0.2595 took: 2.50s  Val. loss: 0.2555\n",
      "Epoch 3, 100% \t Train loss: 0.2594 took: 2.53s  Val. loss: 0.2548\n",
      "Epoch 4, 100% \t Train loss: 0.2593 took: 2.51s  Val. loss: 0.2542\n",
      "Epoch 5, 100% \t Train loss: 0.2594 took: 2.51s  Val. loss: 0.2557\n",
      "Epoch 6, 100% \t Train loss: 0.2594 took: 2.49s  Val. loss: 0.2544\n",
      "Epoch 7, 100% \t Train loss: 0.2594 took: 2.51s  Val. loss: 0.2543\n",
      "Epoch 8, 100% \t Train loss: 0.2594 took: 2.51s  Val. loss: 0.2541\n",
      "Epoch 9, 100% \t Train loss: 0.2593 took: 2.52s  Val. loss: 0.2544\n",
      "Epoch 10, 100% \t Train loss: 0.2592 took: 2.50s  Val. loss: 0.2540\n",
      "Epoch 11, 100% \t Train loss: 0.2592 took: 2.53s  Val. loss: 0.2548\n",
      "Epoch 12, 100% \t Train loss: 0.2591 took: 2.54s  Val. loss: 0.2546\n",
      "Epoch 13, 100% \t Train loss: 0.2593 took: 2.51s  Val. loss: 0.2546\n",
      "Epoch 14, 100% \t Train loss: 0.2592 took: 2.50s  Val. loss: 0.2557\n",
      "Epoch 15, 100% \t Train loss: 0.2594 took: 2.49s  Val. loss: 0.2558\n",
      "Epoch 16, 100% \t Train loss: 0.2593 took: 2.51s  Val. loss: 0.2547\n",
      "Epoch 17, 100% \t Train loss: 0.2592 took: 2.51s  Val. loss: 0.2552\n",
      "Epoch 18, 100% \t Train loss: 0.2593 took: 2.51s  Val. loss: 0.2549\n",
      "Epoch 19, 100% \t Train loss: 0.2593 took: 2.53s  Val. loss: 0.2554\n",
      "Epoch 20, 100% \t Train loss: 0.2593 took: 2.49s  Val. loss: 0.2553\n",
      "Epoch 21, 100% \t Train loss: 0.2593 took: 2.52s  Val. loss: 0.2547\n",
      "Epoch 22, 100% \t Train loss: 0.2592 took: 2.53s  Val. loss: 0.2547\n",
      "Epoch 23, 100% \t Train loss: 0.2592 took: 2.52s  Val. loss: 0.2542\n",
      "Epoch 24, 100% \t Train loss: 0.2593 took: 2.54s  Val. loss: 0.2543\n",
      "Epoch 25, 100% \t Train loss: 0.2593 took: 2.55s  Val. loss: 0.2549\n",
      "Epoch 26, 100% \t Train loss: 0.2592 took: 2.57s  Val. loss: 0.2542\n",
      "Epoch 27, 100% \t Train loss: 0.2592 took: 2.60s  Val. loss: 0.2547\n",
      "Epoch 28, 100% \t Train loss: 0.2592 took: 2.64s  Val. loss: 0.2540\n",
      "Epoch 29, 100% \t Train loss: 0.2592 took: 2.69s  Val. loss: 0.2551\n",
      "Epoch 30, 100% \t Train loss: 0.2593 took: 2.78s  Val. loss: 0.2548\n",
      "Epoch 31, 100% \t Train loss: 0.2592 took: 2.84s  Val. loss: 0.2540\n",
      "Epoch 32, 100% \t Train loss: 0.2592 took: 2.92s  Val. loss: 0.2546\n",
      "Epoch 33, 100% \t Train loss: 0.2592 took: 2.21s  Val. loss: 0.2550\n",
      "Epoch 34, 100% \t Train loss: 0.2592 took: 2.04s  Val. loss: 0.2545\n",
      "Epoch 35, 100% \t Train loss: 0.2593 took: 2.42s  Val. loss: 0.2553\n",
      "Epoch 36, 100% \t Train loss: 0.2592 took: 2.98s  Val. loss: 0.2557\n",
      "Epoch 37, 100% \t Train loss: 0.2592 took: 2.98s  Val. loss: 0.2548\n",
      "Epoch 38, 100% \t Train loss: 0.2592 took: 3.00s  Val. loss: 0.2554\n",
      "Epoch 39, 100% \t Train loss: 0.2592 took: 2.93s  Val. loss: 0.2542\n",
      "Epoch 40, 100% \t Train loss: 0.2592 took: 3.03s  Val. loss: 0.2548\n",
      "Epoch 41, 100% \t Train loss: 0.2592 took: 3.07s  Val. loss: 0.2548\n",
      "Epoch 42, 100% \t Train loss: 0.2592 took: 3.14s  Val. loss: 0.2551\n",
      "Epoch 43, 100% \t Train loss: 0.2592 took: 3.12s  Val. loss: 0.2545\n",
      "Epoch 44, 100% \t Train loss: 0.2592 took: 3.05s  Val. loss: 0.2548\n",
      "Epoch 45, 100% \t Train loss: 0.2592 took: 3.32s  Val. loss: 0.2549\n",
      "Epoch 46, 100% \t Train loss: 0.2592 took: 3.88s  Val. loss: 0.2543\n",
      "Epoch 47, 100% \t Train loss: 0.2592 took: 3.96s  Val. loss: 0.2551\n",
      "Epoch 48, 100% \t Train loss: 0.2592 took: 4.10s  Val. loss: 0.2549\n",
      "Epoch 49, 100% \t Train loss: 0.2592 took: 4.35s  Val. loss: 0.2543\n",
      "Epoch 50, 100% \t Train loss: 0.2592 took: 4.42s  Val. loss: 0.2548\n",
      "Training finished, took 154.36s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2580 took: 2.54s  Val. loss: 0.2629\n",
      "Epoch 2, 100% \t Train loss: 0.2576 took: 2.51s  Val. loss: 0.2633\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 2.55s  Val. loss: 0.2620\n",
      "Epoch 4, 100% \t Train loss: 0.2577 took: 2.53s  Val. loss: 0.2623\n",
      "Epoch 5, 100% \t Train loss: 0.2576 took: 2.52s  Val. loss: 0.2625\n",
      "Epoch 6, 100% \t Train loss: 0.2576 took: 2.55s  Val. loss: 0.2628\n",
      "Epoch 7, 100% \t Train loss: 0.2576 took: 2.53s  Val. loss: 0.2628\n",
      "Epoch 8, 100% \t Train loss: 0.2577 took: 2.54s  Val. loss: 0.2623\n",
      "Epoch 9, 100% \t Train loss: 0.2576 took: 2.54s  Val. loss: 0.2627\n",
      "Epoch 10, 100% \t Train loss: 0.2576 took: 2.54s  Val. loss: 0.2619\n",
      "Epoch 11, 100% \t Train loss: 0.2577 took: 2.54s  Val. loss: 0.2619\n",
      "Epoch 12, 100% \t Train loss: 0.2576 took: 2.53s  Val. loss: 0.2618\n",
      "Epoch 13, 100% \t Train loss: 0.2576 took: 2.54s  Val. loss: 0.2620\n",
      "Epoch 14, 100% \t Train loss: 0.2576 took: 2.53s  Val. loss: 0.2633\n",
      "Epoch 15, 100% \t Train loss: 0.2576 took: 2.49s  Val. loss: 0.2622\n",
      "Epoch 16, 100% \t Train loss: 0.2576 took: 2.56s  Val. loss: 0.2624\n",
      "Epoch 17, 100% \t Train loss: 0.2575 took: 2.53s  Val. loss: 0.2621\n",
      "Epoch 18, 100% \t Train loss: 0.2574 took: 2.54s  Val. loss: 0.2612\n",
      "Epoch 19, 100% \t Train loss: 0.2572 took: 2.54s  Val. loss: 0.2605\n",
      "Epoch 20, 100% \t Train loss: 0.2557 took: 2.55s  Val. loss: 0.2582\n",
      "Epoch 21, 100% \t Train loss: 0.2470 took: 2.53s  Val. loss: 0.2416\n",
      "Epoch 22, 100% \t Train loss: 0.2216 took: 2.53s  Val. loss: 0.2160\n",
      "Epoch 23, 100% \t Train loss: 0.2030 took: 2.57s  Val. loss: 0.2051\n",
      "Epoch 24, 100% \t Train loss: 0.1966 took: 2.49s  Val. loss: 0.2008\n",
      "Epoch 25, 100% \t Train loss: 0.1927 took: 2.51s  Val. loss: 0.1994\n",
      "Epoch 26, 100% \t Train loss: 0.1907 took: 2.52s  Val. loss: 0.1975\n",
      "Epoch 27, 100% \t Train loss: 0.1901 took: 2.54s  Val. loss: 0.1969\n",
      "Epoch 28, 100% \t Train loss: 0.1882 took: 2.55s  Val. loss: 0.1967\n",
      "Epoch 29, 100% \t Train loss: 0.1879 took: 1.57s  Val. loss: 0.1947\n",
      "Epoch 30, 100% \t Train loss: 0.1875 took: 1.58s  Val. loss: 0.1941\n",
      "Epoch 31, 100% \t Train loss: 0.1874 took: 1.61s  Val. loss: 0.1997\n",
      "Epoch 32, 100% \t Train loss: 0.1864 took: 2.65s  Val. loss: 0.1937\n",
      "Epoch 33, 100% \t Train loss: 0.1856 took: 2.65s  Val. loss: 0.1933\n",
      "Epoch 34, 100% \t Train loss: 0.1857 took: 2.66s  Val. loss: 0.1964\n",
      "Epoch 35, 100% \t Train loss: 0.1855 took: 2.66s  Val. loss: 0.1956\n",
      "Epoch 36, 100% \t Train loss: 0.1848 took: 2.67s  Val. loss: 0.1956\n",
      "Epoch 37, 100% \t Train loss: 0.1843 took: 2.68s  Val. loss: 0.1937\n",
      "Epoch 38, 100% \t Train loss: 0.1842 took: 2.64s  Val. loss: 0.1943\n",
      "Epoch 39, 100% \t Train loss: 0.1848 took: 2.65s  Val. loss: 0.1958\n",
      "Epoch 40, 100% \t Train loss: 0.1833 took: 2.68s  Val. loss: 0.1922\n",
      "Epoch 41, 100% \t Train loss: 0.1829 took: 2.70s  Val. loss: 0.1924\n",
      "Epoch 42, 100% \t Train loss: 0.1824 took: 2.81s  Val. loss: 0.1922\n",
      "Epoch 43, 100% \t Train loss: 0.1823 took: 2.88s  Val. loss: 0.1924\n",
      "Epoch 44, 100% \t Train loss: 0.1829 took: 2.96s  Val. loss: 0.1952\n",
      "Epoch 45, 100% \t Train loss: 0.1820 took: 2.99s  Val. loss: 0.1935\n",
      "Epoch 46, 100% \t Train loss: 0.1814 took: 3.01s  Val. loss: 0.1915\n",
      "Epoch 47, 100% \t Train loss: 0.1813 took: 2.98s  Val. loss: 0.1914\n",
      "Epoch 48, 100% \t Train loss: 0.1815 took: 2.73s  Val. loss: 0.1910\n",
      "Epoch 49, 100% \t Train loss: 0.1811 took: 2.71s  Val. loss: 0.1901\n",
      "Epoch 50, 100% \t Train loss: 0.1810 took: 2.71s  Val. loss: 0.1916\n",
      "Training finished, took 141.37s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  16\n",
      "\tinfo_channels :  8\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  32\n",
      "\tresidual_hidden_dim :  64\n",
      "\tn_residual_layers :  2\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.741337\n",
      "lambda: 0.0010 - V: 0.745205\n",
      "lambda: 0.0005 - V: 0.776890\n",
      "Average V: 0.754477\n",
      "Time elapsed: 483.55 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  32\n",
      "\tinfo_channels :  4\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  32\n",
      "\tresidual_hidden_dim :  16\n",
      "\tn_residual_layers :  3\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2611 took: 1.97s  Val. loss: 0.2580\n",
      "Epoch 2, 100% \t Train loss: 0.2605 took: 1.96s  Val. loss: 0.2584\n",
      "Epoch 3, 100% \t Train loss: 0.2527 took: 1.93s  Val. loss: 0.2258\n",
      "Epoch 4, 100% \t Train loss: 0.2076 took: 1.97s  Val. loss: 0.1777\n",
      "Epoch 5, 100% \t Train loss: 0.1798 took: 1.95s  Val. loss: 0.1730\n",
      "Epoch 6, 100% \t Train loss: 0.1746 took: 1.93s  Val. loss: 0.1722\n",
      "Epoch 7, 100% \t Train loss: 0.1722 took: 1.93s  Val. loss: 0.1665\n",
      "Epoch 8, 100% \t Train loss: 0.1698 took: 1.13s  Val. loss: 0.1658\n",
      "Epoch 9, 100% \t Train loss: 0.1672 took: 1.14s  Val. loss: 0.1653\n",
      "Epoch 10, 100% \t Train loss: 0.1657 took: 1.14s  Val. loss: 0.1607\n",
      "Epoch 11, 100% \t Train loss: 0.1645 took: 1.14s  Val. loss: 0.1597\n",
      "Epoch 12, 100% \t Train loss: 0.1642 took: 1.13s  Val. loss: 0.1614\n",
      "Epoch 13, 100% \t Train loss: 0.1622 took: 1.13s  Val. loss: 0.1675\n",
      "Epoch 14, 100% \t Train loss: 0.1610 took: 1.13s  Val. loss: 0.1593\n",
      "Epoch 15, 100% \t Train loss: 0.1586 took: 1.13s  Val. loss: 0.1575\n",
      "Epoch 16, 100% \t Train loss: 0.1551 took: 1.13s  Val. loss: 0.1546\n",
      "Epoch 17, 100% \t Train loss: 0.1466 took: 1.14s  Val. loss: 0.1483\n",
      "Epoch 18, 100% \t Train loss: 0.1396 took: 1.13s  Val. loss: 0.1397\n",
      "Epoch 19, 100% \t Train loss: 0.1330 took: 1.21s  Val. loss: 0.1361\n",
      "Epoch 20, 100% \t Train loss: 0.1279 took: 1.13s  Val. loss: 0.1299\n",
      "Epoch 21, 100% \t Train loss: 0.1239 took: 1.14s  Val. loss: 0.1243\n",
      "Epoch 22, 100% \t Train loss: 0.1206 took: 1.92s  Val. loss: 0.1217\n",
      "Epoch 23, 100% \t Train loss: 0.1175 took: 1.95s  Val. loss: 0.1220\n",
      "Epoch 24, 100% \t Train loss: 0.1145 took: 1.93s  Val. loss: 0.1181\n",
      "Epoch 25, 100% \t Train loss: 0.1139 took: 1.93s  Val. loss: 0.1174\n",
      "Epoch 26, 100% \t Train loss: 0.1117 took: 1.95s  Val. loss: 0.1155\n",
      "Epoch 27, 100% \t Train loss: 0.1102 took: 1.93s  Val. loss: 0.1128\n",
      "Epoch 28, 100% \t Train loss: 0.1087 took: 1.94s  Val. loss: 0.1159\n",
      "Epoch 29, 100% \t Train loss: 0.1091 took: 1.97s  Val. loss: 0.1106\n",
      "Epoch 30, 100% \t Train loss: 0.1060 took: 1.99s  Val. loss: 0.1137\n",
      "Epoch 31, 100% \t Train loss: 0.1049 took: 2.01s  Val. loss: 0.1071\n",
      "Epoch 32, 100% \t Train loss: 0.1030 took: 2.13s  Val. loss: 0.1075\n",
      "Epoch 33, 100% \t Train loss: 0.1021 took: 2.27s  Val. loss: 0.1037\n",
      "Epoch 34, 100% \t Train loss: 0.1014 took: 2.30s  Val. loss: 0.1069\n",
      "Epoch 35, 100% \t Train loss: 0.1003 took: 2.32s  Val. loss: 0.1043\n",
      "Epoch 36, 100% \t Train loss: 0.1013 took: 2.31s  Val. loss: 0.1066\n",
      "Epoch 37, 100% \t Train loss: 0.0999 took: 2.35s  Val. loss: 0.1046\n",
      "Epoch 38, 100% \t Train loss: 0.1004 took: 2.36s  Val. loss: 0.1022\n",
      "Epoch 39, 100% \t Train loss: 0.0983 took: 2.37s  Val. loss: 0.1045\n",
      "Epoch 40, 100% \t Train loss: 0.0982 took: 2.35s  Val. loss: 0.1033\n",
      "Epoch 41, 100% \t Train loss: 0.0968 took: 2.39s  Val. loss: 0.1014\n",
      "Epoch 42, 100% \t Train loss: 0.0974 took: 2.37s  Val. loss: 0.1021\n",
      "Epoch 43, 100% \t Train loss: 0.0958 took: 2.32s  Val. loss: 0.1021\n",
      "Epoch 44, 100% \t Train loss: 0.0975 took: 2.32s  Val. loss: 0.1047\n",
      "Epoch 45, 100% \t Train loss: 0.0968 took: 2.37s  Val. loss: 0.1021\n",
      "Epoch 46, 100% \t Train loss: 0.0960 took: 2.36s  Val. loss: 0.1017\n",
      "Epoch 47, 100% \t Train loss: 0.0944 took: 2.36s  Val. loss: 0.1037\n",
      "Epoch 48, 100% \t Train loss: 0.0950 took: 2.37s  Val. loss: 0.1049\n",
      "Epoch 49, 100% \t Train loss: 0.0946 took: 2.35s  Val. loss: 0.1022\n",
      "Epoch 50, 100% \t Train loss: 0.0951 took: 2.38s  Val. loss: 0.1029\n",
      "Training finished, took 105.58s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2577 took: 1.93s  Val. loss: 0.2593\n",
      "Epoch 2, 100% \t Train loss: 0.2572 took: 1.93s  Val. loss: 0.2593\n",
      "Epoch 3, 100% \t Train loss: 0.2558 took: 1.91s  Val. loss: 0.2545\n",
      "Epoch 4, 100% \t Train loss: 0.2382 took: 1.94s  Val. loss: 0.2191\n",
      "Epoch 5, 100% \t Train loss: 0.2050 took: 1.93s  Val. loss: 0.1875\n",
      "Epoch 6, 100% \t Train loss: 0.1830 took: 1.52s  Val. loss: 0.1738\n",
      "Epoch 7, 100% \t Train loss: 0.1776 took: 1.13s  Val. loss: 0.1703\n",
      "Epoch 8, 100% \t Train loss: 0.1759 took: 1.13s  Val. loss: 0.1770\n",
      "Epoch 9, 100% \t Train loss: 0.1751 took: 1.13s  Val. loss: 0.1688\n",
      "Epoch 10, 100% \t Train loss: 0.1744 took: 1.13s  Val. loss: 0.1695\n",
      "Epoch 11, 100% \t Train loss: 0.1729 took: 1.13s  Val. loss: 0.1671\n",
      "Epoch 12, 100% \t Train loss: 0.1718 took: 1.14s  Val. loss: 0.1673\n",
      "Epoch 13, 100% \t Train loss: 0.1711 took: 1.13s  Val. loss: 0.1670\n",
      "Epoch 14, 100% \t Train loss: 0.1708 took: 1.13s  Val. loss: 0.1661\n",
      "Epoch 15, 100% \t Train loss: 0.1702 took: 1.13s  Val. loss: 0.1671\n",
      "Epoch 16, 100% \t Train loss: 0.1688 took: 1.13s  Val. loss: 0.1655\n",
      "Epoch 17, 100% \t Train loss: 0.1681 took: 1.13s  Val. loss: 0.1664\n",
      "Epoch 18, 100% \t Train loss: 0.1682 took: 1.13s  Val. loss: 0.1674\n",
      "Epoch 19, 100% \t Train loss: 0.1681 took: 1.13s  Val. loss: 0.1652\n",
      "Epoch 20, 100% \t Train loss: 0.1663 took: 1.13s  Val. loss: 0.1617\n",
      "Epoch 21, 100% \t Train loss: 0.1659 took: 1.13s  Val. loss: 0.1611\n",
      "Epoch 22, 100% \t Train loss: 0.1648 took: 1.13s  Val. loss: 0.1635\n",
      "Epoch 23, 100% \t Train loss: 0.1642 took: 1.13s  Val. loss: 0.1612\n",
      "Epoch 24, 100% \t Train loss: 0.1632 took: 1.14s  Val. loss: 0.1675\n",
      "Epoch 25, 100% \t Train loss: 0.1626 took: 1.13s  Val. loss: 0.1615\n",
      "Epoch 26, 100% \t Train loss: 0.1616 took: 1.12s  Val. loss: 0.1602\n",
      "Epoch 27, 100% \t Train loss: 0.1608 took: 1.13s  Val. loss: 0.1609\n",
      "Epoch 28, 100% \t Train loss: 0.1608 took: 1.14s  Val. loss: 0.1585\n",
      "Epoch 29, 100% \t Train loss: 0.1596 took: 1.15s  Val. loss: 0.1576\n",
      "Epoch 30, 100% \t Train loss: 0.1589 took: 1.15s  Val. loss: 0.1580\n",
      "Epoch 31, 100% \t Train loss: 0.1596 took: 1.15s  Val. loss: 0.1591\n",
      "Epoch 32, 100% \t Train loss: 0.1588 took: 1.16s  Val. loss: 0.1583\n",
      "Epoch 33, 100% \t Train loss: 0.1588 took: 1.29s  Val. loss: 0.1581\n",
      "Epoch 34, 100% \t Train loss: 0.1576 took: 1.99s  Val. loss: 0.1543\n",
      "Epoch 35, 100% \t Train loss: 0.1575 took: 1.98s  Val. loss: 0.1546\n",
      "Epoch 36, 100% \t Train loss: 0.1581 took: 2.00s  Val. loss: 0.1563\n",
      "Epoch 37, 100% \t Train loss: 0.1580 took: 1.96s  Val. loss: 0.1575\n",
      "Epoch 38, 100% \t Train loss: 0.1574 took: 1.98s  Val. loss: 0.1545\n",
      "Epoch 39, 100% \t Train loss: 0.1569 took: 1.97s  Val. loss: 0.1557\n",
      "Epoch 40, 100% \t Train loss: 0.1565 took: 1.96s  Val. loss: 0.1589\n",
      "Epoch 41, 100% \t Train loss: 0.1562 took: 1.98s  Val. loss: 0.1554\n",
      "Epoch 42, 100% \t Train loss: 0.1554 took: 1.98s  Val. loss: 0.1537\n",
      "Epoch 43, 100% \t Train loss: 0.1556 took: 1.98s  Val. loss: 0.1561\n",
      "Epoch 44, 100% \t Train loss: 0.1569 took: 1.97s  Val. loss: 0.1544\n",
      "Epoch 45, 100% \t Train loss: 0.1550 took: 1.99s  Val. loss: 0.1514\n",
      "Epoch 46, 100% \t Train loss: 0.1554 took: 2.00s  Val. loss: 0.1553\n",
      "Epoch 47, 100% \t Train loss: 0.1547 took: 2.01s  Val. loss: 0.1534\n",
      "Epoch 48, 100% \t Train loss: 0.1539 took: 2.03s  Val. loss: 0.1556\n",
      "Epoch 49, 100% \t Train loss: 0.1545 took: 2.00s  Val. loss: 0.1541\n",
      "Epoch 50, 100% \t Train loss: 0.1536 took: 2.01s  Val. loss: 0.1531\n",
      "Training finished, took 85.26s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2601 took: 1.98s  Val. loss: 0.2506\n",
      "Epoch 2, 100% \t Train loss: 0.2574 took: 1.96s  Val. loss: 0.2510\n",
      "Epoch 3, 100% \t Train loss: 0.2574 took: 1.98s  Val. loss: 0.2500\n",
      "Epoch 4, 100% \t Train loss: 0.2574 took: 1.96s  Val. loss: 0.2522\n",
      "Epoch 5, 100% \t Train loss: 0.2574 took: 1.96s  Val. loss: 0.2509\n",
      "Epoch 6, 100% \t Train loss: 0.2574 took: 1.94s  Val. loss: 0.2509\n",
      "Epoch 7, 100% \t Train loss: 0.2574 took: 1.94s  Val. loss: 0.2515\n",
      "Epoch 8, 100% \t Train loss: 0.2574 took: 1.96s  Val. loss: 0.2508\n",
      "Epoch 9, 100% \t Train loss: 0.2573 took: 1.95s  Val. loss: 0.2511\n",
      "Epoch 10, 100% \t Train loss: 0.2573 took: 1.96s  Val. loss: 0.2503\n",
      "Epoch 11, 100% \t Train loss: 0.2571 took: 1.96s  Val. loss: 0.2515\n",
      "Epoch 12, 100% \t Train loss: 0.2569 took: 1.96s  Val. loss: 0.2516\n",
      "Epoch 13, 100% \t Train loss: 0.2568 took: 1.94s  Val. loss: 0.2509\n",
      "Epoch 14, 100% \t Train loss: 0.2561 took: 1.94s  Val. loss: 0.2497\n",
      "Epoch 15, 100% \t Train loss: 0.2539 took: 1.95s  Val. loss: 0.2475\n",
      "Epoch 16, 100% \t Train loss: 0.2465 took: 1.96s  Val. loss: 0.2350\n",
      "Epoch 17, 100% \t Train loss: 0.2259 took: 1.96s  Val. loss: 0.2099\n",
      "Epoch 18, 100% \t Train loss: 0.2020 took: 1.23s  Val. loss: 0.1909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1880 took: 1.15s  Val. loss: 0.1808\n",
      "Epoch 20, 100% \t Train loss: 0.1820 took: 1.16s  Val. loss: 0.1793\n",
      "Epoch 21, 100% \t Train loss: 0.1788 took: 1.16s  Val. loss: 0.1731\n",
      "Epoch 22, 100% \t Train loss: 0.1753 took: 1.16s  Val. loss: 0.1698\n",
      "Epoch 23, 100% \t Train loss: 0.1748 took: 1.15s  Val. loss: 0.1687\n",
      "Epoch 24, 100% \t Train loss: 0.1728 took: 1.15s  Val. loss: 0.1701\n",
      "Epoch 25, 100% \t Train loss: 0.1718 took: 1.15s  Val. loss: 0.1657\n",
      "Epoch 26, 100% \t Train loss: 0.1700 took: 1.15s  Val. loss: 0.1643\n",
      "Epoch 27, 100% \t Train loss: 0.1714 took: 1.16s  Val. loss: 0.1653\n",
      "Epoch 28, 100% \t Train loss: 0.1686 took: 1.16s  Val. loss: 0.1640\n",
      "Epoch 29, 100% \t Train loss: 0.1681 took: 1.17s  Val. loss: 0.1639\n",
      "Epoch 30, 100% \t Train loss: 0.1669 took: 1.17s  Val. loss: 0.1653\n",
      "Epoch 31, 100% \t Train loss: 0.1674 took: 1.18s  Val. loss: 0.1637\n",
      "Epoch 32, 100% \t Train loss: 0.1660 took: 1.18s  Val. loss: 0.1625\n",
      "Epoch 33, 100% \t Train loss: 0.1659 took: 1.18s  Val. loss: 0.1609\n",
      "Epoch 34, 100% \t Train loss: 0.1643 took: 1.18s  Val. loss: 0.1605\n",
      "Epoch 35, 100% \t Train loss: 0.1645 took: 1.19s  Val. loss: 0.1622\n",
      "Epoch 36, 100% \t Train loss: 0.1650 took: 1.19s  Val. loss: 0.1618\n",
      "Epoch 37, 100% \t Train loss: 0.1638 took: 1.19s  Val. loss: 0.1588\n",
      "Epoch 38, 100% \t Train loss: 0.1637 took: 1.20s  Val. loss: 0.1589\n",
      "Epoch 39, 100% \t Train loss: 0.1624 took: 1.21s  Val. loss: 0.1615\n",
      "Epoch 40, 100% \t Train loss: 0.1620 took: 1.21s  Val. loss: 0.1593\n",
      "Epoch 41, 100% \t Train loss: 0.1614 took: 1.22s  Val. loss: 0.1620\n",
      "Epoch 42, 100% \t Train loss: 0.1624 took: 1.22s  Val. loss: 0.1682\n",
      "Epoch 43, 100% \t Train loss: 0.1614 took: 1.22s  Val. loss: 0.1592\n",
      "Epoch 44, 100% \t Train loss: 0.1609 took: 1.21s  Val. loss: 0.1587\n",
      "Epoch 45, 100% \t Train loss: 0.1602 took: 1.20s  Val. loss: 0.1574\n",
      "Epoch 46, 100% \t Train loss: 0.1598 took: 1.21s  Val. loss: 0.1584\n",
      "Epoch 47, 100% \t Train loss: 0.1593 took: 1.22s  Val. loss: 0.1625\n",
      "Epoch 48, 100% \t Train loss: 0.1604 took: 1.23s  Val. loss: 0.1583\n",
      "Epoch 49, 100% \t Train loss: 0.1595 took: 1.22s  Val. loss: 0.1587\n",
      "Epoch 50, 100% \t Train loss: 0.1596 took: 2.01s  Val. loss: 0.1605\n",
      "Training finished, took 82.43s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  32\n",
      "\tinfo_channels :  4\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  32\n",
      "\tresidual_hidden_dim :  16\n",
      "\tn_residual_layers :  3\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.866247\n",
      "lambda: 0.0010 - V: 0.831611\n",
      "lambda: 0.0005 - V: 0.807188\n",
      "Average V: 0.835015\n",
      "Time elapsed: 276.77 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    bayes_HP_tuning.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  2\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  4\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  16\n",
      "\tn_residual_layers :  1\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2572 took: 1.76s  Val. loss: 0.2580\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 1.75s  Val. loss: 0.2587\n",
      "Epoch 3, 100% \t Train loss: 0.2564 took: 1.74s  Val. loss: 0.2571\n",
      "Epoch 4, 100% \t Train loss: 0.2563 took: 1.75s  Val. loss: 0.2576\n",
      "Epoch 5, 100% \t Train loss: 0.2563 took: 1.77s  Val. loss: 0.2570\n",
      "Epoch 6, 100% \t Train loss: 0.2556 took: 1.75s  Val. loss: 0.2538\n",
      "Epoch 7, 100% \t Train loss: 0.2250 took: 1.76s  Val. loss: 0.1867\n",
      "Epoch 8, 100% \t Train loss: 0.1696 took: 1.76s  Val. loss: 0.1700\n",
      "Epoch 9, 100% \t Train loss: 0.1615 took: 1.43s  Val. loss: 0.1674\n",
      "Epoch 10, 100% \t Train loss: 0.1569 took: 1.00s  Val. loss: 0.1619\n",
      "Epoch 11, 100% \t Train loss: 0.1517 took: 1.00s  Val. loss: 0.1623\n",
      "Epoch 12, 100% \t Train loss: 0.1492 took: 1.01s  Val. loss: 0.1583\n",
      "Epoch 13, 100% \t Train loss: 0.1476 took: 1.00s  Val. loss: 0.1597\n",
      "Epoch 14, 100% \t Train loss: 0.1471 took: 1.00s  Val. loss: 0.1615\n",
      "Epoch 15, 100% \t Train loss: 0.1449 took: 1.00s  Val. loss: 0.1593\n",
      "Epoch 16, 100% \t Train loss: 0.1442 took: 1.00s  Val. loss: 0.1607\n",
      "Epoch 17, 100% \t Train loss: 0.1422 took: 1.00s  Val. loss: 0.1565\n",
      "Epoch 18, 100% \t Train loss: 0.1419 took: 1.00s  Val. loss: 0.1603\n",
      "Epoch 19, 100% \t Train loss: 0.1405 took: 1.00s  Val. loss: 0.1591\n",
      "Epoch 20, 100% \t Train loss: 0.1387 took: 1.01s  Val. loss: 0.1533\n",
      "Epoch 21, 100% \t Train loss: 0.1358 took: 1.00s  Val. loss: 0.1561\n",
      "Epoch 22, 100% \t Train loss: 0.1313 took: 1.01s  Val. loss: 0.1446\n",
      "Epoch 23, 100% \t Train loss: 0.1242 took: 1.00s  Val. loss: 0.1359\n",
      "Epoch 24, 100% \t Train loss: 0.1170 took: 1.00s  Val. loss: 0.1288\n",
      "Epoch 25, 100% \t Train loss: 0.1081 took: 1.00s  Val. loss: 0.1191\n",
      "Epoch 26, 100% \t Train loss: 0.1005 took: 1.00s  Val. loss: 0.1154\n",
      "Epoch 27, 100% \t Train loss: 0.0948 took: 1.00s  Val. loss: 0.1114\n",
      "Epoch 28, 100% \t Train loss: 0.0910 took: 1.01s  Val. loss: 0.1037\n",
      "Epoch 29, 100% \t Train loss: 0.0871 took: 1.02s  Val. loss: 0.1041\n",
      "Epoch 30, 100% \t Train loss: 0.0856 took: 1.04s  Val. loss: 0.0989\n",
      "Epoch 31, 100% \t Train loss: 0.0844 took: 1.05s  Val. loss: 0.1009\n",
      "Epoch 32, 100% \t Train loss: 0.0824 took: 1.10s  Val. loss: 0.0977\n",
      "Epoch 33, 100% \t Train loss: 0.0815 took: 1.20s  Val. loss: 0.0998\n",
      "Epoch 34, 100% \t Train loss: 0.0809 took: 1.24s  Val. loss: 0.0956\n",
      "Epoch 35, 100% \t Train loss: 0.0796 took: 1.25s  Val. loss: 0.0975\n",
      "Epoch 36, 100% \t Train loss: 0.0794 took: 1.26s  Val. loss: 0.0990\n",
      "Epoch 37, 100% \t Train loss: 0.0786 took: 1.26s  Val. loss: 0.0961\n",
      "Epoch 38, 100% \t Train loss: 0.0771 took: 1.26s  Val. loss: 0.0983\n",
      "Epoch 39, 100% \t Train loss: 0.0774 took: 2.01s  Val. loss: 0.0938\n",
      "Epoch 40, 100% \t Train loss: 0.0762 took: 1.99s  Val. loss: 0.0966\n",
      "Epoch 41, 100% \t Train loss: 0.0758 took: 2.01s  Val. loss: 0.0958\n",
      "Epoch 42, 100% \t Train loss: 0.0758 took: 2.00s  Val. loss: 0.0970\n",
      "Epoch 43, 100% \t Train loss: 0.0761 took: 2.02s  Val. loss: 0.0988\n",
      "Epoch 44, 100% \t Train loss: 0.0755 took: 2.03s  Val. loss: 0.0945\n",
      "Epoch 45, 100% \t Train loss: 0.0744 took: 2.04s  Val. loss: 0.0950\n",
      "Epoch 46, 100% \t Train loss: 0.0749 took: 2.08s  Val. loss: 0.0943\n",
      "Epoch 47, 100% \t Train loss: 0.0732 took: 2.10s  Val. loss: 0.0957\n",
      "Epoch 48, 100% \t Train loss: 0.0732 took: 2.13s  Val. loss: 0.0954\n",
      "Epoch 49, 100% \t Train loss: 0.0735 took: 2.03s  Val. loss: 0.0960\n",
      "Epoch 50, 100% \t Train loss: 0.0728 took: 1.95s  Val. loss: 0.0957\n",
      "Training finished, took 80.42s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2576 took: 1.77s  Val. loss: 0.2566\n",
      "Epoch 2, 100% \t Train loss: 0.2573 took: 1.74s  Val. loss: 0.2559\n",
      "Epoch 3, 100% \t Train loss: 0.2572 took: 1.76s  Val. loss: 0.2552\n",
      "Epoch 4, 100% \t Train loss: 0.2573 took: 1.76s  Val. loss: 0.2554\n",
      "Epoch 5, 100% \t Train loss: 0.2571 took: 1.76s  Val. loss: 0.2552\n",
      "Epoch 6, 100% \t Train loss: 0.2568 took: 1.76s  Val. loss: 0.2546\n",
      "Epoch 7, 100% \t Train loss: 0.2554 took: 1.76s  Val. loss: 0.2509\n",
      "Epoch 8, 100% \t Train loss: 0.2348 took: 1.75s  Val. loss: 0.2136\n",
      "Epoch 9, 100% \t Train loss: 0.2011 took: 1.76s  Val. loss: 0.2011\n",
      "Epoch 10, 100% \t Train loss: 0.1807 took: 1.77s  Val. loss: 0.1807\n",
      "Epoch 11, 100% \t Train loss: 0.1711 took: 1.77s  Val. loss: 0.1892\n",
      "Epoch 12, 100% \t Train loss: 0.1691 took: 1.76s  Val. loss: 0.1722\n",
      "Epoch 13, 100% \t Train loss: 0.1660 took: 1.76s  Val. loss: 0.1823\n",
      "Epoch 14, 100% \t Train loss: 0.1664 took: 1.75s  Val. loss: 0.1714\n",
      "Epoch 15, 100% \t Train loss: 0.1652 took: 1.77s  Val. loss: 0.1788\n",
      "Epoch 16, 100% \t Train loss: 0.1648 took: 1.72s  Val. loss: 0.1719\n",
      "Epoch 17, 100% \t Train loss: 0.1647 took: 1.74s  Val. loss: 0.1707\n",
      "Epoch 18, 100% \t Train loss: 0.1632 took: 1.74s  Val. loss: 0.1731\n",
      "Epoch 19, 100% \t Train loss: 0.1631 took: 1.77s  Val. loss: 0.1779\n",
      "Epoch 20, 100% \t Train loss: 0.1617 took: 1.77s  Val. loss: 0.1726\n",
      "Epoch 21, 100% \t Train loss: 0.1603 took: 1.75s  Val. loss: 0.1722\n",
      "Epoch 22, 100% \t Train loss: 0.1612 took: 1.75s  Val. loss: 0.1708\n",
      "Epoch 23, 100% \t Train loss: 0.1606 took: 1.75s  Val. loss: 0.1677\n",
      "Epoch 24, 100% \t Train loss: 0.1599 took: 1.76s  Val. loss: 0.1716\n",
      "Epoch 25, 100% \t Train loss: 0.1586 took: 1.77s  Val. loss: 0.1690\n",
      "Epoch 26, 100% \t Train loss: 0.1593 took: 1.75s  Val. loss: 0.1694\n",
      "Epoch 27, 100% \t Train loss: 0.1588 took: 1.74s  Val. loss: 0.1692\n",
      "Epoch 28, 100% \t Train loss: 0.1569 took: 1.77s  Val. loss: 0.1661\n",
      "Epoch 29, 100% \t Train loss: 0.1577 took: 1.75s  Val. loss: 0.1717\n",
      "Epoch 30, 100% \t Train loss: 0.1595 took: 1.77s  Val. loss: 0.1682\n",
      "Epoch 31, 100% \t Train loss: 0.1569 took: 1.76s  Val. loss: 0.1670\n",
      "Epoch 32, 100% \t Train loss: 0.1563 took: 1.76s  Val. loss: 0.1710\n",
      "Epoch 33, 100% \t Train loss: 0.1570 took: 1.75s  Val. loss: 0.1744\n",
      "Epoch 34, 100% \t Train loss: 0.1557 took: 1.76s  Val. loss: 0.1706\n",
      "Epoch 35, 100% \t Train loss: 0.1550 took: 1.76s  Val. loss: 0.1663\n",
      "Epoch 36, 100% \t Train loss: 0.1547 took: 1.76s  Val. loss: 0.1670\n",
      "Epoch 37, 100% \t Train loss: 0.1542 took: 1.79s  Val. loss: 0.1672\n",
      "Epoch 38, 100% \t Train loss: 0.1539 took: 1.77s  Val. loss: 0.1656\n",
      "Epoch 39, 100% \t Train loss: 0.1529 took: 1.76s  Val. loss: 0.1660\n",
      "Epoch 40, 100% \t Train loss: 0.1537 took: 1.76s  Val. loss: 0.1660\n",
      "Epoch 41, 100% \t Train loss: 0.1537 took: 1.80s  Val. loss: 0.1716\n",
      "Epoch 42, 100% \t Train loss: 0.1529 took: 1.79s  Val. loss: 0.1693\n",
      "Epoch 43, 100% \t Train loss: 0.1546 took: 1.81s  Val. loss: 0.1688\n",
      "Epoch 44, 100% \t Train loss: 0.1526 took: 1.81s  Val. loss: 0.1672\n",
      "Epoch 45, 100% \t Train loss: 0.1514 took: 1.79s  Val. loss: 0.1660\n",
      "Epoch 46, 100% \t Train loss: 0.1519 took: 1.80s  Val. loss: 0.1665\n",
      "Epoch 47, 100% \t Train loss: 0.1514 took: 1.81s  Val. loss: 0.1659\n",
      "Epoch 48, 100% \t Train loss: 0.1521 took: 1.80s  Val. loss: 0.1690\n",
      "Epoch 49, 100% \t Train loss: 0.1515 took: 1.82s  Val. loss: 0.1676\n",
      "Epoch 50, 100% \t Train loss: 0.1505 took: 1.80s  Val. loss: 0.1624\n",
      "Training finished, took 101.00s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 1.78s  Val. loss: 0.2543\n",
      "Epoch 2, 100% \t Train loss: 0.2597 took: 1.75s  Val. loss: 0.2545\n",
      "Epoch 3, 100% \t Train loss: 0.2595 took: 1.75s  Val. loss: 0.2546\n",
      "Epoch 4, 100% \t Train loss: 0.2593 took: 1.77s  Val. loss: 0.2536\n",
      "Epoch 5, 100% \t Train loss: 0.2592 took: 1.75s  Val. loss: 0.2538\n",
      "Epoch 6, 100% \t Train loss: 0.2585 took: 1.74s  Val. loss: 0.2525\n",
      "Epoch 7, 100% \t Train loss: 0.2564 took: 1.75s  Val. loss: 0.2497\n",
      "Epoch 8, 100% \t Train loss: 0.2479 took: 1.75s  Val. loss: 0.2380\n",
      "Epoch 9, 100% \t Train loss: 0.2252 took: 1.76s  Val. loss: 0.2111\n",
      "Epoch 10, 100% \t Train loss: 0.2033 took: 1.76s  Val. loss: 0.1967\n",
      "Epoch 11, 100% \t Train loss: 0.1915 took: 1.75s  Val. loss: 0.1871\n",
      "Epoch 12, 100% \t Train loss: 0.1864 took: 1.76s  Val. loss: 0.1877\n",
      "Epoch 13, 100% \t Train loss: 0.1802 took: 1.75s  Val. loss: 0.1803\n",
      "Epoch 14, 100% \t Train loss: 0.1773 took: 1.75s  Val. loss: 0.1802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, 100% \t Train loss: 0.1760 took: 1.76s  Val. loss: 0.1757\n",
      "Epoch 16, 100% \t Train loss: 0.1739 took: 1.76s  Val. loss: 0.1735\n",
      "Epoch 17, 100% \t Train loss: 0.1715 took: 1.76s  Val. loss: 0.1733\n",
      "Epoch 18, 100% \t Train loss: 0.1699 took: 1.74s  Val. loss: 0.1700\n",
      "Epoch 19, 100% \t Train loss: 0.1687 took: 1.75s  Val. loss: 0.1697\n",
      "Epoch 20, 100% \t Train loss: 0.1684 took: 1.75s  Val. loss: 0.1726\n",
      "Epoch 21, 100% \t Train loss: 0.1669 took: 1.77s  Val. loss: 0.1692\n",
      "Epoch 22, 100% \t Train loss: 0.1674 took: 1.75s  Val. loss: 0.1671\n",
      "Epoch 23, 100% \t Train loss: 0.1651 took: 1.76s  Val. loss: 0.1666\n",
      "Epoch 24, 100% \t Train loss: 0.1643 took: 1.77s  Val. loss: 0.1667\n",
      "Epoch 25, 100% \t Train loss: 0.1644 took: 1.77s  Val. loss: 0.1693\n",
      "Epoch 26, 100% \t Train loss: 0.1651 took: 1.00s  Val. loss: 0.1699\n",
      "Epoch 27, 100% \t Train loss: 0.1625 took: 1.00s  Val. loss: 0.1654\n",
      "Epoch 28, 100% \t Train loss: 0.1654 took: 1.00s  Val. loss: 0.1675\n",
      "Epoch 29, 100% \t Train loss: 0.1620 took: 1.00s  Val. loss: 0.1650\n",
      "Epoch 30, 100% \t Train loss: 0.1619 took: 1.01s  Val. loss: 0.1645\n",
      "Epoch 31, 100% \t Train loss: 0.1607 took: 1.02s  Val. loss: 0.1654\n",
      "Epoch 32, 100% \t Train loss: 0.1606 took: 1.01s  Val. loss: 0.1648\n",
      "Epoch 33, 100% \t Train loss: 0.1592 took: 1.02s  Val. loss: 0.1645\n",
      "Epoch 34, 100% \t Train loss: 0.1595 took: 1.02s  Val. loss: 0.1667\n",
      "Epoch 35, 100% \t Train loss: 0.1584 took: 1.02s  Val. loss: 0.1665\n",
      "Epoch 36, 100% \t Train loss: 0.1580 took: 1.02s  Val. loss: 0.1662\n",
      "Epoch 37, 100% \t Train loss: 0.1582 took: 1.02s  Val. loss: 0.1661\n",
      "Epoch 38, 100% \t Train loss: 0.1593 took: 1.02s  Val. loss: 0.1708\n",
      "Epoch 39, 100% \t Train loss: 0.1576 took: 1.02s  Val. loss: 0.1644\n",
      "Epoch 40, 100% \t Train loss: 0.1572 took: 1.02s  Val. loss: 0.1626\n",
      "Epoch 41, 100% \t Train loss: 0.1567 took: 1.02s  Val. loss: 0.1640\n",
      "Epoch 42, 100% \t Train loss: 0.1562 took: 1.02s  Val. loss: 0.1639\n",
      "Epoch 43, 100% \t Train loss: 0.1580 took: 1.02s  Val. loss: 0.1648\n",
      "Epoch 44, 100% \t Train loss: 0.1554 took: 1.01s  Val. loss: 0.1655\n",
      "Epoch 45, 100% \t Train loss: 0.1559 took: 1.02s  Val. loss: 0.1656\n",
      "Epoch 46, 100% \t Train loss: 0.1557 took: 1.01s  Val. loss: 0.1639\n",
      "Epoch 47, 100% \t Train loss: 0.1564 took: 1.02s  Val. loss: 0.1651\n",
      "Epoch 48, 100% \t Train loss: 0.1559 took: 1.01s  Val. loss: 0.1665\n",
      "Epoch 49, 100% \t Train loss: 0.1553 took: 1.02s  Val. loss: 0.1646\n",
      "Epoch 50, 100% \t Train loss: 0.1541 took: 1.02s  Val. loss: 0.1635\n",
      "Training finished, took 78.79s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  2\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  4\n",
      "\tmask_channels :  8\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  16\n",
      "\tn_residual_layers :  1\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.860586\n",
      "lambda: 0.0010 - V: 0.816184\n",
      "lambda: 0.0005 - V: 0.816693\n",
      "Average V: 0.831154\n",
      "Time elapsed: 263.69 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]\n",
      "\tmax_pool_size :  3\n",
      "\tn_features :  64\n",
      "\tinfo_channels :  6\n",
      "\tmask_channels :  4\n",
      "\thidden_channels :  6\n",
      "\tresidual_hidden_dim :  64\n",
      "\tn_residual_layers :  2\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2581 took: 1.01s  Val. loss: 0.2541\n",
      "Epoch 2, 100% \t Train loss: 0.2559 took: 1.00s  Val. loss: 0.2545\n",
      "Epoch 3, 100% \t Train loss: 0.2558 took: 1.00s  Val. loss: 0.2541\n",
      "Epoch 4, 100% \t Train loss: 0.2558 took: 1.00s  Val. loss: 0.2544\n",
      "Epoch 5, 100% \t Train loss: 0.2557 took: 1.00s  Val. loss: 0.2539\n",
      "Epoch 6, 100% \t Train loss: 0.2558 took: 1.00s  Val. loss: 0.2532\n",
      "Epoch 7, 100% \t Train loss: 0.2554 took: 1.00s  Val. loss: 0.2539\n",
      "Epoch 8, 100% \t Train loss: 0.2379 took: 1.00s  Val. loss: 0.1874\n",
      "Epoch 9, 100% \t Train loss: 0.1771 took: 1.00s  Val. loss: 0.1532\n",
      "Epoch 10, 100% \t Train loss: 0.1636 took: 1.00s  Val. loss: 0.1499\n",
      "Epoch 11, 100% \t Train loss: 0.1589 took: 1.00s  Val. loss: 0.1458\n",
      "Epoch 12, 100% \t Train loss: 0.1557 took: 1.00s  Val. loss: 0.1458\n",
      "Epoch 13, 100% \t Train loss: 0.1489 took: 1.00s  Val. loss: 0.1344\n",
      "Epoch 14, 100% \t Train loss: 0.1381 took: 1.00s  Val. loss: 0.1225\n",
      "Epoch 15, 100% \t Train loss: 0.1296 took: 1.00s  Val. loss: 0.1215\n",
      "Epoch 16, 100% \t Train loss: 0.1235 took: 1.00s  Val. loss: 0.1152\n",
      "Epoch 17, 100% \t Train loss: 0.1207 took: 1.00s  Val. loss: 0.1194\n",
      "Epoch 18, 100% \t Train loss: 0.1154 took: 1.02s  Val. loss: 0.1129\n",
      "Epoch 19, 100% \t Train loss: 0.1122 took: 1.00s  Val. loss: 0.1109\n",
      "Epoch 20, 100% \t Train loss: 0.1124 took: 1.00s  Val. loss: 0.1082\n",
      "Epoch 21, 100% \t Train loss: 0.1090 took: 1.00s  Val. loss: 0.1130\n",
      "Epoch 22, 100% \t Train loss: 0.1050 took: 1.00s  Val. loss: 0.1089\n",
      "Epoch 23, 100% \t Train loss: 0.1038 took: 1.00s  Val. loss: 0.1082\n",
      "Epoch 24, 100% \t Train loss: 0.1036 took: 1.00s  Val. loss: 0.1032\n",
      "Epoch 25, 100% \t Train loss: 0.1009 took: 1.00s  Val. loss: 0.1026\n",
      "Epoch 26, 100% \t Train loss: 0.0984 took: 1.00s  Val. loss: 0.1066\n",
      "Epoch 27, 100% \t Train loss: 0.0965 took: 1.00s  Val. loss: 0.1054\n",
      "Epoch 28, 100% \t Train loss: 0.0984 took: 1.00s  Val. loss: 0.1012\n",
      "Epoch 29, 100% \t Train loss: 0.0953 took: 1.00s  Val. loss: 0.0989\n",
      "Epoch 30, 100% \t Train loss: 0.0934 took: 1.01s  Val. loss: 0.1006\n",
      "Epoch 31, 100% \t Train loss: 0.0908 took: 1.02s  Val. loss: 0.0962\n",
      "Epoch 32, 100% \t Train loss: 0.0896 took: 1.04s  Val. loss: 0.1048\n",
      "Epoch 33, 100% \t Train loss: 0.0888 took: 1.11s  Val. loss: 0.0976\n",
      "Epoch 34, 100% \t Train loss: 0.0876 took: 1.13s  Val. loss: 0.1055\n",
      "Epoch 35, 100% \t Train loss: 0.0876 took: 1.12s  Val. loss: 0.0956\n",
      "Epoch 36, 100% \t Train loss: 0.0859 took: 1.12s  Val. loss: 0.0996\n",
      "Epoch 37, 100% \t Train loss: 0.0871 took: 1.12s  Val. loss: 0.0933\n",
      "Epoch 38, 100% \t Train loss: 0.0845 took: 1.13s  Val. loss: 0.0960\n",
      "Epoch 39, 100% \t Train loss: 0.0832 took: 1.12s  Val. loss: 0.0941\n",
      "Epoch 40, 100% \t Train loss: 0.0829 took: 1.14s  Val. loss: 0.0942\n",
      "Epoch 41, 100% \t Train loss: 0.0812 took: 1.19s  Val. loss: 0.0915\n",
      "Epoch 42, 100% \t Train loss: 0.0813 took: 1.94s  Val. loss: 0.0926\n",
      "Epoch 43, 100% \t Train loss: 0.0809 took: 1.95s  Val. loss: 0.0901\n",
      "Epoch 44, 100% \t Train loss: 0.0800 took: 1.96s  Val. loss: 0.0933\n",
      "Epoch 45, 100% \t Train loss: 0.0817 took: 1.96s  Val. loss: 0.0920\n",
      "Epoch 46, 100% \t Train loss: 0.0803 took: 1.95s  Val. loss: 0.0945\n",
      "Epoch 47, 100% \t Train loss: 0.0800 took: 1.94s  Val. loss: 0.0915\n",
      "Epoch 48, 100% \t Train loss: 0.0784 took: 1.22s  Val. loss: 0.0917\n",
      "Epoch 49, 100% \t Train loss: 0.0800 took: 1.23s  Val. loss: 0.0890\n",
      "Epoch 50, 100% \t Train loss: 0.0780 took: 1.24s  Val. loss: 0.0989\n",
      "Training finished, took 65.57s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2613 took: 1.72s  Val. loss: 0.2569\n",
      "Epoch 2, 100% \t Train loss: 0.2574 took: 0.99s  Val. loss: 0.2491\n",
      "Epoch 3, 100% \t Train loss: 0.2250 took: 1.00s  Val. loss: 0.1969\n",
      "Epoch 4, 100% \t Train loss: 0.1856 took: 1.00s  Val. loss: 0.1838\n",
      "Epoch 5, 100% \t Train loss: 0.1776 took: 0.99s  Val. loss: 0.1841\n",
      "Epoch 6, 100% \t Train loss: 0.1783 took: 1.00s  Val. loss: 0.1759\n",
      "Epoch 7, 100% \t Train loss: 0.1727 took: 1.00s  Val. loss: 0.1790\n",
      "Epoch 8, 100% \t Train loss: 0.1731 took: 1.00s  Val. loss: 0.1747\n",
      "Epoch 9, 100% \t Train loss: 0.1732 took: 1.00s  Val. loss: 0.1702\n",
      "Epoch 10, 100% \t Train loss: 0.1688 took: 1.00s  Val. loss: 0.1702\n",
      "Epoch 11, 100% \t Train loss: 0.1674 took: 1.00s  Val. loss: 0.1714\n",
      "Epoch 12, 100% \t Train loss: 0.1678 took: 1.00s  Val. loss: 0.1681\n",
      "Epoch 13, 100% \t Train loss: 0.1657 took: 1.00s  Val. loss: 0.1734\n",
      "Epoch 14, 100% \t Train loss: 0.1654 took: 1.00s  Val. loss: 0.1703\n",
      "Epoch 15, 100% \t Train loss: 0.1647 took: 1.00s  Val. loss: 0.1721\n",
      "Epoch 16, 100% \t Train loss: 0.1670 took: 1.00s  Val. loss: 0.1720\n",
      "Epoch 17, 100% \t Train loss: 0.1653 took: 1.00s  Val. loss: 0.1711\n",
      "Epoch 18, 100% \t Train loss: 0.1622 took: 1.00s  Val. loss: 0.1668\n",
      "Epoch 19, 100% \t Train loss: 0.1640 took: 1.00s  Val. loss: 0.1672\n",
      "Epoch 20, 100% \t Train loss: 0.1651 took: 1.00s  Val. loss: 0.1720\n",
      "Epoch 21, 100% \t Train loss: 0.1627 took: 1.00s  Val. loss: 0.1689\n",
      "Epoch 22, 100% \t Train loss: 0.1607 took: 1.00s  Val. loss: 0.1667\n",
      "Epoch 23, 100% \t Train loss: 0.1614 took: 1.00s  Val. loss: 0.1662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1606 took: 1.00s  Val. loss: 0.1636\n",
      "Epoch 25, 100% \t Train loss: 0.1584 took: 1.00s  Val. loss: 0.1636\n",
      "Epoch 26, 100% \t Train loss: 0.1592 took: 1.00s  Val. loss: 0.1650\n",
      "Epoch 27, 100% \t Train loss: 0.1571 took: 1.00s  Val. loss: 0.1615\n",
      "Epoch 28, 100% \t Train loss: 0.1560 took: 1.00s  Val. loss: 0.1630\n",
      "Epoch 29, 100% \t Train loss: 0.1552 took: 1.00s  Val. loss: 0.1614\n",
      "Epoch 30, 100% \t Train loss: 0.1545 took: 1.00s  Val. loss: 0.1669\n",
      "Epoch 31, 100% \t Train loss: 0.1548 took: 1.00s  Val. loss: 0.1646\n",
      "Epoch 32, 100% \t Train loss: 0.1533 took: 1.00s  Val. loss: 0.1600\n",
      "Epoch 33, 100% \t Train loss: 0.1516 took: 1.01s  Val. loss: 0.1583\n",
      "Epoch 34, 100% \t Train loss: 0.1497 took: 1.10s  Val. loss: 0.1558\n",
      "Epoch 35, 100% \t Train loss: 0.1478 took: 1.02s  Val. loss: 0.1571\n",
      "Epoch 36, 100% \t Train loss: 0.1455 took: 1.02s  Val. loss: 0.1548\n",
      "Epoch 37, 100% \t Train loss: 0.1452 took: 1.03s  Val. loss: 0.1512\n",
      "Epoch 38, 100% \t Train loss: 0.1418 took: 1.03s  Val. loss: 0.1496\n",
      "Epoch 39, 100% \t Train loss: 0.1388 took: 1.03s  Val. loss: 0.1522\n",
      "Epoch 40, 100% \t Train loss: 0.1367 took: 1.04s  Val. loss: 0.1439\n",
      "Epoch 41, 100% \t Train loss: 0.1334 took: 1.06s  Val. loss: 0.1488\n",
      "Epoch 42, 100% \t Train loss: 0.1289 took: 1.07s  Val. loss: 0.1349\n",
      "Epoch 43, 100% \t Train loss: 0.1244 took: 1.07s  Val. loss: 0.1297\n",
      "Epoch 44, 100% \t Train loss: 0.1207 took: 1.08s  Val. loss: 0.1305\n",
      "Epoch 45, 100% \t Train loss: 0.1193 took: 1.12s  Val. loss: 0.1266\n",
      "Epoch 46, 100% \t Train loss: 0.1144 took: 1.13s  Val. loss: 0.1238\n",
      "Epoch 47, 100% \t Train loss: 0.1133 took: 1.14s  Val. loss: 0.1177\n",
      "Epoch 48, 100% \t Train loss: 0.1098 took: 1.15s  Val. loss: 0.1186\n",
      "Epoch 49, 100% \t Train loss: 0.1082 took: 1.15s  Val. loss: 0.1148\n",
      "Epoch 50, 100% \t Train loss: 0.1059 took: 1.16s  Val. loss: 0.1118\n",
      "Training finished, took 59.20s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2574 took: 1.00s  Val. loss: 0.2687\n",
      "Epoch 2, 100% \t Train loss: 0.2568 took: 1.00s  Val. loss: 0.2669\n",
      "Epoch 3, 100% \t Train loss: 0.2558 took: 1.00s  Val. loss: 0.2657\n",
      "Epoch 4, 100% \t Train loss: 0.2525 took: 1.00s  Val. loss: 0.2600\n",
      "Epoch 5, 100% \t Train loss: 0.2367 took: 1.00s  Val. loss: 0.2337\n",
      "Epoch 6, 100% \t Train loss: 0.2036 took: 1.00s  Val. loss: 0.2070\n",
      "Epoch 7, 100% \t Train loss: 0.1847 took: 1.00s  Val. loss: 0.1977\n",
      "Epoch 8, 100% \t Train loss: 0.1795 took: 1.00s  Val. loss: 0.1868\n",
      "Epoch 9, 100% \t Train loss: 0.1746 took: 0.99s  Val. loss: 0.1841\n",
      "Epoch 10, 100% \t Train loss: 0.1708 took: 1.00s  Val. loss: 0.1847\n",
      "Epoch 11, 100% \t Train loss: 0.1686 took: 0.99s  Val. loss: 0.1850\n",
      "Epoch 12, 20% \t Train loss: 0.1722 took: 0.20s  "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    bayes_HP_tuning.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
