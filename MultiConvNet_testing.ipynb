{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from Utils import test_env, utils\n",
    "from Utils import HP_tuning \n",
    "from Utils.supervised import *\n",
    "\n",
    "from RelationalModule import AC_networks as nets\n",
    "from RelationalModule.MLP_AC_networks import Actor\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters to try out and their priors, class for evaluation, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Utils.HP_tuning' from '/m/home/home9/94/dainesn1/unix/Workdir/RelationalDeepRL/Utils/HP_tuning.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(HP_tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalSandboxModel():\n",
    "    def __init__(self, model, model_spec, game_params, n_epochs=50, n_samples=10000):\n",
    "        self.model = model\n",
    "        self.model_spec = model_spec\n",
    "        self.game_params = game_params\n",
    "        self.n_epochs = n_epochs\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "    def evaluate_params(self, HPs, lambdas):\n",
    "        train_V_lambda = [] \n",
    "        val_V_lambda = []\n",
    "        for lr in lambdas:\n",
    "            net = self.model(**self.model_spec, **HPs)\n",
    "            results = supervised_training(net, lr, self.n_epochs, self.n_samples, \n",
    "                                          self.game_params, get_probs=True)\n",
    "            trained_net, train_loss, val_loss, dataloader_dict, state_set, action_set, env = results\n",
    "            \n",
    "            train_V = 1-np.array(train_loss)\n",
    "            train_V_lambda.append(train_V)\n",
    "            \n",
    "            val_V = 1-np.array(val_loss)\n",
    "            val_V_lambda.append(val_V)\n",
    "            \n",
    "        return np.array(train_V_lambda), np.array(val_V_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable parameters\n",
    "X = 10\n",
    "Y = 10\n",
    "initial = [0,0]\n",
    "goal = [2,2]\n",
    "MAX_STEPS = 25\n",
    "\n",
    "game_params = dict(x=X, y=Y, initial=initial, goal=goal, max_steps=MAX_STEPS, \n",
    "                   greyscale_state=True, return_ohe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.MultiplicativeActor\n",
    "model_spec = dict(action_space=4, linear_size = X+2, in_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_instance = EvalSandboxModel(model, model_spec, game_params, 50, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_priors_dict = {'out_channels':([[6],[8], [12],[6,12]], [1/4, 1/4, 1/4, 1/4]),\n",
    "                     'max_pool_size':([2,3,4], [0.5, 0.3, 0.2]),\n",
    "                     'n_features':([16,32,64],[1/3,1/3,1/3]),\n",
    "                     'info_channels':([4,6,8],[0.2, 0.3, 0.5]),\n",
    "                     'mask_channels':([4,6,8],[0.2, 0.3, 0.5]),\n",
    "                     'hidden_channels':([6, 12, 32], [1/3, 1/3, 1/3]),\n",
    "                     'residual_hidden_dim':([16,32,64],[1/3, 1/3, 1/3]),\n",
    "                     'n_residual_layers':([1,2,3,4],[0.1, 0.3, 0.3, 0.3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_HP_tuning = HP_tuning.BayesHPTuning(value_priors_dict, eval_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.20\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.50\n",
      "\tmask_channels :  8  - prob: 0.50\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2639 took: 2.02s  Val. loss: 0.2569\n",
      "Epoch 2, 100% \t Train loss: 0.2528 took: 2.00s  Val. loss: 0.2258\n",
      "Epoch 3, 100% \t Train loss: 0.2097 took: 2.01s  Val. loss: 0.1995\n",
      "Epoch 4, 100% \t Train loss: 0.1956 took: 2.00s  Val. loss: 0.1896\n",
      "Epoch 5, 100% \t Train loss: 0.1901 took: 1.99s  Val. loss: 0.1828\n",
      "Epoch 6, 100% \t Train loss: 0.1889 took: 1.99s  Val. loss: 0.1828\n",
      "Epoch 7, 100% \t Train loss: 0.1871 took: 1.98s  Val. loss: 0.1817\n",
      "Epoch 8, 100% \t Train loss: 0.1857 took: 1.99s  Val. loss: 0.1790\n",
      "Epoch 9, 100% \t Train loss: 0.1848 took: 1.97s  Val. loss: 0.1797\n",
      "Epoch 10, 100% \t Train loss: 0.1843 took: 2.01s  Val. loss: 0.1820\n",
      "Epoch 11, 100% \t Train loss: 0.1834 took: 1.97s  Val. loss: 0.1832\n",
      "Epoch 12, 100% \t Train loss: 0.1823 took: 1.99s  Val. loss: 0.1786\n",
      "Epoch 13, 100% \t Train loss: 0.1809 took: 1.99s  Val. loss: 0.1843\n",
      "Epoch 14, 100% \t Train loss: 0.1813 took: 1.98s  Val. loss: 0.1792\n",
      "Epoch 15, 100% \t Train loss: 0.1801 took: 1.97s  Val. loss: 0.1788\n",
      "Epoch 16, 100% \t Train loss: 0.1796 took: 2.00s  Val. loss: 0.1775\n",
      "Epoch 17, 100% \t Train loss: 0.1797 took: 2.01s  Val. loss: 0.1761\n",
      "Epoch 18, 100% \t Train loss: 0.1754 took: 2.00s  Val. loss: 0.1772\n",
      "Epoch 19, 100% \t Train loss: 0.1715 took: 1.99s  Val. loss: 0.1689\n",
      "Epoch 20, 100% \t Train loss: 0.1663 took: 2.01s  Val. loss: 0.1671\n",
      "Epoch 21, 100% \t Train loss: 0.1604 took: 2.00s  Val. loss: 0.1565\n",
      "Epoch 22, 100% \t Train loss: 0.1538 took: 2.00s  Val. loss: 0.1542\n",
      "Epoch 23, 100% \t Train loss: 0.1479 took: 1.99s  Val. loss: 0.1464\n",
      "Epoch 24, 100% \t Train loss: 0.1422 took: 1.99s  Val. loss: 0.1406\n",
      "Epoch 25, 100% \t Train loss: 0.1399 took: 1.99s  Val. loss: 0.1418\n",
      "Epoch 26, 100% \t Train loss: 0.1384 took: 1.98s  Val. loss: 0.1464\n",
      "Epoch 27, 100% \t Train loss: 0.1364 took: 2.00s  Val. loss: 0.1367\n",
      "Epoch 28, 100% \t Train loss: 0.1348 took: 2.01s  Val. loss: 0.1369\n",
      "Epoch 29, 100% \t Train loss: 0.1332 took: 2.00s  Val. loss: 0.1350\n",
      "Epoch 30, 100% \t Train loss: 0.1315 took: 2.02s  Val. loss: 0.1368\n",
      "Epoch 31, 100% \t Train loss: 0.1306 took: 2.06s  Val. loss: 0.1327\n",
      "Epoch 32, 100% \t Train loss: 0.1291 took: 2.12s  Val. loss: 0.1348\n",
      "Epoch 33, 100% \t Train loss: 0.1277 took: 2.25s  Val. loss: 0.1349\n",
      "Epoch 34, 100% \t Train loss: 0.1283 took: 2.29s  Val. loss: 0.1317\n",
      "Epoch 35, 100% \t Train loss: 0.1269 took: 2.28s  Val. loss: 0.1307\n",
      "Epoch 36, 100% \t Train loss: 0.1270 took: 2.29s  Val. loss: 0.1307\n",
      "Epoch 37, 100% \t Train loss: 0.1260 took: 2.28s  Val. loss: 0.1287\n",
      "Epoch 38, 100% \t Train loss: 0.1249 took: 2.25s  Val. loss: 0.1303\n",
      "Epoch 39, 100% \t Train loss: 0.1246 took: 2.18s  Val. loss: 0.1295\n",
      "Epoch 40, 100% \t Train loss: 0.1243 took: 2.21s  Val. loss: 0.1318\n",
      "Epoch 41, 100% \t Train loss: 0.1246 took: 2.18s  Val. loss: 0.1320\n",
      "Epoch 42, 100% \t Train loss: 0.1232 took: 2.17s  Val. loss: 0.1284\n",
      "Epoch 43, 100% \t Train loss: 0.1246 took: 2.16s  Val. loss: 0.1336\n",
      "Epoch 44, 100% \t Train loss: 0.1231 took: 2.16s  Val. loss: 0.1296\n",
      "Epoch 45, 100% \t Train loss: 0.1232 took: 2.17s  Val. loss: 0.1286\n",
      "Epoch 46, 100% \t Train loss: 0.1226 took: 2.17s  Val. loss: 0.1309\n",
      "Epoch 47, 100% \t Train loss: 0.1221 took: 2.17s  Val. loss: 0.1311\n",
      "Epoch 48, 100% \t Train loss: 0.1209 took: 2.16s  Val. loss: 0.1283\n",
      "Epoch 49, 100% \t Train loss: 0.1213 took: 2.16s  Val. loss: 0.1311\n",
      "Epoch 50, 100% \t Train loss: 0.1219 took: 2.17s  Val. loss: 0.1287\n",
      "Training finished, took 117.23s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 2.00s  Val. loss: 0.2547\n",
      "Epoch 2, 100% \t Train loss: 0.2586 took: 1.99s  Val. loss: 0.2541\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 1.99s  Val. loss: 0.2550\n",
      "Epoch 4, 100% \t Train loss: 0.2581 took: 1.99s  Val. loss: 0.2536\n",
      "Epoch 5, 100% \t Train loss: 0.2524 took: 1.98s  Val. loss: 0.2376\n",
      "Epoch 6, 100% \t Train loss: 0.2279 took: 2.01s  Val. loss: 0.2189\n",
      "Epoch 7, 100% \t Train loss: 0.2200 took: 2.00s  Val. loss: 0.2118\n",
      "Epoch 8, 100% \t Train loss: 0.2051 took: 2.01s  Val. loss: 0.1951\n",
      "Epoch 9, 100% \t Train loss: 0.1982 took: 2.00s  Val. loss: 0.1918\n",
      "Epoch 10, 100% \t Train loss: 0.1956 took: 2.00s  Val. loss: 0.1888\n",
      "Epoch 11, 100% \t Train loss: 0.1955 took: 1.99s  Val. loss: 0.1948\n",
      "Epoch 12, 100% \t Train loss: 0.1947 took: 2.00s  Val. loss: 0.1888\n",
      "Epoch 13, 100% \t Train loss: 0.1944 took: 2.01s  Val. loss: 0.1900\n",
      "Epoch 14, 100% \t Train loss: 0.1929 took: 2.01s  Val. loss: 0.1905\n",
      "Epoch 15, 100% \t Train loss: 0.1930 took: 2.02s  Val. loss: 0.1966\n",
      "Epoch 16, 100% \t Train loss: 0.1937 took: 2.00s  Val. loss: 0.1912\n",
      "Epoch 17, 100% \t Train loss: 0.1966 took: 2.01s  Val. loss: 0.1869\n",
      "Epoch 18, 100% \t Train loss: 0.1928 took: 2.02s  Val. loss: 0.1893\n",
      "Epoch 19, 100% \t Train loss: 0.1915 took: 2.01s  Val. loss: 0.1870\n",
      "Epoch 20, 100% \t Train loss: 0.1922 took: 2.00s  Val. loss: 0.1876\n",
      "Epoch 21, 100% \t Train loss: 0.1925 took: 2.00s  Val. loss: 0.1884\n",
      "Epoch 22, 100% \t Train loss: 0.1904 took: 2.00s  Val. loss: 0.1879\n",
      "Epoch 23, 100% \t Train loss: 0.1915 took: 2.02s  Val. loss: 0.1899\n",
      "Epoch 24, 100% \t Train loss: 0.1891 took: 2.00s  Val. loss: 0.1857\n",
      "Epoch 25, 100% \t Train loss: 0.1905 took: 2.01s  Val. loss: 0.1869\n",
      "Epoch 26, 100% \t Train loss: 0.1898 took: 2.01s  Val. loss: 0.1902\n",
      "Epoch 27, 100% \t Train loss: 0.1894 took: 2.01s  Val. loss: 0.1845\n",
      "Epoch 28, 100% \t Train loss: 0.1879 took: 2.00s  Val. loss: 0.1875\n",
      "Epoch 29, 100% \t Train loss: 0.1892 took: 1.99s  Val. loss: 0.1855\n",
      "Epoch 30, 100% \t Train loss: 0.1892 took: 1.98s  Val. loss: 0.1848\n",
      "Epoch 31, 100% \t Train loss: 0.1890 took: 2.02s  Val. loss: 0.1847\n",
      "Epoch 32, 100% \t Train loss: 0.1874 took: 2.01s  Val. loss: 0.1846\n",
      "Epoch 33, 100% \t Train loss: 0.1870 took: 2.03s  Val. loss: 0.1816\n",
      "Epoch 34, 100% \t Train loss: 0.1883 took: 2.03s  Val. loss: 0.1851\n",
      "Epoch 35, 100% \t Train loss: 0.1874 took: 2.03s  Val. loss: 0.1828\n",
      "Epoch 36, 100% \t Train loss: 0.1860 took: 2.05s  Val. loss: 0.1877\n",
      "Epoch 37, 100% \t Train loss: 0.1859 took: 2.04s  Val. loss: 0.1802\n",
      "Epoch 38, 100% \t Train loss: 0.1856 took: 2.04s  Val. loss: 0.1823\n",
      "Epoch 39, 100% \t Train loss: 0.1850 took: 2.07s  Val. loss: 0.1804\n",
      "Epoch 40, 100% \t Train loss: 0.1848 took: 2.06s  Val. loss: 0.1797\n",
      "Epoch 41, 100% \t Train loss: 0.1844 took: 2.08s  Val. loss: 0.1820\n",
      "Epoch 42, 100% \t Train loss: 0.1844 took: 2.09s  Val. loss: 0.1818\n",
      "Epoch 43, 100% \t Train loss: 0.1846 took: 2.10s  Val. loss: 0.1845\n",
      "Epoch 44, 100% \t Train loss: 0.1822 took: 2.11s  Val. loss: 0.1787\n",
      "Epoch 45, 100% \t Train loss: 0.1829 took: 1.30s  Val. loss: 0.1898\n",
      "Epoch 46, 100% \t Train loss: 0.1817 took: 1.30s  Val. loss: 0.1790\n",
      "Epoch 47, 100% \t Train loss: 0.1816 took: 1.31s  Val. loss: 0.1820\n",
      "Epoch 48, 100% \t Train loss: 0.1802 took: 1.32s  Val. loss: 0.1821\n",
      "Epoch 49, 100% \t Train loss: 0.1802 took: 1.32s  Val. loss: 0.1807\n",
      "Epoch 50, 100% \t Train loss: 0.1782 took: 1.32s  Val. loss: 0.1748\n",
      "Training finished, took 109.47s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2611 took: 2.00s  Val. loss: 0.2628\n",
      "Epoch 2, 100% \t Train loss: 0.2609 took: 1.99s  Val. loss: 0.2634\n",
      "Epoch 3, 100% \t Train loss: 0.2607 took: 1.99s  Val. loss: 0.2632\n",
      "Epoch 4, 100% \t Train loss: 0.2605 took: 2.01s  Val. loss: 0.2637\n",
      "Epoch 5, 100% \t Train loss: 0.2588 took: 1.99s  Val. loss: 0.2604\n",
      "Epoch 6, 100% \t Train loss: 0.2494 took: 2.00s  Val. loss: 0.2479\n",
      "Epoch 7, 100% \t Train loss: 0.2338 took: 2.00s  Val. loss: 0.2425\n",
      "Epoch 8, 100% \t Train loss: 0.2286 took: 1.98s  Val. loss: 0.2386\n",
      "Epoch 9, 100% \t Train loss: 0.2218 took: 2.02s  Val. loss: 0.2345\n",
      "Epoch 10, 100% \t Train loss: 0.2142 took: 2.00s  Val. loss: 0.2266\n",
      "Epoch 11, 100% \t Train loss: 0.2074 took: 2.00s  Val. loss: 0.2277\n",
      "Epoch 12, 100% \t Train loss: 0.2046 took: 2.00s  Val. loss: 0.2215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 100% \t Train loss: 0.2037 took: 2.01s  Val. loss: 0.2184\n",
      "Epoch 14, 100% \t Train loss: 0.2011 took: 2.00s  Val. loss: 0.2174\n",
      "Epoch 15, 100% \t Train loss: 0.1998 took: 2.00s  Val. loss: 0.2126\n",
      "Epoch 16, 100% \t Train loss: 0.1992 took: 1.99s  Val. loss: 0.2142\n",
      "Epoch 17, 100% \t Train loss: 0.1990 took: 2.01s  Val. loss: 0.2115\n",
      "Epoch 18, 100% \t Train loss: 0.1969 took: 1.99s  Val. loss: 0.2102\n",
      "Epoch 19, 100% \t Train loss: 0.1984 took: 2.00s  Val. loss: 0.2124\n",
      "Epoch 20, 100% \t Train loss: 0.1951 took: 2.02s  Val. loss: 0.2153\n",
      "Epoch 21, 100% \t Train loss: 0.1947 took: 2.00s  Val. loss: 0.2137\n",
      "Epoch 22, 100% \t Train loss: 0.1952 took: 1.18s  Val. loss: 0.2252\n",
      "Epoch 23, 100% \t Train loss: 0.1972 took: 1.18s  Val. loss: 0.2099\n",
      "Epoch 24, 100% \t Train loss: 0.1949 took: 1.19s  Val. loss: 0.2187\n",
      "Epoch 25, 100% \t Train loss: 0.1935 took: 1.18s  Val. loss: 0.2098\n",
      "Epoch 26, 100% \t Train loss: 0.1946 took: 1.18s  Val. loss: 0.2124\n",
      "Epoch 27, 100% \t Train loss: 0.1926 took: 1.18s  Val. loss: 0.2109\n",
      "Epoch 28, 100% \t Train loss: 0.1950 took: 1.19s  Val. loss: 0.2124\n",
      "Epoch 29, 100% \t Train loss: 0.1918 took: 1.19s  Val. loss: 0.2091\n",
      "Epoch 30, 100% \t Train loss: 0.1928 took: 1.20s  Val. loss: 0.2079\n",
      "Epoch 31, 100% \t Train loss: 0.1914 took: 1.20s  Val. loss: 0.2056\n",
      "Epoch 32, 100% \t Train loss: 0.1902 took: 1.22s  Val. loss: 0.2088\n",
      "Epoch 33, 100% \t Train loss: 0.1908 took: 1.21s  Val. loss: 0.2101\n",
      "Epoch 34, 100% \t Train loss: 0.1895 took: 1.21s  Val. loss: 0.2095\n",
      "Epoch 35, 100% \t Train loss: 0.1896 took: 1.22s  Val. loss: 0.2083\n",
      "Epoch 36, 100% \t Train loss: 0.1889 took: 1.21s  Val. loss: 0.2053\n",
      "Epoch 37, 100% \t Train loss: 0.1891 took: 1.20s  Val. loss: 0.2066\n",
      "Epoch 38, 100% \t Train loss: 0.1896 took: 1.19s  Val. loss: 0.2057\n",
      "Epoch 39, 100% \t Train loss: 0.1889 took: 1.76s  Val. loss: 0.2045\n",
      "Epoch 40, 100% \t Train loss: 0.1878 took: 2.02s  Val. loss: 0.2026\n",
      "Epoch 41, 100% \t Train loss: 0.1885 took: 1.99s  Val. loss: 0.2051\n",
      "Epoch 42, 100% \t Train loss: 0.1865 took: 2.00s  Val. loss: 0.2061\n",
      "Epoch 43, 100% \t Train loss: 0.1869 took: 2.01s  Val. loss: 0.2033\n",
      "Epoch 44, 100% \t Train loss: 0.1864 took: 1.99s  Val. loss: 0.2043\n",
      "Epoch 45, 100% \t Train loss: 0.1843 took: 1.99s  Val. loss: 0.2003\n",
      "Epoch 46, 100% \t Train loss: 0.1836 took: 2.00s  Val. loss: 0.2057\n",
      "Epoch 47, 100% \t Train loss: 0.1831 took: 2.00s  Val. loss: 0.2012\n",
      "Epoch 48, 100% \t Train loss: 0.1824 took: 2.00s  Val. loss: 0.1981\n",
      "Epoch 49, 100% \t Train loss: 0.1838 took: 2.00s  Val. loss: 0.2052\n",
      "Epoch 50, 100% \t Train loss: 0.1823 took: 1.99s  Val. loss: 0.2207\n",
      "Training finished, took 97.16s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.20\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.50\n",
      "\tmask_channels :  8  - prob: 0.50\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.844404\n",
      "lambda: 0.0010 - V: 0.806403\n",
      "lambda: 0.0005 - V: 0.781775\n",
      "Average V: 0.810860\n",
      "Time elapsed: 327.41 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.48\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.32\n",
      "\tmask_channels :  6  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.31\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2593 took: 1.86s  Val. loss: 0.2619\n",
      "Epoch 2, 100% \t Train loss: 0.2578 took: 1.84s  Val. loss: 0.2623\n",
      "Epoch 3, 100% \t Train loss: 0.2578 took: 1.86s  Val. loss: 0.2621\n",
      "Epoch 4, 100% \t Train loss: 0.2576 took: 1.81s  Val. loss: 0.2622\n",
      "Epoch 5, 100% \t Train loss: 0.2576 took: 1.83s  Val. loss: 0.2618\n",
      "Epoch 6, 100% \t Train loss: 0.2573 took: 1.84s  Val. loss: 0.2613\n",
      "Epoch 7, 100% \t Train loss: 0.2518 took: 1.83s  Val. loss: 0.2287\n",
      "Epoch 8, 100% \t Train loss: 0.1855 took: 1.85s  Val. loss: 0.1883\n",
      "Epoch 9, 100% \t Train loss: 0.1685 took: 1.86s  Val. loss: 0.1704\n",
      "Epoch 10, 100% \t Train loss: 0.1600 took: 1.85s  Val. loss: 0.1656\n",
      "Epoch 11, 100% \t Train loss: 0.1579 took: 1.85s  Val. loss: 0.1627\n",
      "Epoch 12, 100% \t Train loss: 0.1572 took: 1.85s  Val. loss: 0.1646\n",
      "Epoch 13, 100% \t Train loss: 0.1540 took: 1.85s  Val. loss: 0.1607\n",
      "Epoch 14, 100% \t Train loss: 0.1541 took: 1.82s  Val. loss: 0.1626\n",
      "Epoch 15, 100% \t Train loss: 0.1523 took: 1.82s  Val. loss: 0.1637\n",
      "Epoch 16, 100% \t Train loss: 0.1528 took: 1.83s  Val. loss: 0.1632\n",
      "Epoch 17, 100% \t Train loss: 0.1519 took: 1.84s  Val. loss: 0.1634\n",
      "Epoch 18, 100% \t Train loss: 0.1505 took: 1.83s  Val. loss: 0.1629\n",
      "Epoch 19, 100% \t Train loss: 0.1511 took: 1.83s  Val. loss: 0.1613\n",
      "Epoch 20, 100% \t Train loss: 0.1498 took: 1.85s  Val. loss: 0.1616\n",
      "Epoch 21, 100% \t Train loss: 0.1489 took: 1.82s  Val. loss: 0.1661\n",
      "Epoch 22, 100% \t Train loss: 0.1479 took: 1.82s  Val. loss: 0.1634\n",
      "Epoch 23, 100% \t Train loss: 0.1477 took: 1.83s  Val. loss: 0.1626\n",
      "Epoch 24, 100% \t Train loss: 0.1480 took: 1.84s  Val. loss: 0.1618\n",
      "Epoch 25, 100% \t Train loss: 0.1466 took: 1.82s  Val. loss: 0.1624\n",
      "Epoch 26, 100% \t Train loss: 0.1460 took: 1.83s  Val. loss: 0.1641\n",
      "Epoch 27, 100% \t Train loss: 0.1469 took: 1.83s  Val. loss: 0.1586\n",
      "Epoch 28, 100% \t Train loss: 0.1450 took: 1.85s  Val. loss: 0.1606\n",
      "Epoch 29, 100% \t Train loss: 0.1458 took: 1.83s  Val. loss: 0.1608\n",
      "Epoch 30, 100% \t Train loss: 0.1459 took: 1.84s  Val. loss: 0.1609\n",
      "Epoch 31, 100% \t Train loss: 0.1450 took: 1.85s  Val. loss: 0.1620\n",
      "Epoch 32, 100% \t Train loss: 0.1441 took: 1.87s  Val. loss: 0.1616\n",
      "Epoch 33, 100% \t Train loss: 0.1436 took: 1.94s  Val. loss: 0.1617\n",
      "Epoch 34, 100% \t Train loss: 0.1444 took: 1.99s  Val. loss: 0.1594\n",
      "Epoch 35, 100% \t Train loss: 0.1432 took: 1.98s  Val. loss: 0.1625\n",
      "Epoch 36, 100% \t Train loss: 0.1430 took: 1.99s  Val. loss: 0.1668\n",
      "Epoch 37, 100% \t Train loss: 0.1432 took: 1.99s  Val. loss: 0.1630\n",
      "Epoch 38, 100% \t Train loss: 0.1426 took: 2.01s  Val. loss: 0.1637\n",
      "Epoch 39, 100% \t Train loss: 0.1418 took: 2.01s  Val. loss: 0.1644\n",
      "Epoch 40, 100% \t Train loss: 0.1426 took: 2.01s  Val. loss: 0.1605\n",
      "Epoch 41, 100% \t Train loss: 0.1418 took: 2.01s  Val. loss: 0.1640\n",
      "Epoch 42, 100% \t Train loss: 0.1415 took: 2.01s  Val. loss: 0.1619\n",
      "Epoch 43, 100% \t Train loss: 0.1410 took: 2.01s  Val. loss: 0.1600\n",
      "Epoch 44, 100% \t Train loss: 0.1410 took: 2.01s  Val. loss: 0.1638\n",
      "Epoch 45, 100% \t Train loss: 0.1393 took: 2.02s  Val. loss: 0.1621\n",
      "Epoch 46, 100% \t Train loss: 0.1386 took: 1.25s  Val. loss: 0.1608\n",
      "Epoch 47, 100% \t Train loss: 0.1365 took: 1.28s  Val. loss: 0.1613\n",
      "Epoch 48, 100% \t Train loss: 0.1355 took: 1.28s  Val. loss: 0.1548\n",
      "Epoch 49, 100% \t Train loss: 0.1322 took: 1.27s  Val. loss: 0.1556\n",
      "Epoch 50, 100% \t Train loss: 0.1273 took: 1.29s  Val. loss: 0.1454\n",
      "Training finished, took 103.58s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 1.84s  Val. loss: 0.2636\n",
      "Epoch 2, 100% \t Train loss: 0.2582 took: 1.82s  Val. loss: 0.2637\n",
      "Epoch 3, 100% \t Train loss: 0.2582 took: 1.83s  Val. loss: 0.2634\n",
      "Epoch 4, 100% \t Train loss: 0.2580 took: 1.83s  Val. loss: 0.2635\n",
      "Epoch 5, 100% \t Train loss: 0.2573 took: 1.83s  Val. loss: 0.2633\n",
      "Epoch 6, 100% \t Train loss: 0.2551 took: 1.83s  Val. loss: 0.2574\n",
      "Epoch 7, 100% \t Train loss: 0.2426 took: 1.82s  Val. loss: 0.2415\n",
      "Epoch 8, 100% \t Train loss: 0.2214 took: 1.83s  Val. loss: 0.2149\n",
      "Epoch 9, 100% \t Train loss: 0.2001 took: 1.07s  Val. loss: 0.2021\n",
      "Epoch 10, 100% \t Train loss: 0.1855 took: 1.07s  Val. loss: 0.1851\n",
      "Epoch 11, 100% \t Train loss: 0.1749 took: 1.06s  Val. loss: 0.1769\n",
      "Epoch 12, 100% \t Train loss: 0.1682 took: 1.06s  Val. loss: 0.1745\n",
      "Epoch 13, 100% \t Train loss: 0.1661 took: 1.07s  Val. loss: 0.1714\n",
      "Epoch 14, 100% \t Train loss: 0.1630 took: 1.07s  Val. loss: 0.1677\n",
      "Epoch 15, 100% \t Train loss: 0.1608 took: 1.06s  Val. loss: 0.1755\n",
      "Epoch 16, 100% \t Train loss: 0.1589 took: 1.06s  Val. loss: 0.1704\n",
      "Epoch 17, 100% \t Train loss: 0.1577 took: 1.06s  Val. loss: 0.1639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, 100% \t Train loss: 0.1551 took: 1.06s  Val. loss: 0.1626\n",
      "Epoch 19, 100% \t Train loss: 0.1538 took: 1.07s  Val. loss: 0.1608\n",
      "Epoch 20, 100% \t Train loss: 0.1545 took: 1.07s  Val. loss: 0.1634\n",
      "Epoch 21, 100% \t Train loss: 0.1537 took: 1.06s  Val. loss: 0.1607\n",
      "Epoch 22, 100% \t Train loss: 0.1521 took: 1.07s  Val. loss: 0.1642\n",
      "Epoch 23, 100% \t Train loss: 0.1522 took: 1.07s  Val. loss: 0.1586\n",
      "Epoch 24, 100% \t Train loss: 0.1516 took: 1.06s  Val. loss: 0.1638\n",
      "Epoch 25, 100% \t Train loss: 0.1505 took: 1.06s  Val. loss: 0.1613\n",
      "Epoch 26, 100% \t Train loss: 0.1488 took: 1.07s  Val. loss: 0.1593\n",
      "Epoch 27, 100% \t Train loss: 0.1496 took: 1.06s  Val. loss: 0.1588\n",
      "Epoch 28, 100% \t Train loss: 0.1475 took: 1.07s  Val. loss: 0.1591\n",
      "Epoch 29, 100% \t Train loss: 0.1466 took: 1.08s  Val. loss: 0.1523\n",
      "Epoch 30, 100% \t Train loss: 0.1469 took: 1.10s  Val. loss: 0.1565\n",
      "Epoch 31, 100% \t Train loss: 0.1458 took: 1.11s  Val. loss: 0.1579\n",
      "Epoch 32, 100% \t Train loss: 0.1449 took: 1.13s  Val. loss: 0.1557\n",
      "Epoch 33, 100% \t Train loss: 0.1431 took: 1.12s  Val. loss: 0.1556\n",
      "Epoch 34, 100% \t Train loss: 0.1437 took: 1.30s  Val. loss: 0.1551\n",
      "Epoch 35, 100% \t Train loss: 0.1428 took: 1.90s  Val. loss: 0.1547\n",
      "Epoch 36, 100% \t Train loss: 0.1419 took: 1.89s  Val. loss: 0.1508\n",
      "Epoch 37, 100% \t Train loss: 0.1432 took: 1.92s  Val. loss: 0.1542\n",
      "Epoch 38, 100% \t Train loss: 0.1406 took: 1.90s  Val. loss: 0.1538\n",
      "Epoch 39, 100% \t Train loss: 0.1394 took: 1.89s  Val. loss: 0.1522\n",
      "Epoch 40, 100% \t Train loss: 0.1395 took: 1.90s  Val. loss: 0.1548\n",
      "Epoch 41, 100% \t Train loss: 0.1385 took: 1.90s  Val. loss: 0.1542\n",
      "Epoch 42, 100% \t Train loss: 0.1376 took: 1.90s  Val. loss: 0.1528\n",
      "Epoch 43, 100% \t Train loss: 0.1375 took: 1.92s  Val. loss: 0.1532\n",
      "Epoch 44, 100% \t Train loss: 0.1364 took: 1.92s  Val. loss: 0.1510\n",
      "Epoch 45, 100% \t Train loss: 0.1354 took: 1.17s  Val. loss: 0.1535\n",
      "Epoch 46, 100% \t Train loss: 0.1359 took: 1.20s  Val. loss: 0.1510\n",
      "Epoch 47, 100% \t Train loss: 0.1346 took: 1.21s  Val. loss: 0.1502\n",
      "Epoch 48, 100% \t Train loss: 0.1342 took: 1.22s  Val. loss: 0.1501\n",
      "Epoch 49, 100% \t Train loss: 0.1335 took: 1.21s  Val. loss: 0.1497\n",
      "Epoch 50, 100% \t Train loss: 0.1321 took: 1.23s  Val. loss: 0.1471\n",
      "Training finished, took 78.09s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2600 took: 1.84s  Val. loss: 0.2595\n",
      "Epoch 2, 100% \t Train loss: 0.2598 took: 1.84s  Val. loss: 0.2609\n",
      "Epoch 3, 100% \t Train loss: 0.2597 took: 1.83s  Val. loss: 0.2593\n",
      "Epoch 4, 100% \t Train loss: 0.2597 took: 1.82s  Val. loss: 0.2608\n",
      "Epoch 5, 100% \t Train loss: 0.2598 took: 1.83s  Val. loss: 0.2597\n",
      "Epoch 6, 100% \t Train loss: 0.2598 took: 1.84s  Val. loss: 0.2604\n",
      "Epoch 7, 100% \t Train loss: 0.2596 took: 1.84s  Val. loss: 0.2599\n",
      "Epoch 8, 100% \t Train loss: 0.2595 took: 1.84s  Val. loss: 0.2591\n",
      "Epoch 9, 100% \t Train loss: 0.2592 took: 1.87s  Val. loss: 0.2590\n",
      "Epoch 10, 100% \t Train loss: 0.2584 took: 1.85s  Val. loss: 0.2580\n",
      "Epoch 11, 100% \t Train loss: 0.2493 took: 1.83s  Val. loss: 0.2341\n",
      "Epoch 12, 100% \t Train loss: 0.2273 took: 1.83s  Val. loss: 0.2190\n",
      "Epoch 13, 100% \t Train loss: 0.2113 took: 1.83s  Val. loss: 0.2018\n",
      "Epoch 14, 100% \t Train loss: 0.1975 took: 1.71s  Val. loss: 0.1949\n",
      "Epoch 15, 100% \t Train loss: 0.1912 took: 1.06s  Val. loss: 0.1875\n",
      "Epoch 16, 100% \t Train loss: 0.1849 took: 1.07s  Val. loss: 0.1892\n",
      "Epoch 17, 100% \t Train loss: 0.1865 took: 1.07s  Val. loss: 0.1835\n",
      "Epoch 18, 100% \t Train loss: 0.1843 took: 1.07s  Val. loss: 0.1884\n",
      "Epoch 19, 100% \t Train loss: 0.1813 took: 1.85s  Val. loss: 0.1864\n",
      "Epoch 20, 100% \t Train loss: 0.1810 took: 1.83s  Val. loss: 0.1821\n",
      "Epoch 21, 100% \t Train loss: 0.1788 took: 1.85s  Val. loss: 0.1805\n",
      "Epoch 22, 100% \t Train loss: 0.1795 took: 1.82s  Val. loss: 0.1821\n",
      "Epoch 23, 100% \t Train loss: 0.1790 took: 1.84s  Val. loss: 0.1994\n",
      "Epoch 24, 100% \t Train loss: 0.1767 took: 1.85s  Val. loss: 0.1768\n",
      "Epoch 25, 100% \t Train loss: 0.1728 took: 1.89s  Val. loss: 0.1770\n",
      "Epoch 26, 100% \t Train loss: 0.1741 took: 1.84s  Val. loss: 0.1789\n",
      "Epoch 27, 100% \t Train loss: 0.1727 took: 1.83s  Val. loss: 0.1741\n",
      "Epoch 28, 100% \t Train loss: 0.1719 took: 1.83s  Val. loss: 0.1846\n",
      "Epoch 29, 100% \t Train loss: 0.1694 took: 1.83s  Val. loss: 0.1708\n",
      "Epoch 30, 100% \t Train loss: 0.1700 took: 1.85s  Val. loss: 0.1711\n",
      "Epoch 31, 100% \t Train loss: 0.1720 took: 1.85s  Val. loss: 0.1705\n",
      "Epoch 32, 100% \t Train loss: 0.1677 took: 1.87s  Val. loss: 0.1765\n",
      "Epoch 33, 100% \t Train loss: 0.1667 took: 1.86s  Val. loss: 0.1680\n",
      "Epoch 34, 100% \t Train loss: 0.1668 took: 1.86s  Val. loss: 0.1693\n",
      "Epoch 35, 100% \t Train loss: 0.1658 took: 1.87s  Val. loss: 0.1665\n",
      "Epoch 36, 100% \t Train loss: 0.1656 took: 1.87s  Val. loss: 0.1719\n",
      "Epoch 37, 100% \t Train loss: 0.1666 took: 1.86s  Val. loss: 0.1688\n",
      "Epoch 38, 100% \t Train loss: 0.1645 took: 1.87s  Val. loss: 0.1717\n",
      "Epoch 39, 100% \t Train loss: 0.1642 took: 1.86s  Val. loss: 0.1688\n",
      "Epoch 40, 100% \t Train loss: 0.1630 took: 1.89s  Val. loss: 0.1672\n",
      "Epoch 41, 100% \t Train loss: 0.1647 took: 1.86s  Val. loss: 0.1677\n",
      "Epoch 42, 100% \t Train loss: 0.1629 took: 1.88s  Val. loss: 0.1786\n",
      "Epoch 43, 100% \t Train loss: 0.1641 took: 1.87s  Val. loss: 0.1652\n",
      "Epoch 44, 100% \t Train loss: 0.1631 took: 1.87s  Val. loss: 0.1658\n",
      "Epoch 45, 100% \t Train loss: 0.1613 took: 1.87s  Val. loss: 0.1691\n",
      "Epoch 46, 100% \t Train loss: 0.1632 took: 1.87s  Val. loss: 0.1786\n",
      "Epoch 47, 100% \t Train loss: 0.1627 took: 1.86s  Val. loss: 0.1658\n",
      "Epoch 48, 100% \t Train loss: 0.1617 took: 1.88s  Val. loss: 0.1671\n",
      "Epoch 49, 100% \t Train loss: 0.1617 took: 1.90s  Val. loss: 0.1675\n",
      "Epoch 50, 100% \t Train loss: 0.1596 took: 1.90s  Val. loss: 0.1659\n",
      "Training finished, took 101.69s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.48\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.32\n",
      "\tmask_channels :  6  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.31\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.824244\n",
      "lambda: 0.0010 - V: 0.824843\n",
      "lambda: 0.0005 - V: 0.805005\n",
      "Average V: 0.818031\n",
      "Time elapsed: 286.80 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.31\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.46\n",
      "\tmask_channels :  4  - prob: 0.22\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.32\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2571 took: 1.80s  Val. loss: 0.2606\n",
      "Epoch 2, 100% \t Train loss: 0.2202 took: 1.78s  Val. loss: 0.1820\n",
      "Epoch 3, 100% \t Train loss: 0.1681 took: 1.79s  Val. loss: 0.1809\n",
      "Epoch 4, 100% \t Train loss: 0.1600 took: 1.02s  Val. loss: 0.1712\n",
      "Epoch 5, 100% \t Train loss: 0.1545 took: 1.02s  Val. loss: 0.1712\n",
      "Epoch 6, 100% \t Train loss: 0.1530 took: 1.02s  Val. loss: 0.1682\n",
      "Epoch 7, 100% \t Train loss: 0.1506 took: 1.03s  Val. loss: 0.1642\n",
      "Epoch 8, 100% \t Train loss: 0.1489 took: 1.03s  Val. loss: 0.1675\n",
      "Epoch 9, 100% \t Train loss: 0.1470 took: 1.02s  Val. loss: 0.1649\n",
      "Epoch 10, 100% \t Train loss: 0.1434 took: 1.03s  Val. loss: 0.1706\n",
      "Epoch 11, 100% \t Train loss: 0.1403 took: 1.04s  Val. loss: 0.1583\n",
      "Epoch 12, 100% \t Train loss: 0.1371 took: 1.03s  Val. loss: 0.1511\n",
      "Epoch 13, 100% \t Train loss: 0.1314 took: 1.03s  Val. loss: 0.1504\n",
      "Epoch 14, 100% \t Train loss: 0.1250 took: 1.03s  Val. loss: 0.1442\n",
      "Epoch 15, 100% \t Train loss: 0.1187 took: 1.02s  Val. loss: 0.1319\n",
      "Epoch 16, 100% \t Train loss: 0.1133 took: 1.02s  Val. loss: 0.1290\n",
      "Epoch 17, 100% \t Train loss: 0.1092 took: 1.02s  Val. loss: 0.1276\n",
      "Epoch 18, 100% \t Train loss: 0.1066 took: 1.01s  Val. loss: 0.1218\n",
      "Epoch 19, 100% \t Train loss: 0.1020 took: 1.01s  Val. loss: 0.1184\n",
      "Epoch 20, 100% \t Train loss: 0.0988 took: 1.01s  Val. loss: 0.1133\n",
      "Epoch 21, 100% \t Train loss: 0.0977 took: 1.02s  Val. loss: 0.1110\n",
      "Epoch 22, 100% \t Train loss: 0.0945 took: 1.01s  Val. loss: 0.1134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, 100% \t Train loss: 0.0919 took: 1.01s  Val. loss: 0.1066\n",
      "Epoch 24, 100% \t Train loss: 0.0907 took: 1.02s  Val. loss: 0.1060\n",
      "Epoch 25, 100% \t Train loss: 0.0893 took: 1.02s  Val. loss: 0.1098\n",
      "Epoch 26, 100% \t Train loss: 0.0884 took: 1.02s  Val. loss: 0.1042\n",
      "Epoch 27, 100% \t Train loss: 0.0848 took: 1.02s  Val. loss: 0.1014\n",
      "Epoch 28, 100% \t Train loss: 0.0842 took: 1.02s  Val. loss: 0.1021\n",
      "Epoch 29, 100% \t Train loss: 0.0828 took: 1.02s  Val. loss: 0.1012\n",
      "Epoch 30, 100% \t Train loss: 0.0827 took: 1.03s  Val. loss: 0.0966\n",
      "Epoch 31, 100% \t Train loss: 0.0812 took: 1.03s  Val. loss: 0.1007\n",
      "Epoch 32, 100% \t Train loss: 0.0815 took: 1.04s  Val. loss: 0.1036\n",
      "Epoch 33, 100% \t Train loss: 0.0806 took: 1.08s  Val. loss: 0.1022\n",
      "Epoch 34, 100% \t Train loss: 0.0798 took: 1.11s  Val. loss: 0.0996\n",
      "Epoch 35, 100% \t Train loss: 0.0788 took: 1.11s  Val. loss: 0.0973\n",
      "Epoch 36, 100% \t Train loss: 0.0795 took: 1.10s  Val. loss: 0.0996\n",
      "Epoch 37, 100% \t Train loss: 0.0782 took: 1.10s  Val. loss: 0.0968\n",
      "Epoch 38, 100% \t Train loss: 0.0783 took: 1.78s  Val. loss: 0.0980\n",
      "Epoch 39, 100% \t Train loss: 0.0771 took: 1.84s  Val. loss: 0.1019\n",
      "Epoch 40, 100% \t Train loss: 0.0776 took: 1.84s  Val. loss: 0.1025\n",
      "Epoch 41, 100% \t Train loss: 0.0773 took: 1.84s  Val. loss: 0.1022\n",
      "Epoch 42, 100% \t Train loss: 0.0760 took: 1.84s  Val. loss: 0.0971\n",
      "Epoch 43, 100% \t Train loss: 0.0761 took: 1.85s  Val. loss: 0.0990\n",
      "Epoch 44, 100% \t Train loss: 0.0751 took: 1.84s  Val. loss: 0.0983\n",
      "Epoch 45, 100% \t Train loss: 0.0760 took: 1.85s  Val. loss: 0.0978\n",
      "Epoch 46, 100% \t Train loss: 0.0755 took: 1.86s  Val. loss: 0.1012\n",
      "Epoch 47, 100% \t Train loss: 0.0750 took: 1.86s  Val. loss: 0.0999\n",
      "Epoch 48, 100% \t Train loss: 0.0745 took: 1.87s  Val. loss: 0.0966\n",
      "Epoch 49, 100% \t Train loss: 0.0737 took: 1.88s  Val. loss: 0.1004\n",
      "Epoch 50, 100% \t Train loss: 0.0736 took: 1.88s  Val. loss: 0.0996\n",
      "Training finished, took 73.36s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 1.80s  Val. loss: 0.2623\n",
      "Epoch 2, 100% \t Train loss: 0.2581 took: 1.79s  Val. loss: 0.2623\n",
      "Epoch 3, 100% \t Train loss: 0.2570 took: 1.80s  Val. loss: 0.2584\n",
      "Epoch 4, 100% \t Train loss: 0.2401 took: 1.77s  Val. loss: 0.2181\n",
      "Epoch 5, 100% \t Train loss: 0.1891 took: 1.77s  Val. loss: 0.1794\n",
      "Epoch 6, 100% \t Train loss: 0.1738 took: 1.77s  Val. loss: 0.1730\n",
      "Epoch 7, 100% \t Train loss: 0.1709 took: 1.76s  Val. loss: 0.1715\n",
      "Epoch 8, 100% \t Train loss: 0.1661 took: 1.77s  Val. loss: 0.1684\n",
      "Epoch 9, 100% \t Train loss: 0.1658 took: 1.79s  Val. loss: 0.1668\n",
      "Epoch 10, 100% \t Train loss: 0.1613 took: 1.79s  Val. loss: 0.1652\n",
      "Epoch 11, 100% \t Train loss: 0.1622 took: 1.78s  Val. loss: 0.1687\n",
      "Epoch 12, 100% \t Train loss: 0.1606 took: 1.77s  Val. loss: 0.1645\n",
      "Epoch 13, 100% \t Train loss: 0.1591 took: 1.77s  Val. loss: 0.1622\n",
      "Epoch 14, 100% \t Train loss: 0.1580 took: 1.77s  Val. loss: 0.1679\n",
      "Epoch 15, 100% \t Train loss: 0.1572 took: 1.78s  Val. loss: 0.1652\n",
      "Epoch 16, 100% \t Train loss: 0.1576 took: 1.79s  Val. loss: 0.1667\n",
      "Epoch 17, 100% \t Train loss: 0.1603 took: 1.78s  Val. loss: 0.1678\n",
      "Epoch 18, 100% \t Train loss: 0.1568 took: 1.79s  Val. loss: 0.1636\n",
      "Epoch 19, 100% \t Train loss: 0.1545 took: 1.80s  Val. loss: 0.1619\n",
      "Epoch 20, 100% \t Train loss: 0.1557 took: 1.78s  Val. loss: 0.1678\n",
      "Epoch 21, 100% \t Train loss: 0.1555 took: 1.77s  Val. loss: 0.1645\n",
      "Epoch 22, 100% \t Train loss: 0.1540 took: 1.80s  Val. loss: 0.1630\n",
      "Epoch 23, 100% \t Train loss: 0.1527 took: 1.77s  Val. loss: 0.1632\n",
      "Epoch 24, 100% \t Train loss: 0.1549 took: 1.76s  Val. loss: 0.1614\n",
      "Epoch 25, 100% \t Train loss: 0.1526 took: 1.79s  Val. loss: 0.1633\n",
      "Epoch 26, 100% \t Train loss: 0.1522 took: 1.78s  Val. loss: 0.1610\n",
      "Epoch 27, 100% \t Train loss: 0.1505 took: 1.77s  Val. loss: 0.1612\n",
      "Epoch 28, 100% \t Train loss: 0.1501 took: 1.79s  Val. loss: 0.1621\n",
      "Epoch 29, 100% \t Train loss: 0.1504 took: 1.80s  Val. loss: 0.1595\n",
      "Epoch 30, 100% \t Train loss: 0.1497 took: 1.77s  Val. loss: 0.1615\n",
      "Epoch 31, 100% \t Train loss: 0.1489 took: 1.78s  Val. loss: 0.1629\n",
      "Epoch 32, 100% \t Train loss: 0.1478 took: 1.79s  Val. loss: 0.1570\n",
      "Epoch 33, 100% \t Train loss: 0.1480 took: 1.79s  Val. loss: 0.1634\n",
      "Epoch 34, 100% \t Train loss: 0.1468 took: 1.80s  Val. loss: 0.1571\n",
      "Epoch 35, 100% \t Train loss: 0.1450 took: 1.81s  Val. loss: 0.1573\n",
      "Epoch 36, 100% \t Train loss: 0.1442 took: 1.81s  Val. loss: 0.1570\n",
      "Epoch 37, 100% \t Train loss: 0.1428 took: 1.80s  Val. loss: 0.1558\n",
      "Epoch 38, 100% \t Train loss: 0.1402 took: 1.80s  Val. loss: 0.1512\n",
      "Epoch 39, 100% \t Train loss: 0.1375 took: 1.81s  Val. loss: 0.1464\n",
      "Epoch 40, 100% \t Train loss: 0.1340 took: 1.83s  Val. loss: 0.1468\n",
      "Epoch 41, 100% \t Train loss: 0.1314 took: 1.82s  Val. loss: 0.1405\n",
      "Epoch 42, 100% \t Train loss: 0.1270 took: 1.79s  Val. loss: 0.1376\n",
      "Epoch 43, 100% \t Train loss: 0.1242 took: 1.82s  Val. loss: 0.1351\n",
      "Epoch 44, 100% \t Train loss: 0.1205 took: 1.80s  Val. loss: 0.1374\n",
      "Epoch 45, 100% \t Train loss: 0.1182 took: 1.84s  Val. loss: 0.1286\n",
      "Epoch 46, 100% \t Train loss: 0.1142 took: 1.82s  Val. loss: 0.1290\n",
      "Epoch 47, 100% \t Train loss: 0.1123 took: 1.83s  Val. loss: 0.1220\n",
      "Epoch 48, 100% \t Train loss: 0.1100 took: 1.85s  Val. loss: 0.1341\n",
      "Epoch 49, 100% \t Train loss: 0.1083 took: 1.83s  Val. loss: 0.1188\n",
      "Epoch 50, 100% \t Train loss: 0.1056 took: 1.82s  Val. loss: 0.1188\n",
      "Training finished, took 102.64s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2585 took: 1.78s  Val. loss: 0.2640\n",
      "Epoch 2, 100% \t Train loss: 0.2581 took: 1.75s  Val. loss: 0.2634\n",
      "Epoch 3, 100% \t Train loss: 0.2581 took: 1.76s  Val. loss: 0.2645\n",
      "Epoch 4, 100% \t Train loss: 0.2583 took: 1.76s  Val. loss: 0.2633\n",
      "Epoch 5, 100% \t Train loss: 0.2582 took: 1.78s  Val. loss: 0.2645\n",
      "Epoch 6, 100% \t Train loss: 0.2580 took: 1.78s  Val. loss: 0.2627\n",
      "Epoch 7, 100% \t Train loss: 0.2579 took: 1.78s  Val. loss: 0.2629\n",
      "Epoch 8, 100% \t Train loss: 0.2572 took: 1.77s  Val. loss: 0.2640\n",
      "Epoch 9, 100% \t Train loss: 0.2551 took: 1.76s  Val. loss: 0.2582\n",
      "Epoch 10, 100% \t Train loss: 0.2462 took: 1.78s  Val. loss: 0.2402\n",
      "Epoch 11, 100% \t Train loss: 0.2244 took: 1.76s  Val. loss: 0.2168\n",
      "Epoch 12, 100% \t Train loss: 0.2055 took: 1.77s  Val. loss: 0.2012\n",
      "Epoch 13, 100% \t Train loss: 0.1934 took: 1.76s  Val. loss: 0.1900\n",
      "Epoch 14, 100% \t Train loss: 0.1887 took: 1.75s  Val. loss: 0.1855\n",
      "Epoch 15, 100% \t Train loss: 0.1844 took: 1.77s  Val. loss: 0.1839\n",
      "Epoch 16, 100% \t Train loss: 0.1830 took: 1.76s  Val. loss: 0.1802\n",
      "Epoch 17, 100% \t Train loss: 0.1805 took: 1.76s  Val. loss: 0.1784\n",
      "Epoch 18, 100% \t Train loss: 0.1774 took: 1.76s  Val. loss: 0.1742\n",
      "Epoch 19, 100% \t Train loss: 0.1767 took: 1.77s  Val. loss: 0.1855\n",
      "Epoch 20, 100% \t Train loss: 0.1770 took: 1.42s  Val. loss: 0.1746\n",
      "Epoch 21, 100% \t Train loss: 0.1733 took: 1.03s  Val. loss: 0.1719\n",
      "Epoch 22, 100% \t Train loss: 0.1728 took: 1.02s  Val. loss: 0.1699\n",
      "Epoch 23, 100% \t Train loss: 0.1750 took: 1.02s  Val. loss: 0.1742\n",
      "Epoch 24, 100% \t Train loss: 0.1726 took: 1.02s  Val. loss: 0.1710\n",
      "Epoch 25, 100% \t Train loss: 0.1714 took: 1.03s  Val. loss: 0.1734\n",
      "Epoch 26, 100% \t Train loss: 0.1731 took: 1.02s  Val. loss: 0.1688\n",
      "Epoch 27, 100% \t Train loss: 0.1696 took: 1.17s  Val. loss: 0.1652\n",
      "Epoch 28, 100% \t Train loss: 0.1710 took: 1.79s  Val. loss: 0.1684\n",
      "Epoch 29, 100% \t Train loss: 0.1712 took: 1.79s  Val. loss: 0.1704\n",
      "Epoch 30, 100% \t Train loss: 0.1687 took: 1.82s  Val. loss: 0.1705\n",
      "Epoch 31, 100% \t Train loss: 0.1678 took: 1.83s  Val. loss: 0.1703\n",
      "Epoch 32, 100% \t Train loss: 0.1678 took: 1.84s  Val. loss: 0.1667\n",
      "Epoch 33, 100% \t Train loss: 0.1656 took: 1.84s  Val. loss: 0.1722\n",
      "Epoch 34, 100% \t Train loss: 0.1690 took: 1.10s  Val. loss: 0.1671\n",
      "Epoch 35, 100% \t Train loss: 0.1665 took: 1.11s  Val. loss: 0.1777\n",
      "Epoch 36, 100% \t Train loss: 0.1668 took: 1.07s  Val. loss: 0.1725\n",
      "Epoch 37, 100% \t Train loss: 0.1641 took: 1.05s  Val. loss: 0.1673\n",
      "Epoch 38, 100% \t Train loss: 0.1676 took: 1.05s  Val. loss: 0.1662\n",
      "Epoch 39, 100% \t Train loss: 0.1642 took: 1.05s  Val. loss: 0.1672\n",
      "Epoch 40, 100% \t Train loss: 0.1644 took: 1.05s  Val. loss: 0.1692\n",
      "Epoch 41, 100% \t Train loss: 0.1638 took: 1.04s  Val. loss: 0.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, 100% \t Train loss: 0.1633 took: 1.05s  Val. loss: 0.1643\n",
      "Epoch 43, 100% \t Train loss: 0.1647 took: 1.06s  Val. loss: 0.1675\n",
      "Epoch 44, 100% \t Train loss: 0.1628 took: 1.06s  Val. loss: 0.1642\n",
      "Epoch 45, 100% \t Train loss: 0.1628 took: 1.06s  Val. loss: 0.1646\n",
      "Epoch 46, 100% \t Train loss: 0.1625 took: 1.05s  Val. loss: 0.1618\n",
      "Epoch 47, 100% \t Train loss: 0.1619 took: 1.06s  Val. loss: 0.1641\n",
      "Epoch 48, 100% \t Train loss: 0.1612 took: 1.05s  Val. loss: 0.1627\n",
      "Epoch 49, 100% \t Train loss: 0.1618 took: 1.05s  Val. loss: 0.1639\n",
      "Epoch 50, 100% \t Train loss: 0.1605 took: 1.05s  Val. loss: 0.1643\n",
      "Training finished, took 81.18s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.31\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.46\n",
      "\tmask_channels :  4  - prob: 0.22\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.32\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.876124\n",
      "lambda: 0.0010 - V: 0.836815\n",
      "lambda: 0.0005 - V: 0.809598\n",
      "Average V: 0.840846\n",
      "Time elapsed: 260.57 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.44\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 1.93s  Val. loss: 0.2590\n",
      "Epoch 2, 100% \t Train loss: 0.2553 took: 1.92s  Val. loss: 0.2302\n",
      "Epoch 3, 100% \t Train loss: 0.1838 took: 1.92s  Val. loss: 0.1699\n",
      "Epoch 4, 100% \t Train loss: 0.1695 took: 1.90s  Val. loss: 0.1690\n",
      "Epoch 5, 100% \t Train loss: 0.1671 took: 1.92s  Val. loss: 0.1706\n",
      "Epoch 6, 100% \t Train loss: 0.1667 took: 1.94s  Val. loss: 0.1694\n",
      "Epoch 7, 100% \t Train loss: 0.1651 took: 1.92s  Val. loss: 0.1690\n",
      "Epoch 8, 100% \t Train loss: 0.1643 took: 1.92s  Val. loss: 0.1671\n",
      "Epoch 9, 100% \t Train loss: 0.1633 took: 1.94s  Val. loss: 0.1690\n",
      "Epoch 10, 100% \t Train loss: 0.1633 took: 1.92s  Val. loss: 0.1740\n",
      "Epoch 11, 100% \t Train loss: 0.1633 took: 1.93s  Val. loss: 0.1694\n",
      "Epoch 12, 100% \t Train loss: 0.1627 took: 1.91s  Val. loss: 0.1717\n",
      "Epoch 13, 100% \t Train loss: 0.1627 took: 1.91s  Val. loss: 0.1687\n",
      "Epoch 14, 100% \t Train loss: 0.1618 took: 1.94s  Val. loss: 0.1677\n",
      "Epoch 15, 100% \t Train loss: 0.1608 took: 1.93s  Val. loss: 0.1697\n",
      "Epoch 16, 100% \t Train loss: 0.1570 took: 1.95s  Val. loss: 0.1622\n",
      "Epoch 17, 100% \t Train loss: 0.1536 took: 1.93s  Val. loss: 0.1606\n",
      "Epoch 18, 100% \t Train loss: 0.1503 took: 1.93s  Val. loss: 0.1577\n",
      "Epoch 19, 100% \t Train loss: 0.1483 took: 1.93s  Val. loss: 0.1581\n",
      "Epoch 20, 100% \t Train loss: 0.1467 took: 1.93s  Val. loss: 0.1550\n",
      "Epoch 21, 100% \t Train loss: 0.1430 took: 1.91s  Val. loss: 0.1549\n",
      "Epoch 22, 100% \t Train loss: 0.1375 took: 1.94s  Val. loss: 0.1447\n",
      "Epoch 23, 100% \t Train loss: 0.1298 took: 1.93s  Val. loss: 0.1363\n",
      "Epoch 24, 100% \t Train loss: 0.1209 took: 1.93s  Val. loss: 0.1278\n",
      "Epoch 25, 100% \t Train loss: 0.1118 took: 1.91s  Val. loss: 0.1127\n",
      "Epoch 26, 100% \t Train loss: 0.1028 took: 1.93s  Val. loss: 0.1088\n",
      "Epoch 27, 100% \t Train loss: 0.0960 took: 1.94s  Val. loss: 0.1062\n",
      "Epoch 28, 100% \t Train loss: 0.0919 took: 1.97s  Val. loss: 0.0975\n",
      "Epoch 29, 100% \t Train loss: 0.0880 took: 2.00s  Val. loss: 0.0920\n",
      "Epoch 30, 100% \t Train loss: 0.0852 took: 2.04s  Val. loss: 0.0911\n",
      "Epoch 31, 100% \t Train loss: 0.0826 took: 2.13s  Val. loss: 0.0933\n",
      "Epoch 32, 100% \t Train loss: 0.0814 took: 2.45s  Val. loss: 0.0921\n",
      "Epoch 33, 100% \t Train loss: 0.0794 took: 2.61s  Val. loss: 0.0874\n",
      "Epoch 34, 100% \t Train loss: 0.0791 took: 2.63s  Val. loss: 0.0868\n",
      "Epoch 35, 100% \t Train loss: 0.0781 took: 2.63s  Val. loss: 0.0895\n",
      "Epoch 36, 100% \t Train loss: 0.0765 took: 2.64s  Val. loss: 0.0864\n",
      "Epoch 37, 100% \t Train loss: 0.0758 took: 2.55s  Val. loss: 0.0877\n",
      "Epoch 38, 100% \t Train loss: 0.0744 took: 2.54s  Val. loss: 0.0872\n",
      "Epoch 39, 100% \t Train loss: 0.0744 took: 2.55s  Val. loss: 0.0833\n",
      "Epoch 40, 100% \t Train loss: 0.0744 took: 2.56s  Val. loss: 0.0843\n",
      "Epoch 41, 100% \t Train loss: 0.0731 took: 2.58s  Val. loss: 0.0858\n",
      "Epoch 42, 100% \t Train loss: 0.0720 took: 2.59s  Val. loss: 0.0829\n",
      "Epoch 43, 100% \t Train loss: 0.0724 took: 2.60s  Val. loss: 0.0839\n",
      "Epoch 44, 100% \t Train loss: 0.0727 took: 2.62s  Val. loss: 0.0829\n",
      "Epoch 45, 100% \t Train loss: 0.0725 took: 2.66s  Val. loss: 0.0853\n",
      "Epoch 46, 100% \t Train loss: 0.0719 took: 2.67s  Val. loss: 0.0832\n",
      "Epoch 47, 100% \t Train loss: 0.0715 took: 2.69s  Val. loss: 0.0841\n",
      "Epoch 48, 100% \t Train loss: 0.0708 took: 2.68s  Val. loss: 0.0869\n",
      "Epoch 49, 100% \t Train loss: 0.0708 took: 2.68s  Val. loss: 0.0855\n",
      "Epoch 50, 100% \t Train loss: 0.0707 took: 2.68s  Val. loss: 0.0822\n",
      "Training finished, took 124.12s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 1.92s  Val. loss: 0.2638\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.94s  Val. loss: 0.2631\n",
      "Epoch 3, 100% \t Train loss: 0.2565 took: 1.93s  Val. loss: 0.2564\n",
      "Epoch 4, 100% \t Train loss: 0.2214 took: 1.94s  Val. loss: 0.2028\n",
      "Epoch 5, 100% \t Train loss: 0.1707 took: 1.92s  Val. loss: 0.1863\n",
      "Epoch 6, 100% \t Train loss: 0.1605 took: 1.92s  Val. loss: 0.1910\n",
      "Epoch 7, 100% \t Train loss: 0.1573 took: 1.93s  Val. loss: 0.1786\n",
      "Epoch 8, 100% \t Train loss: 0.1517 took: 1.44s  Val. loss: 0.1786\n",
      "Epoch 9, 100% \t Train loss: 0.1496 took: 1.97s  Val. loss: 0.1750\n",
      "Epoch 10, 100% \t Train loss: 0.1494 took: 1.93s  Val. loss: 0.1737\n",
      "Epoch 11, 100% \t Train loss: 0.1473 took: 1.94s  Val. loss: 0.1754\n",
      "Epoch 12, 100% \t Train loss: 0.1478 took: 1.92s  Val. loss: 0.1782\n",
      "Epoch 13, 100% \t Train loss: 0.1448 took: 1.93s  Val. loss: 0.1743\n",
      "Epoch 14, 100% \t Train loss: 0.1425 took: 1.93s  Val. loss: 0.1719\n",
      "Epoch 15, 100% \t Train loss: 0.1452 took: 1.96s  Val. loss: 0.1786\n",
      "Epoch 16, 100% \t Train loss: 0.1433 took: 1.86s  Val. loss: 0.1731\n",
      "Epoch 17, 100% \t Train loss: 0.1428 took: 2.01s  Val. loss: 0.1727\n",
      "Epoch 18, 100% \t Train loss: 0.1419 took: 1.92s  Val. loss: 0.1747\n",
      "Epoch 19, 100% \t Train loss: 0.1409 took: 2.00s  Val. loss: 0.1747\n",
      "Epoch 20, 100% \t Train loss: 0.1400 took: 1.80s  Val. loss: 0.1736\n",
      "Epoch 21, 100% \t Train loss: 0.1403 took: 2.03s  Val. loss: 0.1736\n",
      "Epoch 22, 100% \t Train loss: 0.1397 took: 2.06s  Val. loss: 0.1708\n",
      "Epoch 23, 100% \t Train loss: 0.1384 took: 2.13s  Val. loss: 0.1727\n",
      "Epoch 24, 100% \t Train loss: 0.1371 took: 1.99s  Val. loss: 0.1693\n",
      "Epoch 25, 100% \t Train loss: 0.1361 took: 1.98s  Val. loss: 0.1726\n",
      "Epoch 26, 100% \t Train loss: 0.1344 took: 1.93s  Val. loss: 0.1718\n",
      "Epoch 27, 100% \t Train loss: 0.1332 took: 1.45s  Val. loss: 0.1657\n",
      "Epoch 28, 100% \t Train loss: 0.1323 took: 1.15s  Val. loss: 0.1657\n",
      "Epoch 29, 100% \t Train loss: 0.1303 took: 1.30s  Val. loss: 0.1621\n",
      "Epoch 30, 100% \t Train loss: 0.1294 took: 1.16s  Val. loss: 0.1667\n",
      "Epoch 31, 100% \t Train loss: 0.1285 took: 1.18s  Val. loss: 0.1617\n",
      "Epoch 32, 100% \t Train loss: 0.1262 took: 1.21s  Val. loss: 0.1628\n",
      "Epoch 33, 100% \t Train loss: 0.1244 took: 1.20s  Val. loss: 0.1607\n",
      "Epoch 34, 100% \t Train loss: 0.1228 took: 1.20s  Val. loss: 0.1579\n",
      "Epoch 35, 100% \t Train loss: 0.1214 took: 1.21s  Val. loss: 0.1576\n",
      "Epoch 36, 100% \t Train loss: 0.1200 took: 1.21s  Val. loss: 0.1532\n",
      "Epoch 37, 100% \t Train loss: 0.1192 took: 1.21s  Val. loss: 0.1533\n",
      "Epoch 38, 100% \t Train loss: 0.1166 took: 1.21s  Val. loss: 0.1534\n",
      "Epoch 39, 100% \t Train loss: 0.1165 took: 1.22s  Val. loss: 0.1537\n",
      "Epoch 40, 100% \t Train loss: 0.1148 took: 1.20s  Val. loss: 0.1456\n",
      "Epoch 41, 100% \t Train loss: 0.1132 took: 1.22s  Val. loss: 0.1490\n",
      "Epoch 42, 100% \t Train loss: 0.1117 took: 1.20s  Val. loss: 0.1471\n",
      "Epoch 43, 100% \t Train loss: 0.1097 took: 1.20s  Val. loss: 0.1424\n",
      "Epoch 44, 100% \t Train loss: 0.1074 took: 1.86s  Val. loss: 0.1374\n",
      "Epoch 45, 100% \t Train loss: 0.1057 took: 2.00s  Val. loss: 0.1389\n",
      "Epoch 46, 100% \t Train loss: 0.1056 took: 2.00s  Val. loss: 0.1410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, 100% \t Train loss: 0.1031 took: 2.00s  Val. loss: 0.1369\n",
      "Epoch 48, 100% \t Train loss: 0.1005 took: 2.01s  Val. loss: 0.1417\n",
      "Epoch 49, 100% \t Train loss: 0.1007 took: 2.01s  Val. loss: 0.1434\n",
      "Epoch 50, 100% \t Train loss: 0.0977 took: 2.01s  Val. loss: 0.1299\n",
      "Training finished, took 95.81s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2614 took: 1.95s  Val. loss: 0.2633\n",
      "Epoch 2, 100% \t Train loss: 0.2611 took: 1.95s  Val. loss: 0.2628\n",
      "Epoch 3, 100% \t Train loss: 0.2609 took: 1.92s  Val. loss: 0.2629\n",
      "Epoch 4, 100% \t Train loss: 0.2608 took: 1.93s  Val. loss: 0.2615\n",
      "Epoch 5, 100% \t Train loss: 0.2604 took: 1.93s  Val. loss: 0.2611\n",
      "Epoch 6, 100% \t Train loss: 0.2588 took: 1.92s  Val. loss: 0.2587\n",
      "Epoch 7, 100% \t Train loss: 0.2468 took: 1.93s  Val. loss: 0.2338\n",
      "Epoch 8, 100% \t Train loss: 0.2196 took: 1.92s  Val. loss: 0.2212\n",
      "Epoch 9, 100% \t Train loss: 0.2020 took: 1.95s  Val. loss: 0.2139\n",
      "Epoch 10, 100% \t Train loss: 0.1883 took: 1.93s  Val. loss: 0.2112\n",
      "Epoch 11, 100% \t Train loss: 0.1848 took: 1.95s  Val. loss: 0.2110\n",
      "Epoch 12, 100% \t Train loss: 0.1829 took: 1.93s  Val. loss: 0.1972\n",
      "Epoch 13, 100% \t Train loss: 0.1776 took: 1.93s  Val. loss: 0.1891\n",
      "Epoch 14, 100% \t Train loss: 0.1761 took: 1.92s  Val. loss: 0.2013\n",
      "Epoch 15, 100% \t Train loss: 0.1786 took: 1.93s  Val. loss: 0.1991\n",
      "Epoch 16, 100% \t Train loss: 0.1727 took: 1.94s  Val. loss: 0.1855\n",
      "Epoch 17, 100% \t Train loss: 0.1727 took: 1.92s  Val. loss: 0.2075\n",
      "Epoch 18, 100% \t Train loss: 0.1712 took: 1.93s  Val. loss: 0.1874\n",
      "Epoch 19, 100% \t Train loss: 0.1692 took: 1.95s  Val. loss: 0.1910\n",
      "Epoch 20, 100% \t Train loss: 0.1707 took: 1.94s  Val. loss: 0.1869\n",
      "Epoch 21, 100% \t Train loss: 0.1681 took: 1.13s  Val. loss: 0.1896\n",
      "Epoch 22, 100% \t Train loss: 0.1689 took: 1.13s  Val. loss: 0.1880\n",
      "Epoch 23, 100% \t Train loss: 0.1696 took: 1.13s  Val. loss: 0.1858\n",
      "Epoch 24, 100% \t Train loss: 0.1638 took: 1.14s  Val. loss: 0.1905\n",
      "Epoch 25, 100% \t Train loss: 0.1636 took: 1.14s  Val. loss: 0.1794\n",
      "Epoch 26, 100% \t Train loss: 0.1630 took: 1.13s  Val. loss: 0.1814\n",
      "Epoch 27, 100% \t Train loss: 0.1602 took: 1.14s  Val. loss: 0.1762\n",
      "Epoch 28, 100% \t Train loss: 0.1588 took: 1.14s  Val. loss: 0.1822\n",
      "Epoch 29, 100% \t Train loss: 0.1572 took: 1.15s  Val. loss: 0.1828\n",
      "Epoch 30, 100% \t Train loss: 0.1560 took: 1.15s  Val. loss: 0.1761\n",
      "Epoch 31, 100% \t Train loss: 0.1547 took: 1.17s  Val. loss: 0.1751\n",
      "Epoch 32, 100% \t Train loss: 0.1532 took: 1.18s  Val. loss: 0.1716\n",
      "Epoch 33, 100% \t Train loss: 0.1520 took: 1.19s  Val. loss: 0.1715\n",
      "Epoch 34, 100% \t Train loss: 0.1526 took: 1.20s  Val. loss: 0.1811\n",
      "Epoch 35, 100% \t Train loss: 0.1488 took: 1.21s  Val. loss: 0.1800\n",
      "Epoch 36, 100% \t Train loss: 0.1476 took: 1.24s  Val. loss: 0.1706\n",
      "Epoch 37, 100% \t Train loss: 0.1461 took: 1.25s  Val. loss: 0.1649\n",
      "Epoch 38, 100% \t Train loss: 0.1440 took: 1.26s  Val. loss: 0.1677\n",
      "Epoch 39, 100% \t Train loss: 0.1424 took: 1.28s  Val. loss: 0.1621\n",
      "Epoch 40, 100% \t Train loss: 0.1415 took: 1.30s  Val. loss: 0.1616\n",
      "Epoch 41, 100% \t Train loss: 0.1368 took: 1.32s  Val. loss: 0.1605\n",
      "Epoch 42, 100% \t Train loss: 0.1348 took: 1.33s  Val. loss: 0.1569\n",
      "Epoch 43, 100% \t Train loss: 0.1313 took: 1.35s  Val. loss: 0.1640\n",
      "Epoch 44, 100% \t Train loss: 0.1296 took: 1.34s  Val. loss: 0.1528\n",
      "Epoch 45, 100% \t Train loss: 0.1286 took: 1.35s  Val. loss: 0.1668\n",
      "Epoch 46, 100% \t Train loss: 0.1287 took: 1.39s  Val. loss: 0.1503\n",
      "Epoch 47, 100% \t Train loss: 0.1245 took: 1.45s  Val. loss: 0.1533\n",
      "Epoch 48, 100% \t Train loss: 0.1225 took: 2.21s  Val. loss: 0.1575\n",
      "Epoch 49, 100% \t Train loss: 0.1221 took: 1.56s  Val. loss: 0.1432\n",
      "Epoch 50, 100% \t Train loss: 0.1194 took: 2.48s  Val. loss: 0.1508\n",
      "Training finished, took 88.44s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.44\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.872383\n",
      "lambda: 0.0010 - V: 0.830499\n",
      "lambda: 0.0005 - V: 0.809989\n",
      "Average V: 0.837624\n",
      "Time elapsed: 311.75 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.25\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.44\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 1.88s  Val. loss: 0.2574\n",
      "Epoch 2, 100% \t Train loss: 0.2526 took: 1.08s  Val. loss: 0.2266\n",
      "Epoch 3, 100% \t Train loss: 0.2099 took: 1.09s  Val. loss: 0.2009\n",
      "Epoch 4, 100% \t Train loss: 0.1992 took: 1.08s  Val. loss: 0.2040\n",
      "Epoch 5, 100% \t Train loss: 0.1953 took: 1.08s  Val. loss: 0.1930\n",
      "Epoch 6, 100% \t Train loss: 0.1932 took: 1.07s  Val. loss: 0.1949\n",
      "Epoch 7, 100% \t Train loss: 0.1897 took: 1.07s  Val. loss: 0.1932\n",
      "Epoch 8, 100% \t Train loss: 0.1892 took: 1.08s  Val. loss: 0.1962\n",
      "Epoch 9, 100% \t Train loss: 0.1868 took: 1.09s  Val. loss: 0.1931\n",
      "Epoch 10, 100% \t Train loss: 0.1859 took: 1.06s  Val. loss: 0.1911\n",
      "Epoch 11, 100% \t Train loss: 0.1843 took: 1.21s  Val. loss: 0.1879\n",
      "Epoch 12, 100% \t Train loss: 0.1822 took: 1.83s  Val. loss: 0.1903\n",
      "Epoch 13, 100% \t Train loss: 0.1819 took: 1.85s  Val. loss: 0.1854\n",
      "Epoch 14, 100% \t Train loss: 0.1796 took: 1.07s  Val. loss: 0.1843\n",
      "Epoch 15, 100% \t Train loss: 0.1770 took: 1.07s  Val. loss: 0.1829\n",
      "Epoch 16, 100% \t Train loss: 0.1757 took: 1.07s  Val. loss: 0.1780\n",
      "Epoch 17, 100% \t Train loss: 0.1717 took: 1.07s  Val. loss: 0.1758\n",
      "Epoch 18, 100% \t Train loss: 0.1683 took: 1.07s  Val. loss: 0.1751\n",
      "Epoch 19, 100% \t Train loss: 0.1665 took: 1.07s  Val. loss: 0.1770\n",
      "Epoch 20, 100% \t Train loss: 0.1631 took: 1.07s  Val. loss: 0.1744\n",
      "Epoch 21, 100% \t Train loss: 0.1613 took: 1.07s  Val. loss: 0.1704\n",
      "Epoch 22, 100% \t Train loss: 0.1610 took: 1.07s  Val. loss: 0.1716\n",
      "Epoch 23, 100% \t Train loss: 0.1593 took: 1.07s  Val. loss: 0.1670\n",
      "Epoch 24, 100% \t Train loss: 0.1581 took: 1.08s  Val. loss: 0.1665\n",
      "Epoch 25, 100% \t Train loss: 0.1554 took: 1.07s  Val. loss: 0.1684\n",
      "Epoch 26, 100% \t Train loss: 0.1555 took: 1.08s  Val. loss: 0.1658\n",
      "Epoch 27, 100% \t Train loss: 0.1513 took: 1.08s  Val. loss: 0.1620\n",
      "Epoch 28, 100% \t Train loss: 0.1518 took: 1.08s  Val. loss: 0.1620\n",
      "Epoch 29, 100% \t Train loss: 0.1503 took: 1.08s  Val. loss: 0.1594\n",
      "Epoch 30, 100% \t Train loss: 0.1481 took: 1.08s  Val. loss: 0.1587\n",
      "Epoch 31, 100% \t Train loss: 0.1477 took: 1.11s  Val. loss: 0.1559\n",
      "Epoch 32, 100% \t Train loss: 0.1470 took: 1.17s  Val. loss: 0.1560\n",
      "Epoch 33, 100% \t Train loss: 0.1454 took: 1.30s  Val. loss: 0.1551\n",
      "Epoch 34, 100% \t Train loss: 0.1460 took: 1.31s  Val. loss: 0.1559\n",
      "Epoch 35, 100% \t Train loss: 0.1441 took: 1.30s  Val. loss: 0.1561\n",
      "Epoch 36, 100% \t Train loss: 0.1437 took: 1.31s  Val. loss: 0.1545\n",
      "Epoch 37, 100% \t Train loss: 0.1429 took: 1.31s  Val. loss: 0.1521\n",
      "Epoch 38, 100% \t Train loss: 0.1422 took: 1.30s  Val. loss: 0.1510\n",
      "Epoch 39, 100% \t Train loss: 0.1420 took: 1.30s  Val. loss: 0.1476\n",
      "Epoch 40, 100% \t Train loss: 0.1430 took: 1.30s  Val. loss: 0.1547\n",
      "Epoch 41, 100% \t Train loss: 0.1431 took: 1.30s  Val. loss: 0.1487\n",
      "Epoch 42, 100% \t Train loss: 0.1425 took: 1.30s  Val. loss: 0.1537\n",
      "Epoch 43, 100% \t Train loss: 0.1416 took: 1.30s  Val. loss: 0.1567\n",
      "Epoch 44, 100% \t Train loss: 0.1398 took: 1.30s  Val. loss: 0.1520\n",
      "Epoch 45, 100% \t Train loss: 0.1402 took: 1.30s  Val. loss: 0.1531\n",
      "Epoch 46, 100% \t Train loss: 0.1393 took: 1.30s  Val. loss: 0.1480\n",
      "Epoch 47, 100% \t Train loss: 0.1378 took: 1.30s  Val. loss: 0.1501\n",
      "Epoch 48, 100% \t Train loss: 0.1397 took: 1.31s  Val. loss: 0.1512\n",
      "Epoch 49, 100% \t Train loss: 0.1383 took: 1.31s  Val. loss: 0.1474\n",
      "Epoch 50, 100% \t Train loss: 0.1371 took: 1.30s  Val. loss: 0.1452\n",
      "Training finished, took 68.92s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 0.2585 took: 1.84s  Val. loss: 0.2594\n",
      "Epoch 2, 100% \t Train loss: 0.2579 took: 1.83s  Val. loss: 0.2587\n",
      "Epoch 3, 100% \t Train loss: 0.2547 took: 1.85s  Val. loss: 0.2487\n",
      "Epoch 4, 100% \t Train loss: 0.2342 took: 1.83s  Val. loss: 0.2204\n",
      "Epoch 5, 100% \t Train loss: 0.2144 took: 1.83s  Val. loss: 0.2039\n",
      "Epoch 6, 100% \t Train loss: 0.2042 took: 1.83s  Val. loss: 0.1895\n",
      "Epoch 7, 100% \t Train loss: 0.2004 took: 1.84s  Val. loss: 0.1848\n",
      "Epoch 8, 100% \t Train loss: 0.1988 took: 1.85s  Val. loss: 0.1868\n",
      "Epoch 9, 100% \t Train loss: 0.1969 took: 1.87s  Val. loss: 0.1827\n",
      "Epoch 10, 100% \t Train loss: 0.1955 took: 1.85s  Val. loss: 0.1859\n",
      "Epoch 11, 100% \t Train loss: 0.1950 took: 1.85s  Val. loss: 0.1815\n",
      "Epoch 12, 100% \t Train loss: 0.1933 took: 1.86s  Val. loss: 0.1790\n",
      "Epoch 13, 100% \t Train loss: 0.1927 took: 1.85s  Val. loss: 0.1801\n",
      "Epoch 14, 100% \t Train loss: 0.1915 took: 1.87s  Val. loss: 0.1807\n",
      "Epoch 15, 100% \t Train loss: 0.1915 took: 1.85s  Val. loss: 0.1801\n",
      "Epoch 16, 100% \t Train loss: 0.1897 took: 1.86s  Val. loss: 0.1780\n",
      "Epoch 17, 100% \t Train loss: 0.1887 took: 1.85s  Val. loss: 0.1761\n",
      "Epoch 18, 100% \t Train loss: 0.1890 took: 1.85s  Val. loss: 0.1801\n",
      "Epoch 19, 100% \t Train loss: 0.1888 took: 1.85s  Val. loss: 0.1762\n",
      "Epoch 20, 100% \t Train loss: 0.1871 took: 1.85s  Val. loss: 0.1761\n",
      "Epoch 21, 100% \t Train loss: 0.1866 took: 1.85s  Val. loss: 0.1766\n",
      "Epoch 22, 100% \t Train loss: 0.1870 took: 1.84s  Val. loss: 0.1759\n",
      "Epoch 23, 100% \t Train loss: 0.1859 took: 1.84s  Val. loss: 0.1807\n",
      "Epoch 24, 100% \t Train loss: 0.1841 took: 1.84s  Val. loss: 0.1747\n",
      "Epoch 25, 100% \t Train loss: 0.1841 took: 1.85s  Val. loss: 0.1748\n",
      "Epoch 26, 100% \t Train loss: 0.1834 took: 1.83s  Val. loss: 0.1737\n",
      "Epoch 27, 100% \t Train loss: 0.1827 took: 1.86s  Val. loss: 0.1736\n",
      "Epoch 28, 100% \t Train loss: 0.1822 took: 1.85s  Val. loss: 0.1715\n",
      "Epoch 29, 100% \t Train loss: 0.1807 took: 1.85s  Val. loss: 0.1721\n",
      "Epoch 30, 100% \t Train loss: 0.1800 took: 1.86s  Val. loss: 0.1710\n",
      "Epoch 31, 100% \t Train loss: 0.1798 took: 1.85s  Val. loss: 0.1709\n",
      "Epoch 32, 100% \t Train loss: 0.1789 took: 1.84s  Val. loss: 0.1707\n",
      "Epoch 33, 100% \t Train loss: 0.1771 took: 1.85s  Val. loss: 0.1706\n",
      "Epoch 34, 100% \t Train loss: 0.1756 took: 1.85s  Val. loss: 0.1675\n",
      "Epoch 35, 100% \t Train loss: 0.1747 took: 1.87s  Val. loss: 0.1662\n",
      "Epoch 36, 100% \t Train loss: 0.1731 took: 1.87s  Val. loss: 0.1670\n",
      "Epoch 37, 100% \t Train loss: 0.1716 took: 1.87s  Val. loss: 0.1632\n",
      "Epoch 38, 100% \t Train loss: 0.1704 took: 1.87s  Val. loss: 0.1662\n",
      "Epoch 39, 100% \t Train loss: 0.1687 took: 1.87s  Val. loss: 0.1617\n",
      "Epoch 40, 100% \t Train loss: 0.1664 took: 1.87s  Val. loss: 0.1589\n",
      "Epoch 41, 100% \t Train loss: 0.1642 took: 1.85s  Val. loss: 0.1583\n",
      "Epoch 42, 100% \t Train loss: 0.1626 took: 1.08s  Val. loss: 0.1546\n",
      "Epoch 43, 100% \t Train loss: 0.1615 took: 1.09s  Val. loss: 0.1569\n",
      "Epoch 44, 100% \t Train loss: 0.1589 took: 1.09s  Val. loss: 0.1539\n",
      "Epoch 45, 100% \t Train loss: 0.1570 took: 1.08s  Val. loss: 0.1496\n",
      "Epoch 46, 100% \t Train loss: 0.1545 took: 1.08s  Val. loss: 0.1504\n",
      "Epoch 47, 100% \t Train loss: 0.1530 took: 1.10s  Val. loss: 0.1560\n",
      "Epoch 48, 100% \t Train loss: 0.1527 took: 1.08s  Val. loss: 0.1465\n",
      "Epoch 49, 100% \t Train loss: 0.1491 took: 1.09s  Val. loss: 0.1456\n",
      "Epoch 50, 100% \t Train loss: 0.1484 took: 1.08s  Val. loss: 0.1485\n",
      "Training finished, took 97.18s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2585 took: 1.08s  Val. loss: 0.2611\n",
      "Epoch 2, 100% \t Train loss: 0.2581 took: 1.08s  Val. loss: 0.2611\n",
      "Epoch 3, 100% \t Train loss: 0.2581 took: 1.07s  Val. loss: 0.2610\n",
      "Epoch 4, 100% \t Train loss: 0.2576 took: 1.07s  Val. loss: 0.2604\n",
      "Epoch 5, 100% \t Train loss: 0.2563 took: 1.07s  Val. loss: 0.2558\n",
      "Epoch 6, 100% \t Train loss: 0.2508 took: 1.07s  Val. loss: 0.2448\n",
      "Epoch 7, 100% \t Train loss: 0.2365 took: 1.07s  Val. loss: 0.2252\n",
      "Epoch 8, 100% \t Train loss: 0.2199 took: 1.08s  Val. loss: 0.2167\n",
      "Epoch 9, 100% \t Train loss: 0.2080 took: 1.07s  Val. loss: 0.2041\n",
      "Epoch 10, 100% \t Train loss: 0.2022 took: 1.07s  Val. loss: 0.2050\n",
      "Epoch 11, 100% \t Train loss: 0.1989 took: 1.07s  Val. loss: 0.1994\n",
      "Epoch 12, 100% \t Train loss: 0.1978 took: 1.07s  Val. loss: 0.2034\n",
      "Epoch 13, 100% \t Train loss: 0.1970 took: 1.07s  Val. loss: 0.2045\n",
      "Epoch 14, 100% \t Train loss: 0.1961 took: 1.07s  Val. loss: 0.1993\n",
      "Epoch 15, 100% \t Train loss: 0.1955 took: 1.07s  Val. loss: 0.2018\n",
      "Epoch 16, 100% \t Train loss: 0.1968 took: 1.07s  Val. loss: 0.2006\n",
      "Epoch 17, 100% \t Train loss: 0.1943 took: 1.07s  Val. loss: 0.1975\n",
      "Epoch 18, 100% \t Train loss: 0.1944 took: 1.07s  Val. loss: 0.2014\n",
      "Epoch 19, 100% \t Train loss: 0.1937 took: 1.07s  Val. loss: 0.1977\n",
      "Epoch 20, 100% \t Train loss: 0.1938 took: 1.07s  Val. loss: 0.1965\n",
      "Epoch 21, 100% \t Train loss: 0.1935 took: 1.07s  Val. loss: 0.1982\n",
      "Epoch 22, 100% \t Train loss: 0.1930 took: 1.68s  Val. loss: 0.2012\n",
      "Epoch 23, 100% \t Train loss: 0.1926 took: 1.85s  Val. loss: 0.1979\n",
      "Epoch 24, 100% \t Train loss: 0.1921 took: 1.85s  Val. loss: 0.1957\n",
      "Epoch 25, 100% \t Train loss: 0.1922 took: 1.85s  Val. loss: 0.1979\n",
      "Epoch 26, 100% \t Train loss: 0.1928 took: 1.85s  Val. loss: 0.1975\n",
      "Epoch 27, 100% \t Train loss: 0.1923 took: 1.85s  Val. loss: 0.1961\n",
      "Epoch 28, 100% \t Train loss: 0.1933 took: 1.91s  Val. loss: 0.2001\n",
      "Epoch 29, 100% \t Train loss: 0.1917 took: 1.86s  Val. loss: 0.1942\n",
      "Epoch 30, 100% \t Train loss: 0.1913 took: 1.86s  Val. loss: 0.1985\n",
      "Epoch 31, 100% \t Train loss: 0.1915 took: 1.88s  Val. loss: 0.1960\n",
      "Epoch 32, 100% \t Train loss: 0.1917 took: 1.88s  Val. loss: 0.1932\n",
      "Epoch 33, 100% \t Train loss: 0.1912 took: 1.89s  Val. loss: 0.1947\n",
      "Epoch 34, 100% \t Train loss: 0.1904 took: 1.88s  Val. loss: 0.1952\n",
      "Epoch 35, 100% \t Train loss: 0.1907 took: 1.89s  Val. loss: 0.1956\n",
      "Epoch 36, 100% \t Train loss: 0.1904 took: 1.88s  Val. loss: 0.1930\n",
      "Epoch 37, 100% \t Train loss: 0.1897 took: 1.88s  Val. loss: 0.1963\n",
      "Epoch 38, 100% \t Train loss: 0.1899 took: 1.89s  Val. loss: 0.1928\n",
      "Epoch 39, 100% \t Train loss: 0.1901 took: 1.87s  Val. loss: 0.1936\n",
      "Epoch 40, 100% \t Train loss: 0.1891 took: 1.87s  Val. loss: 0.1950\n",
      "Epoch 41, 100% \t Train loss: 0.1888 took: 1.90s  Val. loss: 0.1944\n",
      "Epoch 42, 100% \t Train loss: 0.1882 took: 1.86s  Val. loss: 0.1965\n",
      "Epoch 43, 100% \t Train loss: 0.1883 took: 1.88s  Val. loss: 0.1950\n",
      "Epoch 44, 100% \t Train loss: 0.1882 took: 1.88s  Val. loss: 0.1928\n",
      "Epoch 45, 100% \t Train loss: 0.1880 took: 1.87s  Val. loss: 0.1938\n",
      "Epoch 46, 100% \t Train loss: 0.1883 took: 1.88s  Val. loss: 0.1919\n",
      "Epoch 47, 100% \t Train loss: 0.1878 took: 1.87s  Val. loss: 0.2009\n",
      "Epoch 48, 100% \t Train loss: 0.1876 took: 1.88s  Val. loss: 0.1952\n",
      "Epoch 49, 100% \t Train loss: 0.1876 took: 1.88s  Val. loss: 0.1910\n",
      "Epoch 50, 100% \t Train loss: 0.1872 took: 1.86s  Val. loss: 0.1911\n",
      "Training finished, took 87.01s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.25\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.44\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.828838\n",
      "lambda: 0.0010 - V: 0.823275\n",
      "lambda: 0.0005 - V: 0.794749\n",
      "Average V: 0.815621\n",
      "Time elapsed: 256.61 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.32\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.42\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2600 took: 1.96s  Val. loss: 0.2594\n",
      "Epoch 2, 100% \t Train loss: 0.2361 took: 1.94s  Val. loss: 0.2034\n",
      "Epoch 3, 100% \t Train loss: 0.1743 took: 1.92s  Val. loss: 0.1731\n",
      "Epoch 4, 100% \t Train loss: 0.1631 took: 1.91s  Val. loss: 0.1673\n",
      "Epoch 5, 100% \t Train loss: 0.1586 took: 1.12s  Val. loss: 0.1665\n",
      "Epoch 6, 100% \t Train loss: 0.1564 took: 1.11s  Val. loss: 0.1579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, 100% \t Train loss: 0.1550 took: 1.11s  Val. loss: 0.1619\n",
      "Epoch 8, 100% \t Train loss: 0.1560 took: 1.12s  Val. loss: 0.1630\n",
      "Epoch 9, 100% \t Train loss: 0.1522 took: 1.12s  Val. loss: 0.1609\n",
      "Epoch 10, 100% \t Train loss: 0.1505 took: 1.11s  Val. loss: 0.1577\n",
      "Epoch 11, 100% \t Train loss: 0.1488 took: 1.11s  Val. loss: 0.1567\n",
      "Epoch 12, 100% \t Train loss: 0.1491 took: 1.11s  Val. loss: 0.1594\n",
      "Epoch 13, 100% \t Train loss: 0.1473 took: 1.10s  Val. loss: 0.1603\n",
      "Epoch 14, 100% \t Train loss: 0.1479 took: 1.10s  Val. loss: 0.1576\n",
      "Epoch 15, 100% \t Train loss: 0.1459 took: 1.10s  Val. loss: 0.1589\n",
      "Epoch 16, 100% \t Train loss: 0.1456 took: 1.10s  Val. loss: 0.1565\n",
      "Epoch 17, 100% \t Train loss: 0.1443 took: 1.11s  Val. loss: 0.1595\n",
      "Epoch 18, 100% \t Train loss: 0.1426 took: 1.12s  Val. loss: 0.1648\n",
      "Epoch 19, 100% \t Train loss: 0.1428 took: 1.11s  Val. loss: 0.1597\n",
      "Epoch 20, 100% \t Train loss: 0.1419 took: 1.10s  Val. loss: 0.1546\n",
      "Epoch 21, 100% \t Train loss: 0.1396 took: 1.10s  Val. loss: 0.1539\n",
      "Epoch 22, 100% \t Train loss: 0.1378 took: 1.10s  Val. loss: 0.1537\n",
      "Epoch 23, 100% \t Train loss: 0.1356 took: 1.11s  Val. loss: 0.1519\n",
      "Epoch 24, 100% \t Train loss: 0.1337 took: 1.10s  Val. loss: 0.1454\n",
      "Epoch 25, 100% \t Train loss: 0.1297 took: 1.10s  Val. loss: 0.1516\n",
      "Epoch 26, 100% \t Train loss: 0.1256 took: 1.10s  Val. loss: 0.1373\n",
      "Epoch 27, 100% \t Train loss: 0.1209 took: 1.11s  Val. loss: 0.1367\n",
      "Epoch 28, 100% \t Train loss: 0.1176 took: 1.11s  Val. loss: 0.1376\n",
      "Epoch 29, 100% \t Train loss: 0.1107 took: 1.11s  Val. loss: 0.1278\n",
      "Epoch 30, 100% \t Train loss: 0.1067 took: 1.13s  Val. loss: 0.1205\n",
      "Epoch 31, 100% \t Train loss: 0.1009 took: 1.14s  Val. loss: 0.1121\n",
      "Epoch 32, 100% \t Train loss: 0.0969 took: 1.18s  Val. loss: 0.1079\n",
      "Epoch 33, 100% \t Train loss: 0.0940 took: 1.33s  Val. loss: 0.1076\n",
      "Epoch 34, 100% \t Train loss: 0.0906 took: 1.40s  Val. loss: 0.1059\n",
      "Epoch 35, 100% \t Train loss: 0.0891 took: 2.26s  Val. loss: 0.1062\n",
      "Epoch 36, 100% \t Train loss: 0.0871 took: 2.25s  Val. loss: 0.1034\n",
      "Epoch 37, 100% \t Train loss: 0.0853 took: 2.23s  Val. loss: 0.1001\n",
      "Epoch 38, 100% \t Train loss: 0.0846 took: 2.07s  Val. loss: 0.1002\n",
      "Epoch 39, 100% \t Train loss: 0.0830 took: 2.07s  Val. loss: 0.1019\n",
      "Epoch 40, 100% \t Train loss: 0.0822 took: 2.06s  Val. loss: 0.0989\n",
      "Epoch 41, 100% \t Train loss: 0.0817 took: 2.07s  Val. loss: 0.0983\n",
      "Epoch 42, 100% \t Train loss: 0.0803 took: 2.08s  Val. loss: 0.1011\n",
      "Epoch 43, 100% \t Train loss: 0.0801 took: 2.07s  Val. loss: 0.0980\n",
      "Epoch 44, 100% \t Train loss: 0.0780 took: 2.07s  Val. loss: 0.0952\n",
      "Epoch 45, 100% \t Train loss: 0.0799 took: 2.08s  Val. loss: 0.0990\n",
      "Epoch 46, 100% \t Train loss: 0.0771 took: 2.05s  Val. loss: 0.0958\n",
      "Epoch 47, 100% \t Train loss: 0.0763 took: 2.08s  Val. loss: 0.0945\n",
      "Epoch 48, 100% \t Train loss: 0.0762 took: 1.99s  Val. loss: 0.0938\n",
      "Epoch 49, 100% \t Train loss: 0.0758 took: 1.91s  Val. loss: 0.0935\n",
      "Epoch 50, 100% \t Train loss: 0.0764 took: 1.91s  Val. loss: 0.0968\n",
      "Training finished, took 84.48s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2587 took: 1.93s  Val. loss: 0.2611\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.91s  Val. loss: 0.2593\n",
      "Epoch 3, 100% \t Train loss: 0.2563 took: 1.91s  Val. loss: 0.2544\n",
      "Epoch 4, 100% \t Train loss: 0.2366 took: 1.92s  Val. loss: 0.2302\n",
      "Epoch 5, 100% \t Train loss: 0.2033 took: 1.92s  Val. loss: 0.1914\n",
      "Epoch 6, 100% \t Train loss: 0.1866 took: 1.91s  Val. loss: 0.1832\n",
      "Epoch 7, 100% \t Train loss: 0.1784 took: 1.94s  Val. loss: 0.1817\n",
      "Epoch 8, 100% \t Train loss: 0.1740 took: 1.91s  Val. loss: 0.1828\n",
      "Epoch 9, 100% \t Train loss: 0.1728 took: 1.93s  Val. loss: 0.1770\n",
      "Epoch 10, 100% \t Train loss: 0.1704 took: 1.93s  Val. loss: 0.1761\n",
      "Epoch 11, 100% \t Train loss: 0.1691 took: 1.91s  Val. loss: 0.1764\n",
      "Epoch 12, 100% \t Train loss: 0.1651 took: 1.92s  Val. loss: 0.1740\n",
      "Epoch 13, 100% \t Train loss: 0.1654 took: 1.92s  Val. loss: 0.1691\n",
      "Epoch 14, 100% \t Train loss: 0.1622 took: 1.92s  Val. loss: 0.1696\n",
      "Epoch 15, 100% \t Train loss: 0.1607 took: 1.92s  Val. loss: 0.1685\n",
      "Epoch 16, 100% \t Train loss: 0.1623 took: 1.92s  Val. loss: 0.1661\n",
      "Epoch 17, 100% \t Train loss: 0.1585 took: 1.93s  Val. loss: 0.1693\n",
      "Epoch 18, 100% \t Train loss: 0.1589 took: 1.92s  Val. loss: 0.1684\n",
      "Epoch 19, 100% \t Train loss: 0.1581 took: 1.92s  Val. loss: 0.1697\n",
      "Epoch 20, 100% \t Train loss: 0.1579 took: 1.92s  Val. loss: 0.1664\n",
      "Epoch 21, 100% \t Train loss: 0.1566 took: 1.95s  Val. loss: 0.1668\n",
      "Epoch 22, 100% \t Train loss: 0.1582 took: 1.95s  Val. loss: 0.1685\n",
      "Epoch 23, 100% \t Train loss: 0.1558 took: 1.96s  Val. loss: 0.1648\n",
      "Epoch 24, 100% \t Train loss: 0.1554 took: 1.93s  Val. loss: 0.1632\n",
      "Epoch 25, 100% \t Train loss: 0.1553 took: 1.92s  Val. loss: 0.1668\n",
      "Epoch 26, 100% \t Train loss: 0.1546 took: 1.93s  Val. loss: 0.1650\n",
      "Epoch 27, 100% \t Train loss: 0.1547 took: 1.91s  Val. loss: 0.1635\n",
      "Epoch 28, 100% \t Train loss: 0.1540 took: 1.92s  Val. loss: 0.1647\n",
      "Epoch 29, 100% \t Train loss: 0.1530 took: 1.94s  Val. loss: 0.1663\n",
      "Epoch 30, 100% \t Train loss: 0.1526 took: 1.94s  Val. loss: 0.1704\n",
      "Epoch 31, 100% \t Train loss: 0.1530 took: 1.94s  Val. loss: 0.1634\n",
      "Epoch 32, 100% \t Train loss: 0.1509 took: 1.95s  Val. loss: 0.1653\n",
      "Epoch 33, 100% \t Train loss: 0.1494 took: 1.94s  Val. loss: 0.1625\n",
      "Epoch 34, 100% \t Train loss: 0.1495 took: 1.93s  Val. loss: 0.1630\n",
      "Epoch 35, 100% \t Train loss: 0.1476 took: 1.94s  Val. loss: 0.1594\n",
      "Epoch 36, 100% \t Train loss: 0.1450 took: 1.94s  Val. loss: 0.1600\n",
      "Epoch 37, 100% \t Train loss: 0.1427 took: 1.96s  Val. loss: 0.1553\n",
      "Epoch 38, 100% \t Train loss: 0.1403 took: 1.94s  Val. loss: 0.1571\n",
      "Epoch 39, 100% \t Train loss: 0.1386 took: 1.92s  Val. loss: 0.1516\n",
      "Epoch 40, 100% \t Train loss: 0.1357 took: 1.92s  Val. loss: 0.1541\n",
      "Epoch 41, 100% \t Train loss: 0.1340 took: 1.55s  Val. loss: 0.1508\n",
      "Epoch 42, 100% \t Train loss: 0.1314 took: 1.14s  Val. loss: 0.1551\n",
      "Epoch 43, 100% \t Train loss: 0.1303 took: 1.42s  Val. loss: 0.1478\n",
      "Epoch 44, 100% \t Train loss: 0.1282 took: 1.96s  Val. loss: 0.1491\n",
      "Epoch 45, 100% \t Train loss: 0.1269 took: 1.97s  Val. loss: 0.1457\n",
      "Epoch 46, 100% \t Train loss: 0.1252 took: 1.96s  Val. loss: 0.1449\n",
      "Epoch 47, 100% \t Train loss: 0.1230 took: 1.97s  Val. loss: 0.1433\n",
      "Epoch 48, 100% \t Train loss: 0.1215 took: 1.98s  Val. loss: 0.1488\n",
      "Epoch 49, 100% \t Train loss: 0.1205 took: 1.97s  Val. loss: 0.1375\n",
      "Epoch 50, 100% \t Train loss: 0.1179 took: 1.97s  Val. loss: 0.1436\n",
      "Training finished, took 107.39s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 1.93s  Val. loss: 0.2618\n",
      "Epoch 2, 100% \t Train loss: 0.2582 took: 1.93s  Val. loss: 0.2600\n",
      "Epoch 3, 100% \t Train loss: 0.2582 took: 1.93s  Val. loss: 0.2603\n",
      "Epoch 4, 100% \t Train loss: 0.2581 took: 1.91s  Val. loss: 0.2604\n",
      "Epoch 5, 100% \t Train loss: 0.2581 took: 1.91s  Val. loss: 0.2589\n",
      "Epoch 6, 100% \t Train loss: 0.2579 took: 1.91s  Val. loss: 0.2606\n",
      "Epoch 7, 100% \t Train loss: 0.2578 took: 1.92s  Val. loss: 0.2594\n",
      "Epoch 8, 100% \t Train loss: 0.2571 took: 1.92s  Val. loss: 0.2581\n",
      "Epoch 9, 100% \t Train loss: 0.2541 took: 1.11s  Val. loss: 0.2530\n",
      "Epoch 10, 100% \t Train loss: 0.2420 took: 1.11s  Val. loss: 0.2361\n",
      "Epoch 11, 100% \t Train loss: 0.2278 took: 1.10s  Val. loss: 0.2190\n",
      "Epoch 12, 100% \t Train loss: 0.2142 took: 1.10s  Val. loss: 0.2061\n",
      "Epoch 13, 100% \t Train loss: 0.2042 took: 1.11s  Val. loss: 0.1990\n",
      "Epoch 14, 100% \t Train loss: 0.1975 took: 1.11s  Val. loss: 0.1936\n",
      "Epoch 15, 100% \t Train loss: 0.1923 took: 1.11s  Val. loss: 0.1909\n",
      "Epoch 16, 100% \t Train loss: 0.1897 took: 1.10s  Val. loss: 0.1922\n",
      "Epoch 17, 100% \t Train loss: 0.1867 took: 1.11s  Val. loss: 0.1870\n",
      "Epoch 18, 100% \t Train loss: 0.1842 took: 1.11s  Val. loss: 0.1848\n",
      "Epoch 19, 100% \t Train loss: 0.1826 took: 1.11s  Val. loss: 0.1828\n",
      "Epoch 20, 100% \t Train loss: 0.1813 took: 1.10s  Val. loss: 0.1818\n",
      "Epoch 21, 100% \t Train loss: 0.1802 took: 1.11s  Val. loss: 0.1800\n",
      "Epoch 22, 100% \t Train loss: 0.1785 took: 1.11s  Val. loss: 0.1800\n",
      "Epoch 23, 100% \t Train loss: 0.1770 took: 1.11s  Val. loss: 0.1779\n",
      "Epoch 24, 100% \t Train loss: 0.1761 took: 1.10s  Val. loss: 0.1792\n",
      "Epoch 25, 100% \t Train loss: 0.1740 took: 1.10s  Val. loss: 0.1748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, 100% \t Train loss: 0.1725 took: 1.10s  Val. loss: 0.1759\n",
      "Epoch 27, 100% \t Train loss: 0.1699 took: 1.90s  Val. loss: 0.1721\n",
      "Epoch 28, 100% \t Train loss: 0.1690 took: 1.90s  Val. loss: 0.1702\n",
      "Epoch 29, 100% \t Train loss: 0.1673 took: 1.90s  Val. loss: 0.1699\n",
      "Epoch 30, 100% \t Train loss: 0.1666 took: 1.91s  Val. loss: 0.1709\n",
      "Epoch 31, 100% \t Train loss: 0.1647 took: 1.95s  Val. loss: 0.1671\n",
      "Epoch 32, 100% \t Train loss: 0.1665 took: 1.93s  Val. loss: 0.1680\n",
      "Epoch 33, 100% \t Train loss: 0.1635 took: 1.92s  Val. loss: 0.1662\n",
      "Epoch 34, 100% \t Train loss: 0.1642 took: 1.92s  Val. loss: 0.1668\n",
      "Epoch 35, 100% \t Train loss: 0.1626 took: 1.93s  Val. loss: 0.1664\n",
      "Epoch 36, 100% \t Train loss: 0.1614 took: 1.94s  Val. loss: 0.1648\n",
      "Epoch 37, 100% \t Train loss: 0.1604 took: 1.95s  Val. loss: 0.1640\n",
      "Epoch 38, 100% \t Train loss: 0.1602 took: 1.94s  Val. loss: 0.1648\n",
      "Epoch 39, 100% \t Train loss: 0.1610 took: 1.94s  Val. loss: 0.1643\n",
      "Epoch 40, 100% \t Train loss: 0.1592 took: 1.93s  Val. loss: 0.1653\n",
      "Epoch 41, 100% \t Train loss: 0.1582 took: 1.93s  Val. loss: 0.1636\n",
      "Epoch 42, 100% \t Train loss: 0.1572 took: 1.93s  Val. loss: 0.1645\n",
      "Epoch 43, 100% \t Train loss: 0.1583 took: 1.95s  Val. loss: 0.1650\n",
      "Epoch 44, 100% \t Train loss: 0.1574 took: 1.93s  Val. loss: 0.1656\n",
      "Epoch 45, 100% \t Train loss: 0.1570 took: 1.96s  Val. loss: 0.1639\n",
      "Epoch 46, 100% \t Train loss: 0.1577 took: 1.95s  Val. loss: 0.1626\n",
      "Epoch 47, 100% \t Train loss: 0.1562 took: 1.91s  Val. loss: 0.1649\n",
      "Epoch 48, 100% \t Train loss: 0.1556 took: 1.92s  Val. loss: 0.1624\n",
      "Epoch 49, 100% \t Train loss: 0.1543 took: 1.94s  Val. loss: 0.1632\n",
      "Epoch 50, 100% \t Train loss: 0.1553 took: 1.94s  Val. loss: 0.1636\n",
      "Training finished, took 92.29s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.32\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.42\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.864283\n",
      "lambda: 0.0010 - V: 0.829738\n",
      "lambda: 0.0005 - V: 0.808924\n",
      "Average V: 0.834315\n",
      "Time elapsed: 287.71 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.42\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.44\n",
      "\tmask_channels :  8  - prob: 0.41\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2602 took: 2.06s  Val. loss: 0.2663\n",
      "Epoch 2, 100% \t Train loss: 0.2574 took: 2.06s  Val. loss: 0.2607\n",
      "Epoch 3, 100% \t Train loss: 0.2217 took: 1.22s  Val. loss: 0.1869\n",
      "Epoch 4, 100% \t Train loss: 0.1694 took: 1.22s  Val. loss: 0.1743\n",
      "Epoch 5, 100% \t Train loss: 0.1584 took: 1.22s  Val. loss: 0.1662\n",
      "Epoch 6, 100% \t Train loss: 0.1546 took: 1.83s  Val. loss: 0.1661\n",
      "Epoch 7, 100% \t Train loss: 0.1525 took: 2.03s  Val. loss: 0.1685\n",
      "Epoch 8, 100% \t Train loss: 0.1516 took: 2.02s  Val. loss: 0.1673\n",
      "Epoch 9, 100% \t Train loss: 0.1496 took: 2.02s  Val. loss: 0.1640\n",
      "Epoch 10, 100% \t Train loss: 0.1483 took: 2.03s  Val. loss: 0.1672\n",
      "Epoch 11, 100% \t Train loss: 0.1481 took: 1.45s  Val. loss: 0.1645\n",
      "Epoch 12, 100% \t Train loss: 0.1475 took: 1.21s  Val. loss: 0.1666\n",
      "Epoch 13, 100% \t Train loss: 0.1467 took: 1.21s  Val. loss: 0.1684\n",
      "Epoch 14, 100% \t Train loss: 0.1462 took: 1.20s  Val. loss: 0.1632\n",
      "Epoch 15, 100% \t Train loss: 0.1460 took: 1.20s  Val. loss: 0.1686\n",
      "Epoch 16, 100% \t Train loss: 0.1450 took: 1.20s  Val. loss: 0.1664\n",
      "Epoch 17, 100% \t Train loss: 0.1448 took: 1.20s  Val. loss: 0.1669\n",
      "Epoch 18, 100% \t Train loss: 0.1447 took: 1.20s  Val. loss: 0.1657\n",
      "Epoch 19, 100% \t Train loss: 0.1440 took: 1.20s  Val. loss: 0.1678\n",
      "Epoch 20, 100% \t Train loss: 0.1435 took: 1.20s  Val. loss: 0.1639\n",
      "Epoch 21, 100% \t Train loss: 0.1432 took: 1.20s  Val. loss: 0.1701\n",
      "Epoch 22, 100% \t Train loss: 0.1432 took: 1.20s  Val. loss: 0.1647\n",
      "Epoch 23, 100% \t Train loss: 0.1424 took: 1.20s  Val. loss: 0.1653\n",
      "Epoch 24, 100% \t Train loss: 0.1417 took: 1.20s  Val. loss: 0.1643\n",
      "Epoch 25, 100% \t Train loss: 0.1407 took: 1.20s  Val. loss: 0.1613\n",
      "Epoch 26, 100% \t Train loss: 0.1388 took: 1.21s  Val. loss: 0.1590\n",
      "Epoch 27, 100% \t Train loss: 0.1365 took: 1.20s  Val. loss: 0.1615\n",
      "Epoch 28, 100% \t Train loss: 0.1329 took: 1.21s  Val. loss: 0.1520\n",
      "Epoch 29, 100% \t Train loss: 0.1274 took: 1.21s  Val. loss: 0.1476\n",
      "Epoch 30, 100% \t Train loss: 0.1191 took: 1.22s  Val. loss: 0.1395\n",
      "Epoch 31, 100% \t Train loss: 0.1134 took: 1.24s  Val. loss: 0.1245\n",
      "Epoch 32, 100% \t Train loss: 0.1040 took: 1.32s  Val. loss: 0.1212\n",
      "Epoch 33, 100% \t Train loss: 0.0999 took: 2.23s  Val. loss: 0.1125\n",
      "Epoch 34, 100% \t Train loss: 0.0946 took: 2.23s  Val. loss: 0.1088\n",
      "Epoch 35, 100% \t Train loss: 0.0899 took: 2.21s  Val. loss: 0.1051\n",
      "Epoch 36, 100% \t Train loss: 0.0878 took: 2.25s  Val. loss: 0.1012\n",
      "Epoch 37, 100% \t Train loss: 0.0854 took: 2.26s  Val. loss: 0.1028\n",
      "Epoch 38, 100% \t Train loss: 0.0831 took: 2.25s  Val. loss: 0.1040\n",
      "Epoch 39, 100% \t Train loss: 0.0816 took: 2.22s  Val. loss: 0.1003\n",
      "Epoch 40, 100% \t Train loss: 0.0788 took: 2.26s  Val. loss: 0.0978\n",
      "Epoch 41, 100% \t Train loss: 0.0775 took: 2.26s  Val. loss: 0.0960\n",
      "Epoch 42, 100% \t Train loss: 0.0772 took: 2.29s  Val. loss: 0.0974\n",
      "Epoch 43, 100% \t Train loss: 0.0755 took: 2.32s  Val. loss: 0.0948\n",
      "Epoch 44, 100% \t Train loss: 0.0748 took: 2.33s  Val. loss: 0.0960\n",
      "Epoch 45, 100% \t Train loss: 0.0733 took: 2.34s  Val. loss: 0.0939\n",
      "Epoch 46, 100% \t Train loss: 0.0727 took: 2.34s  Val. loss: 0.0944\n",
      "Epoch 47, 100% \t Train loss: 0.0713 took: 2.35s  Val. loss: 0.0927\n",
      "Epoch 48, 100% \t Train loss: 0.0718 took: 2.37s  Val. loss: 0.0954\n",
      "Epoch 49, 100% \t Train loss: 0.0704 took: 2.44s  Val. loss: 0.0968\n",
      "Epoch 50, 100% \t Train loss: 0.0709 took: 2.46s  Val. loss: 0.0946\n",
      "Training finished, took 96.81s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2575 took: 2.05s  Val. loss: 0.2589\n",
      "Epoch 2, 100% \t Train loss: 0.2570 took: 2.02s  Val. loss: 0.2571\n",
      "Epoch 3, 100% \t Train loss: 0.2374 took: 2.04s  Val. loss: 0.1961\n",
      "Epoch 4, 100% \t Train loss: 0.1795 took: 2.02s  Val. loss: 0.1707\n",
      "Epoch 5, 100% \t Train loss: 0.1733 took: 2.01s  Val. loss: 0.1681\n",
      "Epoch 6, 100% \t Train loss: 0.1713 took: 2.01s  Val. loss: 0.1662\n",
      "Epoch 7, 100% \t Train loss: 0.1704 took: 1.20s  Val. loss: 0.1684\n",
      "Epoch 8, 100% \t Train loss: 0.1670 took: 1.21s  Val. loss: 0.1652\n",
      "Epoch 9, 100% \t Train loss: 0.1670 took: 1.21s  Val. loss: 0.1661\n",
      "Epoch 10, 100% \t Train loss: 0.1643 took: 1.21s  Val. loss: 0.1650\n",
      "Epoch 11, 100% \t Train loss: 0.1626 took: 1.21s  Val. loss: 0.1632\n",
      "Epoch 12, 100% \t Train loss: 0.1607 took: 1.21s  Val. loss: 0.1619\n",
      "Epoch 13, 100% \t Train loss: 0.1598 took: 1.20s  Val. loss: 0.1606\n",
      "Epoch 14, 100% \t Train loss: 0.1568 took: 1.21s  Val. loss: 0.1645\n",
      "Epoch 15, 100% \t Train loss: 0.1571 took: 1.20s  Val. loss: 0.1602\n",
      "Epoch 16, 100% \t Train loss: 0.1555 took: 1.20s  Val. loss: 0.1596\n",
      "Epoch 17, 100% \t Train loss: 0.1544 took: 1.28s  Val. loss: 0.1597\n",
      "Epoch 18, 100% \t Train loss: 0.1540 took: 2.02s  Val. loss: 0.1603\n",
      "Epoch 19, 100% \t Train loss: 0.1530 took: 2.03s  Val. loss: 0.1621\n",
      "Epoch 20, 100% \t Train loss: 0.1518 took: 1.20s  Val. loss: 0.1607\n",
      "Epoch 21, 100% \t Train loss: 0.1515 took: 1.21s  Val. loss: 0.1622\n",
      "Epoch 22, 100% \t Train loss: 0.1523 took: 1.20s  Val. loss: 0.1643\n",
      "Epoch 23, 100% \t Train loss: 0.1522 took: 2.02s  Val. loss: 0.1679\n",
      "Epoch 24, 100% \t Train loss: 0.1509 took: 1.21s  Val. loss: 0.1617\n",
      "Epoch 25, 100% \t Train loss: 0.1496 took: 1.21s  Val. loss: 0.1636\n",
      "Epoch 26, 100% \t Train loss: 0.1478 took: 1.21s  Val. loss: 0.1631\n",
      "Epoch 27, 100% \t Train loss: 0.1479 took: 1.22s  Val. loss: 0.1619\n",
      "Epoch 28, 100% \t Train loss: 0.1454 took: 1.22s  Val. loss: 0.1573\n",
      "Epoch 29, 100% \t Train loss: 0.1424 took: 1.24s  Val. loss: 0.1591\n",
      "Epoch 30, 100% \t Train loss: 0.1406 took: 1.25s  Val. loss: 0.1506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, 100% \t Train loss: 0.1352 took: 1.27s  Val. loss: 0.1508\n",
      "Epoch 32, 100% \t Train loss: 0.1328 took: 1.34s  Val. loss: 0.1470\n",
      "Epoch 33, 100% \t Train loss: 0.1287 took: 1.37s  Val. loss: 0.1432\n",
      "Epoch 34, 100% \t Train loss: 0.1239 took: 1.41s  Val. loss: 0.1351\n",
      "Epoch 35, 100% \t Train loss: 0.1180 took: 1.40s  Val. loss: 0.1334\n",
      "Epoch 36, 100% \t Train loss: 0.1134 took: 1.41s  Val. loss: 0.1257\n",
      "Epoch 37, 100% \t Train loss: 0.1084 took: 1.42s  Val. loss: 0.1255\n",
      "Epoch 38, 100% \t Train loss: 0.1047 took: 1.39s  Val. loss: 0.1237\n",
      "Epoch 39, 100% \t Train loss: 0.1007 took: 1.41s  Val. loss: 0.1170\n",
      "Epoch 40, 100% \t Train loss: 0.0962 took: 1.42s  Val. loss: 0.1150\n",
      "Epoch 41, 100% \t Train loss: 0.0933 took: 1.42s  Val. loss: 0.1164\n",
      "Epoch 42, 100% \t Train loss: 0.0917 took: 1.41s  Val. loss: 0.1108\n",
      "Epoch 43, 100% \t Train loss: 0.0886 took: 1.41s  Val. loss: 0.1071\n",
      "Epoch 44, 100% \t Train loss: 0.0857 took: 1.41s  Val. loss: 0.1031\n",
      "Epoch 45, 100% \t Train loss: 0.0838 took: 1.41s  Val. loss: 0.1027\n",
      "Epoch 46, 100% \t Train loss: 0.0831 took: 1.44s  Val. loss: 0.0993\n",
      "Epoch 47, 100% \t Train loss: 0.0818 took: 1.44s  Val. loss: 0.1038\n",
      "Epoch 48, 100% \t Train loss: 0.0810 took: 1.45s  Val. loss: 0.1009\n",
      "Epoch 49, 100% \t Train loss: 0.0788 took: 1.47s  Val. loss: 0.0956\n",
      "Epoch 50, 100% \t Train loss: 0.0778 took: 1.55s  Val. loss: 0.0977\n",
      "Training finished, took 81.14s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2575 took: 1.21s  Val. loss: 0.2599\n",
      "Epoch 2, 100% \t Train loss: 0.2574 took: 1.20s  Val. loss: 0.2602\n",
      "Epoch 3, 100% \t Train loss: 0.2574 took: 1.20s  Val. loss: 0.2598\n",
      "Epoch 4, 100% \t Train loss: 0.2573 took: 1.20s  Val. loss: 0.2602\n",
      "Epoch 5, 100% \t Train loss: 0.2572 took: 1.21s  Val. loss: 0.2597\n",
      "Epoch 6, 100% \t Train loss: 0.2573 took: 1.19s  Val. loss: 0.2617\n",
      "Epoch 7, 100% \t Train loss: 0.2573 took: 1.37s  Val. loss: 0.2601\n",
      "Epoch 8, 100% \t Train loss: 0.2574 took: 2.04s  Val. loss: 0.2593\n",
      "Epoch 9, 100% \t Train loss: 0.2573 took: 2.03s  Val. loss: 0.2600\n",
      "Epoch 10, 100% \t Train loss: 0.2572 took: 2.03s  Val. loss: 0.2604\n",
      "Epoch 11, 100% \t Train loss: 0.2574 took: 2.02s  Val. loss: 0.2580\n",
      "Epoch 12, 100% \t Train loss: 0.2572 took: 2.03s  Val. loss: 0.2607\n",
      "Epoch 13, 100% \t Train loss: 0.2571 took: 2.01s  Val. loss: 0.2588\n",
      "Epoch 14, 100% \t Train loss: 0.2566 took: 2.01s  Val. loss: 0.2587\n",
      "Epoch 15, 100% \t Train loss: 0.2547 took: 2.02s  Val. loss: 0.2544\n",
      "Epoch 16, 100% \t Train loss: 0.2474 took: 2.02s  Val. loss: 0.2440\n",
      "Epoch 17, 100% \t Train loss: 0.2349 took: 2.03s  Val. loss: 0.2331\n",
      "Epoch 18, 100% \t Train loss: 0.2230 took: 2.03s  Val. loss: 0.2202\n",
      "Epoch 19, 100% \t Train loss: 0.2063 took: 2.05s  Val. loss: 0.2106\n",
      "Epoch 20, 100% \t Train loss: 0.1959 took: 2.06s  Val. loss: 0.2071\n",
      "Epoch 21, 100% \t Train loss: 0.1869 took: 2.05s  Val. loss: 0.1985\n",
      "Epoch 22, 100% \t Train loss: 0.1839 took: 2.04s  Val. loss: 0.1977\n",
      "Epoch 23, 100% \t Train loss: 0.1785 took: 2.04s  Val. loss: 0.1922\n",
      "Epoch 24, 100% \t Train loss: 0.1764 took: 2.03s  Val. loss: 0.1894\n",
      "Epoch 25, 100% \t Train loss: 0.1716 took: 2.04s  Val. loss: 0.1852\n",
      "Epoch 26, 100% \t Train loss: 0.1701 took: 2.05s  Val. loss: 0.1909\n",
      "Epoch 27, 100% \t Train loss: 0.1696 took: 2.07s  Val. loss: 0.1869\n",
      "Epoch 28, 100% \t Train loss: 0.1651 took: 2.04s  Val. loss: 0.1839\n",
      "Epoch 29, 100% \t Train loss: 0.1661 took: 2.06s  Val. loss: 0.1828\n",
      "Epoch 30, 100% \t Train loss: 0.1632 took: 2.05s  Val. loss: 0.1792\n",
      "Epoch 31, 100% \t Train loss: 0.1627 took: 2.09s  Val. loss: 0.1803\n",
      "Epoch 32, 100% \t Train loss: 0.1610 took: 2.12s  Val. loss: 0.1772\n",
      "Epoch 33, 100% \t Train loss: 0.1608 took: 2.12s  Val. loss: 0.1789\n",
      "Epoch 34, 100% \t Train loss: 0.1597 took: 2.12s  Val. loss: 0.1793\n",
      "Epoch 35, 100% \t Train loss: 0.1585 took: 2.12s  Val. loss: 0.1762\n",
      "Epoch 36, 100% \t Train loss: 0.1572 took: 2.12s  Val. loss: 0.1757\n",
      "Epoch 37, 100% \t Train loss: 0.1562 took: 2.14s  Val. loss: 0.1726\n",
      "Epoch 38, 100% \t Train loss: 0.1554 took: 2.14s  Val. loss: 0.1727\n",
      "Epoch 39, 100% \t Train loss: 0.1536 took: 2.15s  Val. loss: 0.1698\n",
      "Epoch 40, 100% \t Train loss: 0.1524 took: 2.16s  Val. loss: 0.1681\n",
      "Epoch 41, 100% \t Train loss: 0.1504 took: 2.18s  Val. loss: 0.1680\n",
      "Epoch 42, 100% \t Train loss: 0.1493 took: 2.19s  Val. loss: 0.1638\n",
      "Epoch 43, 100% \t Train loss: 0.1457 took: 2.19s  Val. loss: 0.1632\n",
      "Epoch 44, 100% \t Train loss: 0.1439 took: 2.20s  Val. loss: 0.1572\n",
      "Epoch 45, 100% \t Train loss: 0.1400 took: 2.23s  Val. loss: 0.1546\n",
      "Epoch 46, 100% \t Train loss: 0.1380 took: 2.23s  Val. loss: 0.1488\n",
      "Epoch 47, 100% \t Train loss: 0.1355 took: 2.24s  Val. loss: 0.1479\n",
      "Epoch 48, 100% \t Train loss: 0.1286 took: 2.26s  Val. loss: 0.1430\n",
      "Epoch 49, 100% \t Train loss: 0.1245 took: 2.22s  Val. loss: 0.1351\n",
      "Epoch 50, 100% \t Train loss: 0.1191 took: 2.24s  Val. loss: 0.1334\n",
      "Training finished, took 111.23s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.42\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.44\n",
      "\tmask_channels :  8  - prob: 0.41\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.856699\n",
      "lambda: 0.0010 - V: 0.850800\n",
      "lambda: 0.0005 - V: 0.796816\n",
      "Average V: 0.834772\n",
      "Time elapsed: 292.54 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.27\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.40\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2576 took: 2.04s  Val. loss: 0.2536\n",
      "Epoch 2, 100% \t Train loss: 0.2495 took: 2.00s  Val. loss: 0.2195\n",
      "Epoch 3, 100% \t Train loss: 0.2036 took: 2.04s  Val. loss: 0.1913\n",
      "Epoch 4, 100% \t Train loss: 0.1915 took: 2.02s  Val. loss: 0.1880\n",
      "Epoch 5, 100% \t Train loss: 0.1887 took: 2.02s  Val. loss: 0.1857\n",
      "Epoch 6, 100% \t Train loss: 0.1887 took: 2.03s  Val. loss: 0.1852\n",
      "Epoch 7, 100% \t Train loss: 0.1853 took: 2.02s  Val. loss: 0.1805\n",
      "Epoch 8, 100% \t Train loss: 0.1829 took: 2.00s  Val. loss: 0.1813\n",
      "Epoch 9, 100% \t Train loss: 0.1812 took: 2.04s  Val. loss: 0.1838\n",
      "Epoch 10, 100% \t Train loss: 0.1806 took: 2.02s  Val. loss: 0.1825\n",
      "Epoch 11, 100% \t Train loss: 0.1808 took: 2.02s  Val. loss: 0.1786\n",
      "Epoch 12, 100% \t Train loss: 0.1795 took: 2.03s  Val. loss: 0.1770\n",
      "Epoch 13, 100% \t Train loss: 0.1769 took: 2.03s  Val. loss: 0.1752\n",
      "Epoch 14, 100% \t Train loss: 0.1746 took: 2.04s  Val. loss: 0.1750\n",
      "Epoch 15, 100% \t Train loss: 0.1724 took: 2.05s  Val. loss: 0.1749\n",
      "Epoch 16, 100% \t Train loss: 0.1707 took: 2.04s  Val. loss: 0.1699\n",
      "Epoch 17, 100% \t Train loss: 0.1657 took: 2.04s  Val. loss: 0.1679\n",
      "Epoch 18, 100% \t Train loss: 0.1584 took: 2.03s  Val. loss: 0.1552\n",
      "Epoch 19, 100% \t Train loss: 0.1493 took: 2.02s  Val. loss: 0.1452\n",
      "Epoch 20, 100% \t Train loss: 0.1419 took: 2.03s  Val. loss: 0.1434\n",
      "Epoch 21, 100% \t Train loss: 0.1408 took: 2.03s  Val. loss: 0.1409\n",
      "Epoch 22, 100% \t Train loss: 0.1358 took: 2.01s  Val. loss: 0.1373\n",
      "Epoch 23, 100% \t Train loss: 0.1342 took: 2.02s  Val. loss: 0.1408\n",
      "Epoch 24, 100% \t Train loss: 0.1307 took: 2.01s  Val. loss: 0.1327\n",
      "Epoch 25, 100% \t Train loss: 0.1304 took: 2.00s  Val. loss: 0.1318\n",
      "Epoch 26, 100% \t Train loss: 0.1296 took: 2.02s  Val. loss: 0.1261\n",
      "Epoch 27, 100% \t Train loss: 0.1271 took: 2.05s  Val. loss: 0.1363\n",
      "Epoch 28, 100% \t Train loss: 0.1265 took: 2.06s  Val. loss: 0.1281\n",
      "Epoch 29, 100% \t Train loss: 0.1252 took: 2.05s  Val. loss: 0.1264\n",
      "Epoch 30, 100% \t Train loss: 0.1241 took: 2.07s  Val. loss: 0.1298\n",
      "Epoch 31, 100% \t Train loss: 0.1241 took: 2.10s  Val. loss: 0.1275\n",
      "Epoch 32, 100% \t Train loss: 0.1237 took: 2.20s  Val. loss: 0.1295\n",
      "Epoch 33, 100% \t Train loss: 0.1235 took: 2.42s  Val. loss: 0.1277\n",
      "Epoch 34, 100% \t Train loss: 0.1215 took: 2.47s  Val. loss: 0.1242\n",
      "Epoch 35, 100% \t Train loss: 0.1204 took: 2.49s  Val. loss: 0.1255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, 100% \t Train loss: 0.1219 took: 2.49s  Val. loss: 0.1265\n",
      "Epoch 37, 100% \t Train loss: 0.1193 took: 2.50s  Val. loss: 0.1265\n",
      "Epoch 38, 100% \t Train loss: 0.1189 took: 2.51s  Val. loss: 0.1279\n",
      "Epoch 39, 100% \t Train loss: 0.1198 took: 2.50s  Val. loss: 0.1261\n",
      "Epoch 40, 100% \t Train loss: 0.1187 took: 2.50s  Val. loss: 0.1238\n",
      "Epoch 41, 100% \t Train loss: 0.1186 took: 2.51s  Val. loss: 0.1236\n",
      "Epoch 42, 100% \t Train loss: 0.1186 took: 2.53s  Val. loss: 0.1289\n",
      "Epoch 43, 100% \t Train loss: 0.1176 took: 2.56s  Val. loss: 0.1268\n",
      "Epoch 44, 100% \t Train loss: 0.1176 took: 2.53s  Val. loss: 0.1262\n",
      "Epoch 45, 100% \t Train loss: 0.1180 took: 2.56s  Val. loss: 0.1284\n",
      "Epoch 46, 100% \t Train loss: 0.1178 took: 2.53s  Val. loss: 0.1251\n",
      "Epoch 47, 100% \t Train loss: 0.1169 took: 2.52s  Val. loss: 0.1241\n",
      "Epoch 48, 100% \t Train loss: 0.1167 took: 2.54s  Val. loss: 0.1191\n",
      "Epoch 49, 100% \t Train loss: 0.1162 took: 2.54s  Val. loss: 0.1222\n",
      "Epoch 50, 100% \t Train loss: 0.1161 took: 2.56s  Val. loss: 0.1244\n",
      "Training finished, took 124.47s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2609 took: 2.03s  Val. loss: 0.2558\n",
      "Epoch 2, 100% \t Train loss: 0.2589 took: 2.03s  Val. loss: 0.2541\n",
      "Epoch 3, 100% \t Train loss: 0.2489 took: 2.03s  Val. loss: 0.2327\n",
      "Epoch 4, 100% \t Train loss: 0.2239 took: 2.03s  Val. loss: 0.2110\n",
      "Epoch 5, 100% \t Train loss: 0.2103 took: 2.04s  Val. loss: 0.2033\n",
      "Epoch 6, 100% \t Train loss: 0.2083 took: 2.03s  Val. loss: 0.2016\n",
      "Epoch 7, 100% \t Train loss: 0.2058 took: 2.02s  Val. loss: 0.2008\n",
      "Epoch 8, 100% \t Train loss: 0.2076 took: 2.04s  Val. loss: 0.1994\n",
      "Epoch 9, 100% \t Train loss: 0.2031 took: 2.03s  Val. loss: 0.1969\n",
      "Epoch 10, 100% \t Train loss: 0.2001 took: 2.02s  Val. loss: 0.1961\n",
      "Epoch 11, 100% \t Train loss: 0.1977 took: 2.04s  Val. loss: 0.1923\n",
      "Epoch 12, 100% \t Train loss: 0.1913 took: 2.03s  Val. loss: 0.1874\n",
      "Epoch 13, 100% \t Train loss: 0.1868 took: 2.02s  Val. loss: 0.1857\n",
      "Epoch 14, 100% \t Train loss: 0.1813 took: 2.05s  Val. loss: 0.1761\n",
      "Epoch 15, 100% \t Train loss: 0.1766 took: 2.03s  Val. loss: 0.1718\n",
      "Epoch 16, 100% \t Train loss: 0.1712 took: 2.03s  Val. loss: 0.1729\n",
      "Epoch 17, 100% \t Train loss: 0.1697 took: 2.02s  Val. loss: 0.1674\n",
      "Epoch 18, 100% \t Train loss: 0.1644 took: 2.02s  Val. loss: 0.1668\n",
      "Epoch 19, 100% \t Train loss: 0.1616 took: 2.02s  Val. loss: 0.1614\n",
      "Epoch 20, 100% \t Train loss: 0.1595 took: 1.19s  Val. loss: 0.1619\n",
      "Epoch 21, 100% \t Train loss: 0.1571 took: 1.19s  Val. loss: 0.1576\n",
      "Epoch 22, 100% \t Train loss: 0.1538 took: 1.20s  Val. loss: 0.1623\n",
      "Epoch 23, 100% \t Train loss: 0.1521 took: 1.19s  Val. loss: 0.1526\n",
      "Epoch 24, 100% \t Train loss: 0.1517 took: 1.19s  Val. loss: 0.1551\n",
      "Epoch 25, 100% \t Train loss: 0.1490 took: 1.19s  Val. loss: 0.1481\n",
      "Epoch 26, 100% \t Train loss: 0.1493 took: 1.19s  Val. loss: 0.1601\n",
      "Epoch 27, 100% \t Train loss: 0.1472 took: 1.19s  Val. loss: 0.1474\n",
      "Epoch 28, 100% \t Train loss: 0.1445 took: 1.18s  Val. loss: 0.1458\n",
      "Epoch 29, 100% \t Train loss: 0.1435 took: 1.19s  Val. loss: 0.1464\n",
      "Epoch 30, 100% \t Train loss: 0.1417 took: 1.20s  Val. loss: 0.1453\n",
      "Epoch 31, 100% \t Train loss: 0.1401 took: 1.21s  Val. loss: 0.1422\n",
      "Epoch 32, 100% \t Train loss: 0.1395 took: 1.21s  Val. loss: 0.1418\n",
      "Epoch 33, 100% \t Train loss: 0.1390 took: 1.21s  Val. loss: 0.1405\n",
      "Epoch 34, 100% \t Train loss: 0.1391 took: 1.21s  Val. loss: 0.1494\n",
      "Epoch 35, 100% \t Train loss: 0.1371 took: 1.21s  Val. loss: 0.1425\n",
      "Epoch 36, 100% \t Train loss: 0.1371 took: 1.21s  Val. loss: 0.1454\n",
      "Epoch 37, 100% \t Train loss: 0.1362 took: 1.21s  Val. loss: 0.1402\n",
      "Epoch 38, 100% \t Train loss: 0.1359 took: 1.21s  Val. loss: 0.1406\n",
      "Epoch 39, 100% \t Train loss: 0.1347 took: 1.21s  Val. loss: 0.1388\n",
      "Epoch 40, 100% \t Train loss: 0.1336 took: 1.33s  Val. loss: 0.1460\n",
      "Epoch 41, 100% \t Train loss: 0.1361 took: 2.04s  Val. loss: 0.1371\n",
      "Epoch 42, 100% \t Train loss: 0.1344 took: 2.06s  Val. loss: 0.1396\n",
      "Epoch 43, 100% \t Train loss: 0.1329 took: 2.06s  Val. loss: 0.1361\n",
      "Epoch 44, 100% \t Train loss: 0.1331 took: 2.07s  Val. loss: 0.1394\n",
      "Epoch 45, 100% \t Train loss: 0.1327 took: 2.04s  Val. loss: 0.1378\n",
      "Epoch 46, 100% \t Train loss: 0.1334 took: 2.04s  Val. loss: 0.1423\n",
      "Epoch 47, 100% \t Train loss: 0.1314 took: 2.06s  Val. loss: 0.1366\n",
      "Epoch 48, 100% \t Train loss: 0.1305 took: 1.21s  Val. loss: 0.1353\n",
      "Epoch 49, 100% \t Train loss: 0.1298 took: 1.21s  Val. loss: 0.1446\n",
      "Epoch 50, 100% \t Train loss: 0.1304 took: 1.20s  Val. loss: 0.1367\n",
      "Training finished, took 92.13s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 1.19s  Val. loss: 0.2593\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 1.19s  Val. loss: 0.2596\n",
      "Epoch 3, 100% \t Train loss: 0.2579 took: 1.19s  Val. loss: 0.2581\n",
      "Epoch 4, 100% \t Train loss: 0.2551 took: 1.20s  Val. loss: 0.2513\n",
      "Epoch 5, 100% \t Train loss: 0.2406 took: 1.20s  Val. loss: 0.2289\n",
      "Epoch 6, 100% \t Train loss: 0.2198 took: 1.18s  Val. loss: 0.2088\n",
      "Epoch 7, 100% \t Train loss: 0.2056 took: 1.18s  Val. loss: 0.1965\n",
      "Epoch 8, 100% \t Train loss: 0.2011 took: 1.18s  Val. loss: 0.1946\n",
      "Epoch 9, 100% \t Train loss: 0.1996 took: 1.18s  Val. loss: 0.1928\n",
      "Epoch 10, 100% \t Train loss: 0.1984 took: 1.19s  Val. loss: 0.1913\n",
      "Epoch 11, 100% \t Train loss: 0.1962 took: 1.18s  Val. loss: 0.1941\n",
      "Epoch 12, 100% \t Train loss: 0.1962 took: 1.19s  Val. loss: 0.1946\n",
      "Epoch 13, 100% \t Train loss: 0.1943 took: 1.19s  Val. loss: 0.1899\n",
      "Epoch 14, 100% \t Train loss: 0.1929 took: 1.18s  Val. loss: 0.1908\n",
      "Epoch 15, 100% \t Train loss: 0.1923 took: 1.18s  Val. loss: 0.1879\n",
      "Epoch 16, 100% \t Train loss: 0.1923 took: 1.19s  Val. loss: 0.1877\n",
      "Epoch 17, 100% \t Train loss: 0.1922 took: 1.18s  Val. loss: 0.1942\n",
      "Epoch 18, 100% \t Train loss: 0.1923 took: 1.18s  Val. loss: 0.1942\n",
      "Epoch 19, 100% \t Train loss: 0.1911 took: 1.18s  Val. loss: 0.1898\n",
      "Epoch 20, 100% \t Train loss: 0.1901 took: 1.19s  Val. loss: 0.1925\n",
      "Epoch 21, 100% \t Train loss: 0.1902 took: 1.19s  Val. loss: 0.1876\n",
      "Epoch 22, 100% \t Train loss: 0.1896 took: 1.19s  Val. loss: 0.1893\n",
      "Epoch 23, 100% \t Train loss: 0.1890 took: 1.19s  Val. loss: 0.1865\n",
      "Epoch 24, 100% \t Train loss: 0.1886 took: 1.19s  Val. loss: 0.1938\n",
      "Epoch 25, 100% \t Train loss: 0.1892 took: 1.19s  Val. loss: 0.1868\n",
      "Epoch 26, 100% \t Train loss: 0.1874 took: 1.19s  Val. loss: 0.1866\n",
      "Epoch 27, 100% \t Train loss: 0.1873 took: 1.20s  Val. loss: 0.1857\n",
      "Epoch 28, 100% \t Train loss: 0.1870 took: 1.21s  Val. loss: 0.1862\n",
      "Epoch 29, 100% \t Train loss: 0.1857 took: 1.50s  Val. loss: 0.1863\n",
      "Epoch 30, 100% \t Train loss: 0.1851 took: 2.05s  Val. loss: 0.1862\n",
      "Epoch 31, 100% \t Train loss: 0.1844 took: 2.07s  Val. loss: 0.1862\n",
      "Epoch 32, 100% \t Train loss: 0.1848 took: 2.09s  Val. loss: 0.1872\n",
      "Epoch 33, 100% \t Train loss: 0.1852 took: 2.11s  Val. loss: 0.1877\n",
      "Epoch 34, 100% \t Train loss: 0.1839 took: 2.10s  Val. loss: 0.1864\n",
      "Epoch 35, 100% \t Train loss: 0.1833 took: 2.11s  Val. loss: 0.1845\n",
      "Epoch 36, 100% \t Train loss: 0.1833 took: 2.11s  Val. loss: 0.1839\n",
      "Epoch 37, 100% \t Train loss: 0.1814 took: 2.10s  Val. loss: 0.1848\n",
      "Epoch 38, 100% \t Train loss: 0.1816 took: 2.11s  Val. loss: 0.1854\n",
      "Epoch 39, 100% \t Train loss: 0.1820 took: 2.12s  Val. loss: 0.1872\n",
      "Epoch 40, 100% \t Train loss: 0.1819 took: 2.14s  Val. loss: 0.1841\n",
      "Epoch 41, 100% \t Train loss: 0.1802 took: 2.14s  Val. loss: 0.1842\n",
      "Epoch 42, 100% \t Train loss: 0.1788 took: 2.14s  Val. loss: 0.1810\n",
      "Epoch 43, 100% \t Train loss: 0.1776 took: 2.12s  Val. loss: 0.1819\n",
      "Epoch 44, 100% \t Train loss: 0.1780 took: 1.34s  Val. loss: 0.1799\n",
      "Epoch 45, 100% \t Train loss: 0.1781 took: 1.25s  Val. loss: 0.1810\n",
      "Epoch 46, 100% \t Train loss: 0.1774 took: 1.26s  Val. loss: 0.1811\n",
      "Epoch 47, 100% \t Train loss: 0.1763 took: 1.27s  Val. loss: 0.1847\n",
      "Epoch 48, 100% \t Train loss: 0.1757 took: 1.28s  Val. loss: 0.1774\n",
      "Epoch 49, 100% \t Train loss: 0.1748 took: 1.30s  Val. loss: 0.1764\n",
      "Epoch 50, 100% \t Train loss: 0.1759 took: 1.31s  Val. loss: 0.1869\n",
      "Training finished, took 82.06s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.27\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.40\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.850842\n",
      "lambda: 0.0010 - V: 0.835417\n",
      "lambda: 0.0005 - V: 0.805924\n",
      "Average V: 0.830728\n",
      "Time elapsed: 302.00 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.40\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.43\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2606 took: 1.07s  Val. loss: 0.2546\n",
      "Epoch 2, 100% \t Train loss: 0.2597 took: 1.06s  Val. loss: 0.2554\n",
      "Epoch 3, 100% \t Train loss: 0.2598 took: 1.06s  Val. loss: 0.2542\n",
      "Epoch 4, 100% \t Train loss: 0.2597 took: 1.06s  Val. loss: 0.2549\n",
      "Epoch 5, 100% \t Train loss: 0.2594 took: 1.07s  Val. loss: 0.2548\n",
      "Epoch 6, 100% \t Train loss: 0.2595 took: 1.06s  Val. loss: 0.2554\n",
      "Epoch 7, 100% \t Train loss: 0.2593 took: 1.06s  Val. loss: 0.2552\n",
      "Epoch 8, 100% \t Train loss: 0.2593 took: 1.06s  Val. loss: 0.2547\n",
      "Epoch 9, 100% \t Train loss: 0.2594 took: 1.07s  Val. loss: 0.2549\n",
      "Epoch 10, 100% \t Train loss: 0.2595 took: 1.07s  Val. loss: 0.2550\n",
      "Epoch 11, 100% \t Train loss: 0.2593 took: 1.06s  Val. loss: 0.2548\n",
      "Epoch 12, 100% \t Train loss: 0.2593 took: 1.06s  Val. loss: 0.2568\n",
      "Epoch 13, 100% \t Train loss: 0.2594 took: 1.43s  Val. loss: 0.2551\n",
      "Epoch 14, 100% \t Train loss: 0.2593 took: 1.85s  Val. loss: 0.2546\n",
      "Epoch 15, 100% \t Train loss: 0.2593 took: 1.83s  Val. loss: 0.2552\n",
      "Epoch 16, 100% \t Train loss: 0.2593 took: 1.84s  Val. loss: 0.2556\n",
      "Epoch 17, 100% \t Train loss: 0.2594 took: 1.85s  Val. loss: 0.2546\n",
      "Epoch 18, 100% \t Train loss: 0.2593 took: 1.83s  Val. loss: 0.2549\n",
      "Epoch 19, 100% \t Train loss: 0.2593 took: 1.82s  Val. loss: 0.2552\n",
      "Epoch 20, 100% \t Train loss: 0.2593 took: 1.83s  Val. loss: 0.2549\n",
      "Epoch 21, 100% \t Train loss: 0.2591 took: 1.83s  Val. loss: 0.2552\n",
      "Epoch 22, 100% \t Train loss: 0.2590 took: 1.83s  Val. loss: 0.2550\n",
      "Epoch 23, 100% \t Train loss: 0.2252 took: 1.85s  Val. loss: 0.1859\n",
      "Epoch 24, 100% \t Train loss: 0.1826 took: 1.83s  Val. loss: 0.1731\n",
      "Epoch 25, 100% \t Train loss: 0.1760 took: 1.83s  Val. loss: 0.1699\n",
      "Epoch 26, 100% \t Train loss: 0.1746 took: 1.83s  Val. loss: 0.1695\n",
      "Epoch 27, 100% \t Train loss: 0.1718 took: 1.83s  Val. loss: 0.1654\n",
      "Epoch 28, 100% \t Train loss: 0.1710 took: 1.84s  Val. loss: 0.1683\n",
      "Epoch 29, 100% \t Train loss: 0.1689 took: 1.86s  Val. loss: 0.1646\n",
      "Epoch 30, 100% \t Train loss: 0.1672 took: 1.88s  Val. loss: 0.1635\n",
      "Epoch 31, 100% \t Train loss: 0.1646 took: 1.87s  Val. loss: 0.1619\n",
      "Epoch 32, 100% \t Train loss: 0.1619 took: 1.94s  Val. loss: 0.1580\n",
      "Epoch 33, 100% \t Train loss: 0.1602 took: 2.09s  Val. loss: 0.1571\n",
      "Epoch 34, 100% \t Train loss: 0.1592 took: 2.12s  Val. loss: 0.1595\n",
      "Epoch 35, 100% \t Train loss: 0.1576 took: 2.11s  Val. loss: 0.1594\n",
      "Epoch 36, 100% \t Train loss: 0.1563 took: 2.10s  Val. loss: 0.1580\n",
      "Epoch 37, 100% \t Train loss: 0.1564 took: 2.10s  Val. loss: 0.1567\n",
      "Epoch 38, 100% \t Train loss: 0.1564 took: 2.10s  Val. loss: 0.1589\n",
      "Epoch 39, 100% \t Train loss: 0.1559 took: 2.09s  Val. loss: 0.1577\n",
      "Epoch 40, 100% \t Train loss: 0.1548 took: 2.10s  Val. loss: 0.1597\n",
      "Epoch 41, 100% \t Train loss: 0.1543 took: 2.11s  Val. loss: 0.1564\n",
      "Epoch 42, 100% \t Train loss: 0.1551 took: 2.13s  Val. loss: 0.1567\n",
      "Epoch 43, 100% \t Train loss: 0.1541 took: 2.12s  Val. loss: 0.1609\n",
      "Epoch 44, 100% \t Train loss: 0.1537 took: 2.15s  Val. loss: 0.1596\n",
      "Epoch 45, 100% \t Train loss: 0.1541 took: 1.98s  Val. loss: 0.1593\n",
      "Epoch 46, 100% \t Train loss: 0.1533 took: 1.97s  Val. loss: 0.1613\n",
      "Epoch 47, 100% \t Train loss: 0.1532 took: 1.98s  Val. loss: 0.1580\n",
      "Epoch 48, 100% \t Train loss: 0.1524 took: 1.97s  Val. loss: 0.1574\n",
      "Epoch 49, 100% \t Train loss: 0.1526 took: 1.98s  Val. loss: 0.1639\n",
      "Epoch 50, 100% \t Train loss: 0.1526 took: 1.98s  Val. loss: 0.1596\n",
      "Training finished, took 98.28s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2593 took: 1.87s  Val. loss: 0.2575\n",
      "Epoch 2, 100% \t Train loss: 0.2589 took: 1.85s  Val. loss: 0.2583\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 1.84s  Val. loss: 0.2575\n",
      "Epoch 4, 100% \t Train loss: 0.2588 took: 1.06s  Val. loss: 0.2571\n",
      "Epoch 5, 100% \t Train loss: 0.2587 took: 1.05s  Val. loss: 0.2580\n",
      "Epoch 6, 100% \t Train loss: 0.2569 took: 1.06s  Val. loss: 0.2512\n",
      "Epoch 7, 100% \t Train loss: 0.2281 took: 1.06s  Val. loss: 0.1984\n",
      "Epoch 8, 100% \t Train loss: 0.1911 took: 1.06s  Val. loss: 0.1862\n",
      "Epoch 9, 100% \t Train loss: 0.1843 took: 1.06s  Val. loss: 0.1846\n",
      "Epoch 10, 100% \t Train loss: 0.1799 took: 1.06s  Val. loss: 0.1807\n",
      "Epoch 11, 100% \t Train loss: 0.1777 took: 1.06s  Val. loss: 0.1832\n",
      "Epoch 12, 100% \t Train loss: 0.1765 took: 1.06s  Val. loss: 0.1803\n",
      "Epoch 13, 100% \t Train loss: 0.1761 took: 1.06s  Val. loss: 0.1791\n",
      "Epoch 14, 100% \t Train loss: 0.1758 took: 1.06s  Val. loss: 0.1867\n",
      "Epoch 15, 100% \t Train loss: 0.1732 took: 1.06s  Val. loss: 0.1823\n",
      "Epoch 16, 100% \t Train loss: 0.1744 took: 1.05s  Val. loss: 0.1792\n",
      "Epoch 17, 100% \t Train loss: 0.1721 took: 1.06s  Val. loss: 0.1793\n",
      "Epoch 18, 100% \t Train loss: 0.1707 took: 1.06s  Val. loss: 0.1781\n",
      "Epoch 19, 100% \t Train loss: 0.1705 took: 1.06s  Val. loss: 0.1776\n",
      "Epoch 20, 100% \t Train loss: 0.1691 took: 1.06s  Val. loss: 0.1756\n",
      "Epoch 21, 100% \t Train loss: 0.1685 took: 1.06s  Val. loss: 0.1810\n",
      "Epoch 22, 100% \t Train loss: 0.1681 took: 1.06s  Val. loss: 0.1864\n",
      "Epoch 23, 100% \t Train loss: 0.1687 took: 1.06s  Val. loss: 0.1761\n",
      "Epoch 24, 100% \t Train loss: 0.1666 took: 1.07s  Val. loss: 0.1737\n",
      "Epoch 25, 100% \t Train loss: 0.1662 took: 1.07s  Val. loss: 0.1729\n",
      "Epoch 26, 100% \t Train loss: 0.1669 took: 1.06s  Val. loss: 0.1782\n",
      "Epoch 27, 100% \t Train loss: 0.1656 took: 1.06s  Val. loss: 0.1735\n",
      "Epoch 28, 100% \t Train loss: 0.1651 took: 1.36s  Val. loss: 0.1738\n",
      "Epoch 29, 100% \t Train loss: 0.1644 took: 1.88s  Val. loss: 0.1741\n",
      "Epoch 30, 100% \t Train loss: 0.1638 took: 1.86s  Val. loss: 0.1715\n",
      "Epoch 31, 100% \t Train loss: 0.1663 took: 1.87s  Val. loss: 0.1753\n",
      "Epoch 32, 100% \t Train loss: 0.1645 took: 1.89s  Val. loss: 0.1718\n",
      "Epoch 33, 100% \t Train loss: 0.1635 took: 1.89s  Val. loss: 0.1707\n",
      "Epoch 34, 100% \t Train loss: 0.1628 took: 1.89s  Val. loss: 0.1748\n",
      "Epoch 35, 100% \t Train loss: 0.1633 took: 1.89s  Val. loss: 0.1688\n",
      "Epoch 36, 100% \t Train loss: 0.1635 took: 1.89s  Val. loss: 0.1715\n",
      "Epoch 37, 100% \t Train loss: 0.1617 took: 1.90s  Val. loss: 0.1709\n",
      "Epoch 38, 100% \t Train loss: 0.1629 took: 1.93s  Val. loss: 0.1738\n",
      "Epoch 39, 100% \t Train loss: 0.1618 took: 1.95s  Val. loss: 0.1710\n",
      "Epoch 40, 100% \t Train loss: 0.1613 took: 1.94s  Val. loss: 0.1772\n",
      "Epoch 41, 100% \t Train loss: 0.1607 took: 1.94s  Val. loss: 0.1769\n",
      "Epoch 42, 100% \t Train loss: 0.1619 took: 1.93s  Val. loss: 0.1708\n",
      "Epoch 43, 100% \t Train loss: 0.1607 took: 1.94s  Val. loss: 0.1695\n",
      "Epoch 44, 100% \t Train loss: 0.1596 took: 1.96s  Val. loss: 0.1702\n",
      "Epoch 45, 100% \t Train loss: 0.1589 took: 1.99s  Val. loss: 0.1771\n",
      "Epoch 46, 100% \t Train loss: 0.1591 took: 1.99s  Val. loss: 0.1686\n",
      "Epoch 47, 100% \t Train loss: 0.1599 took: 2.00s  Val. loss: 0.1680\n",
      "Epoch 48, 100% \t Train loss: 0.1581 took: 1.99s  Val. loss: 0.1730\n",
      "Epoch 49, 100% \t Train loss: 0.1588 took: 1.98s  Val. loss: 0.1703\n",
      "Epoch 50, 100% \t Train loss: 0.1599 took: 1.99s  Val. loss: 0.1718\n",
      "Training finished, took 84.71s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2535 took: 1.84s  Val. loss: 0.2597\n",
      "Epoch 2, 100% \t Train loss: 0.2528 took: 1.84s  Val. loss: 0.2599\n",
      "Epoch 3, 100% \t Train loss: 0.2528 took: 1.83s  Val. loss: 0.2588\n",
      "Epoch 4, 100% \t Train loss: 0.2529 took: 1.83s  Val. loss: 0.2593\n",
      "Epoch 5, 100% \t Train loss: 0.2528 took: 1.68s  Val. loss: 0.2599\n",
      "Epoch 6, 100% \t Train loss: 0.2528 took: 1.06s  Val. loss: 0.2606\n",
      "Epoch 7, 100% \t Train loss: 0.2527 took: 1.05s  Val. loss: 0.2590\n",
      "Epoch 8, 100% \t Train loss: 0.2528 took: 1.05s  Val. loss: 0.2580\n",
      "Epoch 9, 100% \t Train loss: 0.2525 took: 1.05s  Val. loss: 0.2589\n",
      "Epoch 10, 100% \t Train loss: 0.2523 took: 1.05s  Val. loss: 0.2588\n",
      "Epoch 11, 100% \t Train loss: 0.2515 took: 1.05s  Val. loss: 0.2566\n",
      "Epoch 12, 100% \t Train loss: 0.2469 took: 1.05s  Val. loss: 0.2475\n",
      "Epoch 13, 100% \t Train loss: 0.2220 took: 1.05s  Val. loss: 0.2200\n",
      "Epoch 14, 100% \t Train loss: 0.2018 took: 1.06s  Val. loss: 0.2034\n",
      "Epoch 15, 100% \t Train loss: 0.1950 took: 1.06s  Val. loss: 0.1938\n",
      "Epoch 16, 100% \t Train loss: 0.1867 took: 1.06s  Val. loss: 0.2019\n",
      "Epoch 17, 100% \t Train loss: 0.1860 took: 1.07s  Val. loss: 0.1884\n",
      "Epoch 18, 100% \t Train loss: 0.1811 took: 1.06s  Val. loss: 0.1873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1772 took: 1.07s  Val. loss: 0.1899\n",
      "Epoch 20, 100% \t Train loss: 0.1784 took: 1.07s  Val. loss: 0.2076\n",
      "Epoch 21, 100% \t Train loss: 0.1766 took: 1.07s  Val. loss: 0.1819\n",
      "Epoch 22, 100% \t Train loss: 0.1718 took: 1.07s  Val. loss: 0.1827\n",
      "Epoch 23, 100% \t Train loss: 0.1720 took: 1.07s  Val. loss: 0.1864\n",
      "Epoch 24, 100% \t Train loss: 0.1680 took: 1.07s  Val. loss: 0.1820\n",
      "Epoch 25, 100% \t Train loss: 0.1689 took: 1.07s  Val. loss: 0.1865\n",
      "Epoch 26, 100% \t Train loss: 0.1677 took: 1.07s  Val. loss: 0.1789\n",
      "Epoch 27, 100% \t Train loss: 0.1683 took: 1.07s  Val. loss: 0.1823\n",
      "Epoch 28, 100% \t Train loss: 0.1673 took: 1.08s  Val. loss: 0.1804\n",
      "Epoch 29, 100% \t Train loss: 0.1674 took: 1.10s  Val. loss: 0.1789\n",
      "Epoch 30, 100% \t Train loss: 0.1645 took: 1.09s  Val. loss: 0.1808\n",
      "Epoch 31, 100% \t Train loss: 0.1641 took: 1.09s  Val. loss: 0.1826\n",
      "Epoch 32, 100% \t Train loss: 0.1638 took: 1.10s  Val. loss: 0.1819\n",
      "Epoch 33, 100% \t Train loss: 0.1616 took: 1.10s  Val. loss: 0.1795\n",
      "Epoch 34, 100% \t Train loss: 0.1631 took: 1.10s  Val. loss: 0.1786\n",
      "Epoch 35, 100% \t Train loss: 0.1637 took: 1.10s  Val. loss: 0.1780\n",
      "Epoch 36, 100% \t Train loss: 0.1609 took: 1.10s  Val. loss: 0.1800\n",
      "Epoch 37, 100% \t Train loss: 0.1608 took: 1.10s  Val. loss: 0.1814\n",
      "Epoch 38, 100% \t Train loss: 0.1632 took: 1.10s  Val. loss: 0.1783\n",
      "Epoch 39, 100% \t Train loss: 0.1612 took: 1.11s  Val. loss: 0.1792\n",
      "Epoch 40, 100% \t Train loss: 0.1594 took: 1.12s  Val. loss: 0.1767\n",
      "Epoch 41, 100% \t Train loss: 0.1593 took: 1.12s  Val. loss: 0.1794\n",
      "Epoch 42, 100% \t Train loss: 0.1594 took: 1.13s  Val. loss: 0.1755\n",
      "Epoch 43, 100% \t Train loss: 0.1577 took: 1.13s  Val. loss: 0.1769\n",
      "Epoch 44, 100% \t Train loss: 0.1577 took: 1.14s  Val. loss: 0.1839\n",
      "Epoch 45, 100% \t Train loss: 0.1579 took: 1.13s  Val. loss: 0.1729\n",
      "Epoch 46, 100% \t Train loss: 0.1577 took: 1.14s  Val. loss: 0.1759\n",
      "Epoch 47, 100% \t Train loss: 0.1564 took: 1.14s  Val. loss: 0.1720\n",
      "Epoch 48, 100% \t Train loss: 0.1553 took: 1.16s  Val. loss: 0.1738\n",
      "Epoch 49, 100% \t Train loss: 0.1535 took: 1.16s  Val. loss: 0.1687\n",
      "Epoch 50, 100% \t Train loss: 0.1534 took: 1.17s  Val. loss: 0.1692\n",
      "Training finished, took 65.39s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.40\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.43\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.796975\n",
      "lambda: 0.0010 - V: 0.814121\n",
      "lambda: 0.0005 - V: 0.798909\n",
      "Average V: 0.803335\n",
      "Time elapsed: 251.88 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.40\n",
      "\thidden_channels :  32  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2621 took: 2.74s  Val. loss: 0.2596\n",
      "Epoch 2, 100% \t Train loss: 0.2587 took: 2.75s  Val. loss: 0.2586\n",
      "Epoch 3, 100% \t Train loss: 0.2585 took: 2.79s  Val. loss: 0.2568\n",
      "Epoch 4, 100% \t Train loss: 0.2583 took: 2.77s  Val. loss: 0.2561\n",
      "Epoch 5, 100% \t Train loss: 0.2585 took: 2.79s  Val. loss: 0.2572\n",
      "Epoch 6, 100% \t Train loss: 0.2584 took: 2.74s  Val. loss: 0.2577\n",
      "Epoch 7, 100% \t Train loss: 0.2583 took: 2.73s  Val. loss: 0.2578\n",
      "Epoch 8, 100% \t Train loss: 0.2583 took: 2.80s  Val. loss: 0.2563\n",
      "Epoch 9, 100% \t Train loss: 0.2584 took: 2.75s  Val. loss: 0.2573\n",
      "Epoch 10, 100% \t Train loss: 0.2583 took: 2.71s  Val. loss: 0.2566\n",
      "Epoch 11, 100% \t Train loss: 0.2584 took: 2.74s  Val. loss: 0.2581\n",
      "Epoch 12, 100% \t Train loss: 0.2584 took: 1.70s  Val. loss: 0.2570\n",
      "Epoch 13, 100% \t Train loss: 0.2583 took: 1.69s  Val. loss: 0.2580\n",
      "Epoch 14, 100% \t Train loss: 0.2583 took: 1.69s  Val. loss: 0.2581\n",
      "Epoch 15, 100% \t Train loss: 0.2583 took: 1.69s  Val. loss: 0.2570\n",
      "Epoch 16, 100% \t Train loss: 0.2582 took: 1.69s  Val. loss: 0.2570\n",
      "Epoch 17, 100% \t Train loss: 0.2583 took: 1.70s  Val. loss: 0.2565\n",
      "Epoch 18, 100% \t Train loss: 0.2583 took: 1.70s  Val. loss: 0.2573\n",
      "Epoch 19, 100% \t Train loss: 0.2583 took: 1.69s  Val. loss: 0.2571\n",
      "Epoch 20, 100% \t Train loss: 0.2582 took: 1.70s  Val. loss: 0.2570\n",
      "Epoch 21, 100% \t Train loss: 0.2584 took: 1.71s  Val. loss: 0.2565\n",
      "Epoch 22, 100% \t Train loss: 0.2583 took: 1.71s  Val. loss: 0.2561\n",
      "Epoch 23, 100% \t Train loss: 0.2584 took: 1.71s  Val. loss: 0.2570\n",
      "Epoch 24, 100% \t Train loss: 0.2583 took: 1.75s  Val. loss: 0.2574\n",
      "Epoch 25, 100% \t Train loss: 0.2585 took: 1.72s  Val. loss: 0.2570\n",
      "Epoch 26, 100% \t Train loss: 0.2584 took: 1.75s  Val. loss: 0.2573\n",
      "Epoch 27, 100% \t Train loss: 0.2583 took: 1.80s  Val. loss: 0.2563\n",
      "Epoch 28, 100% \t Train loss: 0.2583 took: 1.88s  Val. loss: 0.2568\n",
      "Epoch 29, 100% \t Train loss: 0.2582 took: 1.88s  Val. loss: 0.2578\n",
      "Epoch 30, 100% \t Train loss: 0.2583 took: 2.01s  Val. loss: 0.2562\n",
      "Epoch 31, 100% \t Train loss: 0.2582 took: 3.27s  Val. loss: 0.2569\n",
      "Epoch 32, 100% \t Train loss: 0.2582 took: 3.82s  Val. loss: 0.2580\n",
      "Epoch 33, 100% \t Train loss: 0.2582 took: 4.37s  Val. loss: 0.2577\n",
      "Epoch 34, 100% \t Train loss: 0.2583 took: 4.32s  Val. loss: 0.2570\n",
      "Epoch 35, 100% \t Train loss: 0.2583 took: 4.53s  Val. loss: 0.2576\n",
      "Epoch 36, 100% \t Train loss: 0.2582 took: 4.80s  Val. loss: 0.2583\n",
      "Epoch 37, 100% \t Train loss: 0.2583 took: 4.55s  Val. loss: 0.2580\n",
      "Epoch 38, 100% \t Train loss: 0.2582 took: 4.80s  Val. loss: 0.2580\n",
      "Epoch 39, 100% \t Train loss: 0.2582 took: 3.52s  Val. loss: 0.2571\n",
      "Epoch 40, 100% \t Train loss: 0.2582 took: 3.60s  Val. loss: 0.2571\n",
      "Epoch 41, 100% \t Train loss: 0.2582 took: 3.59s  Val. loss: 0.2565\n",
      "Epoch 42, 100% \t Train loss: 0.2582 took: 4.98s  Val. loss: 0.2579\n",
      "Epoch 43, 100% \t Train loss: 0.2582 took: 4.78s  Val. loss: 0.2570\n",
      "Epoch 44, 100% \t Train loss: 0.2582 took: 5.08s  Val. loss: 0.2572\n",
      "Epoch 45, 100% \t Train loss: 0.2582 took: 4.74s  Val. loss: 0.2571\n",
      "Epoch 46, 100% \t Train loss: 0.2582 took: 4.40s  Val. loss: 0.2566\n",
      "Epoch 47, 100% \t Train loss: 0.2582 took: 4.74s  Val. loss: 0.2578\n",
      "Epoch 48, 100% \t Train loss: 0.2582 took: 4.67s  Val. loss: 0.2567\n",
      "Epoch 49, 100% \t Train loss: 0.2582 took: 4.70s  Val. loss: 0.2567\n",
      "Epoch 50, 100% \t Train loss: 0.2582 took: 4.79s  Val. loss: 0.2577\n",
      "Training finished, took 167.01s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2576 took: 2.81s  Val. loss: 0.2655\n",
      "Epoch 2, 100% \t Train loss: 0.2572 took: 2.79s  Val. loss: 0.2653\n",
      "Epoch 3, 100% \t Train loss: 0.2572 took: 2.76s  Val. loss: 0.2637\n",
      "Epoch 4, 100% \t Train loss: 0.2570 took: 2.77s  Val. loss: 0.2654\n",
      "Epoch 5, 100% \t Train loss: 0.2571 took: 2.76s  Val. loss: 0.2639\n",
      "Epoch 6, 100% \t Train loss: 0.2570 took: 2.75s  Val. loss: 0.2654\n",
      "Epoch 7, 100% \t Train loss: 0.2569 took: 2.75s  Val. loss: 0.2636\n",
      "Epoch 8, 100% \t Train loss: 0.2569 took: 1.69s  Val. loss: 0.2637\n",
      "Epoch 9, 100% \t Train loss: 0.2569 took: 1.69s  Val. loss: 0.2660\n",
      "Epoch 10, 100% \t Train loss: 0.2571 took: 1.70s  Val. loss: 0.2644\n",
      "Epoch 11, 100% \t Train loss: 0.2570 took: 1.69s  Val. loss: 0.2643\n",
      "Epoch 12, 100% \t Train loss: 0.2570 took: 1.70s  Val. loss: 0.2644\n",
      "Epoch 13, 100% \t Train loss: 0.2569 took: 1.70s  Val. loss: 0.2645\n",
      "Epoch 14, 100% \t Train loss: 0.2570 took: 1.70s  Val. loss: 0.2656\n",
      "Epoch 15, 100% \t Train loss: 0.2570 took: 1.69s  Val. loss: 0.2638\n",
      "Epoch 16, 100% \t Train loss: 0.2569 took: 1.70s  Val. loss: 0.2643\n",
      "Epoch 17, 100% \t Train loss: 0.2570 took: 1.70s  Val. loss: 0.2638\n",
      "Epoch 18, 100% \t Train loss: 0.2569 took: 1.69s  Val. loss: 0.2643\n",
      "Epoch 19, 100% \t Train loss: 0.2570 took: 1.70s  Val. loss: 0.2638\n",
      "Epoch 20, 100% \t Train loss: 0.2569 took: 1.71s  Val. loss: 0.2634\n",
      "Epoch 21, 100% \t Train loss: 0.2571 took: 1.70s  Val. loss: 0.2638\n",
      "Epoch 22, 100% \t Train loss: 0.2569 took: 1.70s  Val. loss: 0.2653\n",
      "Epoch 23, 100% \t Train loss: 0.2569 took: 1.71s  Val. loss: 0.2646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.2569 took: 1.69s  Val. loss: 0.2637\n",
      "Epoch 25, 100% \t Train loss: 0.2569 took: 1.71s  Val. loss: 0.2648\n",
      "Epoch 26, 100% \t Train loss: 0.2569 took: 1.72s  Val. loss: 0.2646\n",
      "Epoch 27, 100% \t Train loss: 0.2569 took: 1.76s  Val. loss: 0.2641\n",
      "Epoch 28, 100% \t Train loss: 0.2569 took: 1.81s  Val. loss: 0.2647\n",
      "Epoch 29, 100% \t Train loss: 0.2569 took: 1.85s  Val. loss: 0.2654\n",
      "Epoch 30, 100% \t Train loss: 0.2569 took: 2.93s  Val. loss: 0.2645\n",
      "Epoch 31, 100% \t Train loss: 0.2569 took: 3.00s  Val. loss: 0.2652\n",
      "Epoch 32, 100% \t Train loss: 0.2569 took: 3.11s  Val. loss: 0.2649\n",
      "Epoch 33, 100% \t Train loss: 0.2569 took: 3.12s  Val. loss: 0.2650\n",
      "Epoch 34, 100% \t Train loss: 0.2569 took: 3.14s  Val. loss: 0.2645\n",
      "Epoch 35, 100% \t Train loss: 0.2569 took: 3.21s  Val. loss: 0.2656\n",
      "Epoch 36, 100% \t Train loss: 0.2569 took: 3.26s  Val. loss: 0.2659\n",
      "Epoch 37, 100% \t Train loss: 0.2569 took: 3.24s  Val. loss: 0.2650\n",
      "Epoch 38, 100% \t Train loss: 0.2569 took: 3.22s  Val. loss: 0.2643\n",
      "Epoch 39, 100% \t Train loss: 0.2568 took: 3.27s  Val. loss: 0.2641\n",
      "Epoch 40, 100% \t Train loss: 0.2569 took: 3.37s  Val. loss: 0.2639\n",
      "Epoch 41, 100% \t Train loss: 0.2569 took: 3.42s  Val. loss: 0.2651\n",
      "Epoch 42, 100% \t Train loss: 0.2569 took: 3.51s  Val. loss: 0.2647\n",
      "Epoch 43, 100% \t Train loss: 0.2569 took: 3.50s  Val. loss: 0.2649\n",
      "Epoch 44, 100% \t Train loss: 0.2569 took: 3.39s  Val. loss: 0.2647\n",
      "Epoch 45, 100% \t Train loss: 0.2569 took: 3.30s  Val. loss: 0.2642\n",
      "Epoch 46, 100% \t Train loss: 0.2569 took: 3.38s  Val. loss: 0.2639\n",
      "Epoch 47, 100% \t Train loss: 0.2569 took: 3.42s  Val. loss: 0.2651\n",
      "Epoch 48, 100% \t Train loss: 0.2569 took: 3.62s  Val. loss: 0.2643\n",
      "Epoch 49, 100% \t Train loss: 0.2569 took: 3.82s  Val. loss: 0.2649\n",
      "Epoch 50, 100% \t Train loss: 0.2569 took: 2.98s  Val. loss: 0.2645\n",
      "Training finished, took 138.17s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2570 took: 2.72s  Val. loss: 0.2609\n",
      "Epoch 2, 100% \t Train loss: 0.2568 took: 2.76s  Val. loss: 0.2604\n",
      "Epoch 3, 100% \t Train loss: 0.2568 took: 2.79s  Val. loss: 0.2602\n",
      "Epoch 4, 100% \t Train loss: 0.2567 took: 2.80s  Val. loss: 0.2626\n",
      "Epoch 5, 100% \t Train loss: 0.2567 took: 2.80s  Val. loss: 0.2603\n",
      "Epoch 6, 100% \t Train loss: 0.2568 took: 2.80s  Val. loss: 0.2594\n",
      "Epoch 7, 100% \t Train loss: 0.2566 took: 2.79s  Val. loss: 0.2605\n",
      "Epoch 8, 100% \t Train loss: 0.2568 took: 2.78s  Val. loss: 0.2609\n",
      "Epoch 9, 100% \t Train loss: 0.2565 took: 2.79s  Val. loss: 0.2598\n",
      "Epoch 10, 100% \t Train loss: 0.2567 took: 2.75s  Val. loss: 0.2604\n",
      "Epoch 11, 100% \t Train loss: 0.2563 took: 2.78s  Val. loss: 0.2595\n",
      "Epoch 12, 100% \t Train loss: 0.2530 took: 2.78s  Val. loss: 0.2491\n",
      "Epoch 13, 100% \t Train loss: 0.2235 took: 2.80s  Val. loss: 0.2143\n",
      "Epoch 14, 100% \t Train loss: 0.2007 took: 2.79s  Val. loss: 0.2072\n",
      "Epoch 15, 100% \t Train loss: 0.1960 took: 1.83s  Val. loss: 0.2056\n",
      "Epoch 16, 100% \t Train loss: 0.1936 took: 1.75s  Val. loss: 0.2031\n",
      "Epoch 17, 100% \t Train loss: 0.1933 took: 1.74s  Val. loss: 0.2087\n",
      "Epoch 18, 100% \t Train loss: 0.1932 took: 2.37s  Val. loss: 0.2052\n",
      "Epoch 19, 100% \t Train loss: 0.1905 took: 2.79s  Val. loss: 0.2019\n",
      "Epoch 20, 100% \t Train loss: 0.1893 took: 2.77s  Val. loss: 0.2008\n",
      "Epoch 21, 100% \t Train loss: 0.1883 took: 2.77s  Val. loss: 0.2001\n",
      "Epoch 22, 100% \t Train loss: 0.1881 took: 2.81s  Val. loss: 0.2028\n",
      "Epoch 23, 100% \t Train loss: 0.1879 took: 2.82s  Val. loss: 0.2017\n",
      "Epoch 24, 100% \t Train loss: 0.1862 took: 2.78s  Val. loss: 0.1980\n",
      "Epoch 25, 100% \t Train loss: 0.1855 took: 2.78s  Val. loss: 0.1989\n",
      "Epoch 26, 100% \t Train loss: 0.1845 took: 2.81s  Val. loss: 0.2011\n",
      "Epoch 27, 100% \t Train loss: 0.1839 took: 2.79s  Val. loss: 0.1996\n",
      "Epoch 28, 100% \t Train loss: 0.1841 took: 2.80s  Val. loss: 0.1982\n",
      "Epoch 29, 100% \t Train loss: 0.1841 took: 2.85s  Val. loss: 0.1994\n",
      "Epoch 30, 100% \t Train loss: 0.1828 took: 2.86s  Val. loss: 0.1992\n",
      "Epoch 31, 100% \t Train loss: 0.1829 took: 2.92s  Val. loss: 0.2034\n",
      "Epoch 32, 100% \t Train loss: 0.1828 took: 1.88s  Val. loss: 0.1987\n",
      "Epoch 33, 100% \t Train loss: 0.1811 took: 1.90s  Val. loss: 0.2008\n",
      "Epoch 34, 100% \t Train loss: 0.1808 took: 1.91s  Val. loss: 0.1987\n",
      "Epoch 35, 100% \t Train loss: 0.1806 took: 1.91s  Val. loss: 0.1965\n",
      "Epoch 36, 100% \t Train loss: 0.1798 took: 1.91s  Val. loss: 0.2026\n",
      "Epoch 37, 100% \t Train loss: 0.1801 took: 1.95s  Val. loss: 0.1975\n",
      "Epoch 38, 100% \t Train loss: 0.1794 took: 1.98s  Val. loss: 0.1966\n",
      "Epoch 39, 100% \t Train loss: 0.1794 took: 2.00s  Val. loss: 0.1993\n",
      "Epoch 40, 100% \t Train loss: 0.1791 took: 2.01s  Val. loss: 0.1978\n",
      "Epoch 41, 100% \t Train loss: 0.1788 took: 2.05s  Val. loss: 0.2010\n",
      "Epoch 42, 100% \t Train loss: 0.1781 took: 2.06s  Val. loss: 0.2023\n",
      "Epoch 43, 100% \t Train loss: 0.1789 took: 2.73s  Val. loss: 0.2016\n",
      "Epoch 44, 100% \t Train loss: 0.1780 took: 3.23s  Val. loss: 0.1990\n",
      "Epoch 45, 100% \t Train loss: 0.1772 took: 3.20s  Val. loss: 0.2010\n",
      "Epoch 46, 100% \t Train loss: 0.1769 took: 3.29s  Val. loss: 0.1983\n",
      "Epoch 47, 100% \t Train loss: 0.1772 took: 3.31s  Val. loss: 0.1987\n",
      "Epoch 48, 100% \t Train loss: 0.1761 took: 3.34s  Val. loss: 0.1979\n",
      "Epoch 49, 100% \t Train loss: 0.1766 took: 3.37s  Val. loss: 0.1974\n",
      "Epoch 50, 100% \t Train loss: 0.1765 took: 3.39s  Val. loss: 0.1994\n",
      "Training finished, took 143.34s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.40\n",
      "\thidden_channels :  32  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.742759\n",
      "lambda: 0.0010 - V: 0.735414\n",
      "lambda: 0.0005 - V: 0.785039\n",
      "Average V: 0.754404\n",
      "Time elapsed: 452.09 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.39\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.42\n",
      "\tmask_channels :  8  - prob: 0.39\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2589 took: 1.93s  Val. loss: 0.2570\n",
      "Epoch 2, 100% \t Train loss: 0.2579 took: 1.91s  Val. loss: 0.2523\n",
      "Epoch 3, 100% \t Train loss: 0.2577 took: 1.90s  Val. loss: 0.2536\n",
      "Epoch 4, 100% \t Train loss: 0.2579 took: 1.91s  Val. loss: 0.2541\n",
      "Epoch 5, 100% \t Train loss: 0.2576 took: 1.92s  Val. loss: 0.2529\n",
      "Epoch 6, 100% \t Train loss: 0.2576 took: 1.92s  Val. loss: 0.2525\n",
      "Epoch 7, 100% \t Train loss: 0.2557 took: 1.91s  Val. loss: 0.2339\n",
      "Epoch 8, 100% \t Train loss: 0.1881 took: 1.92s  Val. loss: 0.1711\n",
      "Epoch 9, 100% \t Train loss: 0.1663 took: 1.94s  Val. loss: 0.1643\n",
      "Epoch 10, 100% \t Train loss: 0.1612 took: 1.92s  Val. loss: 0.1658\n",
      "Epoch 11, 100% \t Train loss: 0.1595 took: 1.92s  Val. loss: 0.1598\n",
      "Epoch 12, 100% \t Train loss: 0.1569 took: 1.91s  Val. loss: 0.1544\n",
      "Epoch 13, 100% \t Train loss: 0.1532 took: 1.93s  Val. loss: 0.1553\n",
      "Epoch 14, 100% \t Train loss: 0.1507 took: 1.91s  Val. loss: 0.1563\n",
      "Epoch 15, 100% \t Train loss: 0.1509 took: 1.93s  Val. loss: 0.1512\n",
      "Epoch 16, 100% \t Train loss: 0.1482 took: 1.93s  Val. loss: 0.1528\n",
      "Epoch 17, 100% \t Train loss: 0.1466 took: 1.93s  Val. loss: 0.1579\n",
      "Epoch 18, 100% \t Train loss: 0.1451 took: 1.91s  Val. loss: 0.1503\n",
      "Epoch 19, 100% \t Train loss: 0.1431 took: 1.92s  Val. loss: 0.1503\n",
      "Epoch 20, 100% \t Train loss: 0.1377 took: 1.92s  Val. loss: 0.1458\n",
      "Epoch 21, 100% \t Train loss: 0.1334 took: 1.92s  Val. loss: 0.1445\n",
      "Epoch 22, 100% \t Train loss: 0.1289 took: 1.91s  Val. loss: 0.1345\n",
      "Epoch 23, 100% \t Train loss: 0.1223 took: 1.92s  Val. loss: 0.1300\n",
      "Epoch 24, 100% \t Train loss: 0.1174 took: 1.92s  Val. loss: 0.1243\n",
      "Epoch 25, 100% \t Train loss: 0.1107 took: 1.92s  Val. loss: 0.1120\n",
      "Epoch 26, 100% \t Train loss: 0.1039 took: 1.91s  Val. loss: 0.1097\n",
      "Epoch 27, 100% \t Train loss: 0.0972 took: 1.92s  Val. loss: 0.1067\n",
      "Epoch 28, 100% \t Train loss: 0.0930 took: 1.95s  Val. loss: 0.1078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.0896 took: 1.91s  Val. loss: 0.0972\n",
      "Epoch 30, 100% \t Train loss: 0.0856 took: 1.92s  Val. loss: 0.0982\n",
      "Epoch 31, 100% \t Train loss: 0.0846 took: 1.93s  Val. loss: 0.0974\n",
      "Epoch 32, 100% \t Train loss: 0.0841 took: 1.19s  Val. loss: 0.0969\n",
      "Epoch 33, 100% \t Train loss: 0.0809 took: 1.37s  Val. loss: 0.0934\n",
      "Epoch 34, 100% \t Train loss: 0.0778 took: 1.43s  Val. loss: 0.0912\n",
      "Epoch 35, 100% \t Train loss: 0.0770 took: 1.44s  Val. loss: 0.0933\n",
      "Epoch 36, 100% \t Train loss: 0.0766 took: 1.44s  Val. loss: 0.0924\n",
      "Epoch 37, 100% \t Train loss: 0.0755 took: 1.38s  Val. loss: 0.0926\n",
      "Epoch 38, 100% \t Train loss: 0.0746 took: 1.27s  Val. loss: 0.0941\n",
      "Epoch 39, 100% \t Train loss: 0.0742 took: 1.34s  Val. loss: 0.0913\n",
      "Epoch 40, 100% \t Train loss: 0.0745 took: 1.28s  Val. loss: 0.0901\n",
      "Epoch 41, 100% \t Train loss: 0.0730 took: 1.27s  Val. loss: 0.0902\n",
      "Epoch 42, 100% \t Train loss: 0.0727 took: 1.28s  Val. loss: 0.0918\n",
      "Epoch 43, 100% \t Train loss: 0.0735 took: 1.28s  Val. loss: 0.0854\n",
      "Epoch 44, 100% \t Train loss: 0.0709 took: 1.27s  Val. loss: 0.0889\n",
      "Epoch 45, 100% \t Train loss: 0.0711 took: 1.28s  Val. loss: 0.0918\n",
      "Epoch 46, 100% \t Train loss: 0.0699 took: 1.29s  Val. loss: 0.0893\n",
      "Epoch 47, 100% \t Train loss: 0.0695 took: 1.28s  Val. loss: 0.0911\n",
      "Epoch 48, 100% \t Train loss: 0.0689 took: 1.92s  Val. loss: 0.0900\n",
      "Epoch 49, 100% \t Train loss: 0.0708 took: 2.06s  Val. loss: 0.0895\n",
      "Epoch 50, 100% \t Train loss: 0.0700 took: 2.09s  Val. loss: 0.0882\n",
      "Training finished, took 98.29s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2569 took: 1.93s  Val. loss: 0.2566\n",
      "Epoch 2, 100% \t Train loss: 0.2554 took: 1.92s  Val. loss: 0.2539\n",
      "Epoch 3, 100% \t Train loss: 0.2475 took: 1.12s  Val. loss: 0.2344\n",
      "Epoch 4, 100% \t Train loss: 0.2183 took: 1.12s  Val. loss: 0.1996\n",
      "Epoch 5, 100% \t Train loss: 0.1919 took: 1.13s  Val. loss: 0.1783\n",
      "Epoch 6, 100% \t Train loss: 0.1777 took: 1.11s  Val. loss: 0.1690\n",
      "Epoch 7, 100% \t Train loss: 0.1700 took: 1.10s  Val. loss: 0.1661\n",
      "Epoch 8, 100% \t Train loss: 0.1664 took: 1.11s  Val. loss: 0.1663\n",
      "Epoch 9, 100% \t Train loss: 0.1630 took: 1.10s  Val. loss: 0.1605\n",
      "Epoch 10, 100% \t Train loss: 0.1614 took: 1.11s  Val. loss: 0.1602\n",
      "Epoch 11, 100% \t Train loss: 0.1584 took: 1.11s  Val. loss: 0.1576\n",
      "Epoch 12, 100% \t Train loss: 0.1570 took: 1.11s  Val. loss: 0.1575\n",
      "Epoch 13, 100% \t Train loss: 0.1565 took: 1.11s  Val. loss: 0.1563\n",
      "Epoch 14, 100% \t Train loss: 0.1533 took: 1.12s  Val. loss: 0.1565\n",
      "Epoch 15, 100% \t Train loss: 0.1532 took: 1.13s  Val. loss: 0.1577\n",
      "Epoch 16, 100% \t Train loss: 0.1514 took: 1.12s  Val. loss: 0.1548\n",
      "Epoch 17, 100% \t Train loss: 0.1507 took: 1.11s  Val. loss: 0.1569\n",
      "Epoch 18, 100% \t Train loss: 0.1489 took: 1.12s  Val. loss: 0.1554\n",
      "Epoch 19, 100% \t Train loss: 0.1487 took: 1.12s  Val. loss: 0.1544\n",
      "Epoch 20, 100% \t Train loss: 0.1463 took: 1.12s  Val. loss: 0.1523\n",
      "Epoch 21, 100% \t Train loss: 0.1441 took: 1.11s  Val. loss: 0.1518\n",
      "Epoch 22, 100% \t Train loss: 0.1427 took: 1.12s  Val. loss: 0.1534\n",
      "Epoch 23, 100% \t Train loss: 0.1402 took: 1.11s  Val. loss: 0.1500\n",
      "Epoch 24, 100% \t Train loss: 0.1398 took: 1.11s  Val. loss: 0.1502\n",
      "Epoch 25, 100% \t Train loss: 0.1376 took: 1.11s  Val. loss: 0.1485\n",
      "Epoch 26, 100% \t Train loss: 0.1379 took: 1.12s  Val. loss: 0.1492\n",
      "Epoch 27, 100% \t Train loss: 0.1356 took: 1.12s  Val. loss: 0.1494\n",
      "Epoch 28, 100% \t Train loss: 0.1343 took: 1.12s  Val. loss: 0.1532\n",
      "Epoch 29, 100% \t Train loss: 0.1327 took: 1.12s  Val. loss: 0.1509\n",
      "Epoch 30, 100% \t Train loss: 0.1311 took: 1.12s  Val. loss: 0.1487\n",
      "Epoch 31, 100% \t Train loss: 0.1296 took: 1.12s  Val. loss: 0.1470\n",
      "Epoch 32, 100% \t Train loss: 0.1277 took: 1.13s  Val. loss: 0.1493\n",
      "Epoch 33, 100% \t Train loss: 0.1261 took: 1.13s  Val. loss: 0.1468\n",
      "Epoch 34, 100% \t Train loss: 0.1250 took: 1.12s  Val. loss: 0.1450\n",
      "Epoch 35, 100% \t Train loss: 0.1239 took: 1.12s  Val. loss: 0.1456\n",
      "Epoch 36, 100% \t Train loss: 0.1222 took: 1.12s  Val. loss: 0.1407\n",
      "Epoch 37, 100% \t Train loss: 0.1201 took: 1.11s  Val. loss: 0.1434\n",
      "Epoch 38, 100% \t Train loss: 0.1177 took: 1.11s  Val. loss: 0.1395\n",
      "Epoch 39, 100% \t Train loss: 0.1158 took: 1.11s  Val. loss: 0.1394\n",
      "Epoch 40, 100% \t Train loss: 0.1146 took: 1.12s  Val. loss: 0.1406\n",
      "Epoch 41, 100% \t Train loss: 0.1115 took: 1.88s  Val. loss: 0.1304\n",
      "Epoch 42, 100% \t Train loss: 0.1113 took: 1.90s  Val. loss: 0.1305\n",
      "Epoch 43, 100% \t Train loss: 0.1090 took: 1.91s  Val. loss: 0.1281\n",
      "Epoch 44, 100% \t Train loss: 0.1066 took: 1.92s  Val. loss: 0.1283\n",
      "Epoch 45, 100% \t Train loss: 0.1059 took: 1.92s  Val. loss: 0.1318\n",
      "Epoch 46, 100% \t Train loss: 0.1042 took: 1.93s  Val. loss: 0.1263\n",
      "Epoch 47, 100% \t Train loss: 0.1023 took: 1.91s  Val. loss: 0.1225\n",
      "Epoch 48, 100% \t Train loss: 0.1020 took: 1.13s  Val. loss: 0.1202\n",
      "Epoch 49, 100% \t Train loss: 0.0998 took: 1.12s  Val. loss: 0.1196\n",
      "Epoch 50, 100% \t Train loss: 0.0985 took: 1.12s  Val. loss: 0.1177\n",
      "Training finished, took 71.16s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2580 took: 1.12s  Val. loss: 0.2579\n",
      "Epoch 2, 100% \t Train loss: 0.2578 took: 1.11s  Val. loss: 0.2569\n",
      "Epoch 3, 100% \t Train loss: 0.2577 took: 1.11s  Val. loss: 0.2569\n",
      "Epoch 4, 100% \t Train loss: 0.2576 took: 1.11s  Val. loss: 0.2573\n",
      "Epoch 5, 100% \t Train loss: 0.2571 took: 1.11s  Val. loss: 0.2562\n",
      "Epoch 6, 100% \t Train loss: 0.2551 took: 1.12s  Val. loss: 0.2504\n",
      "Epoch 7, 100% \t Train loss: 0.2385 took: 1.12s  Val. loss: 0.2236\n",
      "Epoch 8, 100% \t Train loss: 0.2119 took: 1.12s  Val. loss: 0.2009\n",
      "Epoch 9, 100% \t Train loss: 0.1923 took: 1.12s  Val. loss: 0.1845\n",
      "Epoch 10, 100% \t Train loss: 0.1846 took: 1.11s  Val. loss: 0.1822\n",
      "Epoch 11, 100% \t Train loss: 0.1769 took: 1.12s  Val. loss: 0.1757\n",
      "Epoch 12, 100% \t Train loss: 0.1758 took: 1.12s  Val. loss: 0.1738\n",
      "Epoch 13, 100% \t Train loss: 0.1712 took: 1.12s  Val. loss: 0.1769\n",
      "Epoch 14, 100% \t Train loss: 0.1714 took: 1.12s  Val. loss: 0.1799\n",
      "Epoch 15, 100% \t Train loss: 0.1698 took: 1.12s  Val. loss: 0.1704\n",
      "Epoch 16, 100% \t Train loss: 0.1695 took: 1.12s  Val. loss: 0.1681\n",
      "Epoch 17, 100% \t Train loss: 0.1676 took: 1.12s  Val. loss: 0.1666\n",
      "Epoch 18, 100% \t Train loss: 0.1662 took: 1.11s  Val. loss: 0.1654\n",
      "Epoch 19, 100% \t Train loss: 0.1650 took: 1.11s  Val. loss: 0.1662\n",
      "Epoch 20, 100% \t Train loss: 0.1654 took: 1.12s  Val. loss: 0.1676\n",
      "Epoch 21, 100% \t Train loss: 0.1645 took: 1.12s  Val. loss: 0.1637\n",
      "Epoch 22, 100% \t Train loss: 0.1622 took: 1.12s  Val. loss: 0.1615\n",
      "Epoch 23, 100% \t Train loss: 0.1622 took: 1.12s  Val. loss: 0.1610\n",
      "Epoch 24, 100% \t Train loss: 0.1632 took: 1.12s  Val. loss: 0.1630\n",
      "Epoch 25, 100% \t Train loss: 0.1611 took: 1.12s  Val. loss: 0.1612\n",
      "Epoch 26, 100% \t Train loss: 0.1593 took: 1.12s  Val. loss: 0.1607\n",
      "Epoch 27, 100% \t Train loss: 0.1611 took: 1.13s  Val. loss: 0.1598\n",
      "Epoch 28, 100% \t Train loss: 0.1592 took: 1.14s  Val. loss: 0.1596\n",
      "Epoch 29, 100% \t Train loss: 0.1584 took: 1.16s  Val. loss: 0.1615\n",
      "Epoch 30, 100% \t Train loss: 0.1597 took: 1.17s  Val. loss: 0.1628\n",
      "Epoch 31, 100% \t Train loss: 0.1576 took: 1.17s  Val. loss: 0.1611\n",
      "Epoch 32, 100% \t Train loss: 0.1584 took: 1.18s  Val. loss: 0.1589\n",
      "Epoch 33, 100% \t Train loss: 0.1590 took: 1.18s  Val. loss: 0.1652\n",
      "Epoch 34, 100% \t Train loss: 0.1597 took: 1.18s  Val. loss: 0.1635\n",
      "Epoch 35, 100% \t Train loss: 0.1580 took: 1.20s  Val. loss: 0.1616\n",
      "Epoch 36, 100% \t Train loss: 0.1571 took: 1.20s  Val. loss: 0.1581\n",
      "Epoch 37, 100% \t Train loss: 0.1547 took: 1.20s  Val. loss: 0.1586\n",
      "Epoch 38, 100% \t Train loss: 0.1565 took: 1.20s  Val. loss: 0.1576\n",
      "Epoch 39, 100% \t Train loss: 0.1543 took: 1.20s  Val. loss: 0.1596\n",
      "Epoch 40, 100% \t Train loss: 0.1557 took: 1.19s  Val. loss: 0.1647\n",
      "Epoch 41, 100% \t Train loss: 0.1556 took: 1.19s  Val. loss: 0.1585\n",
      "Epoch 42, 100% \t Train loss: 0.1540 took: 1.19s  Val. loss: 0.1594\n",
      "Epoch 43, 100% \t Train loss: 0.1534 took: 1.19s  Val. loss: 0.1569\n",
      "Epoch 44, 100% \t Train loss: 0.1527 took: 1.20s  Val. loss: 0.1575\n",
      "Epoch 45, 100% \t Train loss: 0.1525 took: 1.20s  Val. loss: 0.1567\n",
      "Epoch 46, 100% \t Train loss: 0.1523 took: 1.20s  Val. loss: 0.1560\n",
      "Epoch 47, 100% \t Train loss: 0.1526 took: 1.73s  Val. loss: 0.1567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1521 took: 1.99s  Val. loss: 0.1602\n",
      "Epoch 49, 100% \t Train loss: 0.1520 took: 1.99s  Val. loss: 0.1567\n",
      "Epoch 50, 100% \t Train loss: 0.1517 took: 1.99s  Val. loss: 0.1555\n",
      "Training finished, took 67.95s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.39\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.42\n",
      "\tmask_channels :  8  - prob: 0.39\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.864297\n",
      "lambda: 0.0010 - V: 0.845952\n",
      "lambda: 0.0005 - V: 0.823290\n",
      "Average V: 0.844513\n",
      "Time elapsed: 240.79 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.39\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2560 took: 1.81s  Val. loss: 0.2511\n",
      "Epoch 2, 100% \t Train loss: 0.2533 took: 1.80s  Val. loss: 0.2321\n",
      "Epoch 3, 100% \t Train loss: 0.1792 took: 1.82s  Val. loss: 0.1585\n",
      "Epoch 4, 100% \t Train loss: 0.1543 took: 1.81s  Val. loss: 0.1542\n",
      "Epoch 5, 100% \t Train loss: 0.1493 took: 1.81s  Val. loss: 0.1585\n",
      "Epoch 6, 100% \t Train loss: 0.1462 took: 1.82s  Val. loss: 0.1532\n",
      "Epoch 7, 100% \t Train loss: 0.1448 took: 1.81s  Val. loss: 0.1514\n",
      "Epoch 8, 100% \t Train loss: 0.1436 took: 1.81s  Val. loss: 0.1504\n",
      "Epoch 9, 100% \t Train loss: 0.1429 took: 1.82s  Val. loss: 0.1500\n",
      "Epoch 10, 100% \t Train loss: 0.1418 took: 1.83s  Val. loss: 0.1491\n",
      "Epoch 11, 100% \t Train loss: 0.1415 took: 1.83s  Val. loss: 0.1525\n",
      "Epoch 12, 100% \t Train loss: 0.1399 took: 1.82s  Val. loss: 0.1493\n",
      "Epoch 13, 100% \t Train loss: 0.1394 took: 1.82s  Val. loss: 0.1513\n",
      "Epoch 14, 100% \t Train loss: 0.1388 took: 1.81s  Val. loss: 0.1530\n",
      "Epoch 15, 100% \t Train loss: 0.1389 took: 1.81s  Val. loss: 0.1524\n",
      "Epoch 16, 100% \t Train loss: 0.1389 took: 1.83s  Val. loss: 0.1510\n",
      "Epoch 17, 100% \t Train loss: 0.1385 took: 1.82s  Val. loss: 0.1546\n",
      "Epoch 18, 100% \t Train loss: 0.1383 took: 1.82s  Val. loss: 0.1546\n",
      "Epoch 19, 100% \t Train loss: 0.1378 took: 1.82s  Val. loss: 0.1518\n",
      "Epoch 20, 100% \t Train loss: 0.1381 took: 1.84s  Val. loss: 0.1548\n",
      "Epoch 21, 100% \t Train loss: 0.1372 took: 1.81s  Val. loss: 0.1538\n",
      "Epoch 22, 100% \t Train loss: 0.1367 took: 1.82s  Val. loss: 0.1537\n",
      "Epoch 23, 100% \t Train loss: 0.1368 took: 1.83s  Val. loss: 0.1559\n",
      "Epoch 24, 100% \t Train loss: 0.1368 took: 1.80s  Val. loss: 0.1543\n",
      "Epoch 25, 100% \t Train loss: 0.1364 took: 1.80s  Val. loss: 0.1542\n",
      "Epoch 26, 100% \t Train loss: 0.1363 took: 1.81s  Val. loss: 0.1578\n",
      "Epoch 27, 100% \t Train loss: 0.1365 took: 1.80s  Val. loss: 0.1528\n",
      "Epoch 28, 100% \t Train loss: 0.1369 took: 1.82s  Val. loss: 0.1532\n",
      "Epoch 29, 100% \t Train loss: 0.1359 took: 1.83s  Val. loss: 0.1533\n",
      "Epoch 30, 100% \t Train loss: 0.1356 took: 1.81s  Val. loss: 0.1564\n",
      "Epoch 31, 100% \t Train loss: 0.1355 took: 1.80s  Val. loss: 0.1561\n",
      "Epoch 32, 100% \t Train loss: 0.1361 took: 1.81s  Val. loss: 0.1571\n",
      "Epoch 33, 100% \t Train loss: 0.1356 took: 1.82s  Val. loss: 0.1557\n",
      "Epoch 34, 100% \t Train loss: 0.1357 took: 1.81s  Val. loss: 0.1542\n",
      "Epoch 35, 100% \t Train loss: 0.1354 took: 1.81s  Val. loss: 0.1551\n",
      "Epoch 36, 100% \t Train loss: 0.1354 took: 1.82s  Val. loss: 0.1546\n",
      "Epoch 37, 100% \t Train loss: 0.1351 took: 1.82s  Val. loss: 0.1567\n",
      "Epoch 38, 100% \t Train loss: 0.1348 took: 1.82s  Val. loss: 0.1571\n",
      "Epoch 39, 100% \t Train loss: 0.1351 took: 1.82s  Val. loss: 0.1550\n",
      "Epoch 40, 100% \t Train loss: 0.1345 took: 1.84s  Val. loss: 0.1613\n",
      "Epoch 41, 100% \t Train loss: 0.1349 took: 1.81s  Val. loss: 0.1583\n",
      "Epoch 42, 100% \t Train loss: 0.1348 took: 1.81s  Val. loss: 0.1567\n",
      "Epoch 43, 100% \t Train loss: 0.1344 took: 1.80s  Val. loss: 0.1604\n",
      "Epoch 44, 100% \t Train loss: 0.1344 took: 1.81s  Val. loss: 0.1618\n",
      "Epoch 45, 100% \t Train loss: 0.1347 took: 1.83s  Val. loss: 0.1587\n",
      "Epoch 46, 100% \t Train loss: 0.1343 took: 1.82s  Val. loss: 0.1584\n",
      "Epoch 47, 100% \t Train loss: 0.1346 took: 1.83s  Val. loss: 0.1574\n",
      "Epoch 48, 100% \t Train loss: 0.1340 took: 1.85s  Val. loss: 0.1608\n",
      "Epoch 49, 100% \t Train loss: 0.1349 took: 1.86s  Val. loss: 0.1582\n",
      "Epoch 50, 100% \t Train loss: 0.1338 took: 1.88s  Val. loss: 0.1607\n",
      "Training finished, took 103.21s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2613 took: 1.87s  Val. loss: 0.2568\n",
      "Epoch 2, 100% \t Train loss: 0.2603 took: 1.83s  Val. loss: 0.2569\n",
      "Epoch 3, 100% \t Train loss: 0.2603 took: 1.83s  Val. loss: 0.2566\n",
      "Epoch 4, 100% \t Train loss: 0.2604 took: 1.84s  Val. loss: 0.2571\n",
      "Epoch 5, 100% \t Train loss: 0.2603 took: 1.85s  Val. loss: 0.2569\n",
      "Epoch 6, 100% \t Train loss: 0.2602 took: 1.82s  Val. loss: 0.2563\n",
      "Epoch 7, 100% \t Train loss: 0.2597 took: 1.83s  Val. loss: 0.2557\n",
      "Epoch 8, 100% \t Train loss: 0.2550 took: 1.83s  Val. loss: 0.2422\n",
      "Epoch 9, 100% \t Train loss: 0.2201 took: 1.83s  Val. loss: 0.2035\n",
      "Epoch 10, 100% \t Train loss: 0.1943 took: 1.85s  Val. loss: 0.1889\n",
      "Epoch 11, 100% \t Train loss: 0.1824 took: 1.83s  Val. loss: 0.1813\n",
      "Epoch 12, 100% \t Train loss: 0.1787 took: 1.84s  Val. loss: 0.1771\n",
      "Epoch 13, 100% \t Train loss: 0.1763 took: 1.84s  Val. loss: 0.1809\n",
      "Epoch 14, 100% \t Train loss: 0.1733 took: 1.86s  Val. loss: 0.1747\n",
      "Epoch 15, 100% \t Train loss: 0.1715 took: 1.85s  Val. loss: 0.1777\n",
      "Epoch 16, 100% \t Train loss: 0.1701 took: 1.83s  Val. loss: 0.1699\n",
      "Epoch 17, 100% \t Train loss: 0.1705 took: 1.86s  Val. loss: 0.1658\n",
      "Epoch 18, 100% \t Train loss: 0.1681 took: 1.84s  Val. loss: 0.1693\n",
      "Epoch 19, 100% \t Train loss: 0.1667 took: 1.83s  Val. loss: 0.1694\n",
      "Epoch 20, 100% \t Train loss: 0.1656 took: 1.83s  Val. loss: 0.1648\n",
      "Epoch 21, 100% \t Train loss: 0.1659 took: 1.84s  Val. loss: 0.1674\n",
      "Epoch 22, 100% \t Train loss: 0.1617 took: 1.83s  Val. loss: 0.1665\n",
      "Epoch 23, 100% \t Train loss: 0.1633 took: 1.82s  Val. loss: 0.1651\n",
      "Epoch 24, 100% \t Train loss: 0.1614 took: 1.81s  Val. loss: 0.1731\n",
      "Epoch 25, 100% \t Train loss: 0.1604 took: 1.82s  Val. loss: 0.1648\n",
      "Epoch 26, 100% \t Train loss: 0.1590 took: 1.82s  Val. loss: 0.1619\n",
      "Epoch 27, 100% \t Train loss: 0.1591 took: 1.82s  Val. loss: 0.1634\n",
      "Epoch 28, 100% \t Train loss: 0.1586 took: 1.82s  Val. loss: 0.1726\n",
      "Epoch 29, 100% \t Train loss: 0.1582 took: 1.83s  Val. loss: 0.1659\n",
      "Epoch 30, 100% \t Train loss: 0.1577 took: 1.83s  Val. loss: 0.1655\n",
      "Epoch 31, 100% \t Train loss: 0.1571 took: 1.84s  Val. loss: 0.1702\n",
      "Epoch 32, 100% \t Train loss: 0.1584 took: 1.85s  Val. loss: 0.1631\n",
      "Epoch 33, 100% \t Train loss: 0.1574 took: 1.85s  Val. loss: 0.1649\n",
      "Epoch 34, 100% \t Train loss: 0.1574 took: 1.86s  Val. loss: 0.1612\n",
      "Epoch 35, 100% \t Train loss: 0.1553 took: 1.86s  Val. loss: 0.1618\n",
      "Epoch 36, 100% \t Train loss: 0.1566 took: 1.86s  Val. loss: 0.1605\n",
      "Epoch 37, 100% \t Train loss: 0.1562 took: 1.88s  Val. loss: 0.1640\n",
      "Epoch 38, 100% \t Train loss: 0.1547 took: 1.91s  Val. loss: 0.1613\n",
      "Epoch 39, 100% \t Train loss: 0.1540 took: 1.93s  Val. loss: 0.1631\n",
      "Epoch 40, 100% \t Train loss: 0.1550 took: 1.93s  Val. loss: 0.1611\n",
      "Epoch 41, 100% \t Train loss: 0.1537 took: 1.93s  Val. loss: 0.1629\n",
      "Epoch 42, 100% \t Train loss: 0.1535 took: 1.93s  Val. loss: 0.1639\n",
      "Epoch 43, 100% \t Train loss: 0.1529 took: 1.92s  Val. loss: 0.1646\n",
      "Epoch 44, 100% \t Train loss: 0.1541 took: 1.91s  Val. loss: 0.1651\n",
      "Epoch 45, 100% \t Train loss: 0.1528 took: 1.92s  Val. loss: 0.1644\n",
      "Epoch 46, 100% \t Train loss: 0.1518 took: 1.91s  Val. loss: 0.1683\n",
      "Epoch 47, 100% \t Train loss: 0.1520 took: 1.92s  Val. loss: 0.1605\n",
      "Epoch 48, 100% \t Train loss: 0.1521 took: 1.92s  Val. loss: 0.1664\n",
      "Epoch 49, 100% \t Train loss: 0.1511 took: 1.99s  Val. loss: 0.1658\n",
      "Epoch 50, 100% \t Train loss: 0.1509 took: 1.24s  Val. loss: 0.1706\n",
      "Training finished, took 104.95s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 1.33s  Val. loss: 0.2569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2582 took: 1.81s  Val. loss: 0.2573\n",
      "Epoch 3, 100% \t Train loss: 0.2583 took: 1.81s  Val. loss: 0.2573\n",
      "Epoch 4, 100% \t Train loss: 0.2584 took: 1.81s  Val. loss: 0.2566\n",
      "Epoch 5, 100% \t Train loss: 0.2581 took: 1.82s  Val. loss: 0.2571\n",
      "Epoch 6, 100% \t Train loss: 0.2581 took: 1.83s  Val. loss: 0.2578\n",
      "Epoch 7, 100% \t Train loss: 0.2579 took: 1.84s  Val. loss: 0.2564\n",
      "Epoch 8, 100% \t Train loss: 0.2574 took: 1.82s  Val. loss: 0.2556\n",
      "Epoch 9, 100% \t Train loss: 0.2555 took: 1.83s  Val. loss: 0.2523\n",
      "Epoch 10, 100% \t Train loss: 0.2465 took: 1.82s  Val. loss: 0.2353\n",
      "Epoch 11, 100% \t Train loss: 0.2156 took: 1.82s  Val. loss: 0.2053\n",
      "Epoch 12, 100% \t Train loss: 0.1937 took: 1.82s  Val. loss: 0.1871\n",
      "Epoch 13, 100% \t Train loss: 0.1845 took: 1.81s  Val. loss: 0.1804\n",
      "Epoch 14, 100% \t Train loss: 0.1787 took: 1.84s  Val. loss: 0.1772\n",
      "Epoch 15, 100% \t Train loss: 0.1789 took: 1.82s  Val. loss: 0.1782\n",
      "Epoch 16, 100% \t Train loss: 0.1753 took: 1.82s  Val. loss: 0.1744\n",
      "Epoch 17, 100% \t Train loss: 0.1754 took: 1.83s  Val. loss: 0.1736\n",
      "Epoch 18, 100% \t Train loss: 0.1731 took: 1.82s  Val. loss: 0.1748\n",
      "Epoch 19, 100% \t Train loss: 0.1716 took: 1.82s  Val. loss: 0.1722\n",
      "Epoch 20, 100% \t Train loss: 0.1700 took: 1.09s  Val. loss: 0.1698\n",
      "Epoch 21, 100% \t Train loss: 0.1683 took: 1.06s  Val. loss: 0.1698\n",
      "Epoch 22, 100% \t Train loss: 0.1678 took: 1.05s  Val. loss: 0.1690\n",
      "Epoch 23, 100% \t Train loss: 0.1673 took: 1.05s  Val. loss: 0.1703\n",
      "Epoch 24, 100% \t Train loss: 0.1673 took: 1.05s  Val. loss: 0.1699\n",
      "Epoch 25, 100% \t Train loss: 0.1655 took: 1.05s  Val. loss: 0.1669\n",
      "Epoch 26, 100% \t Train loss: 0.1653 took: 1.05s  Val. loss: 0.1672\n",
      "Epoch 27, 100% \t Train loss: 0.1647 took: 1.05s  Val. loss: 0.1657\n",
      "Epoch 28, 100% \t Train loss: 0.1641 took: 1.05s  Val. loss: 0.1693\n",
      "Epoch 29, 100% \t Train loss: 0.1670 took: 1.05s  Val. loss: 0.1717\n",
      "Epoch 30, 100% \t Train loss: 0.1632 took: 1.05s  Val. loss: 0.1707\n",
      "Epoch 31, 100% \t Train loss: 0.1630 took: 1.06s  Val. loss: 0.1671\n",
      "Epoch 32, 100% \t Train loss: 0.1619 took: 1.06s  Val. loss: 0.1675\n",
      "Epoch 33, 100% \t Train loss: 0.1615 took: 1.07s  Val. loss: 0.1663\n",
      "Epoch 34, 100% \t Train loss: 0.1600 took: 1.07s  Val. loss: 0.1729\n",
      "Epoch 35, 100% \t Train loss: 0.1610 took: 1.07s  Val. loss: 0.1658\n",
      "Epoch 36, 100% \t Train loss: 0.1631 took: 1.06s  Val. loss: 0.1658\n",
      "Epoch 37, 100% \t Train loss: 0.1607 took: 1.06s  Val. loss: 0.1701\n",
      "Epoch 38, 100% \t Train loss: 0.1589 took: 1.51s  Val. loss: 0.1656\n",
      "Epoch 39, 100% \t Train loss: 0.1587 took: 1.83s  Val. loss: 0.1658\n",
      "Epoch 40, 100% \t Train loss: 0.1628 took: 1.84s  Val. loss: 0.1664\n",
      "Epoch 41, 100% \t Train loss: 0.1577 took: 1.83s  Val. loss: 0.1661\n",
      "Epoch 42, 100% \t Train loss: 0.1614 took: 1.05s  Val. loss: 0.1668\n",
      "Epoch 43, 100% \t Train loss: 0.1592 took: 1.05s  Val. loss: 0.1659\n",
      "Epoch 44, 100% \t Train loss: 0.1565 took: 1.06s  Val. loss: 0.1661\n",
      "Epoch 45, 100% \t Train loss: 0.1585 took: 1.06s  Val. loss: 0.1656\n",
      "Epoch 46, 100% \t Train loss: 0.1564 took: 1.06s  Val. loss: 0.1653\n",
      "Epoch 47, 100% \t Train loss: 0.1558 took: 1.06s  Val. loss: 0.1637\n",
      "Epoch 48, 100% \t Train loss: 0.1560 took: 1.07s  Val. loss: 0.1641\n",
      "Epoch 49, 100% \t Train loss: 0.1556 took: 1.06s  Val. loss: 0.1646\n",
      "Epoch 50, 100% \t Train loss: 0.1560 took: 1.05s  Val. loss: 0.1639\n",
      "Training finished, took 79.01s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.39\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.841329\n",
      "lambda: 0.0010 - V: 0.817769\n",
      "lambda: 0.0005 - V: 0.812969\n",
      "Average V: 0.824022\n",
      "Time elapsed: 290.55 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.23\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2599 took: 1.79s  Val. loss: 0.2583\n",
      "Epoch 2, 100% \t Train loss: 0.2579 took: 1.84s  Val. loss: 0.2593\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 1.83s  Val. loss: 0.2584\n",
      "Epoch 4, 100% \t Train loss: 0.2575 took: 1.84s  Val. loss: 0.2592\n",
      "Epoch 5, 100% \t Train loss: 0.2575 took: 1.85s  Val. loss: 0.2577\n",
      "Epoch 6, 100% \t Train loss: 0.2574 took: 1.84s  Val. loss: 0.2587\n",
      "Epoch 7, 100% \t Train loss: 0.2574 took: 1.84s  Val. loss: 0.2590\n",
      "Epoch 8, 100% \t Train loss: 0.2575 took: 1.84s  Val. loss: 0.2584\n",
      "Epoch 9, 100% \t Train loss: 0.2574 took: 1.84s  Val. loss: 0.2585\n",
      "Epoch 10, 100% \t Train loss: 0.2574 took: 1.07s  Val. loss: 0.2577\n",
      "Epoch 11, 100% \t Train loss: 0.2574 took: 1.08s  Val. loss: 0.2579\n",
      "Epoch 12, 100% \t Train loss: 0.2575 took: 1.07s  Val. loss: 0.2585\n",
      "Epoch 13, 100% \t Train loss: 0.2574 took: 1.07s  Val. loss: 0.2582\n",
      "Epoch 14, 100% \t Train loss: 0.2574 took: 1.07s  Val. loss: 0.2585\n",
      "Epoch 15, 100% \t Train loss: 0.2574 took: 1.06s  Val. loss: 0.2588\n",
      "Epoch 16, 100% \t Train loss: 0.2575 took: 1.07s  Val. loss: 0.2587\n",
      "Epoch 17, 100% \t Train loss: 0.2576 took: 1.08s  Val. loss: 0.2583\n",
      "Epoch 18, 100% \t Train loss: 0.2576 took: 1.07s  Val. loss: 0.2592\n",
      "Epoch 19, 100% \t Train loss: 0.2574 took: 1.07s  Val. loss: 0.2585\n",
      "Epoch 20, 100% \t Train loss: 0.2574 took: 1.06s  Val. loss: 0.2591\n",
      "Epoch 21, 100% \t Train loss: 0.2574 took: 1.06s  Val. loss: 0.2596\n",
      "Epoch 22, 100% \t Train loss: 0.2574 took: 1.06s  Val. loss: 0.2583\n",
      "Epoch 23, 100% \t Train loss: 0.2574 took: 1.06s  Val. loss: 0.2578\n",
      "Epoch 24, 100% \t Train loss: 0.2574 took: 1.07s  Val. loss: 0.2584\n",
      "Epoch 25, 100% \t Train loss: 0.2574 took: 1.06s  Val. loss: 0.2572\n",
      "Epoch 26, 100% \t Train loss: 0.2574 took: 1.07s  Val. loss: 0.2582\n",
      "Epoch 27, 100% \t Train loss: 0.2574 took: 1.07s  Val. loss: 0.2592\n",
      "Epoch 28, 100% \t Train loss: 0.2574 took: 1.68s  Val. loss: 0.2587\n",
      "Epoch 29, 100% \t Train loss: 0.2574 took: 1.87s  Val. loss: 0.2589\n",
      "Epoch 30, 100% \t Train loss: 0.2574 took: 1.88s  Val. loss: 0.2571\n",
      "Epoch 31, 100% \t Train loss: 0.2574 took: 1.91s  Val. loss: 0.2579\n",
      "Epoch 32, 100% \t Train loss: 0.2574 took: 1.97s  Val. loss: 0.2584\n",
      "Epoch 33, 100% \t Train loss: 0.2574 took: 2.05s  Val. loss: 0.2581\n",
      "Epoch 34, 100% \t Train loss: 0.2573 took: 2.08s  Val. loss: 0.2575\n",
      "Epoch 35, 100% \t Train loss: 0.2574 took: 2.09s  Val. loss: 0.2591\n",
      "Epoch 36, 100% \t Train loss: 0.2574 took: 2.11s  Val. loss: 0.2585\n",
      "Epoch 37, 100% \t Train loss: 0.2574 took: 2.12s  Val. loss: 0.2582\n",
      "Epoch 38, 100% \t Train loss: 0.2574 took: 2.12s  Val. loss: 0.2581\n",
      "Epoch 39, 100% \t Train loss: 0.2573 took: 2.11s  Val. loss: 0.2589\n",
      "Epoch 40, 100% \t Train loss: 0.2574 took: 2.13s  Val. loss: 0.2577\n",
      "Epoch 41, 100% \t Train loss: 0.2573 took: 2.13s  Val. loss: 0.2579\n",
      "Epoch 42, 100% \t Train loss: 0.2573 took: 2.12s  Val. loss: 0.2577\n",
      "Epoch 43, 100% \t Train loss: 0.2573 took: 1.36s  Val. loss: 0.2578\n",
      "Epoch 44, 100% \t Train loss: 0.2574 took: 1.37s  Val. loss: 0.2585\n",
      "Epoch 45, 100% \t Train loss: 0.2573 took: 1.38s  Val. loss: 0.2590\n",
      "Epoch 46, 100% \t Train loss: 0.2574 took: 1.38s  Val. loss: 0.2586\n",
      "Epoch 47, 100% \t Train loss: 0.2574 took: 1.39s  Val. loss: 0.2582\n",
      "Epoch 48, 100% \t Train loss: 0.2574 took: 1.40s  Val. loss: 0.2586\n",
      "Epoch 49, 100% \t Train loss: 0.2573 took: 1.99s  Val. loss: 0.2581\n",
      "Epoch 50, 100% \t Train loss: 0.2573 took: 2.18s  Val. loss: 0.2587\n",
      "Training finished, took 89.06s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2569 took: 1.84s  Val. loss: 0.2478\n",
      "Epoch 2, 100% \t Train loss: 0.2189 took: 1.85s  Val. loss: 0.1991\n",
      "Epoch 3, 100% \t Train loss: 0.1807 took: 1.85s  Val. loss: 0.1847\n",
      "Epoch 4, 100% \t Train loss: 0.1717 took: 1.85s  Val. loss: 0.1797\n",
      "Epoch 5, 100% \t Train loss: 0.1694 took: 1.07s  Val. loss: 0.1797\n",
      "Epoch 6, 100% \t Train loss: 0.1686 took: 1.16s  Val. loss: 0.1802\n",
      "Epoch 7, 100% \t Train loss: 0.1659 took: 1.84s  Val. loss: 0.1812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.1629 took: 1.83s  Val. loss: 0.1729\n",
      "Epoch 9, 100% \t Train loss: 0.1583 took: 1.84s  Val. loss: 0.1707\n",
      "Epoch 10, 100% \t Train loss: 0.1586 took: 1.84s  Val. loss: 0.1755\n",
      "Epoch 11, 100% \t Train loss: 0.1550 took: 1.08s  Val. loss: 0.1681\n",
      "Epoch 12, 100% \t Train loss: 0.1538 took: 1.07s  Val. loss: 0.1677\n",
      "Epoch 13, 100% \t Train loss: 0.1527 took: 1.07s  Val. loss: 0.1681\n",
      "Epoch 14, 100% \t Train loss: 0.1539 took: 1.07s  Val. loss: 0.1705\n",
      "Epoch 15, 100% \t Train loss: 0.1535 took: 1.07s  Val. loss: 0.1679\n",
      "Epoch 16, 100% \t Train loss: 0.1511 took: 1.06s  Val. loss: 0.1661\n",
      "Epoch 17, 100% \t Train loss: 0.1496 took: 1.07s  Val. loss: 0.1658\n",
      "Epoch 18, 100% \t Train loss: 0.1492 took: 1.07s  Val. loss: 0.1699\n",
      "Epoch 19, 100% \t Train loss: 0.1484 took: 1.07s  Val. loss: 0.1712\n",
      "Epoch 20, 100% \t Train loss: 0.1488 took: 1.07s  Val. loss: 0.1693\n",
      "Epoch 21, 100% \t Train loss: 0.1479 took: 1.07s  Val. loss: 0.1715\n",
      "Epoch 22, 100% \t Train loss: 0.1477 took: 1.07s  Val. loss: 0.1677\n",
      "Epoch 23, 100% \t Train loss: 0.1464 took: 1.07s  Val. loss: 0.1681\n",
      "Epoch 24, 100% \t Train loss: 0.1470 took: 1.07s  Val. loss: 0.1748\n",
      "Epoch 25, 100% \t Train loss: 0.1471 took: 1.08s  Val. loss: 0.1702\n",
      "Epoch 26, 100% \t Train loss: 0.1470 took: 1.07s  Val. loss: 0.1675\n",
      "Epoch 27, 100% \t Train loss: 0.1454 took: 1.07s  Val. loss: 0.1694\n",
      "Epoch 28, 100% \t Train loss: 0.1449 took: 1.06s  Val. loss: 0.1699\n",
      "Epoch 29, 100% \t Train loss: 0.1448 took: 1.07s  Val. loss: 0.1703\n",
      "Epoch 30, 100% \t Train loss: 0.1438 took: 1.08s  Val. loss: 0.1713\n",
      "Epoch 31, 100% \t Train loss: 0.1444 took: 1.08s  Val. loss: 0.1691\n",
      "Epoch 32, 100% \t Train loss: 0.1437 took: 1.08s  Val. loss: 0.1729\n",
      "Epoch 33, 100% \t Train loss: 0.1436 took: 1.08s  Val. loss: 0.1720\n",
      "Epoch 34, 100% \t Train loss: 0.1437 took: 1.07s  Val. loss: 0.1679\n",
      "Epoch 35, 100% \t Train loss: 0.1428 took: 1.07s  Val. loss: 0.1684\n",
      "Epoch 36, 100% \t Train loss: 0.1440 took: 1.09s  Val. loss: 0.1691\n",
      "Epoch 37, 100% \t Train loss: 0.1426 took: 1.09s  Val. loss: 0.1740\n",
      "Epoch 38, 100% \t Train loss: 0.1418 took: 1.09s  Val. loss: 0.1678\n",
      "Epoch 39, 100% \t Train loss: 0.1416 took: 1.09s  Val. loss: 0.1708\n",
      "Epoch 40, 100% \t Train loss: 0.1403 took: 1.09s  Val. loss: 0.1688\n",
      "Epoch 41, 100% \t Train loss: 0.1392 took: 1.10s  Val. loss: 0.1679\n",
      "Epoch 42, 100% \t Train loss: 0.1381 took: 1.17s  Val. loss: 0.1697\n",
      "Epoch 43, 100% \t Train loss: 0.1376 took: 1.09s  Val. loss: 0.1667\n",
      "Epoch 44, 100% \t Train loss: 0.1355 took: 1.09s  Val. loss: 0.1670\n",
      "Epoch 45, 100% \t Train loss: 0.1348 took: 1.09s  Val. loss: 0.1643\n",
      "Epoch 46, 100% \t Train loss: 0.1326 took: 1.10s  Val. loss: 0.1613\n",
      "Epoch 47, 100% \t Train loss: 0.1317 took: 1.09s  Val. loss: 0.1598\n",
      "Epoch 48, 100% \t Train loss: 0.1286 took: 1.09s  Val. loss: 0.1559\n",
      "Epoch 49, 100% \t Train loss: 0.1270 took: 1.42s  Val. loss: 0.1552\n",
      "Epoch 50, 100% \t Train loss: 0.1237 took: 1.85s  Val. loss: 0.1563\n",
      "Training finished, took 69.42s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2601 took: 1.83s  Val. loss: 0.2558\n",
      "Epoch 2, 100% \t Train loss: 0.2596 took: 1.82s  Val. loss: 0.2560\n",
      "Epoch 3, 100% \t Train loss: 0.2593 took: 1.83s  Val. loss: 0.2551\n",
      "Epoch 4, 100% \t Train loss: 0.2589 took: 1.86s  Val. loss: 0.2543\n",
      "Epoch 5, 100% \t Train loss: 0.2568 took: 1.82s  Val. loss: 0.2504\n",
      "Epoch 6, 100% \t Train loss: 0.2451 took: 1.84s  Val. loss: 0.2229\n",
      "Epoch 7, 100% \t Train loss: 0.2177 took: 1.82s  Val. loss: 0.1994\n",
      "Epoch 8, 100% \t Train loss: 0.2026 took: 1.08s  Val. loss: 0.1894\n",
      "Epoch 9, 100% \t Train loss: 0.1931 took: 1.06s  Val. loss: 0.1754\n",
      "Epoch 10, 100% \t Train loss: 0.1900 took: 1.06s  Val. loss: 0.1815\n",
      "Epoch 11, 100% \t Train loss: 0.1866 took: 1.07s  Val. loss: 0.1761\n",
      "Epoch 12, 100% \t Train loss: 0.1822 took: 1.07s  Val. loss: 0.1716\n",
      "Epoch 13, 100% \t Train loss: 0.1878 took: 1.07s  Val. loss: 0.1735\n",
      "Epoch 14, 100% \t Train loss: 0.1803 took: 1.07s  Val. loss: 0.1766\n",
      "Epoch 15, 100% \t Train loss: 0.1796 took: 1.07s  Val. loss: 0.1738\n",
      "Epoch 16, 100% \t Train loss: 0.1788 took: 1.07s  Val. loss: 0.1735\n",
      "Epoch 17, 100% \t Train loss: 0.1769 took: 1.07s  Val. loss: 0.1722\n",
      "Epoch 18, 100% \t Train loss: 0.1757 took: 1.06s  Val. loss: 0.1737\n",
      "Epoch 19, 100% \t Train loss: 0.1740 took: 1.06s  Val. loss: 0.1645\n",
      "Epoch 20, 100% \t Train loss: 0.1760 took: 1.06s  Val. loss: 0.1669\n",
      "Epoch 21, 100% \t Train loss: 0.1740 took: 1.06s  Val. loss: 0.1708\n",
      "Epoch 22, 100% \t Train loss: 0.1732 took: 1.07s  Val. loss: 0.1666\n",
      "Epoch 23, 100% \t Train loss: 0.1722 took: 1.07s  Val. loss: 0.1642\n",
      "Epoch 24, 100% \t Train loss: 0.1706 took: 1.07s  Val. loss: 0.1636\n",
      "Epoch 25, 100% \t Train loss: 0.1715 took: 1.07s  Val. loss: 0.1696\n",
      "Epoch 26, 100% \t Train loss: 0.1697 took: 1.08s  Val. loss: 0.1656\n",
      "Epoch 27, 100% \t Train loss: 0.1699 took: 1.08s  Val. loss: 0.1687\n",
      "Epoch 28, 100% \t Train loss: 0.1704 took: 1.08s  Val. loss: 0.1650\n",
      "Epoch 29, 100% \t Train loss: 0.1708 took: 1.08s  Val. loss: 0.1663\n",
      "Epoch 30, 100% \t Train loss: 0.1688 took: 1.09s  Val. loss: 0.1648\n",
      "Epoch 31, 100% \t Train loss: 0.1699 took: 1.09s  Val. loss: 0.1637\n",
      "Epoch 32, 100% \t Train loss: 0.1677 took: 1.10s  Val. loss: 0.1664\n",
      "Epoch 33, 100% \t Train loss: 0.1713 took: 1.10s  Val. loss: 0.1658\n",
      "Epoch 34, 100% \t Train loss: 0.1663 took: 1.10s  Val. loss: 0.1678\n",
      "Epoch 35, 100% \t Train loss: 0.1667 took: 1.10s  Val. loss: 0.1626\n",
      "Epoch 36, 100% \t Train loss: 0.1679 took: 1.09s  Val. loss: 0.1636\n",
      "Epoch 37, 100% \t Train loss: 0.1657 took: 1.09s  Val. loss: 0.1675\n",
      "Epoch 38, 100% \t Train loss: 0.1682 took: 1.09s  Val. loss: 0.1642\n",
      "Epoch 39, 100% \t Train loss: 0.1666 took: 1.10s  Val. loss: 0.1673\n",
      "Epoch 40, 100% \t Train loss: 0.1669 took: 1.10s  Val. loss: 0.1623\n",
      "Epoch 41, 100% \t Train loss: 0.1647 took: 1.10s  Val. loss: 0.1657\n",
      "Epoch 42, 100% \t Train loss: 0.1647 took: 1.10s  Val. loss: 0.1703\n",
      "Epoch 43, 100% \t Train loss: 0.1659 took: 1.10s  Val. loss: 0.1617\n",
      "Epoch 44, 100% \t Train loss: 0.1649 took: 1.11s  Val. loss: 0.1649\n",
      "Epoch 45, 100% \t Train loss: 0.1661 took: 1.58s  Val. loss: 0.1640\n",
      "Epoch 46, 100% \t Train loss: 0.1632 took: 1.88s  Val. loss: 0.1611\n",
      "Epoch 47, 100% \t Train loss: 0.1625 took: 1.88s  Val. loss: 0.1660\n",
      "Epoch 48, 100% \t Train loss: 0.1652 took: 1.90s  Val. loss: 0.1639\n",
      "Epoch 49, 100% \t Train loss: 0.1647 took: 1.88s  Val. loss: 0.1646\n",
      "Epoch 50, 100% \t Train loss: 0.1639 took: 1.13s  Val. loss: 0.1633\n",
      "Training finished, took 71.31s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.23\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.741595\n",
      "lambda: 0.0010 - V: 0.828372\n",
      "lambda: 0.0005 - V: 0.821506\n",
      "Average V: 0.797158\n",
      "Time elapsed: 233.18 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.40\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.31\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2574 took: 1.05s  Val. loss: 0.2526\n",
      "Epoch 2, 100% \t Train loss: 0.2347 took: 1.04s  Val. loss: 0.1847\n",
      "Epoch 3, 100% \t Train loss: 0.1726 took: 1.04s  Val. loss: 0.1765\n",
      "Epoch 4, 100% \t Train loss: 0.1637 took: 1.05s  Val. loss: 0.1655\n",
      "Epoch 5, 100% \t Train loss: 0.1596 took: 1.05s  Val. loss: 0.1677\n",
      "Epoch 6, 100% \t Train loss: 0.1578 took: 1.04s  Val. loss: 0.1636\n",
      "Epoch 7, 100% \t Train loss: 0.1560 took: 1.04s  Val. loss: 0.1621\n",
      "Epoch 8, 100% \t Train loss: 0.1545 took: 1.04s  Val. loss: 0.1625\n",
      "Epoch 9, 100% \t Train loss: 0.1540 took: 1.05s  Val. loss: 0.1617\n",
      "Epoch 10, 100% \t Train loss: 0.1537 took: 1.04s  Val. loss: 0.1643\n",
      "Epoch 11, 100% \t Train loss: 0.1522 took: 1.04s  Val. loss: 0.1606\n",
      "Epoch 12, 100% \t Train loss: 0.1518 took: 1.04s  Val. loss: 0.1621\n",
      "Epoch 13, 100% \t Train loss: 0.1506 took: 1.04s  Val. loss: 0.1617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.1499 took: 1.04s  Val. loss: 0.1646\n",
      "Epoch 15, 100% \t Train loss: 0.1488 took: 1.03s  Val. loss: 0.1615\n",
      "Epoch 16, 100% \t Train loss: 0.1481 took: 1.03s  Val. loss: 0.1584\n",
      "Epoch 17, 100% \t Train loss: 0.1466 took: 1.04s  Val. loss: 0.1641\n",
      "Epoch 18, 100% \t Train loss: 0.1461 took: 1.03s  Val. loss: 0.1601\n",
      "Epoch 19, 100% \t Train loss: 0.1438 took: 1.04s  Val. loss: 0.1572\n",
      "Epoch 20, 100% \t Train loss: 0.1428 took: 1.04s  Val. loss: 0.1565\n",
      "Epoch 21, 100% \t Train loss: 0.1393 took: 1.03s  Val. loss: 0.1522\n",
      "Epoch 22, 100% \t Train loss: 0.1354 took: 1.03s  Val. loss: 0.1451\n",
      "Epoch 23, 100% \t Train loss: 0.1290 took: 1.04s  Val. loss: 0.1421\n",
      "Epoch 24, 100% \t Train loss: 0.1238 took: 1.03s  Val. loss: 0.1320\n",
      "Epoch 25, 100% \t Train loss: 0.1173 took: 1.04s  Val. loss: 0.1295\n",
      "Epoch 26, 100% \t Train loss: 0.1134 took: 1.04s  Val. loss: 0.1269\n",
      "Epoch 27, 100% \t Train loss: 0.1074 took: 1.03s  Val. loss: 0.1185\n",
      "Epoch 28, 100% \t Train loss: 0.1046 took: 1.03s  Val. loss: 0.1174\n",
      "Epoch 29, 100% \t Train loss: 0.1003 took: 1.05s  Val. loss: 0.1102\n",
      "Epoch 30, 100% \t Train loss: 0.0962 took: 1.06s  Val. loss: 0.1078\n",
      "Epoch 31, 100% \t Train loss: 0.0955 took: 1.06s  Val. loss: 0.1091\n",
      "Epoch 32, 100% \t Train loss: 0.0918 took: 1.08s  Val. loss: 0.1094\n",
      "Epoch 33, 100% \t Train loss: 0.0898 took: 1.16s  Val. loss: 0.1044\n",
      "Epoch 34, 100% \t Train loss: 0.0872 took: 1.21s  Val. loss: 0.1024\n",
      "Epoch 35, 100% \t Train loss: 0.0855 took: 1.21s  Val. loss: 0.1034\n",
      "Epoch 36, 100% \t Train loss: 0.0860 took: 1.22s  Val. loss: 0.1004\n",
      "Epoch 37, 100% \t Train loss: 0.0848 took: 1.22s  Val. loss: 0.1016\n",
      "Epoch 38, 100% \t Train loss: 0.0837 took: 1.21s  Val. loss: 0.1020\n",
      "Epoch 39, 100% \t Train loss: 0.0831 took: 1.21s  Val. loss: 0.1025\n",
      "Epoch 40, 100% \t Train loss: 0.0828 took: 1.84s  Val. loss: 0.1014\n",
      "Epoch 41, 100% \t Train loss: 0.0835 took: 1.99s  Val. loss: 0.0997\n",
      "Epoch 42, 100% \t Train loss: 0.0812 took: 1.99s  Val. loss: 0.0980\n",
      "Epoch 43, 100% \t Train loss: 0.0818 took: 2.01s  Val. loss: 0.0955\n",
      "Epoch 44, 100% \t Train loss: 0.0801 took: 2.01s  Val. loss: 0.0995\n",
      "Epoch 45, 100% \t Train loss: 0.0792 took: 2.03s  Val. loss: 0.0961\n",
      "Epoch 46, 100% \t Train loss: 0.0790 took: 2.03s  Val. loss: 0.0980\n",
      "Epoch 47, 100% \t Train loss: 0.0786 took: 2.03s  Val. loss: 0.1003\n",
      "Epoch 48, 100% \t Train loss: 0.0781 took: 2.02s  Val. loss: 0.1038\n",
      "Epoch 49, 100% \t Train loss: 0.0787 took: 2.02s  Val. loss: 0.0993\n",
      "Epoch 50, 100% \t Train loss: 0.0775 took: 2.02s  Val. loss: 0.0988\n",
      "Training finished, took 72.38s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.82s  Val. loss: 0.2603\n",
      "Epoch 2, 100% \t Train loss: 0.2581 took: 1.82s  Val. loss: 0.2606\n",
      "Epoch 3, 100% \t Train loss: 0.2491 took: 1.80s  Val. loss: 0.2281\n",
      "Epoch 4, 100% \t Train loss: 0.1964 took: 1.79s  Val. loss: 0.1752\n",
      "Epoch 5, 100% \t Train loss: 0.1763 took: 1.81s  Val. loss: 0.1724\n",
      "Epoch 6, 100% \t Train loss: 0.1740 took: 1.81s  Val. loss: 0.1700\n",
      "Epoch 7, 100% \t Train loss: 0.1715 took: 1.81s  Val. loss: 0.1742\n",
      "Epoch 8, 100% \t Train loss: 0.1713 took: 1.82s  Val. loss: 0.1712\n",
      "Epoch 9, 100% \t Train loss: 0.1691 took: 1.80s  Val. loss: 0.1713\n",
      "Epoch 10, 100% \t Train loss: 0.1693 took: 1.81s  Val. loss: 0.1685\n",
      "Epoch 11, 100% \t Train loss: 0.1677 took: 1.05s  Val. loss: 0.1690\n",
      "Epoch 12, 100% \t Train loss: 0.1661 took: 1.04s  Val. loss: 0.1694\n",
      "Epoch 13, 100% \t Train loss: 0.1650 took: 1.04s  Val. loss: 0.1668\n",
      "Epoch 14, 100% \t Train loss: 0.1640 took: 1.04s  Val. loss: 0.1662\n",
      "Epoch 15, 100% \t Train loss: 0.1645 took: 1.05s  Val. loss: 0.1683\n",
      "Epoch 16, 100% \t Train loss: 0.1623 took: 1.04s  Val. loss: 0.1626\n",
      "Epoch 17, 100% \t Train loss: 0.1601 took: 1.05s  Val. loss: 0.1632\n",
      "Epoch 18, 100% \t Train loss: 0.1580 took: 1.05s  Val. loss: 0.1614\n",
      "Epoch 19, 100% \t Train loss: 0.1585 took: 1.05s  Val. loss: 0.1631\n",
      "Epoch 20, 100% \t Train loss: 0.1568 took: 1.05s  Val. loss: 0.1624\n",
      "Epoch 21, 100% \t Train loss: 0.1561 took: 1.04s  Val. loss: 0.1586\n",
      "Epoch 22, 100% \t Train loss: 0.1540 took: 1.39s  Val. loss: 0.1625\n",
      "Epoch 23, 100% \t Train loss: 0.1549 took: 1.82s  Val. loss: 0.1574\n",
      "Epoch 24, 100% \t Train loss: 0.1527 took: 1.79s  Val. loss: 0.1570\n",
      "Epoch 25, 100% \t Train loss: 0.1523 took: 1.79s  Val. loss: 0.1536\n",
      "Epoch 26, 100% \t Train loss: 0.1489 took: 1.79s  Val. loss: 0.1539\n",
      "Epoch 27, 100% \t Train loss: 0.1480 took: 1.80s  Val. loss: 0.1505\n",
      "Epoch 28, 100% \t Train loss: 0.1431 took: 1.80s  Val. loss: 0.1488\n",
      "Epoch 29, 100% \t Train loss: 0.1407 took: 1.80s  Val. loss: 0.1451\n",
      "Epoch 30, 100% \t Train loss: 0.1365 took: 1.82s  Val. loss: 0.1399\n",
      "Epoch 31, 100% \t Train loss: 0.1325 took: 1.82s  Val. loss: 0.1378\n",
      "Epoch 32, 100% \t Train loss: 0.1269 took: 1.82s  Val. loss: 0.1322\n",
      "Epoch 33, 100% \t Train loss: 0.1221 took: 1.82s  Val. loss: 0.1297\n",
      "Epoch 34, 100% \t Train loss: 0.1187 took: 1.82s  Val. loss: 0.1236\n",
      "Epoch 35, 100% \t Train loss: 0.1157 took: 1.60s  Val. loss: 0.1305\n",
      "Epoch 36, 100% \t Train loss: 0.1132 took: 1.84s  Val. loss: 0.1201\n",
      "Epoch 37, 100% \t Train loss: 0.1093 took: 1.07s  Val. loss: 0.1215\n",
      "Epoch 38, 100% \t Train loss: 0.1080 took: 1.07s  Val. loss: 0.1172\n",
      "Epoch 39, 100% \t Train loss: 0.1097 took: 1.08s  Val. loss: 0.1132\n",
      "Epoch 40, 100% \t Train loss: 0.1037 took: 1.08s  Val. loss: 0.1120\n",
      "Epoch 41, 100% \t Train loss: 0.1017 took: 1.08s  Val. loss: 0.1101\n",
      "Epoch 42, 100% \t Train loss: 0.1007 took: 1.08s  Val. loss: 0.1103\n",
      "Epoch 43, 100% \t Train loss: 0.0994 took: 1.09s  Val. loss: 0.1136\n",
      "Epoch 44, 100% \t Train loss: 0.0981 took: 1.09s  Val. loss: 0.1076\n",
      "Epoch 45, 100% \t Train loss: 0.0971 took: 1.09s  Val. loss: 0.1056\n",
      "Epoch 46, 100% \t Train loss: 0.0962 took: 1.09s  Val. loss: 0.1026\n",
      "Epoch 47, 100% \t Train loss: 0.0941 took: 1.10s  Val. loss: 0.1014\n",
      "Epoch 48, 100% \t Train loss: 0.0942 took: 1.11s  Val. loss: 0.1025\n",
      "Epoch 49, 100% \t Train loss: 0.0921 took: 1.12s  Val. loss: 0.0965\n",
      "Epoch 50, 100% \t Train loss: 0.0908 took: 1.11s  Val. loss: 0.0993\n",
      "Training finished, took 81.04s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2595 took: 1.05s  Val. loss: 0.2606\n",
      "Epoch 2, 100% \t Train loss: 0.2591 took: 1.05s  Val. loss: 0.2588\n",
      "Epoch 3, 100% \t Train loss: 0.2590 took: 1.04s  Val. loss: 0.2604\n",
      "Epoch 4, 100% \t Train loss: 0.2591 took: 1.04s  Val. loss: 0.2590\n",
      "Epoch 5, 100% \t Train loss: 0.2591 took: 1.04s  Val. loss: 0.2585\n",
      "Epoch 6, 100% \t Train loss: 0.2589 took: 1.04s  Val. loss: 0.2583\n",
      "Epoch 7, 100% \t Train loss: 0.2588 took: 1.51s  Val. loss: 0.2595\n",
      "Epoch 8, 100% \t Train loss: 0.2585 took: 1.79s  Val. loss: 0.2593\n",
      "Epoch 9, 100% \t Train loss: 0.2573 took: 1.79s  Val. loss: 0.2579\n",
      "Epoch 10, 100% \t Train loss: 0.2538 took: 1.81s  Val. loss: 0.2506\n",
      "Epoch 11, 100% \t Train loss: 0.2432 took: 1.80s  Val. loss: 0.2374\n",
      "Epoch 12, 100% \t Train loss: 0.2279 took: 1.80s  Val. loss: 0.2246\n",
      "Epoch 13, 100% \t Train loss: 0.2198 took: 1.80s  Val. loss: 0.2178\n",
      "Epoch 14, 100% \t Train loss: 0.2141 took: 1.80s  Val. loss: 0.2175\n",
      "Epoch 15, 100% \t Train loss: 0.2064 took: 1.79s  Val. loss: 0.2061\n",
      "Epoch 16, 100% \t Train loss: 0.1994 took: 1.80s  Val. loss: 0.1978\n",
      "Epoch 17, 100% \t Train loss: 0.1956 took: 1.81s  Val. loss: 0.1882\n",
      "Epoch 18, 100% \t Train loss: 0.1910 took: 1.80s  Val. loss: 0.1853\n",
      "Epoch 19, 100% \t Train loss: 0.1901 took: 1.83s  Val. loss: 0.1860\n",
      "Epoch 20, 100% \t Train loss: 0.1876 took: 1.79s  Val. loss: 0.1824\n",
      "Epoch 21, 100% \t Train loss: 0.1864 took: 1.82s  Val. loss: 0.1843\n",
      "Epoch 22, 100% \t Train loss: 0.1856 took: 1.81s  Val. loss: 0.1811\n",
      "Epoch 23, 100% \t Train loss: 0.1864 took: 1.80s  Val. loss: 0.1792\n",
      "Epoch 24, 100% \t Train loss: 0.1841 took: 1.80s  Val. loss: 0.1826\n",
      "Epoch 25, 100% \t Train loss: 0.1825 took: 1.80s  Val. loss: 0.1807\n",
      "Epoch 26, 100% \t Train loss: 0.1819 took: 1.80s  Val. loss: 0.1796\n",
      "Epoch 27, 100% \t Train loss: 0.1805 took: 1.80s  Val. loss: 0.1788\n",
      "Epoch 28, 100% \t Train loss: 0.1792 took: 1.80s  Val. loss: 0.1773\n",
      "Epoch 29, 100% \t Train loss: 0.1791 took: 1.80s  Val. loss: 0.1771\n",
      "Epoch 30, 100% \t Train loss: 0.1772 took: 1.81s  Val. loss: 0.1795\n",
      "Epoch 31, 100% \t Train loss: 0.1762 took: 1.81s  Val. loss: 0.1784\n",
      "Epoch 32, 100% \t Train loss: 0.1758 took: 1.81s  Val. loss: 0.1809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, 100% \t Train loss: 0.1732 took: 1.82s  Val. loss: 0.1762\n",
      "Epoch 34, 100% \t Train loss: 0.1734 took: 1.83s  Val. loss: 0.1727\n",
      "Epoch 35, 100% \t Train loss: 0.1713 took: 1.81s  Val. loss: 0.1725\n",
      "Epoch 36, 100% \t Train loss: 0.1716 took: 1.82s  Val. loss: 0.1752\n",
      "Epoch 37, 100% \t Train loss: 0.1725 took: 1.85s  Val. loss: 0.1767\n",
      "Epoch 38, 100% \t Train loss: 0.1700 took: 1.83s  Val. loss: 0.1717\n",
      "Epoch 39, 100% \t Train loss: 0.1695 took: 1.82s  Val. loss: 0.1698\n",
      "Epoch 40, 100% \t Train loss: 0.1697 took: 1.85s  Val. loss: 0.1681\n",
      "Epoch 41, 100% \t Train loss: 0.1671 took: 1.83s  Val. loss: 0.1726\n",
      "Epoch 42, 100% \t Train loss: 0.1697 took: 1.80s  Val. loss: 0.1747\n",
      "Epoch 43, 100% \t Train loss: 0.1681 took: 1.83s  Val. loss: 0.1716\n",
      "Epoch 44, 100% \t Train loss: 0.1682 took: 1.80s  Val. loss: 0.1675\n",
      "Epoch 45, 100% \t Train loss: 0.1665 took: 1.79s  Val. loss: 0.1763\n",
      "Epoch 46, 100% \t Train loss: 0.1657 took: 1.80s  Val. loss: 0.1744\n",
      "Epoch 47, 100% \t Train loss: 0.1641 took: 1.80s  Val. loss: 0.1690\n",
      "Epoch 48, 100% \t Train loss: 0.1640 took: 1.81s  Val. loss: 0.1666\n",
      "Epoch 49, 100% \t Train loss: 0.1634 took: 1.80s  Val. loss: 0.1706\n",
      "Epoch 50, 100% \t Train loss: 0.1645 took: 1.82s  Val. loss: 0.1687\n",
      "Training finished, took 97.52s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.40\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.31\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.866496\n",
      "lambda: 0.0010 - V: 0.851630\n",
      "lambda: 0.0005 - V: 0.802389\n",
      "Average V: 0.840172\n",
      "Time elapsed: 254.39 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.40\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2598 took: 1.85s  Val. loss: 0.2575\n",
      "Epoch 2, 100% \t Train loss: 0.2161 took: 1.86s  Val. loss: 0.1919\n",
      "Epoch 3, 100% \t Train loss: 0.1770 took: 1.86s  Val. loss: 0.1812\n",
      "Epoch 4, 100% \t Train loss: 0.1703 took: 1.88s  Val. loss: 0.1773\n",
      "Epoch 5, 100% \t Train loss: 0.1637 took: 1.88s  Val. loss: 0.1664\n",
      "Epoch 6, 100% \t Train loss: 0.1578 took: 1.86s  Val. loss: 0.1592\n",
      "Epoch 7, 100% \t Train loss: 0.1508 took: 1.85s  Val. loss: 0.1500\n",
      "Epoch 8, 100% \t Train loss: 0.1328 took: 1.84s  Val. loss: 0.1329\n",
      "Epoch 9, 100% \t Train loss: 0.1153 took: 1.86s  Val. loss: 0.1248\n",
      "Epoch 10, 100% \t Train loss: 0.1040 took: 1.87s  Val. loss: 0.1133\n",
      "Epoch 11, 100% \t Train loss: 0.0931 took: 1.85s  Val. loss: 0.1018\n",
      "Epoch 12, 100% \t Train loss: 0.0889 took: 1.85s  Val. loss: 0.1003\n",
      "Epoch 13, 100% \t Train loss: 0.0868 took: 1.85s  Val. loss: 0.1052\n",
      "Epoch 14, 100% \t Train loss: 0.0852 took: 1.85s  Val. loss: 0.0957\n",
      "Epoch 15, 100% \t Train loss: 0.0837 took: 1.85s  Val. loss: 0.0976\n",
      "Epoch 16, 100% \t Train loss: 0.0831 took: 1.85s  Val. loss: 0.0934\n",
      "Epoch 17, 100% \t Train loss: 0.0807 took: 1.85s  Val. loss: 0.0899\n",
      "Epoch 18, 100% \t Train loss: 0.0793 took: 1.85s  Val. loss: 0.0944\n",
      "Epoch 19, 100% \t Train loss: 0.0782 took: 1.86s  Val. loss: 0.0926\n",
      "Epoch 20, 100% \t Train loss: 0.0766 took: 1.86s  Val. loss: 0.0944\n",
      "Epoch 21, 100% \t Train loss: 0.0771 took: 1.86s  Val. loss: 0.0948\n",
      "Epoch 22, 100% \t Train loss: 0.0764 took: 1.84s  Val. loss: 0.0950\n",
      "Epoch 23, 100% \t Train loss: 0.0760 took: 1.85s  Val. loss: 0.0902\n",
      "Epoch 24, 100% \t Train loss: 0.0751 took: 1.85s  Val. loss: 0.0926\n",
      "Epoch 25, 100% \t Train loss: 0.0742 took: 1.84s  Val. loss: 0.0933\n",
      "Epoch 26, 100% \t Train loss: 0.0733 took: 1.83s  Val. loss: 0.0900\n",
      "Epoch 27, 100% \t Train loss: 0.0726 took: 1.84s  Val. loss: 0.0917\n",
      "Epoch 28, 100% \t Train loss: 0.0743 took: 1.84s  Val. loss: 0.0938\n",
      "Epoch 29, 100% \t Train loss: 0.0728 took: 1.86s  Val. loss: 0.0933\n",
      "Epoch 30, 100% \t Train loss: 0.0722 took: 1.84s  Val. loss: 0.0923\n",
      "Epoch 31, 100% \t Train loss: 0.0720 took: 1.85s  Val. loss: 0.0912\n",
      "Epoch 32, 100% \t Train loss: 0.0721 took: 1.85s  Val. loss: 0.0879\n",
      "Epoch 33, 100% \t Train loss: 0.0712 took: 1.87s  Val. loss: 0.0929\n",
      "Epoch 34, 100% \t Train loss: 0.0724 took: 1.87s  Val. loss: 0.0899\n",
      "Epoch 35, 100% \t Train loss: 0.0709 took: 1.86s  Val. loss: 0.0918\n",
      "Epoch 36, 100% \t Train loss: 0.0705 took: 1.84s  Val. loss: 0.0904\n",
      "Epoch 37, 100% \t Train loss: 0.0699 took: 1.86s  Val. loss: 0.0924\n",
      "Epoch 38, 100% \t Train loss: 0.0704 took: 1.86s  Val. loss: 0.0927\n",
      "Epoch 39, 100% \t Train loss: 0.0700 took: 1.87s  Val. loss: 0.0911\n",
      "Epoch 40, 100% \t Train loss: 0.0686 took: 1.87s  Val. loss: 0.0889\n",
      "Epoch 41, 100% \t Train loss: 0.0699 took: 1.88s  Val. loss: 0.0917\n",
      "Epoch 42, 100% \t Train loss: 0.0696 took: 1.86s  Val. loss: 0.0910\n",
      "Epoch 43, 100% \t Train loss: 0.0690 took: 1.85s  Val. loss: 0.0957\n",
      "Epoch 44, 100% \t Train loss: 0.0689 took: 1.85s  Val. loss: 0.0907\n",
      "Epoch 45, 100% \t Train loss: 0.0689 took: 1.87s  Val. loss: 0.0942\n",
      "Epoch 46, 100% \t Train loss: 0.0677 took: 1.86s  Val. loss: 0.0941\n",
      "Epoch 47, 100% \t Train loss: 0.0691 took: 1.87s  Val. loss: 0.0908\n",
      "Epoch 48, 100% \t Train loss: 0.0672 took: 1.86s  Val. loss: 0.0942\n",
      "Epoch 49, 100% \t Train loss: 0.0670 took: 1.86s  Val. loss: 0.0911\n",
      "Epoch 50, 100% \t Train loss: 0.0670 took: 1.86s  Val. loss: 0.0938\n",
      "Training finished, took 105.39s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 1.86s  Val. loss: 0.2567\n",
      "Epoch 2, 100% \t Train loss: 0.2561 took: 1.82s  Val. loss: 0.2557\n",
      "Epoch 3, 100% \t Train loss: 0.2545 took: 1.84s  Val. loss: 0.2523\n",
      "Epoch 4, 100% \t Train loss: 0.2395 took: 1.85s  Val. loss: 0.2220\n",
      "Epoch 5, 100% \t Train loss: 0.2036 took: 1.85s  Val. loss: 0.1864\n",
      "Epoch 6, 100% \t Train loss: 0.1821 took: 1.85s  Val. loss: 0.1928\n",
      "Epoch 7, 100% \t Train loss: 0.1778 took: 1.85s  Val. loss: 0.1782\n",
      "Epoch 8, 100% \t Train loss: 0.1777 took: 1.87s  Val. loss: 0.1832\n",
      "Epoch 9, 100% \t Train loss: 0.1756 took: 1.86s  Val. loss: 0.1857\n",
      "Epoch 10, 100% \t Train loss: 0.1715 took: 1.85s  Val. loss: 0.1784\n",
      "Epoch 11, 100% \t Train loss: 0.1696 took: 1.85s  Val. loss: 0.1751\n",
      "Epoch 12, 100% \t Train loss: 0.1752 took: 1.85s  Val. loss: 0.1791\n",
      "Epoch 13, 100% \t Train loss: 0.1693 took: 1.62s  Val. loss: 0.1749\n",
      "Epoch 14, 100% \t Train loss: 0.1680 took: 1.08s  Val. loss: 0.1749\n",
      "Epoch 15, 100% \t Train loss: 0.1674 took: 1.09s  Val. loss: 0.1762\n",
      "Epoch 16, 100% \t Train loss: 0.1655 took: 1.09s  Val. loss: 0.1693\n",
      "Epoch 17, 100% \t Train loss: 0.1657 took: 1.08s  Val. loss: 0.1704\n",
      "Epoch 18, 100% \t Train loss: 0.1627 took: 1.09s  Val. loss: 0.1732\n",
      "Epoch 19, 100% \t Train loss: 0.1634 took: 1.08s  Val. loss: 0.1680\n",
      "Epoch 20, 100% \t Train loss: 0.1620 took: 1.08s  Val. loss: 0.1666\n",
      "Epoch 21, 100% \t Train loss: 0.1620 took: 1.08s  Val. loss: 0.1651\n",
      "Epoch 22, 100% \t Train loss: 0.1606 took: 1.09s  Val. loss: 0.1639\n",
      "Epoch 23, 100% \t Train loss: 0.1590 took: 1.08s  Val. loss: 0.1613\n",
      "Epoch 24, 100% \t Train loss: 0.1576 took: 1.08s  Val. loss: 0.1637\n",
      "Epoch 25, 100% \t Train loss: 0.1584 took: 1.09s  Val. loss: 0.1640\n",
      "Epoch 26, 100% \t Train loss: 0.1582 took: 1.09s  Val. loss: 0.1632\n",
      "Epoch 27, 100% \t Train loss: 0.1558 took: 1.09s  Val. loss: 0.1616\n",
      "Epoch 28, 100% \t Train loss: 0.1561 took: 1.10s  Val. loss: 0.1598\n",
      "Epoch 29, 100% \t Train loss: 0.1548 took: 1.12s  Val. loss: 0.1580\n",
      "Epoch 30, 100% \t Train loss: 0.1539 took: 1.59s  Val. loss: 0.1622\n",
      "Epoch 31, 100% \t Train loss: 0.1551 took: 1.90s  Val. loss: 0.1656\n",
      "Epoch 32, 100% \t Train loss: 0.1525 took: 1.91s  Val. loss: 0.1576\n",
      "Epoch 33, 100% \t Train loss: 0.1519 took: 1.92s  Val. loss: 0.1575\n",
      "Epoch 34, 100% \t Train loss: 0.1500 took: 1.92s  Val. loss: 0.1561\n",
      "Epoch 35, 100% \t Train loss: 0.1481 took: 1.93s  Val. loss: 0.1567\n",
      "Epoch 36, 100% \t Train loss: 0.1476 took: 1.94s  Val. loss: 0.1545\n",
      "Epoch 37, 100% \t Train loss: 0.1443 took: 1.94s  Val. loss: 0.1531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, 100% \t Train loss: 0.1441 took: 1.95s  Val. loss: 0.1523\n",
      "Epoch 39, 100% \t Train loss: 0.1434 took: 1.95s  Val. loss: 0.1463\n",
      "Epoch 40, 100% \t Train loss: 0.1413 took: 1.98s  Val. loss: 0.1513\n",
      "Epoch 41, 100% \t Train loss: 0.1399 took: 1.99s  Val. loss: 0.1415\n",
      "Epoch 42, 100% \t Train loss: 0.1366 took: 1.99s  Val. loss: 0.1438\n",
      "Epoch 43, 100% \t Train loss: 0.1344 took: 1.99s  Val. loss: 0.1397\n",
      "Epoch 44, 100% \t Train loss: 0.1306 took: 2.00s  Val. loss: 0.1394\n",
      "Epoch 45, 100% \t Train loss: 0.1279 took: 2.01s  Val. loss: 0.1347\n",
      "Epoch 46, 100% \t Train loss: 0.1265 took: 2.03s  Val. loss: 0.1372\n",
      "Epoch 47, 100% \t Train loss: 0.1220 took: 2.03s  Val. loss: 0.1297\n",
      "Epoch 48, 100% \t Train loss: 0.1200 took: 2.04s  Val. loss: 0.1282\n",
      "Epoch 49, 100% \t Train loss: 0.1183 took: 1.97s  Val. loss: 0.1279\n",
      "Epoch 50, 100% \t Train loss: 0.1148 took: 1.95s  Val. loss: 0.1207\n",
      "Training finished, took 92.89s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2575 took: 1.87s  Val. loss: 0.2543\n",
      "Epoch 2, 100% \t Train loss: 0.2567 took: 1.85s  Val. loss: 0.2545\n",
      "Epoch 3, 100% \t Train loss: 0.2542 took: 1.86s  Val. loss: 0.2473\n",
      "Epoch 4, 100% \t Train loss: 0.2363 took: 1.85s  Val. loss: 0.2162\n",
      "Epoch 5, 100% \t Train loss: 0.2067 took: 1.86s  Val. loss: 0.2003\n",
      "Epoch 6, 100% \t Train loss: 0.1869 took: 1.87s  Val. loss: 0.1889\n",
      "Epoch 7, 100% \t Train loss: 0.1780 took: 1.86s  Val. loss: 0.1897\n",
      "Epoch 8, 100% \t Train loss: 0.1761 took: 1.86s  Val. loss: 0.1913\n",
      "Epoch 9, 100% \t Train loss: 0.1735 took: 1.85s  Val. loss: 0.1860\n",
      "Epoch 10, 100% \t Train loss: 0.1715 took: 1.86s  Val. loss: 0.1905\n",
      "Epoch 11, 100% \t Train loss: 0.1708 took: 1.86s  Val. loss: 0.1865\n",
      "Epoch 12, 100% \t Train loss: 0.1708 took: 1.86s  Val. loss: 0.1921\n",
      "Epoch 13, 100% \t Train loss: 0.1687 took: 1.87s  Val. loss: 0.1829\n",
      "Epoch 14, 100% \t Train loss: 0.1682 took: 1.87s  Val. loss: 0.1828\n",
      "Epoch 15, 100% \t Train loss: 0.1664 took: 1.85s  Val. loss: 0.1828\n",
      "Epoch 16, 100% \t Train loss: 0.1659 took: 1.85s  Val. loss: 0.1819\n",
      "Epoch 17, 100% \t Train loss: 0.1637 took: 1.84s  Val. loss: 0.1856\n",
      "Epoch 18, 100% \t Train loss: 0.1654 took: 1.84s  Val. loss: 0.1832\n",
      "Epoch 19, 100% \t Train loss: 0.1623 took: 1.86s  Val. loss: 0.1817\n",
      "Epoch 20, 100% \t Train loss: 0.1615 took: 1.86s  Val. loss: 0.1818\n",
      "Epoch 21, 100% \t Train loss: 0.1624 took: 1.85s  Val. loss: 0.1811\n",
      "Epoch 22, 100% \t Train loss: 0.1598 took: 1.86s  Val. loss: 0.1789\n",
      "Epoch 23, 100% \t Train loss: 0.1605 took: 1.85s  Val. loss: 0.1788\n",
      "Epoch 24, 100% \t Train loss: 0.1602 took: 1.86s  Val. loss: 0.1845\n",
      "Epoch 25, 100% \t Train loss: 0.1576 took: 1.86s  Val. loss: 0.1779\n",
      "Epoch 26, 100% \t Train loss: 0.1573 took: 1.85s  Val. loss: 0.1791\n",
      "Epoch 27, 100% \t Train loss: 0.1565 took: 1.85s  Val. loss: 0.1777\n",
      "Epoch 28, 100% \t Train loss: 0.1596 took: 1.85s  Val. loss: 0.1783\n",
      "Epoch 29, 100% \t Train loss: 0.1553 took: 1.49s  Val. loss: 0.1776\n",
      "Epoch 30, 100% \t Train loss: 0.1536 took: 1.10s  Val. loss: 0.1773\n",
      "Epoch 31, 100% \t Train loss: 0.1551 took: 1.10s  Val. loss: 0.1752\n",
      "Epoch 32, 100% \t Train loss: 0.1525 took: 1.10s  Val. loss: 0.1736\n",
      "Epoch 33, 100% \t Train loss: 0.1503 took: 1.10s  Val. loss: 0.1743\n",
      "Epoch 34, 100% \t Train loss: 0.1478 took: 1.10s  Val. loss: 0.1765\n",
      "Epoch 35, 100% \t Train loss: 0.1469 took: 1.10s  Val. loss: 0.1687\n",
      "Epoch 36, 100% \t Train loss: 0.1441 took: 1.69s  Val. loss: 0.1651\n",
      "Epoch 37, 100% \t Train loss: 0.1420 took: 1.91s  Val. loss: 0.1652\n",
      "Epoch 38, 100% \t Train loss: 0.1393 took: 1.91s  Val. loss: 0.1599\n",
      "Epoch 39, 100% \t Train loss: 0.1376 took: 1.89s  Val. loss: 0.1678\n",
      "Epoch 40, 100% \t Train loss: 0.1347 took: 1.91s  Val. loss: 0.1546\n",
      "Epoch 41, 100% \t Train loss: 0.1320 took: 1.94s  Val. loss: 0.1518\n",
      "Epoch 42, 100% \t Train loss: 0.1307 took: 1.93s  Val. loss: 0.1497\n",
      "Epoch 43, 100% \t Train loss: 0.1268 took: 1.90s  Val. loss: 0.1471\n",
      "Epoch 44, 100% \t Train loss: 0.1239 took: 1.93s  Val. loss: 0.1422\n",
      "Epoch 45, 100% \t Train loss: 0.1221 took: 1.92s  Val. loss: 0.1421\n",
      "Epoch 46, 100% \t Train loss: 0.1192 took: 1.95s  Val. loss: 0.1341\n",
      "Epoch 47, 100% \t Train loss: 0.1174 took: 1.93s  Val. loss: 0.1321\n",
      "Epoch 48, 100% \t Train loss: 0.1155 took: 1.94s  Val. loss: 0.1318\n",
      "Epoch 49, 100% \t Train loss: 0.1151 took: 1.96s  Val. loss: 0.1305\n",
      "Epoch 50, 100% \t Train loss: 0.1104 took: 1.96s  Val. loss: 0.1287\n",
      "Training finished, took 100.39s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.40\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.892326\n",
      "lambda: 0.0010 - V: 0.833281\n",
      "lambda: 0.0005 - V: 0.823545\n",
      "Average V: 0.849717\n",
      "Time elapsed: 302.08 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.38\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2609 took: 1.90s  Val. loss: 0.2625\n",
      "Epoch 2, 100% \t Train loss: 0.2604 took: 1.92s  Val. loss: 0.2588\n",
      "Epoch 3, 100% \t Train loss: 0.2598 took: 1.87s  Val. loss: 0.2597\n",
      "Epoch 4, 100% \t Train loss: 0.2597 took: 1.87s  Val. loss: 0.2601\n",
      "Epoch 5, 100% \t Train loss: 0.2595 took: 1.87s  Val. loss: 0.2579\n",
      "Epoch 6, 100% \t Train loss: 0.2381 took: 1.88s  Val. loss: 0.1884\n",
      "Epoch 7, 100% \t Train loss: 0.1808 took: 1.88s  Val. loss: 0.1777\n",
      "Epoch 8, 100% \t Train loss: 0.1742 took: 1.89s  Val. loss: 0.1733\n",
      "Epoch 9, 100% \t Train loss: 0.1705 took: 1.89s  Val. loss: 0.1707\n",
      "Epoch 10, 100% \t Train loss: 0.1673 took: 1.90s  Val. loss: 0.1701\n",
      "Epoch 11, 100% \t Train loss: 0.1627 took: 1.88s  Val. loss: 0.1630\n",
      "Epoch 12, 100% \t Train loss: 0.1600 took: 1.89s  Val. loss: 0.1606\n",
      "Epoch 13, 100% \t Train loss: 0.1575 took: 1.88s  Val. loss: 0.1615\n",
      "Epoch 14, 100% \t Train loss: 0.1567 took: 1.10s  Val. loss: 0.1611\n",
      "Epoch 15, 100% \t Train loss: 0.1558 took: 1.11s  Val. loss: 0.1618\n",
      "Epoch 16, 100% \t Train loss: 0.1556 took: 1.10s  Val. loss: 0.1625\n",
      "Epoch 17, 100% \t Train loss: 0.1544 took: 1.84s  Val. loss: 0.1596\n",
      "Epoch 18, 100% \t Train loss: 0.1538 took: 1.88s  Val. loss: 0.1635\n",
      "Epoch 19, 100% \t Train loss: 0.1539 took: 1.86s  Val. loss: 0.1624\n",
      "Epoch 20, 100% \t Train loss: 0.1540 took: 1.89s  Val. loss: 0.1616\n",
      "Epoch 21, 100% \t Train loss: 0.1523 took: 1.89s  Val. loss: 0.1596\n",
      "Epoch 22, 100% \t Train loss: 0.1519 took: 1.90s  Val. loss: 0.1600\n",
      "Epoch 23, 100% \t Train loss: 0.1513 took: 1.89s  Val. loss: 0.1635\n",
      "Epoch 24, 100% \t Train loss: 0.1518 took: 1.89s  Val. loss: 0.1632\n",
      "Epoch 25, 100% \t Train loss: 0.1511 took: 1.89s  Val. loss: 0.1612\n",
      "Epoch 26, 100% \t Train loss: 0.1508 took: 1.88s  Val. loss: 0.1632\n",
      "Epoch 27, 100% \t Train loss: 0.1506 took: 1.89s  Val. loss: 0.1652\n",
      "Epoch 28, 100% \t Train loss: 0.1499 took: 1.91s  Val. loss: 0.1644\n",
      "Epoch 29, 100% \t Train loss: 0.1495 took: 1.93s  Val. loss: 0.1622\n",
      "Epoch 30, 100% \t Train loss: 0.1492 took: 1.90s  Val. loss: 0.1636\n",
      "Epoch 31, 100% \t Train loss: 0.1492 took: 1.90s  Val. loss: 0.1635\n",
      "Epoch 32, 100% \t Train loss: 0.1484 took: 1.95s  Val. loss: 0.1653\n",
      "Epoch 33, 100% \t Train loss: 0.1482 took: 1.98s  Val. loss: 0.1636\n",
      "Epoch 34, 100% \t Train loss: 0.1479 took: 1.97s  Val. loss: 0.1635\n",
      "Epoch 35, 100% \t Train loss: 0.1474 took: 1.99s  Val. loss: 0.1644\n",
      "Epoch 36, 100% \t Train loss: 0.1470 took: 1.98s  Val. loss: 0.1651\n",
      "Epoch 37, 100% \t Train loss: 0.1455 took: 1.78s  Val. loss: 0.1654\n",
      "Epoch 38, 100% \t Train loss: 0.1439 took: 1.23s  Val. loss: 0.1572\n",
      "Epoch 39, 100% \t Train loss: 0.1403 took: 1.23s  Val. loss: 0.1575\n",
      "Epoch 40, 100% \t Train loss: 0.1370 took: 1.24s  Val. loss: 0.1543\n",
      "Epoch 41, 100% \t Train loss: 0.1330 took: 1.25s  Val. loss: 0.1486\n",
      "Epoch 42, 100% \t Train loss: 0.1287 took: 1.26s  Val. loss: 0.1459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, 100% \t Train loss: 0.1239 took: 1.26s  Val. loss: 0.1393\n",
      "Epoch 44, 100% \t Train loss: 0.1199 took: 1.27s  Val. loss: 0.1393\n",
      "Epoch 45, 100% \t Train loss: 0.1174 took: 1.98s  Val. loss: 0.1360\n",
      "Epoch 46, 100% \t Train loss: 0.1127 took: 1.98s  Val. loss: 0.1357\n",
      "Epoch 47, 100% \t Train loss: 0.1100 took: 1.99s  Val. loss: 0.1266\n",
      "Epoch 48, 100% \t Train loss: 0.1067 took: 1.96s  Val. loss: 0.1265\n",
      "Epoch 49, 100% \t Train loss: 0.1041 took: 1.96s  Val. loss: 0.1234\n",
      "Epoch 50, 100% \t Train loss: 0.1012 took: 1.96s  Val. loss: 0.1172\n",
      "Training finished, took 100.07s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2610 took: 1.89s  Val. loss: 0.2577\n",
      "Epoch 2, 100% \t Train loss: 0.2599 took: 1.89s  Val. loss: 0.2575\n",
      "Epoch 3, 100% \t Train loss: 0.2596 took: 1.11s  Val. loss: 0.2562\n",
      "Epoch 4, 100% \t Train loss: 0.2574 took: 1.11s  Val. loss: 0.2508\n",
      "Epoch 5, 100% \t Train loss: 0.2395 took: 1.10s  Val. loss: 0.2253\n",
      "Epoch 6, 100% \t Train loss: 0.2201 took: 1.10s  Val. loss: 0.2111\n",
      "Epoch 7, 100% \t Train loss: 0.1997 took: 1.10s  Val. loss: 0.1908\n",
      "Epoch 8, 100% \t Train loss: 0.1815 took: 1.10s  Val. loss: 0.1841\n",
      "Epoch 9, 100% \t Train loss: 0.1749 took: 1.10s  Val. loss: 0.1823\n",
      "Epoch 10, 100% \t Train loss: 0.1698 took: 1.09s  Val. loss: 0.1830\n",
      "Epoch 11, 100% \t Train loss: 0.1708 took: 1.10s  Val. loss: 0.1819\n",
      "Epoch 12, 100% \t Train loss: 0.1670 took: 1.10s  Val. loss: 0.1806\n",
      "Epoch 13, 100% \t Train loss: 0.1668 took: 1.11s  Val. loss: 0.1792\n",
      "Epoch 14, 100% \t Train loss: 0.1661 took: 1.09s  Val. loss: 0.1806\n",
      "Epoch 15, 100% \t Train loss: 0.1641 took: 1.10s  Val. loss: 0.1767\n",
      "Epoch 16, 100% \t Train loss: 0.1639 took: 1.10s  Val. loss: 0.1757\n",
      "Epoch 17, 100% \t Train loss: 0.1624 took: 1.10s  Val. loss: 0.1764\n",
      "Epoch 18, 100% \t Train loss: 0.1607 took: 1.11s  Val. loss: 0.1796\n",
      "Epoch 19, 100% \t Train loss: 0.1620 took: 1.10s  Val. loss: 0.1720\n",
      "Epoch 20, 100% \t Train loss: 0.1602 took: 1.10s  Val. loss: 0.1811\n",
      "Epoch 21, 100% \t Train loss: 0.1609 took: 1.10s  Val. loss: 0.1731\n",
      "Epoch 22, 100% \t Train loss: 0.1579 took: 1.10s  Val. loss: 0.1731\n",
      "Epoch 23, 100% \t Train loss: 0.1578 took: 1.10s  Val. loss: 0.1759\n",
      "Epoch 24, 100% \t Train loss: 0.1569 took: 1.10s  Val. loss: 0.1716\n",
      "Epoch 25, 100% \t Train loss: 0.1564 took: 1.10s  Val. loss: 0.1734\n",
      "Epoch 26, 100% \t Train loss: 0.1558 took: 1.11s  Val. loss: 0.1744\n",
      "Epoch 27, 100% \t Train loss: 0.1549 took: 1.11s  Val. loss: 0.1708\n",
      "Epoch 28, 100% \t Train loss: 0.1546 took: 1.10s  Val. loss: 0.1728\n",
      "Epoch 29, 100% \t Train loss: 0.1549 took: 1.10s  Val. loss: 0.1741\n",
      "Epoch 30, 100% \t Train loss: 0.1548 took: 1.10s  Val. loss: 0.1720\n",
      "Epoch 31, 100% \t Train loss: 0.1541 took: 1.11s  Val. loss: 0.1707\n",
      "Epoch 32, 100% \t Train loss: 0.1529 took: 1.11s  Val. loss: 0.1708\n",
      "Epoch 33, 100% \t Train loss: 0.1525 took: 1.11s  Val. loss: 0.1732\n",
      "Epoch 34, 100% \t Train loss: 0.1530 took: 1.11s  Val. loss: 0.1707\n",
      "Epoch 35, 100% \t Train loss: 0.1516 took: 1.13s  Val. loss: 0.1711\n",
      "Epoch 36, 100% \t Train loss: 0.1513 took: 1.14s  Val. loss: 0.1705\n",
      "Epoch 37, 100% \t Train loss: 0.1517 took: 1.14s  Val. loss: 0.1740\n",
      "Epoch 38, 100% \t Train loss: 0.1514 took: 1.15s  Val. loss: 0.1716\n",
      "Epoch 39, 100% \t Train loss: 0.1512 took: 1.14s  Val. loss: 0.1700\n",
      "Epoch 40, 100% \t Train loss: 0.1504 took: 1.94s  Val. loss: 0.1706\n",
      "Epoch 41, 100% \t Train loss: 0.1506 took: 1.98s  Val. loss: 0.1712\n",
      "Epoch 42, 100% \t Train loss: 0.1499 took: 2.01s  Val. loss: 0.1709\n",
      "Epoch 43, 100% \t Train loss: 0.1496 took: 2.00s  Val. loss: 0.1697\n",
      "Epoch 44, 100% \t Train loss: 0.1489 took: 1.98s  Val. loss: 0.1692\n",
      "Epoch 45, 100% \t Train loss: 0.1492 took: 2.00s  Val. loss: 0.1710\n",
      "Epoch 46, 100% \t Train loss: 0.1483 took: 1.23s  Val. loss: 0.1709\n",
      "Epoch 47, 100% \t Train loss: 0.1479 took: 1.22s  Val. loss: 0.1703\n",
      "Epoch 48, 100% \t Train loss: 0.1475 took: 1.22s  Val. loss: 0.1679\n",
      "Epoch 49, 100% \t Train loss: 0.1455 took: 1.24s  Val. loss: 0.1724\n",
      "Epoch 50, 100% \t Train loss: 0.1460 took: 1.26s  Val. loss: 0.1656\n",
      "Training finished, took 70.89s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2614 took: 1.10s  Val. loss: 0.2561\n",
      "Epoch 2, 100% \t Train loss: 0.2593 took: 1.10s  Val. loss: 0.2563\n",
      "Epoch 3, 100% \t Train loss: 0.2592 took: 1.10s  Val. loss: 0.2558\n",
      "Epoch 4, 100% \t Train loss: 0.2592 took: 1.10s  Val. loss: 0.2561\n",
      "Epoch 5, 100% \t Train loss: 0.2590 took: 1.09s  Val. loss: 0.2565\n",
      "Epoch 6, 100% \t Train loss: 0.2584 took: 1.10s  Val. loss: 0.2555\n",
      "Epoch 7, 100% \t Train loss: 0.2554 took: 1.10s  Val. loss: 0.2504\n",
      "Epoch 8, 100% \t Train loss: 0.2452 took: 1.10s  Val. loss: 0.2381\n",
      "Epoch 9, 100% \t Train loss: 0.2305 took: 1.10s  Val. loss: 0.2315\n",
      "Epoch 10, 100% \t Train loss: 0.2190 took: 1.10s  Val. loss: 0.2213\n",
      "Epoch 11, 100% \t Train loss: 0.2108 took: 1.09s  Val. loss: 0.2212\n",
      "Epoch 12, 100% \t Train loss: 0.2035 took: 1.10s  Val. loss: 0.2071\n",
      "Epoch 13, 100% \t Train loss: 0.1949 took: 1.10s  Val. loss: 0.1936\n",
      "Epoch 14, 100% \t Train loss: 0.1897 took: 1.09s  Val. loss: 0.1879\n",
      "Epoch 15, 100% \t Train loss: 0.1834 took: 1.10s  Val. loss: 0.1822\n",
      "Epoch 16, 100% \t Train loss: 0.1811 took: 1.10s  Val. loss: 0.1834\n",
      "Epoch 17, 100% \t Train loss: 0.1822 took: 1.10s  Val. loss: 0.1810\n",
      "Epoch 18, 100% \t Train loss: 0.1796 took: 1.10s  Val. loss: 0.1777\n",
      "Epoch 19, 100% \t Train loss: 0.1782 took: 1.10s  Val. loss: 0.1788\n",
      "Epoch 20, 100% \t Train loss: 0.1784 took: 1.10s  Val. loss: 0.1775\n",
      "Epoch 21, 100% \t Train loss: 0.1765 took: 1.10s  Val. loss: 0.1749\n",
      "Epoch 22, 100% \t Train loss: 0.1765 took: 1.10s  Val. loss: 0.1788\n",
      "Epoch 23, 100% \t Train loss: 0.1756 took: 1.10s  Val. loss: 0.1795\n",
      "Epoch 24, 100% \t Train loss: 0.1778 took: 1.10s  Val. loss: 0.1784\n",
      "Epoch 25, 100% \t Train loss: 0.1754 took: 1.10s  Val. loss: 0.1787\n",
      "Epoch 26, 100% \t Train loss: 0.1764 took: 1.10s  Val. loss: 0.1801\n",
      "Epoch 27, 100% \t Train loss: 0.1758 took: 1.10s  Val. loss: 0.1737\n",
      "Epoch 28, 100% \t Train loss: 0.1732 took: 1.10s  Val. loss: 0.1761\n",
      "Epoch 29, 100% \t Train loss: 0.1735 took: 1.10s  Val. loss: 0.1734\n",
      "Epoch 30, 100% \t Train loss: 0.1722 took: 1.11s  Val. loss: 0.1744\n",
      "Epoch 31, 100% \t Train loss: 0.1737 took: 1.12s  Val. loss: 0.1765\n",
      "Epoch 32, 100% \t Train loss: 0.1730 took: 1.85s  Val. loss: 0.1728\n",
      "Epoch 33, 100% \t Train loss: 0.1726 took: 1.93s  Val. loss: 0.1774\n",
      "Epoch 34, 100% \t Train loss: 0.1722 took: 1.14s  Val. loss: 0.1741\n",
      "Epoch 35, 100% \t Train loss: 0.1715 took: 1.12s  Val. loss: 0.1708\n",
      "Epoch 36, 100% \t Train loss: 0.1699 took: 1.13s  Val. loss: 0.1718\n",
      "Epoch 37, 100% \t Train loss: 0.1699 took: 1.13s  Val. loss: 0.1710\n",
      "Epoch 38, 100% \t Train loss: 0.1692 took: 1.14s  Val. loss: 0.1717\n",
      "Epoch 39, 100% \t Train loss: 0.1687 took: 1.14s  Val. loss: 0.1710\n",
      "Epoch 40, 100% \t Train loss: 0.1687 took: 1.14s  Val. loss: 0.1750\n",
      "Epoch 41, 100% \t Train loss: 0.1679 took: 1.14s  Val. loss: 0.1753\n",
      "Epoch 42, 100% \t Train loss: 0.1683 took: 1.14s  Val. loss: 0.1789\n",
      "Epoch 43, 100% \t Train loss: 0.1683 took: 1.14s  Val. loss: 0.1710\n",
      "Epoch 44, 100% \t Train loss: 0.1691 took: 1.14s  Val. loss: 0.1776\n",
      "Epoch 45, 100% \t Train loss: 0.1673 took: 1.15s  Val. loss: 0.1735\n",
      "Epoch 46, 100% \t Train loss: 0.1676 took: 1.14s  Val. loss: 0.1709\n",
      "Epoch 47, 100% \t Train loss: 0.1667 took: 1.14s  Val. loss: 0.1674\n",
      "Epoch 48, 100% \t Train loss: 0.1648 took: 1.13s  Val. loss: 0.1682\n",
      "Epoch 49, 100% \t Train loss: 0.1662 took: 1.14s  Val. loss: 0.1737\n",
      "Epoch 50, 100% \t Train loss: 0.1658 took: 1.15s  Val. loss: 0.1688\n",
      "Training finished, took 64.38s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.38\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.832379\n",
      "lambda: 0.0010 - V: 0.817481\n",
      "lambda: 0.0005 - V: 0.808136\n",
      "Average V: 0.819332\n",
      "Time elapsed: 238.78 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.38\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2573 took: 1.08s  Val. loss: 0.2548\n",
      "Epoch 2, 100% \t Train loss: 0.2411 took: 1.06s  Val. loss: 0.2021\n",
      "Epoch 3, 100% \t Train loss: 0.1757 took: 1.07s  Val. loss: 0.1710\n",
      "Epoch 4, 100% \t Train loss: 0.1653 took: 1.06s  Val. loss: 0.1756\n",
      "Epoch 5, 100% \t Train loss: 0.1634 took: 1.06s  Val. loss: 0.1666\n",
      "Epoch 6, 100% \t Train loss: 0.1615 took: 1.07s  Val. loss: 0.1673\n",
      "Epoch 7, 100% \t Train loss: 0.1594 took: 1.06s  Val. loss: 0.1694\n",
      "Epoch 8, 100% \t Train loss: 0.1579 took: 1.07s  Val. loss: 0.1669\n",
      "Epoch 9, 100% \t Train loss: 0.1541 took: 1.06s  Val. loss: 0.1591\n",
      "Epoch 10, 100% \t Train loss: 0.1429 took: 1.07s  Val. loss: 0.1462\n",
      "Epoch 11, 100% \t Train loss: 0.1229 took: 1.07s  Val. loss: 0.1232\n",
      "Epoch 12, 100% \t Train loss: 0.1037 took: 1.07s  Val. loss: 0.1112\n",
      "Epoch 13, 100% \t Train loss: 0.0911 took: 1.07s  Val. loss: 0.0996\n",
      "Epoch 14, 100% \t Train loss: 0.0844 took: 1.07s  Val. loss: 0.0944\n",
      "Epoch 15, 100% \t Train loss: 0.0809 took: 1.07s  Val. loss: 0.0911\n",
      "Epoch 16, 100% \t Train loss: 0.0766 took: 1.20s  Val. loss: 0.0886\n",
      "Epoch 17, 100% \t Train loss: 0.0743 took: 1.83s  Val. loss: 0.0906\n",
      "Epoch 18, 100% \t Train loss: 0.0734 took: 1.82s  Val. loss: 0.0859\n",
      "Epoch 19, 100% \t Train loss: 0.0727 took: 1.82s  Val. loss: 0.0881\n",
      "Epoch 20, 100% \t Train loss: 0.0726 took: 1.83s  Val. loss: 0.0873\n",
      "Epoch 21, 100% \t Train loss: 0.0704 took: 1.69s  Val. loss: 0.0866\n",
      "Epoch 22, 100% \t Train loss: 0.0708 took: 1.83s  Val. loss: 0.0872\n",
      "Epoch 23, 100% \t Train loss: 0.0695 took: 1.82s  Val. loss: 0.0895\n",
      "Epoch 24, 100% \t Train loss: 0.0691 took: 1.82s  Val. loss: 0.0916\n",
      "Epoch 25, 100% \t Train loss: 0.0681 took: 1.83s  Val. loss: 0.0892\n",
      "Epoch 26, 100% \t Train loss: 0.0684 took: 1.07s  Val. loss: 0.0912\n",
      "Epoch 27, 100% \t Train loss: 0.0688 took: 1.07s  Val. loss: 0.0889\n",
      "Epoch 28, 100% \t Train loss: 0.0674 took: 1.37s  Val. loss: 0.0912\n",
      "Epoch 29, 100% \t Train loss: 0.0677 took: 1.82s  Val. loss: 0.0866\n",
      "Epoch 30, 100% \t Train loss: 0.0666 took: 1.99s  Val. loss: 0.0886\n",
      "Epoch 31, 100% \t Train loss: 0.0664 took: 1.88s  Val. loss: 0.0865\n",
      "Epoch 32, 100% \t Train loss: 0.0652 took: 1.79s  Val. loss: 0.0880\n",
      "Epoch 33, 100% \t Train loss: 0.0655 took: 2.15s  Val. loss: 0.0890\n",
      "Epoch 34, 100% \t Train loss: 0.0656 took: 2.33s  Val. loss: 0.0919\n",
      "Epoch 35, 100% \t Train loss: 0.0643 took: 2.45s  Val. loss: 0.0899\n",
      "Epoch 36, 100% \t Train loss: 0.0647 took: 2.32s  Val. loss: 0.0902\n",
      "Epoch 37, 100% \t Train loss: 0.0643 took: 2.30s  Val. loss: 0.0943\n",
      "Epoch 38, 100% \t Train loss: 0.0644 took: 2.30s  Val. loss: 0.0915\n",
      "Epoch 39, 100% \t Train loss: 0.0634 took: 2.33s  Val. loss: 0.0888\n",
      "Epoch 40, 100% \t Train loss: 0.0637 took: 2.27s  Val. loss: 0.0887\n",
      "Epoch 41, 100% \t Train loss: 0.0634 took: 2.11s  Val. loss: 0.0914\n",
      "Epoch 42, 100% \t Train loss: 0.0640 took: 2.07s  Val. loss: 0.0906\n",
      "Epoch 43, 100% \t Train loss: 0.0627 took: 2.07s  Val. loss: 0.0931\n",
      "Epoch 44, 100% \t Train loss: 0.0625 took: 2.08s  Val. loss: 0.0917\n",
      "Epoch 45, 100% \t Train loss: 0.0623 took: 2.07s  Val. loss: 0.0923\n",
      "Epoch 46, 100% \t Train loss: 0.0625 took: 2.07s  Val. loss: 0.0910\n",
      "Epoch 47, 100% \t Train loss: 0.0624 took: 2.10s  Val. loss: 0.0918\n",
      "Epoch 48, 100% \t Train loss: 0.0625 took: 2.10s  Val. loss: 0.0947\n",
      "Epoch 49, 100% \t Train loss: 0.0621 took: 1.98s  Val. loss: 0.0925\n",
      "Epoch 50, 100% \t Train loss: 0.0617 took: 1.97s  Val. loss: 0.0912\n",
      "Training finished, took 94.98s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2609 took: 1.07s  Val. loss: 0.2562\n",
      "Epoch 2, 100% \t Train loss: 0.2599 took: 1.07s  Val. loss: 0.2543\n",
      "Epoch 3, 100% \t Train loss: 0.2519 took: 1.07s  Val. loss: 0.2281\n",
      "Epoch 4, 100% \t Train loss: 0.2096 took: 1.06s  Val. loss: 0.1946\n",
      "Epoch 5, 100% \t Train loss: 0.1816 took: 1.07s  Val. loss: 0.1867\n",
      "Epoch 6, 100% \t Train loss: 0.1795 took: 1.07s  Val. loss: 0.1910\n",
      "Epoch 7, 100% \t Train loss: 0.1744 took: 1.07s  Val. loss: 0.1889\n",
      "Epoch 8, 100% \t Train loss: 0.1703 took: 1.07s  Val. loss: 0.1808\n",
      "Epoch 9, 100% \t Train loss: 0.1660 took: 1.50s  Val. loss: 0.1824\n",
      "Epoch 10, 100% \t Train loss: 0.1689 took: 1.82s  Val. loss: 0.1825\n",
      "Epoch 11, 100% \t Train loss: 0.1648 took: 1.82s  Val. loss: 0.1795\n",
      "Epoch 12, 100% \t Train loss: 0.1620 took: 1.81s  Val. loss: 0.1789\n",
      "Epoch 13, 100% \t Train loss: 0.1627 took: 1.81s  Val. loss: 0.1774\n",
      "Epoch 14, 100% \t Train loss: 0.1582 took: 1.81s  Val. loss: 0.1856\n",
      "Epoch 15, 100% \t Train loss: 0.1587 took: 1.81s  Val. loss: 0.1860\n",
      "Epoch 16, 100% \t Train loss: 0.1574 took: 1.82s  Val. loss: 0.1834\n",
      "Epoch 17, 100% \t Train loss: 0.1560 took: 1.83s  Val. loss: 0.1855\n",
      "Epoch 18, 100% \t Train loss: 0.1543 took: 1.85s  Val. loss: 0.1840\n",
      "Epoch 19, 100% \t Train loss: 0.1530 took: 1.83s  Val. loss: 0.1763\n",
      "Epoch 20, 100% \t Train loss: 0.1529 took: 1.83s  Val. loss: 0.1834\n",
      "Epoch 21, 100% \t Train loss: 0.1500 took: 1.83s  Val. loss: 0.1818\n",
      "Epoch 22, 100% \t Train loss: 0.1494 took: 1.84s  Val. loss: 0.1763\n",
      "Epoch 23, 100% \t Train loss: 0.1471 took: 1.82s  Val. loss: 0.1720\n",
      "Epoch 24, 100% \t Train loss: 0.1444 took: 1.83s  Val. loss: 0.1723\n",
      "Epoch 25, 100% \t Train loss: 0.1419 took: 1.82s  Val. loss: 0.1651\n",
      "Epoch 26, 100% \t Train loss: 0.1366 took: 1.83s  Val. loss: 0.1646\n",
      "Epoch 27, 100% \t Train loss: 0.1346 took: 1.83s  Val. loss: 0.1522\n",
      "Epoch 28, 100% \t Train loss: 0.1287 took: 1.84s  Val. loss: 0.1525\n",
      "Epoch 29, 100% \t Train loss: 0.1226 took: 1.83s  Val. loss: 0.1430\n",
      "Epoch 30, 100% \t Train loss: 0.1176 took: 1.86s  Val. loss: 0.1355\n",
      "Epoch 31, 100% \t Train loss: 0.1127 took: 1.88s  Val. loss: 0.1307\n",
      "Epoch 32, 100% \t Train loss: 0.1081 took: 1.89s  Val. loss: 0.1267\n",
      "Epoch 33, 100% \t Train loss: 0.1023 took: 1.88s  Val. loss: 0.1180\n",
      "Epoch 34, 100% \t Train loss: 0.0978 took: 1.88s  Val. loss: 0.1180\n",
      "Epoch 35, 100% \t Train loss: 0.0946 took: 1.88s  Val. loss: 0.1167\n",
      "Epoch 36, 100% \t Train loss: 0.0915 took: 1.91s  Val. loss: 0.1125\n",
      "Epoch 37, 100% \t Train loss: 0.0912 took: 1.92s  Val. loss: 0.1110\n",
      "Epoch 38, 100% \t Train loss: 0.0883 took: 1.94s  Val. loss: 0.1108\n",
      "Epoch 39, 100% \t Train loss: 0.0867 took: 1.95s  Val. loss: 0.1053\n",
      "Epoch 40, 100% \t Train loss: 0.0851 took: 1.96s  Val. loss: 0.1043\n",
      "Epoch 41, 100% \t Train loss: 0.0828 took: 1.98s  Val. loss: 0.1074\n",
      "Epoch 42, 100% \t Train loss: 0.0818 took: 1.98s  Val. loss: 0.1001\n",
      "Epoch 43, 100% \t Train loss: 0.0806 took: 1.99s  Val. loss: 0.1003\n",
      "Epoch 44, 100% \t Train loss: 0.0800 took: 2.03s  Val. loss: 0.1130\n",
      "Epoch 45, 100% \t Train loss: 0.0798 took: 2.08s  Val. loss: 0.0998\n",
      "Epoch 46, 100% \t Train loss: 0.0791 took: 2.08s  Val. loss: 0.1007\n",
      "Epoch 47, 100% \t Train loss: 0.0777 took: 2.10s  Val. loss: 0.0999\n",
      "Epoch 48, 100% \t Train loss: 0.0777 took: 2.10s  Val. loss: 0.0970\n",
      "Epoch 49, 100% \t Train loss: 0.0784 took: 2.09s  Val. loss: 0.0970\n",
      "Epoch 50, 100% \t Train loss: 0.0760 took: 2.09s  Val. loss: 0.1012\n",
      "Training finished, took 99.87s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2589 took: 1.83s  Val. loss: 0.2471\n",
      "Epoch 2, 100% \t Train loss: 0.2586 took: 1.82s  Val. loss: 0.2464\n",
      "Epoch 3, 100% \t Train loss: 0.2586 took: 1.83s  Val. loss: 0.2479\n",
      "Epoch 4, 100% \t Train loss: 0.2582 took: 1.83s  Val. loss: 0.2461\n",
      "Epoch 5, 100% \t Train loss: 0.2565 took: 1.08s  Val. loss: 0.2418\n",
      "Epoch 6, 100% \t Train loss: 0.2438 took: 1.07s  Val. loss: 0.2211\n",
      "Epoch 7, 100% \t Train loss: 0.2217 took: 1.08s  Val. loss: 0.2022\n",
      "Epoch 8, 100% \t Train loss: 0.2052 took: 1.07s  Val. loss: 0.2004\n",
      "Epoch 9, 100% \t Train loss: 0.1955 took: 1.07s  Val. loss: 0.1832\n",
      "Epoch 10, 100% \t Train loss: 0.1866 took: 1.08s  Val. loss: 0.1796\n",
      "Epoch 11, 100% \t Train loss: 0.1818 took: 1.58s  Val. loss: 0.1825\n",
      "Epoch 12, 100% \t Train loss: 0.1782 took: 1.84s  Val. loss: 0.1795\n",
      "Epoch 13, 100% \t Train loss: 0.1748 took: 1.82s  Val. loss: 0.1733\n",
      "Epoch 14, 100% \t Train loss: 0.1732 took: 1.81s  Val. loss: 0.1740\n",
      "Epoch 15, 100% \t Train loss: 0.1696 took: 1.84s  Val. loss: 0.1732\n",
      "Epoch 16, 100% \t Train loss: 0.1722 took: 1.83s  Val. loss: 0.1771\n",
      "Epoch 17, 100% \t Train loss: 0.1717 took: 1.82s  Val. loss: 0.1709\n",
      "Epoch 18, 100% \t Train loss: 0.1701 took: 1.81s  Val. loss: 0.1763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1690 took: 1.83s  Val. loss: 0.1763\n",
      "Epoch 20, 100% \t Train loss: 0.1699 took: 1.85s  Val. loss: 0.1725\n",
      "Epoch 21, 100% \t Train loss: 0.1653 took: 1.83s  Val. loss: 0.1708\n",
      "Epoch 22, 100% \t Train loss: 0.1645 took: 1.82s  Val. loss: 0.1700\n",
      "Epoch 23, 100% \t Train loss: 0.1639 took: 1.82s  Val. loss: 0.1722\n",
      "Epoch 24, 100% \t Train loss: 0.1635 took: 1.82s  Val. loss: 0.1694\n",
      "Epoch 25, 100% \t Train loss: 0.1623 took: 1.83s  Val. loss: 0.1655\n",
      "Epoch 26, 100% \t Train loss: 0.1607 took: 1.83s  Val. loss: 0.1731\n",
      "Epoch 27, 100% \t Train loss: 0.1644 took: 1.82s  Val. loss: 0.1698\n",
      "Epoch 28, 100% \t Train loss: 0.1652 took: 1.83s  Val. loss: 0.1684\n",
      "Epoch 29, 100% \t Train loss: 0.1623 took: 1.84s  Val. loss: 0.1678\n",
      "Epoch 30, 100% \t Train loss: 0.1593 took: 1.86s  Val. loss: 0.1672\n",
      "Epoch 31, 100% \t Train loss: 0.1602 took: 1.86s  Val. loss: 0.1674\n",
      "Epoch 32, 100% \t Train loss: 0.1598 took: 1.89s  Val. loss: 0.1727\n",
      "Epoch 33, 100% \t Train loss: 0.1598 took: 1.92s  Val. loss: 0.1710\n",
      "Epoch 34, 100% \t Train loss: 0.1575 took: 1.89s  Val. loss: 0.1667\n",
      "Epoch 35, 100% \t Train loss: 0.1558 took: 1.92s  Val. loss: 0.1689\n",
      "Epoch 36, 100% \t Train loss: 0.1579 took: 1.89s  Val. loss: 0.1674\n",
      "Epoch 37, 100% \t Train loss: 0.1571 took: 1.92s  Val. loss: 0.1689\n",
      "Epoch 38, 100% \t Train loss: 0.1556 took: 1.79s  Val. loss: 0.1687\n",
      "Epoch 39, 100% \t Train loss: 0.1551 took: 1.91s  Val. loss: 0.1686\n",
      "Epoch 40, 100% \t Train loss: 0.1567 took: 1.90s  Val. loss: 0.1674\n",
      "Epoch 41, 100% \t Train loss: 0.1553 took: 1.90s  Val. loss: 0.1676\n",
      "Epoch 42, 100% \t Train loss: 0.1554 took: 1.92s  Val. loss: 0.1676\n",
      "Epoch 43, 100% \t Train loss: 0.1549 took: 1.91s  Val. loss: 0.1662\n",
      "Epoch 44, 100% \t Train loss: 0.1545 took: 1.91s  Val. loss: 0.1675\n",
      "Epoch 45, 100% \t Train loss: 0.1536 took: 1.94s  Val. loss: 0.1667\n",
      "Epoch 46, 100% \t Train loss: 0.1549 took: 1.95s  Val. loss: 0.1676\n",
      "Epoch 47, 100% \t Train loss: 0.1532 took: 1.95s  Val. loss: 0.1661\n",
      "Epoch 48, 100% \t Train loss: 0.1526 took: 1.96s  Val. loss: 0.1707\n",
      "Epoch 49, 100% \t Train loss: 0.1525 took: 2.00s  Val. loss: 0.1664\n",
      "Epoch 50, 100% \t Train loss: 0.1518 took: 2.04s  Val. loss: 0.1649\n",
      "Training finished, took 100.38s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.38\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.891031\n",
      "lambda: 0.0010 - V: 0.846976\n",
      "lambda: 0.0005 - V: 0.819508\n",
      "Average V: 0.852505\n",
      "Time elapsed: 298.68 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.29\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.39\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2585 took: 1.92s  Val. loss: 0.2540\n",
      "Epoch 2, 100% \t Train loss: 0.2579 took: 1.91s  Val. loss: 0.2549\n",
      "Epoch 3, 100% \t Train loss: 0.2575 took: 1.92s  Val. loss: 0.2525\n",
      "Epoch 4, 100% \t Train loss: 0.2507 took: 1.91s  Val. loss: 0.2135\n",
      "Epoch 5, 100% \t Train loss: 0.1980 took: 1.92s  Val. loss: 0.1937\n",
      "Epoch 6, 100% \t Train loss: 0.1915 took: 1.90s  Val. loss: 0.1945\n",
      "Epoch 7, 100% \t Train loss: 0.1894 took: 1.90s  Val. loss: 0.1937\n",
      "Epoch 8, 100% \t Train loss: 0.1880 took: 1.89s  Val. loss: 0.1886\n",
      "Epoch 9, 100% \t Train loss: 0.1864 took: 1.91s  Val. loss: 0.1889\n",
      "Epoch 10, 100% \t Train loss: 0.1860 took: 1.91s  Val. loss: 0.1873\n",
      "Epoch 11, 100% \t Train loss: 0.1865 took: 1.90s  Val. loss: 0.1898\n",
      "Epoch 12, 100% \t Train loss: 0.1856 took: 1.90s  Val. loss: 0.1878\n",
      "Epoch 13, 100% \t Train loss: 0.1831 took: 1.90s  Val. loss: 0.1909\n",
      "Epoch 14, 100% \t Train loss: 0.1831 took: 1.88s  Val. loss: 0.1875\n",
      "Epoch 15, 100% \t Train loss: 0.1841 took: 1.90s  Val. loss: 0.1892\n",
      "Epoch 16, 100% \t Train loss: 0.1822 took: 1.92s  Val. loss: 0.1900\n",
      "Epoch 17, 100% \t Train loss: 0.1806 took: 1.89s  Val. loss: 0.1855\n",
      "Epoch 18, 100% \t Train loss: 0.1810 took: 1.88s  Val. loss: 0.1883\n",
      "Epoch 19, 100% \t Train loss: 0.1795 took: 1.94s  Val. loss: 0.1887\n",
      "Epoch 20, 100% \t Train loss: 0.1794 took: 1.90s  Val. loss: 0.1853\n",
      "Epoch 21, 100% \t Train loss: 0.1787 took: 1.89s  Val. loss: 0.1872\n",
      "Epoch 22, 100% \t Train loss: 0.1781 took: 1.91s  Val. loss: 0.1887\n",
      "Epoch 23, 100% \t Train loss: 0.1760 took: 1.92s  Val. loss: 0.1853\n",
      "Epoch 24, 100% \t Train loss: 0.1733 took: 1.91s  Val. loss: 0.1845\n",
      "Epoch 25, 100% \t Train loss: 0.1698 took: 1.90s  Val. loss: 0.1803\n",
      "Epoch 26, 100% \t Train loss: 0.1645 took: 1.91s  Val. loss: 0.1670\n",
      "Epoch 27, 100% \t Train loss: 0.1572 took: 1.90s  Val. loss: 0.1649\n",
      "Epoch 28, 100% \t Train loss: 0.1499 took: 1.89s  Val. loss: 0.1585\n",
      "Epoch 29, 100% \t Train loss: 0.1459 took: 1.90s  Val. loss: 0.1530\n",
      "Epoch 30, 100% \t Train loss: 0.1419 took: 1.90s  Val. loss: 0.1497\n",
      "Epoch 31, 100% \t Train loss: 0.1399 took: 1.93s  Val. loss: 0.1502\n",
      "Epoch 32, 100% \t Train loss: 0.1355 took: 1.94s  Val. loss: 0.1446\n",
      "Epoch 33, 100% \t Train loss: 0.1341 took: 2.01s  Val. loss: 0.1445\n",
      "Epoch 34, 100% \t Train loss: 0.1321 took: 2.09s  Val. loss: 0.1403\n",
      "Epoch 35, 100% \t Train loss: 0.1306 took: 2.03s  Val. loss: 0.1407\n",
      "Epoch 36, 100% \t Train loss: 0.1286 took: 2.02s  Val. loss: 0.1370\n",
      "Epoch 37, 100% \t Train loss: 0.1276 took: 2.06s  Val. loss: 0.1383\n",
      "Epoch 38, 100% \t Train loss: 0.1266 took: 2.05s  Val. loss: 0.1359\n",
      "Epoch 39, 100% \t Train loss: 0.1257 took: 2.02s  Val. loss: 0.1360\n",
      "Epoch 40, 100% \t Train loss: 0.1252 took: 2.04s  Val. loss: 0.1328\n",
      "Epoch 41, 100% \t Train loss: 0.1242 took: 2.06s  Val. loss: 0.1368\n",
      "Epoch 42, 100% \t Train loss: 0.1234 took: 2.03s  Val. loss: 0.1339\n",
      "Epoch 43, 100% \t Train loss: 0.1241 took: 2.03s  Val. loss: 0.1327\n",
      "Epoch 44, 100% \t Train loss: 0.1230 took: 2.04s  Val. loss: 0.1305\n",
      "Epoch 45, 100% \t Train loss: 0.1218 took: 2.02s  Val. loss: 0.1333\n",
      "Epoch 46, 100% \t Train loss: 0.1213 took: 1.25s  Val. loss: 0.1351\n",
      "Epoch 47, 100% \t Train loss: 0.1210 took: 1.26s  Val. loss: 0.1286\n",
      "Epoch 48, 100% \t Train loss: 0.1206 took: 1.26s  Val. loss: 0.1302\n",
      "Epoch 49, 100% \t Train loss: 0.1201 took: 1.26s  Val. loss: 0.1325\n",
      "Epoch 50, 100% \t Train loss: 0.1201 took: 1.28s  Val. loss: 0.1329\n",
      "Training finished, took 106.29s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2595 took: 1.50s  Val. loss: 0.2607\n",
      "Epoch 2, 100% \t Train loss: 0.2575 took: 1.77s  Val. loss: 0.2569\n",
      "Epoch 3, 100% \t Train loss: 0.2422 took: 1.89s  Val. loss: 0.2367\n",
      "Epoch 4, 100% \t Train loss: 0.2271 took: 1.89s  Val. loss: 0.2235\n",
      "Epoch 5, 100% \t Train loss: 0.2176 took: 1.89s  Val. loss: 0.2118\n",
      "Epoch 6, 100% \t Train loss: 0.2060 took: 1.89s  Val. loss: 0.2073\n",
      "Epoch 7, 100% \t Train loss: 0.2001 took: 1.89s  Val. loss: 0.2052\n",
      "Epoch 8, 100% \t Train loss: 0.1978 took: 1.91s  Val. loss: 0.2032\n",
      "Epoch 9, 100% \t Train loss: 0.1952 took: 1.89s  Val. loss: 0.2035\n",
      "Epoch 10, 100% \t Train loss: 0.1944 took: 1.90s  Val. loss: 0.2002\n",
      "Epoch 11, 100% \t Train loss: 0.1949 took: 1.89s  Val. loss: 0.1979\n",
      "Epoch 12, 100% \t Train loss: 0.1928 took: 1.91s  Val. loss: 0.1980\n",
      "Epoch 13, 100% \t Train loss: 0.1914 took: 1.89s  Val. loss: 0.1972\n",
      "Epoch 14, 100% \t Train loss: 0.1915 took: 1.91s  Val. loss: 0.1994\n",
      "Epoch 15, 100% \t Train loss: 0.1900 took: 1.94s  Val. loss: 0.1975\n",
      "Epoch 16, 100% \t Train loss: 0.1903 took: 1.91s  Val. loss: 0.1980\n",
      "Epoch 17, 100% \t Train loss: 0.1888 took: 1.88s  Val. loss: 0.1984\n",
      "Epoch 18, 100% \t Train loss: 0.1878 took: 1.88s  Val. loss: 0.1959\n",
      "Epoch 19, 100% \t Train loss: 0.1885 took: 1.91s  Val. loss: 0.1956\n",
      "Epoch 20, 100% \t Train loss: 0.1864 took: 1.89s  Val. loss: 0.1933\n",
      "Epoch 21, 100% \t Train loss: 0.1854 took: 1.87s  Val. loss: 0.1938\n",
      "Epoch 22, 100% \t Train loss: 0.1831 took: 1.89s  Val. loss: 0.1908\n",
      "Epoch 23, 100% \t Train loss: 0.1808 took: 1.88s  Val. loss: 0.1945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1807 took: 1.89s  Val. loss: 0.1887\n",
      "Epoch 25, 100% \t Train loss: 0.1778 took: 1.86s  Val. loss: 0.1851\n",
      "Epoch 26, 100% \t Train loss: 0.1771 took: 1.90s  Val. loss: 0.1832\n",
      "Epoch 27, 100% \t Train loss: 0.1730 took: 1.90s  Val. loss: 0.1813\n",
      "Epoch 28, 100% \t Train loss: 0.1711 took: 1.92s  Val. loss: 0.1736\n",
      "Epoch 29, 100% \t Train loss: 0.1692 took: 1.92s  Val. loss: 0.1767\n",
      "Epoch 30, 100% \t Train loss: 0.1699 took: 1.93s  Val. loss: 0.1757\n",
      "Epoch 31, 100% \t Train loss: 0.1656 took: 1.97s  Val. loss: 0.1692\n",
      "Epoch 32, 100% \t Train loss: 0.1605 took: 1.97s  Val. loss: 0.1607\n",
      "Epoch 33, 100% \t Train loss: 0.1613 took: 1.95s  Val. loss: 0.1613\n",
      "Epoch 34, 100% \t Train loss: 0.1555 took: 1.92s  Val. loss: 0.1561\n",
      "Epoch 35, 100% \t Train loss: 0.1541 took: 1.91s  Val. loss: 0.1572\n",
      "Epoch 36, 100% \t Train loss: 0.1513 took: 1.92s  Val. loss: 0.1524\n",
      "Epoch 37, 100% \t Train loss: 0.1496 took: 1.92s  Val. loss: 0.1558\n",
      "Epoch 38, 100% \t Train loss: 0.1499 took: 1.93s  Val. loss: 0.1452\n",
      "Epoch 39, 100% \t Train loss: 0.1477 took: 1.92s  Val. loss: 0.1497\n",
      "Epoch 40, 100% \t Train loss: 0.1470 took: 1.91s  Val. loss: 0.1494\n",
      "Epoch 41, 100% \t Train loss: 0.1439 took: 1.93s  Val. loss: 0.1439\n",
      "Epoch 42, 100% \t Train loss: 0.1431 took: 1.92s  Val. loss: 0.1421\n",
      "Epoch 43, 100% \t Train loss: 0.1422 took: 1.92s  Val. loss: 0.1442\n",
      "Epoch 44, 100% \t Train loss: 0.1409 took: 1.92s  Val. loss: 0.1406\n",
      "Epoch 45, 100% \t Train loss: 0.1406 took: 1.92s  Val. loss: 0.1434\n",
      "Epoch 46, 100% \t Train loss: 0.1389 took: 1.93s  Val. loss: 0.1426\n",
      "Epoch 47, 100% \t Train loss: 0.1392 took: 1.95s  Val. loss: 0.1450\n",
      "Epoch 48, 100% \t Train loss: 0.1400 took: 1.94s  Val. loss: 0.1447\n",
      "Epoch 49, 100% \t Train loss: 0.1369 took: 1.95s  Val. loss: 0.1486\n",
      "Epoch 50, 100% \t Train loss: 0.1374 took: 1.95s  Val. loss: 0.1414\n",
      "Training finished, took 107.38s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2575 took: 1.91s  Val. loss: 0.2551\n",
      "Epoch 2, 100% \t Train loss: 0.2570 took: 1.91s  Val. loss: 0.2555\n",
      "Epoch 3, 100% \t Train loss: 0.2557 took: 1.93s  Val. loss: 0.2525\n",
      "Epoch 4, 100% \t Train loss: 0.2455 took: 1.93s  Val. loss: 0.2273\n",
      "Epoch 5, 100% \t Train loss: 0.2237 took: 1.90s  Val. loss: 0.2147\n",
      "Epoch 6, 100% \t Train loss: 0.2122 took: 1.89s  Val. loss: 0.2011\n",
      "Epoch 7, 100% \t Train loss: 0.2033 took: 1.89s  Val. loss: 0.1972\n",
      "Epoch 8, 100% \t Train loss: 0.2024 took: 1.90s  Val. loss: 0.1913\n",
      "Epoch 9, 100% \t Train loss: 0.1983 took: 1.89s  Val. loss: 0.1894\n",
      "Epoch 10, 100% \t Train loss: 0.1988 took: 1.90s  Val. loss: 0.1896\n",
      "Epoch 11, 100% \t Train loss: 0.1979 took: 1.92s  Val. loss: 0.1923\n",
      "Epoch 12, 100% \t Train loss: 0.1963 took: 1.91s  Val. loss: 0.1898\n",
      "Epoch 13, 100% \t Train loss: 0.1947 took: 1.90s  Val. loss: 0.1864\n",
      "Epoch 14, 100% \t Train loss: 0.1932 took: 1.90s  Val. loss: 0.1861\n",
      "Epoch 15, 100% \t Train loss: 0.1925 took: 1.90s  Val. loss: 0.1842\n",
      "Epoch 16, 100% \t Train loss: 0.1927 took: 1.89s  Val. loss: 0.1830\n",
      "Epoch 17, 100% \t Train loss: 0.1915 took: 1.93s  Val. loss: 0.1812\n",
      "Epoch 18, 100% \t Train loss: 0.1919 took: 1.91s  Val. loss: 0.1868\n",
      "Epoch 19, 100% \t Train loss: 0.1932 took: 1.92s  Val. loss: 0.1863\n",
      "Epoch 20, 100% \t Train loss: 0.1888 took: 1.91s  Val. loss: 0.1825\n",
      "Epoch 21, 100% \t Train loss: 0.1876 took: 1.93s  Val. loss: 0.1834\n",
      "Epoch 22, 100% \t Train loss: 0.1880 took: 1.91s  Val. loss: 0.1805\n",
      "Epoch 23, 100% \t Train loss: 0.1881 took: 1.92s  Val. loss: 0.1821\n",
      "Epoch 24, 100% \t Train loss: 0.1889 took: 1.91s  Val. loss: 0.1829\n",
      "Epoch 25, 100% \t Train loss: 0.1858 took: 1.90s  Val. loss: 0.1810\n",
      "Epoch 26, 100% \t Train loss: 0.1858 took: 1.90s  Val. loss: 0.1827\n",
      "Epoch 27, 100% \t Train loss: 0.1859 took: 1.90s  Val. loss: 0.1866\n",
      "Epoch 28, 100% \t Train loss: 0.1874 took: 1.91s  Val. loss: 0.1787\n",
      "Epoch 29, 100% \t Train loss: 0.1858 took: 1.92s  Val. loss: 0.1810\n",
      "Epoch 30, 100% \t Train loss: 0.1846 took: 1.92s  Val. loss: 0.1782\n",
      "Epoch 31, 100% \t Train loss: 0.1839 took: 1.93s  Val. loss: 0.1836\n",
      "Epoch 32, 100% \t Train loss: 0.1838 took: 1.95s  Val. loss: 0.1795\n",
      "Epoch 33, 100% \t Train loss: 0.1835 took: 1.91s  Val. loss: 0.1824\n",
      "Epoch 34, 100% \t Train loss: 0.1841 took: 1.91s  Val. loss: 0.1840\n",
      "Epoch 35, 100% \t Train loss: 0.1844 took: 1.93s  Val. loss: 0.1787\n",
      "Epoch 36, 100% \t Train loss: 0.1830 took: 1.92s  Val. loss: 0.1831\n",
      "Epoch 37, 100% \t Train loss: 0.1839 took: 1.92s  Val. loss: 0.1815\n",
      "Epoch 38, 100% \t Train loss: 0.1832 took: 1.93s  Val. loss: 0.1821\n",
      "Epoch 39, 100% \t Train loss: 0.1823 took: 1.96s  Val. loss: 0.1796\n",
      "Epoch 40, 100% \t Train loss: 0.1830 took: 1.94s  Val. loss: 0.1781\n",
      "Epoch 41, 100% \t Train loss: 0.1818 took: 1.96s  Val. loss: 0.1764\n",
      "Epoch 42, 100% \t Train loss: 0.1810 took: 1.94s  Val. loss: 0.1784\n",
      "Epoch 43, 100% \t Train loss: 0.1808 took: 1.94s  Val. loss: 0.1786\n",
      "Epoch 44, 100% \t Train loss: 0.1812 took: 1.93s  Val. loss: 0.1772\n",
      "Epoch 45, 100% \t Train loss: 0.1805 took: 1.94s  Val. loss: 0.1792\n",
      "Epoch 46, 100% \t Train loss: 0.1799 took: 1.93s  Val. loss: 0.1798\n",
      "Epoch 47, 100% \t Train loss: 0.1806 took: 1.94s  Val. loss: 0.1769\n",
      "Epoch 48, 100% \t Train loss: 0.1796 took: 1.93s  Val. loss: 0.1808\n",
      "Epoch 49, 100% \t Train loss: 0.1782 took: 1.36s  Val. loss: 0.1775\n",
      "Epoch 50, 100% \t Train loss: 0.1773 took: 1.13s  Val. loss: 0.1764\n",
      "Training finished, took 106.65s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.29\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.39\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.830990\n",
      "lambda: 0.0010 - V: 0.819648\n",
      "lambda: 0.0005 - V: 0.811136\n",
      "Average V: 0.820592\n",
      "Time elapsed: 323.66 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.26\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2581 took: 1.78s  Val. loss: 0.2629\n",
      "Epoch 2, 100% \t Train loss: 0.2551 took: 1.82s  Val. loss: 0.2400\n",
      "Epoch 3, 100% \t Train loss: 0.1878 took: 1.81s  Val. loss: 0.1909\n",
      "Epoch 4, 100% \t Train loss: 0.1663 took: 1.83s  Val. loss: 0.1924\n",
      "Epoch 5, 100% \t Train loss: 0.1603 took: 1.80s  Val. loss: 0.1852\n",
      "Epoch 6, 100% \t Train loss: 0.1567 took: 1.81s  Val. loss: 0.1884\n",
      "Epoch 7, 100% \t Train loss: 0.1545 took: 1.80s  Val. loss: 0.1826\n",
      "Epoch 8, 100% \t Train loss: 0.1534 took: 1.82s  Val. loss: 0.1828\n",
      "Epoch 9, 100% \t Train loss: 0.1522 took: 1.80s  Val. loss: 0.1838\n",
      "Epoch 10, 100% \t Train loss: 0.1504 took: 1.81s  Val. loss: 0.1810\n",
      "Epoch 11, 100% \t Train loss: 0.1492 took: 1.80s  Val. loss: 0.1860\n",
      "Epoch 12, 100% \t Train loss: 0.1497 took: 1.80s  Val. loss: 0.1804\n",
      "Epoch 13, 100% \t Train loss: 0.1478 took: 1.80s  Val. loss: 0.1862\n",
      "Epoch 14, 100% \t Train loss: 0.1503 took: 1.82s  Val. loss: 0.1840\n",
      "Epoch 15, 100% \t Train loss: 0.1471 took: 1.80s  Val. loss: 0.1846\n",
      "Epoch 16, 100% \t Train loss: 0.1457 took: 1.78s  Val. loss: 0.1833\n",
      "Epoch 17, 100% \t Train loss: 0.1462 took: 1.79s  Val. loss: 0.1847\n",
      "Epoch 18, 100% \t Train loss: 0.1454 took: 1.79s  Val. loss: 0.1844\n",
      "Epoch 19, 100% \t Train loss: 0.1449 took: 1.79s  Val. loss: 0.1840\n",
      "Epoch 20, 100% \t Train loss: 0.1444 took: 1.80s  Val. loss: 0.1840\n",
      "Epoch 21, 100% \t Train loss: 0.1441 took: 1.79s  Val. loss: 0.1875\n",
      "Epoch 22, 100% \t Train loss: 0.1436 took: 1.78s  Val. loss: 0.1843\n",
      "Epoch 23, 100% \t Train loss: 0.1428 took: 1.79s  Val. loss: 0.1850\n",
      "Epoch 24, 100% \t Train loss: 0.1429 took: 1.79s  Val. loss: 0.1847\n",
      "Epoch 25, 100% \t Train loss: 0.1423 took: 1.80s  Val. loss: 0.1810\n",
      "Epoch 26, 100% \t Train loss: 0.1401 took: 1.81s  Val. loss: 0.1826\n",
      "Epoch 27, 100% \t Train loss: 0.1356 took: 1.79s  Val. loss: 0.1728\n",
      "Epoch 28, 100% \t Train loss: 0.1269 took: 1.83s  Val. loss: 0.1605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.1160 took: 1.81s  Val. loss: 0.1425\n",
      "Epoch 30, 100% \t Train loss: 0.1080 took: 1.82s  Val. loss: 0.1355\n",
      "Epoch 31, 100% \t Train loss: 0.1017 took: 1.81s  Val. loss: 0.1262\n",
      "Epoch 32, 100% \t Train loss: 0.0975 took: 1.86s  Val. loss: 0.1199\n",
      "Epoch 33, 100% \t Train loss: 0.0950 took: 1.90s  Val. loss: 0.1187\n",
      "Epoch 34, 100% \t Train loss: 0.0914 took: 1.90s  Val. loss: 0.1171\n",
      "Epoch 35, 100% \t Train loss: 0.0888 took: 1.91s  Val. loss: 0.1115\n",
      "Epoch 36, 100% \t Train loss: 0.0876 took: 1.90s  Val. loss: 0.1076\n",
      "Epoch 37, 100% \t Train loss: 0.0854 took: 1.15s  Val. loss: 0.1069\n",
      "Epoch 38, 100% \t Train loss: 0.0848 took: 1.15s  Val. loss: 0.1072\n",
      "Epoch 39, 100% \t Train loss: 0.0829 took: 1.14s  Val. loss: 0.1053\n",
      "Epoch 40, 100% \t Train loss: 0.0820 took: 1.14s  Val. loss: 0.1042\n",
      "Epoch 41, 100% \t Train loss: 0.0808 took: 1.14s  Val. loss: 0.1045\n",
      "Epoch 42, 100% \t Train loss: 0.0797 took: 1.14s  Val. loss: 0.1028\n",
      "Epoch 43, 100% \t Train loss: 0.0783 took: 1.14s  Val. loss: 0.1035\n",
      "Epoch 44, 100% \t Train loss: 0.0780 took: 1.13s  Val. loss: 0.1002\n",
      "Epoch 45, 100% \t Train loss: 0.0772 took: 1.13s  Val. loss: 0.0970\n",
      "Epoch 46, 100% \t Train loss: 0.0755 took: 1.15s  Val. loss: 0.0960\n",
      "Epoch 47, 100% \t Train loss: 0.0765 took: 1.14s  Val. loss: 0.0989\n",
      "Epoch 48, 100% \t Train loss: 0.0749 took: 1.14s  Val. loss: 0.0993\n",
      "Epoch 49, 100% \t Train loss: 0.0739 took: 1.14s  Val. loss: 0.1016\n",
      "Epoch 50, 100% \t Train loss: 0.0731 took: 1.14s  Val. loss: 0.1004\n",
      "Training finished, took 92.54s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2585 took: 1.80s  Val. loss: 0.2576\n",
      "Epoch 2, 100% \t Train loss: 0.2571 took: 1.81s  Val. loss: 0.2569\n",
      "Epoch 3, 100% \t Train loss: 0.2508 took: 1.81s  Val. loss: 0.2438\n",
      "Epoch 4, 100% \t Train loss: 0.2289 took: 1.80s  Val. loss: 0.2290\n",
      "Epoch 5, 100% \t Train loss: 0.2192 took: 1.81s  Val. loss: 0.2270\n",
      "Epoch 6, 100% \t Train loss: 0.2164 took: 1.80s  Val. loss: 0.2204\n",
      "Epoch 7, 100% \t Train loss: 0.2103 took: 1.79s  Val. loss: 0.2104\n",
      "Epoch 8, 100% \t Train loss: 0.1934 took: 1.05s  Val. loss: 0.1927\n",
      "Epoch 9, 100% \t Train loss: 0.1814 took: 1.04s  Val. loss: 0.1822\n",
      "Epoch 10, 100% \t Train loss: 0.1744 took: 1.04s  Val. loss: 0.1823\n",
      "Epoch 11, 100% \t Train loss: 0.1717 took: 1.04s  Val. loss: 0.1766\n",
      "Epoch 12, 100% \t Train loss: 0.1688 took: 1.04s  Val. loss: 0.1855\n",
      "Epoch 13, 100% \t Train loss: 0.1670 took: 1.04s  Val. loss: 0.1796\n",
      "Epoch 14, 100% \t Train loss: 0.1670 took: 1.04s  Val. loss: 0.1799\n",
      "Epoch 15, 100% \t Train loss: 0.1645 took: 1.55s  Val. loss: 0.1770\n",
      "Epoch 16, 100% \t Train loss: 0.1657 took: 1.82s  Val. loss: 0.1755\n",
      "Epoch 17, 100% \t Train loss: 0.1620 took: 1.82s  Val. loss: 0.1760\n",
      "Epoch 18, 100% \t Train loss: 0.1607 took: 1.82s  Val. loss: 0.1737\n",
      "Epoch 19, 100% \t Train loss: 0.1619 took: 1.82s  Val. loss: 0.1777\n",
      "Epoch 20, 100% \t Train loss: 0.1611 took: 1.81s  Val. loss: 0.1720\n",
      "Epoch 21, 100% \t Train loss: 0.1589 took: 1.81s  Val. loss: 0.1722\n",
      "Epoch 22, 100% \t Train loss: 0.1595 took: 1.81s  Val. loss: 0.1746\n",
      "Epoch 23, 100% \t Train loss: 0.1590 took: 1.81s  Val. loss: 0.1694\n",
      "Epoch 24, 100% \t Train loss: 0.1566 took: 1.81s  Val. loss: 0.1702\n",
      "Epoch 25, 100% \t Train loss: 0.1559 took: 1.80s  Val. loss: 0.1705\n",
      "Epoch 26, 100% \t Train loss: 0.1545 took: 1.81s  Val. loss: 0.1700\n",
      "Epoch 27, 100% \t Train loss: 0.1533 took: 1.81s  Val. loss: 0.1686\n",
      "Epoch 28, 100% \t Train loss: 0.1534 took: 1.81s  Val. loss: 0.1717\n",
      "Epoch 29, 100% \t Train loss: 0.1524 took: 1.80s  Val. loss: 0.1756\n",
      "Epoch 30, 100% \t Train loss: 0.1543 took: 1.81s  Val. loss: 0.1678\n",
      "Epoch 31, 100% \t Train loss: 0.1509 took: 1.79s  Val. loss: 0.1674\n",
      "Epoch 32, 100% \t Train loss: 0.1512 took: 1.80s  Val. loss: 0.1690\n",
      "Epoch 33, 100% \t Train loss: 0.1526 took: 1.80s  Val. loss: 0.1705\n",
      "Epoch 34, 100% \t Train loss: 0.1498 took: 1.82s  Val. loss: 0.1688\n",
      "Epoch 35, 100% \t Train loss: 0.1504 took: 1.80s  Val. loss: 0.1682\n",
      "Epoch 36, 100% \t Train loss: 0.1494 took: 1.80s  Val. loss: 0.1653\n",
      "Epoch 37, 100% \t Train loss: 0.1488 took: 1.80s  Val. loss: 0.1673\n",
      "Epoch 38, 100% \t Train loss: 0.1488 took: 1.82s  Val. loss: 0.1722\n",
      "Epoch 39, 100% \t Train loss: 0.1474 took: 1.80s  Val. loss: 0.1685\n",
      "Epoch 40, 100% \t Train loss: 0.1481 took: 1.80s  Val. loss: 0.1664\n",
      "Epoch 41, 100% \t Train loss: 0.1471 took: 1.80s  Val. loss: 0.1666\n",
      "Epoch 42, 100% \t Train loss: 0.1471 took: 1.82s  Val. loss: 0.1671\n",
      "Epoch 43, 100% \t Train loss: 0.1465 took: 1.81s  Val. loss: 0.1692\n",
      "Epoch 44, 100% \t Train loss: 0.1467 took: 1.81s  Val. loss: 0.1673\n",
      "Epoch 45, 100% \t Train loss: 0.1462 took: 1.81s  Val. loss: 0.1694\n",
      "Epoch 46, 100% \t Train loss: 0.1461 took: 1.80s  Val. loss: 0.1660\n",
      "Epoch 47, 100% \t Train loss: 0.1460 took: 1.82s  Val. loss: 0.1667\n",
      "Epoch 48, 100% \t Train loss: 0.1451 took: 1.80s  Val. loss: 0.1669\n",
      "Epoch 49, 100% \t Train loss: 0.1449 took: 1.81s  Val. loss: 0.1694\n",
      "Epoch 50, 100% \t Train loss: 0.1445 took: 1.80s  Val. loss: 0.1674\n",
      "Training finished, took 96.30s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2554 took: 1.82s  Val. loss: 0.2549\n",
      "Epoch 2, 100% \t Train loss: 0.2551 took: 1.81s  Val. loss: 0.2550\n",
      "Epoch 3, 100% \t Train loss: 0.2550 took: 1.80s  Val. loss: 0.2548\n",
      "Epoch 4, 100% \t Train loss: 0.2550 took: 1.80s  Val. loss: 0.2556\n",
      "Epoch 5, 100% \t Train loss: 0.2548 took: 1.03s  Val. loss: 0.2554\n",
      "Epoch 6, 100% \t Train loss: 0.2537 took: 1.04s  Val. loss: 0.2533\n",
      "Epoch 7, 100% \t Train loss: 0.2477 took: 1.04s  Val. loss: 0.2432\n",
      "Epoch 8, 100% \t Train loss: 0.2352 took: 1.03s  Val. loss: 0.2363\n",
      "Epoch 9, 100% \t Train loss: 0.2280 took: 1.03s  Val. loss: 0.2312\n",
      "Epoch 10, 100% \t Train loss: 0.2230 took: 1.03s  Val. loss: 0.2302\n",
      "Epoch 11, 100% \t Train loss: 0.2181 took: 1.04s  Val. loss: 0.2287\n",
      "Epoch 12, 100% \t Train loss: 0.2146 took: 1.03s  Val. loss: 0.2221\n",
      "Epoch 13, 100% \t Train loss: 0.2088 took: 1.03s  Val. loss: 0.2161\n",
      "Epoch 14, 100% \t Train loss: 0.2037 took: 1.04s  Val. loss: 0.2095\n",
      "Epoch 15, 100% \t Train loss: 0.1951 took: 1.03s  Val. loss: 0.2021\n",
      "Epoch 16, 100% \t Train loss: 0.1913 took: 1.04s  Val. loss: 0.1997\n",
      "Epoch 17, 100% \t Train loss: 0.1860 took: 1.03s  Val. loss: 0.1943\n",
      "Epoch 18, 100% \t Train loss: 0.1837 took: 1.04s  Val. loss: 0.1933\n",
      "Epoch 19, 100% \t Train loss: 0.1801 took: 1.04s  Val. loss: 0.1885\n",
      "Epoch 20, 100% \t Train loss: 0.1768 took: 1.06s  Val. loss: 0.1900\n",
      "Epoch 21, 100% \t Train loss: 0.1769 took: 1.04s  Val. loss: 0.1897\n",
      "Epoch 22, 100% \t Train loss: 0.1808 took: 1.04s  Val. loss: 0.1863\n",
      "Epoch 23, 100% \t Train loss: 0.1746 took: 1.04s  Val. loss: 0.1825\n",
      "Epoch 24, 100% \t Train loss: 0.1732 took: 1.03s  Val. loss: 0.1831\n",
      "Epoch 25, 100% \t Train loss: 0.1728 took: 1.04s  Val. loss: 0.1938\n",
      "Epoch 26, 100% \t Train loss: 0.1704 took: 1.05s  Val. loss: 0.1822\n",
      "Epoch 27, 100% \t Train loss: 0.1719 took: 1.04s  Val. loss: 0.1853\n",
      "Epoch 28, 100% \t Train loss: 0.1723 took: 1.04s  Val. loss: 0.1827\n",
      "Epoch 29, 100% \t Train loss: 0.1692 took: 1.04s  Val. loss: 0.1801\n",
      "Epoch 30, 100% \t Train loss: 0.1720 took: 1.05s  Val. loss: 0.1833\n",
      "Epoch 31, 100% \t Train loss: 0.1682 took: 1.06s  Val. loss: 0.1771\n",
      "Epoch 32, 100% \t Train loss: 0.1681 took: 1.06s  Val. loss: 0.1787\n",
      "Epoch 33, 100% \t Train loss: 0.1664 took: 1.07s  Val. loss: 0.1786\n",
      "Epoch 34, 100% \t Train loss: 0.1654 took: 1.08s  Val. loss: 0.1814\n",
      "Epoch 35, 100% \t Train loss: 0.1674 took: 1.10s  Val. loss: 0.1789\n",
      "Epoch 36, 100% \t Train loss: 0.1640 took: 1.11s  Val. loss: 0.1768\n",
      "Epoch 37, 100% \t Train loss: 0.1666 took: 1.11s  Val. loss: 0.1781\n",
      "Epoch 38, 100% \t Train loss: 0.1651 took: 1.12s  Val. loss: 0.1808\n",
      "Epoch 39, 100% \t Train loss: 0.1646 took: 1.11s  Val. loss: 0.1777\n",
      "Epoch 40, 100% \t Train loss: 0.1632 took: 1.11s  Val. loss: 0.1783\n",
      "Epoch 41, 100% \t Train loss: 0.1650 took: 1.12s  Val. loss: 0.1782\n",
      "Epoch 42, 100% \t Train loss: 0.1624 took: 1.11s  Val. loss: 0.1758\n",
      "Epoch 43, 100% \t Train loss: 0.1624 took: 1.12s  Val. loss: 0.1777\n",
      "Epoch 44, 100% \t Train loss: 0.1617 took: 1.11s  Val. loss: 0.1769\n",
      "Epoch 45, 100% \t Train loss: 0.1631 took: 1.11s  Val. loss: 0.1768\n",
      "Epoch 46, 100% \t Train loss: 0.1610 took: 1.10s  Val. loss: 0.1756\n",
      "Epoch 47, 100% \t Train loss: 0.1615 took: 1.44s  Val. loss: 0.1744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1613 took: 1.89s  Val. loss: 0.1781\n",
      "Epoch 49, 100% \t Train loss: 0.1608 took: 1.33s  Val. loss: 0.1736\n",
      "Epoch 50, 100% \t Train loss: 0.1600 took: 1.90s  Val. loss: 0.1781\n",
      "Training finished, took 66.06s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.26\n",
      "\tmask_channels :  6  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.846466\n",
      "lambda: 0.0010 - V: 0.819082\n",
      "lambda: 0.0005 - V: 0.801703\n",
      "Average V: 0.822417\n",
      "Time elapsed: 258.31 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.39\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 1.91s  Val. loss: 0.2546\n",
      "Epoch 2, 100% \t Train loss: 0.2573 took: 1.91s  Val. loss: 0.2572\n",
      "Epoch 3, 100% \t Train loss: 0.2557 took: 1.92s  Val. loss: 0.2438\n",
      "Epoch 4, 100% \t Train loss: 0.1958 took: 1.91s  Val. loss: 0.1782\n",
      "Epoch 5, 100% \t Train loss: 0.1732 took: 1.90s  Val. loss: 0.1715\n",
      "Epoch 6, 100% \t Train loss: 0.1684 took: 1.92s  Val. loss: 0.1646\n",
      "Epoch 7, 100% \t Train loss: 0.1623 took: 1.93s  Val. loss: 0.1621\n",
      "Epoch 8, 100% \t Train loss: 0.1600 took: 1.94s  Val. loss: 0.1611\n",
      "Epoch 9, 100% \t Train loss: 0.1575 took: 1.96s  Val. loss: 0.1623\n",
      "Epoch 10, 100% \t Train loss: 0.1558 took: 1.94s  Val. loss: 0.1646\n",
      "Epoch 11, 100% \t Train loss: 0.1549 took: 1.94s  Val. loss: 0.1610\n",
      "Epoch 12, 100% \t Train loss: 0.1538 took: 1.93s  Val. loss: 0.1622\n",
      "Epoch 13, 100% \t Train loss: 0.1536 took: 1.94s  Val. loss: 0.1631\n",
      "Epoch 14, 100% \t Train loss: 0.1536 took: 1.94s  Val. loss: 0.1610\n",
      "Epoch 15, 100% \t Train loss: 0.1515 took: 1.94s  Val. loss: 0.1567\n",
      "Epoch 16, 100% \t Train loss: 0.1502 took: 1.95s  Val. loss: 0.1599\n",
      "Epoch 17, 100% \t Train loss: 0.1486 took: 1.92s  Val. loss: 0.1586\n",
      "Epoch 18, 100% \t Train loss: 0.1446 took: 1.92s  Val. loss: 0.1530\n",
      "Epoch 19, 100% \t Train loss: 0.1360 took: 1.92s  Val. loss: 0.1429\n",
      "Epoch 20, 100% \t Train loss: 0.1251 took: 1.91s  Val. loss: 0.1377\n",
      "Epoch 21, 100% \t Train loss: 0.1161 took: 1.92s  Val. loss: 0.1337\n",
      "Epoch 22, 100% \t Train loss: 0.1092 took: 1.93s  Val. loss: 0.1220\n",
      "Epoch 23, 100% \t Train loss: 0.1019 took: 1.93s  Val. loss: 0.1149\n",
      "Epoch 24, 100% \t Train loss: 0.0980 took: 1.94s  Val. loss: 0.1107\n",
      "Epoch 25, 100% \t Train loss: 0.0938 took: 1.94s  Val. loss: 0.1051\n",
      "Epoch 26, 100% \t Train loss: 0.0892 took: 1.94s  Val. loss: 0.1015\n",
      "Epoch 27, 100% \t Train loss: 0.0855 took: 1.96s  Val. loss: 0.0996\n",
      "Epoch 28, 100% \t Train loss: 0.0835 took: 1.98s  Val. loss: 0.0947\n",
      "Epoch 29, 100% \t Train loss: 0.0824 took: 1.96s  Val. loss: 0.0977\n",
      "Epoch 30, 100% \t Train loss: 0.0813 took: 1.97s  Val. loss: 0.0956\n",
      "Epoch 31, 100% \t Train loss: 0.0807 took: 1.98s  Val. loss: 0.0970\n",
      "Epoch 32, 100% \t Train loss: 0.0796 took: 2.02s  Val. loss: 0.0935\n",
      "Epoch 33, 100% \t Train loss: 0.0782 took: 2.16s  Val. loss: 0.0934\n",
      "Epoch 34, 100% \t Train loss: 0.0777 took: 2.16s  Val. loss: 0.0957\n",
      "Epoch 35, 100% \t Train loss: 0.0770 took: 2.17s  Val. loss: 0.0925\n",
      "Epoch 36, 100% \t Train loss: 0.0754 took: 2.18s  Val. loss: 0.0929\n",
      "Epoch 37, 100% \t Train loss: 0.0759 took: 2.19s  Val. loss: 0.0928\n",
      "Epoch 38, 100% \t Train loss: 0.0742 took: 2.17s  Val. loss: 0.0929\n",
      "Epoch 39, 100% \t Train loss: 0.0746 took: 2.19s  Val. loss: 0.0930\n",
      "Epoch 40, 100% \t Train loss: 0.0734 took: 2.19s  Val. loss: 0.0912\n",
      "Epoch 41, 100% \t Train loss: 0.0727 took: 2.20s  Val. loss: 0.0934\n",
      "Epoch 42, 100% \t Train loss: 0.0727 took: 2.20s  Val. loss: 0.0910\n",
      "Epoch 43, 100% \t Train loss: 0.0715 took: 2.19s  Val. loss: 0.0912\n",
      "Epoch 44, 100% \t Train loss: 0.0704 took: 2.20s  Val. loss: 0.0915\n",
      "Epoch 45, 100% \t Train loss: 0.0726 took: 2.19s  Val. loss: 0.0904\n",
      "Epoch 46, 100% \t Train loss: 0.0718 took: 2.19s  Val. loss: 0.0894\n",
      "Epoch 47, 100% \t Train loss: 0.0702 took: 2.20s  Val. loss: 0.0927\n",
      "Epoch 48, 100% \t Train loss: 0.0705 took: 2.19s  Val. loss: 0.0911\n",
      "Epoch 49, 100% \t Train loss: 0.0706 took: 2.19s  Val. loss: 0.0893\n",
      "Epoch 50, 100% \t Train loss: 0.0691 took: 2.19s  Val. loss: 0.0937\n",
      "Training finished, took 114.39s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2587 took: 1.97s  Val. loss: 0.2505\n",
      "Epoch 2, 100% \t Train loss: 0.2569 took: 1.96s  Val. loss: 0.2519\n",
      "Epoch 3, 100% \t Train loss: 0.2567 took: 1.94s  Val. loss: 0.2512\n",
      "Epoch 4, 100% \t Train loss: 0.2568 took: 1.94s  Val. loss: 0.2521\n",
      "Epoch 5, 100% \t Train loss: 0.2496 took: 1.94s  Val. loss: 0.2305\n",
      "Epoch 6, 100% \t Train loss: 0.2191 took: 1.94s  Val. loss: 0.2011\n",
      "Epoch 7, 100% \t Train loss: 0.1938 took: 1.94s  Val. loss: 0.1872\n",
      "Epoch 8, 100% \t Train loss: 0.1872 took: 1.95s  Val. loss: 0.1872\n",
      "Epoch 9, 100% \t Train loss: 0.1819 took: 1.95s  Val. loss: 0.1776\n",
      "Epoch 10, 100% \t Train loss: 0.1773 took: 1.96s  Val. loss: 0.1741\n",
      "Epoch 11, 100% \t Train loss: 0.1759 took: 1.96s  Val. loss: 0.1748\n",
      "Epoch 12, 100% \t Train loss: 0.1715 took: 1.95s  Val. loss: 0.1738\n",
      "Epoch 13, 100% \t Train loss: 0.1677 took: 1.96s  Val. loss: 0.1706\n",
      "Epoch 14, 100% \t Train loss: 0.1674 took: 1.95s  Val. loss: 0.1709\n",
      "Epoch 15, 100% \t Train loss: 0.1668 took: 1.94s  Val. loss: 0.1703\n",
      "Epoch 16, 100% \t Train loss: 0.1657 took: 1.95s  Val. loss: 0.1739\n",
      "Epoch 17, 100% \t Train loss: 0.1658 took: 1.96s  Val. loss: 0.1732\n",
      "Epoch 18, 100% \t Train loss: 0.1621 took: 1.94s  Val. loss: 0.1674\n",
      "Epoch 19, 100% \t Train loss: 0.1597 took: 1.94s  Val. loss: 0.1666\n",
      "Epoch 20, 100% \t Train loss: 0.1608 took: 1.96s  Val. loss: 0.1635\n",
      "Epoch 21, 100% \t Train loss: 0.1596 took: 1.98s  Val. loss: 0.1652\n",
      "Epoch 22, 100% \t Train loss: 0.1570 took: 1.95s  Val. loss: 0.1641\n",
      "Epoch 23, 100% \t Train loss: 0.1574 took: 1.96s  Val. loss: 0.1725\n",
      "Epoch 24, 100% \t Train loss: 0.1578 took: 1.93s  Val. loss: 0.1675\n",
      "Epoch 25, 100% \t Train loss: 0.1559 took: 1.95s  Val. loss: 0.1627\n",
      "Epoch 26, 100% \t Train loss: 0.1550 took: 1.94s  Val. loss: 0.1701\n",
      "Epoch 27, 100% \t Train loss: 0.1548 took: 1.93s  Val. loss: 0.1693\n",
      "Epoch 28, 100% \t Train loss: 0.1539 took: 1.93s  Val. loss: 0.1659\n",
      "Epoch 29, 100% \t Train loss: 0.1537 took: 1.96s  Val. loss: 0.1656\n",
      "Epoch 30, 100% \t Train loss: 0.1548 took: 1.96s  Val. loss: 0.1621\n",
      "Epoch 31, 100% \t Train loss: 0.1526 took: 1.96s  Val. loss: 0.1633\n",
      "Epoch 32, 100% \t Train loss: 0.1523 took: 1.96s  Val. loss: 0.1641\n",
      "Epoch 33, 100% \t Train loss: 0.1499 took: 1.95s  Val. loss: 0.1638\n",
      "Epoch 34, 100% \t Train loss: 0.1485 took: 1.96s  Val. loss: 0.1610\n",
      "Epoch 35, 100% \t Train loss: 0.1468 took: 1.94s  Val. loss: 0.1636\n",
      "Epoch 36, 100% \t Train loss: 0.1448 took: 1.95s  Val. loss: 0.1577\n",
      "Epoch 37, 100% \t Train loss: 0.1411 took: 1.93s  Val. loss: 0.1555\n",
      "Epoch 38, 100% \t Train loss: 0.1391 took: 1.96s  Val. loss: 0.1529\n",
      "Epoch 39, 100% \t Train loss: 0.1330 took: 1.94s  Val. loss: 0.1487\n",
      "Epoch 40, 100% \t Train loss: 0.1295 took: 1.96s  Val. loss: 0.1426\n",
      "Epoch 41, 100% \t Train loss: 0.1252 took: 1.96s  Val. loss: 0.1427\n",
      "Epoch 42, 100% \t Train loss: 0.1210 took: 1.96s  Val. loss: 0.1428\n",
      "Epoch 43, 100% \t Train loss: 0.1183 took: 1.97s  Val. loss: 0.1441\n",
      "Epoch 44, 100% \t Train loss: 0.1159 took: 1.98s  Val. loss: 0.1372\n",
      "Epoch 45, 100% \t Train loss: 0.1114 took: 1.97s  Val. loss: 0.1381\n",
      "Epoch 46, 100% \t Train loss: 0.1110 took: 1.98s  Val. loss: 0.1321\n",
      "Epoch 47, 100% \t Train loss: 0.1093 took: 1.99s  Val. loss: 0.1253\n",
      "Epoch 48, 100% \t Train loss: 0.1058 took: 1.98s  Val. loss: 0.1279\n",
      "Epoch 49, 100% \t Train loss: 0.1035 took: 1.99s  Val. loss: 0.1304\n",
      "Epoch 50, 100% \t Train loss: 0.1010 took: 1.99s  Val. loss: 0.1174\n",
      "Training finished, took 110.85s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2527 took: 1.92s  Val. loss: 0.2638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2524 took: 1.94s  Val. loss: 0.2628\n",
      "Epoch 3, 100% \t Train loss: 0.2523 took: 1.94s  Val. loss: 0.2630\n",
      "Epoch 4, 100% \t Train loss: 0.2523 took: 1.94s  Val. loss: 0.2640\n",
      "Epoch 5, 100% \t Train loss: 0.2521 took: 1.93s  Val. loss: 0.2649\n",
      "Epoch 6, 100% \t Train loss: 0.2521 took: 1.94s  Val. loss: 0.2643\n",
      "Epoch 7, 100% \t Train loss: 0.2518 took: 1.12s  Val. loss: 0.2626\n",
      "Epoch 8, 100% \t Train loss: 0.2501 took: 1.12s  Val. loss: 0.2620\n",
      "Epoch 9, 100% \t Train loss: 0.2390 took: 1.12s  Val. loss: 0.2393\n",
      "Epoch 10, 100% \t Train loss: 0.2138 took: 1.12s  Val. loss: 0.2142\n",
      "Epoch 11, 100% \t Train loss: 0.1942 took: 1.12s  Val. loss: 0.2029\n",
      "Epoch 12, 100% \t Train loss: 0.1876 took: 1.12s  Val. loss: 0.1982\n",
      "Epoch 13, 100% \t Train loss: 0.1808 took: 1.13s  Val. loss: 0.2018\n",
      "Epoch 14, 100% \t Train loss: 0.1771 took: 1.13s  Val. loss: 0.1903\n",
      "Epoch 15, 100% \t Train loss: 0.1779 took: 1.12s  Val. loss: 0.1886\n",
      "Epoch 16, 100% \t Train loss: 0.1744 took: 1.13s  Val. loss: 0.1867\n",
      "Epoch 17, 100% \t Train loss: 0.1735 took: 1.13s  Val. loss: 0.1903\n",
      "Epoch 18, 100% \t Train loss: 0.1698 took: 1.13s  Val. loss: 0.1847\n",
      "Epoch 19, 100% \t Train loss: 0.1692 took: 1.31s  Val. loss: 0.1827\n",
      "Epoch 20, 100% \t Train loss: 0.1661 took: 1.94s  Val. loss: 0.1826\n",
      "Epoch 21, 100% \t Train loss: 0.1626 took: 1.91s  Val. loss: 0.1837\n",
      "Epoch 22, 100% \t Train loss: 0.1634 took: 1.92s  Val. loss: 0.1798\n",
      "Epoch 23, 100% \t Train loss: 0.1603 took: 1.92s  Val. loss: 0.1804\n",
      "Epoch 24, 100% \t Train loss: 0.1597 took: 1.91s  Val. loss: 0.1767\n",
      "Epoch 25, 100% \t Train loss: 0.1578 took: 1.93s  Val. loss: 0.1760\n",
      "Epoch 26, 100% \t Train loss: 0.1582 took: 1.91s  Val. loss: 0.1748\n",
      "Epoch 27, 100% \t Train loss: 0.1563 took: 1.93s  Val. loss: 0.1756\n",
      "Epoch 28, 100% \t Train loss: 0.1571 took: 1.94s  Val. loss: 0.1798\n",
      "Epoch 29, 100% \t Train loss: 0.1544 took: 1.97s  Val. loss: 0.1788\n",
      "Epoch 30, 100% \t Train loss: 0.1555 took: 1.95s  Val. loss: 0.1737\n",
      "Epoch 31, 100% \t Train loss: 0.1536 took: 1.97s  Val. loss: 0.1760\n",
      "Epoch 32, 100% \t Train loss: 0.1542 took: 1.95s  Val. loss: 0.1727\n",
      "Epoch 33, 100% \t Train loss: 0.1557 took: 1.95s  Val. loss: 0.1733\n",
      "Epoch 34, 100% \t Train loss: 0.1521 took: 1.97s  Val. loss: 0.1721\n",
      "Epoch 35, 100% \t Train loss: 0.1516 took: 1.95s  Val. loss: 0.1729\n",
      "Epoch 36, 100% \t Train loss: 0.1537 took: 1.96s  Val. loss: 0.1770\n",
      "Epoch 37, 100% \t Train loss: 0.1520 took: 1.96s  Val. loss: 0.1748\n",
      "Epoch 38, 100% \t Train loss: 0.1513 took: 1.96s  Val. loss: 0.1734\n",
      "Epoch 39, 100% \t Train loss: 0.1520 took: 1.95s  Val. loss: 0.1784\n",
      "Epoch 40, 100% \t Train loss: 0.1512 took: 1.95s  Val. loss: 0.1789\n",
      "Epoch 41, 100% \t Train loss: 0.1525 took: 1.95s  Val. loss: 0.1722\n",
      "Epoch 42, 100% \t Train loss: 0.1505 took: 1.94s  Val. loss: 0.1778\n",
      "Epoch 43, 100% \t Train loss: 0.1498 took: 1.95s  Val. loss: 0.1699\n",
      "Epoch 44, 100% \t Train loss: 0.1495 took: 1.94s  Val. loss: 0.1694\n",
      "Epoch 45, 100% \t Train loss: 0.1496 took: 1.93s  Val. loss: 0.1710\n",
      "Epoch 46, 100% \t Train loss: 0.1486 took: 1.95s  Val. loss: 0.1728\n",
      "Epoch 47, 100% \t Train loss: 0.1468 took: 1.93s  Val. loss: 0.1729\n",
      "Epoch 48, 100% \t Train loss: 0.1508 took: 1.95s  Val. loss: 0.1719\n",
      "Epoch 49, 100% \t Train loss: 0.1484 took: 1.94s  Val. loss: 0.1678\n",
      "Epoch 50, 100% \t Train loss: 0.1503 took: 1.94s  Val. loss: 0.1719\n",
      "Training finished, took 97.89s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  32  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.39\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.872006\n",
      "lambda: 0.0010 - V: 0.831103\n",
      "lambda: 0.0005 - V: 0.805679\n",
      "Average V: 0.836263\n",
      "Time elapsed: 326.52 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.27\n",
      "\tmask_channels :  4  - prob: 0.26\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 0.99s  Val. loss: 0.2661\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 1.00s  Val. loss: 0.2663\n",
      "Epoch 3, 100% \t Train loss: 0.2586 took: 0.99s  Val. loss: 0.2654\n",
      "Epoch 4, 100% \t Train loss: 0.2584 took: 0.99s  Val. loss: 0.2655\n",
      "Epoch 5, 100% \t Train loss: 0.2583 took: 0.99s  Val. loss: 0.2652\n",
      "Epoch 6, 100% \t Train loss: 0.2359 took: 1.00s  Val. loss: 0.2020\n",
      "Epoch 7, 100% \t Train loss: 0.1872 took: 1.00s  Val. loss: 0.1898\n",
      "Epoch 8, 100% \t Train loss: 0.1798 took: 0.99s  Val. loss: 0.1865\n",
      "Epoch 9, 100% \t Train loss: 0.1772 took: 0.98s  Val. loss: 0.1834\n",
      "Epoch 10, 100% \t Train loss: 0.1746 took: 1.00s  Val. loss: 0.1821\n",
      "Epoch 11, 100% \t Train loss: 0.1728 took: 1.27s  Val. loss: 0.1833\n",
      "Epoch 12, 100% \t Train loss: 0.1741 took: 1.76s  Val. loss: 0.1847\n",
      "Epoch 13, 100% \t Train loss: 0.1691 took: 1.73s  Val. loss: 0.1773\n",
      "Epoch 14, 100% \t Train loss: 0.1676 took: 1.70s  Val. loss: 0.1749\n",
      "Epoch 15, 100% \t Train loss: 0.1674 took: 1.77s  Val. loss: 0.1794\n",
      "Epoch 16, 100% \t Train loss: 0.1666 took: 1.74s  Val. loss: 0.1744\n",
      "Epoch 17, 100% \t Train loss: 0.1649 took: 1.72s  Val. loss: 0.1771\n",
      "Epoch 18, 100% \t Train loss: 0.1638 took: 1.73s  Val. loss: 0.1744\n",
      "Epoch 19, 100% \t Train loss: 0.1638 took: 1.74s  Val. loss: 0.1754\n",
      "Epoch 20, 100% \t Train loss: 0.1624 took: 1.75s  Val. loss: 0.1742\n",
      "Epoch 21, 100% \t Train loss: 0.1612 took: 1.76s  Val. loss: 0.1764\n",
      "Epoch 22, 100% \t Train loss: 0.1613 took: 1.74s  Val. loss: 0.1760\n",
      "Epoch 23, 100% \t Train loss: 0.1607 took: 1.75s  Val. loss: 0.1759\n",
      "Epoch 24, 100% \t Train loss: 0.1613 took: 1.74s  Val. loss: 0.1748\n",
      "Epoch 25, 100% \t Train loss: 0.1603 took: 1.74s  Val. loss: 0.1751\n",
      "Epoch 26, 100% \t Train loss: 0.1598 took: 1.72s  Val. loss: 0.1742\n",
      "Epoch 27, 100% \t Train loss: 0.1594 took: 1.74s  Val. loss: 0.1733\n",
      "Epoch 28, 100% \t Train loss: 0.1592 took: 1.75s  Val. loss: 0.1747\n",
      "Epoch 29, 100% \t Train loss: 0.1591 took: 1.77s  Val. loss: 0.1760\n",
      "Epoch 30, 100% \t Train loss: 0.1584 took: 1.02s  Val. loss: 0.1775\n",
      "Epoch 31, 100% \t Train loss: 0.1589 took: 1.01s  Val. loss: 0.1713\n",
      "Epoch 32, 100% \t Train loss: 0.1583 took: 1.06s  Val. loss: 0.1757\n",
      "Epoch 33, 100% \t Train loss: 0.1586 took: 1.17s  Val. loss: 0.1743\n",
      "Epoch 34, 100% \t Train loss: 0.1583 took: 1.18s  Val. loss: 0.1742\n",
      "Epoch 35, 100% \t Train loss: 0.1579 took: 1.18s  Val. loss: 0.1734\n",
      "Epoch 36, 100% \t Train loss: 0.1580 took: 1.18s  Val. loss: 0.1721\n",
      "Epoch 37, 100% \t Train loss: 0.1578 took: 1.19s  Val. loss: 0.1737\n",
      "Epoch 38, 100% \t Train loss: 0.1581 took: 1.21s  Val. loss: 0.1732\n",
      "Epoch 39, 100% \t Train loss: 0.1577 took: 1.21s  Val. loss: 0.1743\n",
      "Epoch 40, 100% \t Train loss: 0.1576 took: 1.21s  Val. loss: 0.1737\n",
      "Epoch 41, 100% \t Train loss: 0.1573 took: 1.21s  Val. loss: 0.1743\n",
      "Epoch 42, 100% \t Train loss: 0.1580 took: 1.98s  Val. loss: 0.1720\n",
      "Epoch 43, 100% \t Train loss: 0.1574 took: 1.98s  Val. loss: 0.1723\n",
      "Epoch 44, 100% \t Train loss: 0.1572 took: 2.00s  Val. loss: 0.1751\n",
      "Epoch 45, 100% \t Train loss: 0.1563 took: 1.99s  Val. loss: 0.1741\n",
      "Epoch 46, 100% \t Train loss: 0.1551 took: 1.98s  Val. loss: 0.1739\n",
      "Epoch 47, 100% \t Train loss: 0.1545 took: 2.00s  Val. loss: 0.1768\n",
      "Epoch 48, 100% \t Train loss: 0.1543 took: 2.03s  Val. loss: 0.1742\n",
      "Epoch 49, 100% \t Train loss: 0.1536 took: 2.03s  Val. loss: 0.1762\n",
      "Epoch 50, 100% \t Train loss: 0.1531 took: 2.05s  Val. loss: 0.1783\n",
      "Training finished, took 84.93s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2583 took: 1.76s  Val. loss: 0.2550\n",
      "Epoch 2, 100% \t Train loss: 0.2579 took: 1.77s  Val. loss: 0.2553\n",
      "Epoch 3, 100% \t Train loss: 0.2560 took: 1.74s  Val. loss: 0.2521\n",
      "Epoch 4, 100% \t Train loss: 0.2406 took: 1.75s  Val. loss: 0.2257\n",
      "Epoch 5, 100% \t Train loss: 0.1998 took: 1.75s  Val. loss: 0.1949\n",
      "Epoch 6, 100% \t Train loss: 0.1796 took: 1.74s  Val. loss: 0.1859\n",
      "Epoch 7, 100% \t Train loss: 0.1730 took: 1.75s  Val. loss: 0.1818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.1704 took: 1.73s  Val. loss: 0.1810\n",
      "Epoch 9, 100% \t Train loss: 0.1712 took: 1.73s  Val. loss: 0.1805\n",
      "Epoch 10, 100% \t Train loss: 0.1677 took: 1.75s  Val. loss: 0.1823\n",
      "Epoch 11, 100% \t Train loss: 0.1678 took: 1.74s  Val. loss: 0.1794\n",
      "Epoch 12, 100% \t Train loss: 0.1663 took: 1.77s  Val. loss: 0.1808\n",
      "Epoch 13, 100% \t Train loss: 0.1648 took: 1.75s  Val. loss: 0.1815\n",
      "Epoch 14, 100% \t Train loss: 0.1634 took: 1.76s  Val. loss: 0.1797\n",
      "Epoch 15, 100% \t Train loss: 0.1637 took: 1.75s  Val. loss: 0.1773\n",
      "Epoch 16, 100% \t Train loss: 0.1637 took: 1.73s  Val. loss: 0.1772\n",
      "Epoch 17, 100% \t Train loss: 0.1626 took: 1.73s  Val. loss: 0.1814\n",
      "Epoch 18, 100% \t Train loss: 0.1614 took: 1.77s  Val. loss: 0.1847\n",
      "Epoch 19, 100% \t Train loss: 0.1621 took: 1.73s  Val. loss: 0.1796\n",
      "Epoch 20, 100% \t Train loss: 0.1606 took: 1.77s  Val. loss: 0.1852\n",
      "Epoch 21, 100% \t Train loss: 0.1606 took: 1.74s  Val. loss: 0.1809\n",
      "Epoch 22, 100% \t Train loss: 0.1597 took: 1.74s  Val. loss: 0.1807\n",
      "Epoch 23, 100% \t Train loss: 0.1602 took: 1.75s  Val. loss: 0.1843\n",
      "Epoch 24, 100% \t Train loss: 0.1616 took: 1.74s  Val. loss: 0.1786\n",
      "Epoch 25, 100% \t Train loss: 0.1592 took: 1.74s  Val. loss: 0.1793\n",
      "Epoch 26, 100% \t Train loss: 0.1582 took: 1.76s  Val. loss: 0.1848\n",
      "Epoch 27, 100% \t Train loss: 0.1579 took: 1.75s  Val. loss: 0.1830\n",
      "Epoch 28, 100% \t Train loss: 0.1576 took: 1.76s  Val. loss: 0.1778\n",
      "Epoch 29, 100% \t Train loss: 0.1569 took: 1.78s  Val. loss: 0.1793\n",
      "Epoch 30, 100% \t Train loss: 0.1549 took: 1.78s  Val. loss: 0.1774\n",
      "Epoch 31, 100% \t Train loss: 0.1553 took: 1.76s  Val. loss: 0.1770\n",
      "Epoch 32, 100% \t Train loss: 0.1539 took: 1.72s  Val. loss: 0.1767\n",
      "Epoch 33, 100% \t Train loss: 0.1553 took: 1.80s  Val. loss: 0.1753\n",
      "Epoch 34, 100% \t Train loss: 0.1569 took: 1.80s  Val. loss: 0.1820\n",
      "Epoch 35, 100% \t Train loss: 0.1540 took: 1.80s  Val. loss: 0.1746\n",
      "Epoch 36, 100% \t Train loss: 0.1544 took: 1.07s  Val. loss: 0.1745\n",
      "Epoch 37, 100% \t Train loss: 0.1530 took: 1.05s  Val. loss: 0.1813\n",
      "Epoch 38, 100% \t Train loss: 0.1536 took: 1.05s  Val. loss: 0.1771\n",
      "Epoch 39, 100% \t Train loss: 0.1539 took: 1.06s  Val. loss: 0.1788\n",
      "Epoch 40, 100% \t Train loss: 0.1528 took: 1.07s  Val. loss: 0.1745\n",
      "Epoch 41, 100% \t Train loss: 0.1529 took: 1.07s  Val. loss: 0.1744\n",
      "Epoch 42, 100% \t Train loss: 0.1510 took: 1.07s  Val. loss: 0.1738\n",
      "Epoch 43, 100% \t Train loss: 0.1502 took: 1.06s  Val. loss: 0.1755\n",
      "Epoch 44, 100% \t Train loss: 0.1499 took: 1.05s  Val. loss: 0.1736\n",
      "Epoch 45, 100% \t Train loss: 0.1495 took: 1.06s  Val. loss: 0.1742\n",
      "Epoch 46, 100% \t Train loss: 0.1497 took: 1.06s  Val. loss: 0.1817\n",
      "Epoch 47, 100% \t Train loss: 0.1498 took: 1.07s  Val. loss: 0.1758\n",
      "Epoch 48, 100% \t Train loss: 0.1499 took: 1.06s  Val. loss: 0.1759\n",
      "Epoch 49, 100% \t Train loss: 0.1500 took: 1.06s  Val. loss: 0.1828\n",
      "Epoch 50, 100% \t Train loss: 0.1490 took: 1.06s  Val. loss: 0.1749\n",
      "Training finished, took 87.84s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2634 took: 1.75s  Val. loss: 0.2560\n",
      "Epoch 2, 100% \t Train loss: 0.2598 took: 1.74s  Val. loss: 0.2554\n",
      "Epoch 3, 100% \t Train loss: 0.2598 took: 1.71s  Val. loss: 0.2563\n",
      "Epoch 4, 100% \t Train loss: 0.2598 took: 1.74s  Val. loss: 0.2552\n",
      "Epoch 5, 100% \t Train loss: 0.2598 took: 1.72s  Val. loss: 0.2551\n",
      "Epoch 6, 100% \t Train loss: 0.2597 took: 1.74s  Val. loss: 0.2554\n",
      "Epoch 7, 100% \t Train loss: 0.2596 took: 1.74s  Val. loss: 0.2538\n",
      "Epoch 8, 100% \t Train loss: 0.2594 took: 1.65s  Val. loss: 0.2554\n",
      "Epoch 9, 100% \t Train loss: 0.2590 took: 1.74s  Val. loss: 0.2542\n",
      "Epoch 10, 100% \t Train loss: 0.2579 took: 1.75s  Val. loss: 0.2537\n",
      "Epoch 11, 100% \t Train loss: 0.2548 took: 1.67s  Val. loss: 0.2468\n",
      "Epoch 12, 100% \t Train loss: 0.2447 took: 1.74s  Val. loss: 0.2372\n",
      "Epoch 13, 100% \t Train loss: 0.2312 took: 1.74s  Val. loss: 0.2192\n",
      "Epoch 14, 100% \t Train loss: 0.2208 took: 1.75s  Val. loss: 0.2140\n",
      "Epoch 15, 100% \t Train loss: 0.2138 took: 1.73s  Val. loss: 0.2053\n",
      "Epoch 16, 100% \t Train loss: 0.2082 took: 1.54s  Val. loss: 0.2017\n",
      "Epoch 17, 100% \t Train loss: 0.2024 took: 0.99s  Val. loss: 0.2019\n",
      "Epoch 18, 100% \t Train loss: 0.1979 took: 0.99s  Val. loss: 0.1916\n",
      "Epoch 19, 100% \t Train loss: 0.1942 took: 0.99s  Val. loss: 0.1901\n",
      "Epoch 20, 100% \t Train loss: 0.1909 took: 1.52s  Val. loss: 0.1871\n",
      "Epoch 21, 100% \t Train loss: 0.1855 took: 0.99s  Val. loss: 0.1858\n",
      "Epoch 22, 100% \t Train loss: 0.1853 took: 0.99s  Val. loss: 0.1832\n",
      "Epoch 23, 100% \t Train loss: 0.1837 took: 0.99s  Val. loss: 0.1890\n",
      "Epoch 24, 100% \t Train loss: 0.1799 took: 0.99s  Val. loss: 0.1801\n",
      "Epoch 25, 100% \t Train loss: 0.1780 took: 0.99s  Val. loss: 0.1788\n",
      "Epoch 26, 100% \t Train loss: 0.1795 took: 0.99s  Val. loss: 0.1775\n",
      "Epoch 27, 100% \t Train loss: 0.1759 took: 1.00s  Val. loss: 0.1815\n",
      "Epoch 28, 100% \t Train loss: 0.1756 took: 1.00s  Val. loss: 0.1763\n",
      "Epoch 29, 100% \t Train loss: 0.1750 took: 1.00s  Val. loss: 0.1745\n",
      "Epoch 30, 100% \t Train loss: 0.1731 took: 1.01s  Val. loss: 0.1738\n",
      "Epoch 31, 100% \t Train loss: 0.1707 took: 1.00s  Val. loss: 0.1748\n",
      "Epoch 32, 100% \t Train loss: 0.1707 took: 1.01s  Val. loss: 0.1729\n",
      "Epoch 33, 100% \t Train loss: 0.1696 took: 1.00s  Val. loss: 0.1786\n",
      "Epoch 34, 100% \t Train loss: 0.1702 took: 1.01s  Val. loss: 0.1721\n",
      "Epoch 35, 100% \t Train loss: 0.1693 took: 1.01s  Val. loss: 0.1745\n",
      "Epoch 36, 100% \t Train loss: 0.1687 took: 1.01s  Val. loss: 0.1739\n",
      "Epoch 37, 100% \t Train loss: 0.1673 took: 1.01s  Val. loss: 0.1716\n",
      "Epoch 38, 100% \t Train loss: 0.1690 took: 1.01s  Val. loss: 0.1853\n",
      "Epoch 39, 100% \t Train loss: 0.1676 took: 1.01s  Val. loss: 0.1714\n",
      "Epoch 40, 100% \t Train loss: 0.1664 took: 1.03s  Val. loss: 0.1722\n",
      "Epoch 41, 100% \t Train loss: 0.1657 took: 1.01s  Val. loss: 0.1678\n",
      "Epoch 42, 100% \t Train loss: 0.1642 took: 1.01s  Val. loss: 0.1705\n",
      "Epoch 43, 100% \t Train loss: 0.1644 took: 1.02s  Val. loss: 0.1686\n",
      "Epoch 44, 100% \t Train loss: 0.1646 took: 1.01s  Val. loss: 0.1715\n",
      "Epoch 45, 100% \t Train loss: 0.1649 took: 1.01s  Val. loss: 0.1727\n",
      "Epoch 46, 100% \t Train loss: 0.1633 took: 1.02s  Val. loss: 0.1670\n",
      "Epoch 47, 100% \t Train loss: 0.1629 took: 1.02s  Val. loss: 0.1656\n",
      "Epoch 48, 100% \t Train loss: 0.1623 took: 1.03s  Val. loss: 0.1684\n",
      "Epoch 49, 100% \t Train loss: 0.1611 took: 1.03s  Val. loss: 0.1724\n",
      "Epoch 50, 100% \t Train loss: 0.1625 took: 1.03s  Val. loss: 0.1670\n",
      "Training finished, took 70.42s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.27\n",
      "\tmask_channels :  4  - prob: 0.26\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.814302\n",
      "lambda: 0.0010 - V: 0.815163\n",
      "lambda: 0.0005 - V: 0.802308\n",
      "Average V: 0.810591\n",
      "Time elapsed: 246.59 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.28\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2561 took: 1.03s  Val. loss: 0.2564\n",
      "Epoch 2, 100% \t Train loss: 0.2548 took: 1.04s  Val. loss: 0.2572\n",
      "Epoch 3, 100% \t Train loss: 0.2547 took: 1.03s  Val. loss: 0.2559\n",
      "Epoch 4, 100% \t Train loss: 0.2545 took: 1.04s  Val. loss: 0.2566\n",
      "Epoch 5, 100% \t Train loss: 0.2546 took: 1.03s  Val. loss: 0.2547\n",
      "Epoch 6, 100% \t Train loss: 0.2545 took: 1.03s  Val. loss: 0.2572\n",
      "Epoch 7, 100% \t Train loss: 0.2540 took: 1.03s  Val. loss: 0.2541\n",
      "Epoch 8, 100% \t Train loss: 0.2317 took: 1.03s  Val. loss: 0.2211\n",
      "Epoch 9, 100% \t Train loss: 0.1938 took: 1.03s  Val. loss: 0.1781\n",
      "Epoch 10, 100% \t Train loss: 0.1666 took: 1.03s  Val. loss: 0.1692\n",
      "Epoch 11, 100% \t Train loss: 0.1616 took: 1.03s  Val. loss: 0.1670\n",
      "Epoch 12, 100% \t Train loss: 0.1577 took: 1.03s  Val. loss: 0.1656\n",
      "Epoch 13, 100% \t Train loss: 0.1535 took: 1.03s  Val. loss: 0.1604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.1501 took: 1.03s  Val. loss: 0.1672\n",
      "Epoch 15, 100% \t Train loss: 0.1498 took: 1.03s  Val. loss: 0.1605\n",
      "Epoch 16, 100% \t Train loss: 0.1472 took: 1.04s  Val. loss: 0.1602\n",
      "Epoch 17, 100% \t Train loss: 0.1473 took: 1.32s  Val. loss: 0.1560\n",
      "Epoch 18, 100% \t Train loss: 0.1454 took: 1.77s  Val. loss: 0.1577\n",
      "Epoch 19, 100% \t Train loss: 0.1433 took: 1.78s  Val. loss: 0.1542\n",
      "Epoch 20, 100% \t Train loss: 0.1424 took: 1.78s  Val. loss: 0.1561\n",
      "Epoch 21, 100% \t Train loss: 0.1410 took: 1.78s  Val. loss: 0.1599\n",
      "Epoch 22, 100% \t Train loss: 0.1415 took: 1.76s  Val. loss: 0.1551\n",
      "Epoch 23, 100% \t Train loss: 0.1406 took: 1.76s  Val. loss: 0.1567\n",
      "Epoch 24, 100% \t Train loss: 0.1408 took: 1.76s  Val. loss: 0.1543\n",
      "Epoch 25, 100% \t Train loss: 0.1397 took: 1.77s  Val. loss: 0.1576\n",
      "Epoch 26, 100% \t Train loss: 0.1385 took: 1.03s  Val. loss: 0.1593\n",
      "Epoch 27, 100% \t Train loss: 0.1377 took: 1.03s  Val. loss: 0.1555\n",
      "Epoch 28, 100% \t Train loss: 0.1366 took: 1.04s  Val. loss: 0.1596\n",
      "Epoch 29, 100% \t Train loss: 0.1345 took: 1.06s  Val. loss: 0.1579\n",
      "Epoch 30, 100% \t Train loss: 0.1317 took: 1.08s  Val. loss: 0.1537\n",
      "Epoch 31, 100% \t Train loss: 0.1298 took: 1.09s  Val. loss: 0.1480\n",
      "Epoch 32, 100% \t Train loss: 0.1263 took: 1.11s  Val. loss: 0.1510\n",
      "Epoch 33, 100% \t Train loss: 0.1222 took: 1.18s  Val. loss: 0.1482\n",
      "Epoch 34, 100% \t Train loss: 0.1181 took: 1.16s  Val. loss: 0.1394\n",
      "Epoch 35, 100% \t Train loss: 0.1135 took: 1.16s  Val. loss: 0.1317\n",
      "Epoch 36, 100% \t Train loss: 0.1093 took: 1.18s  Val. loss: 0.1252\n",
      "Epoch 37, 100% \t Train loss: 0.1034 took: 1.20s  Val. loss: 0.1207\n",
      "Epoch 38, 100% \t Train loss: 0.0993 took: 1.23s  Val. loss: 0.1174\n",
      "Epoch 39, 100% \t Train loss: 0.0972 took: 1.24s  Val. loss: 0.1166\n",
      "Epoch 40, 100% \t Train loss: 0.0926 took: 1.23s  Val. loss: 0.1209\n",
      "Epoch 41, 100% \t Train loss: 0.0901 took: 1.23s  Val. loss: 0.1137\n",
      "Epoch 42, 100% \t Train loss: 0.0877 took: 1.22s  Val. loss: 0.1092\n",
      "Epoch 43, 100% \t Train loss: 0.0851 took: 1.22s  Val. loss: 0.1105\n",
      "Epoch 44, 100% \t Train loss: 0.0820 took: 1.22s  Val. loss: 0.1125\n",
      "Epoch 45, 100% \t Train loss: 0.0822 took: 1.22s  Val. loss: 0.1182\n",
      "Epoch 46, 100% \t Train loss: 0.0813 took: 1.24s  Val. loss: 0.1063\n",
      "Epoch 47, 100% \t Train loss: 0.0789 took: 1.24s  Val. loss: 0.1024\n",
      "Epoch 48, 100% \t Train loss: 0.0772 took: 1.31s  Val. loss: 0.1013\n",
      "Epoch 49, 100% \t Train loss: 0.0774 took: 1.24s  Val. loss: 0.1058\n",
      "Epoch 50, 100% \t Train loss: 0.0767 took: 1.25s  Val. loss: 0.1024\n",
      "Training finished, took 69.82s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2578 took: 1.03s  Val. loss: 0.2553\n",
      "Epoch 2, 100% \t Train loss: 0.2573 took: 1.02s  Val. loss: 0.2557\n",
      "Epoch 3, 100% \t Train loss: 0.2565 took: 1.03s  Val. loss: 0.2538\n",
      "Epoch 4, 100% \t Train loss: 0.2528 took: 1.02s  Val. loss: 0.2440\n",
      "Epoch 5, 100% \t Train loss: 0.2311 took: 1.02s  Val. loss: 0.2154\n",
      "Epoch 6, 100% \t Train loss: 0.2028 took: 1.02s  Val. loss: 0.1971\n",
      "Epoch 7, 100% \t Train loss: 0.1874 took: 1.02s  Val. loss: 0.1896\n",
      "Epoch 8, 100% \t Train loss: 0.1799 took: 1.56s  Val. loss: 0.1862\n",
      "Epoch 9, 100% \t Train loss: 0.1781 took: 1.77s  Val. loss: 0.1893\n",
      "Epoch 10, 100% \t Train loss: 0.1744 took: 1.79s  Val. loss: 0.1770\n",
      "Epoch 11, 100% \t Train loss: 0.1694 took: 1.78s  Val. loss: 0.1791\n",
      "Epoch 12, 100% \t Train loss: 0.1668 took: 1.78s  Val. loss: 0.1749\n",
      "Epoch 13, 100% \t Train loss: 0.1680 took: 1.78s  Val. loss: 0.1787\n",
      "Epoch 14, 100% \t Train loss: 0.1630 took: 1.78s  Val. loss: 0.1728\n",
      "Epoch 15, 100% \t Train loss: 0.1641 took: 1.78s  Val. loss: 0.1709\n",
      "Epoch 16, 100% \t Train loss: 0.1608 took: 1.78s  Val. loss: 0.1799\n",
      "Epoch 17, 100% \t Train loss: 0.1603 took: 1.78s  Val. loss: 0.1698\n",
      "Epoch 18, 100% \t Train loss: 0.1556 took: 1.78s  Val. loss: 0.1733\n",
      "Epoch 19, 100% \t Train loss: 0.1552 took: 1.78s  Val. loss: 0.1679\n",
      "Epoch 20, 100% \t Train loss: 0.1533 took: 1.78s  Val. loss: 0.1672\n",
      "Epoch 21, 100% \t Train loss: 0.1497 took: 1.80s  Val. loss: 0.1661\n",
      "Epoch 22, 100% \t Train loss: 0.1492 took: 1.79s  Val. loss: 0.1653\n",
      "Epoch 23, 100% \t Train loss: 0.1460 took: 1.78s  Val. loss: 0.1699\n",
      "Epoch 24, 100% \t Train loss: 0.1456 took: 1.78s  Val. loss: 0.1606\n",
      "Epoch 25, 100% \t Train loss: 0.1405 took: 1.78s  Val. loss: 0.1575\n",
      "Epoch 26, 100% \t Train loss: 0.1389 took: 1.77s  Val. loss: 0.1582\n",
      "Epoch 27, 100% \t Train loss: 0.1341 took: 1.78s  Val. loss: 0.1539\n",
      "Epoch 28, 100% \t Train loss: 0.1310 took: 1.78s  Val. loss: 0.1556\n",
      "Epoch 29, 100% \t Train loss: 0.1280 took: 1.79s  Val. loss: 0.1433\n",
      "Epoch 30, 100% \t Train loss: 0.1234 took: 1.80s  Val. loss: 0.1452\n",
      "Epoch 31, 100% \t Train loss: 0.1221 took: 1.78s  Val. loss: 0.1494\n",
      "Epoch 32, 100% \t Train loss: 0.1188 took: 1.80s  Val. loss: 0.1326\n",
      "Epoch 33, 100% \t Train loss: 0.1143 took: 1.80s  Val. loss: 0.1303\n",
      "Epoch 34, 100% \t Train loss: 0.1122 took: 1.80s  Val. loss: 0.1287\n",
      "Epoch 35, 100% \t Train loss: 0.1083 took: 1.80s  Val. loss: 0.1260\n",
      "Epoch 36, 100% \t Train loss: 0.1054 took: 1.81s  Val. loss: 0.1292\n",
      "Epoch 37, 100% \t Train loss: 0.1060 took: 1.81s  Val. loss: 0.1279\n",
      "Epoch 38, 100% \t Train loss: 0.1025 took: 1.80s  Val. loss: 0.1189\n",
      "Epoch 39, 100% \t Train loss: 0.0994 took: 1.80s  Val. loss: 0.1192\n",
      "Epoch 40, 100% \t Train loss: 0.0983 took: 1.80s  Val. loss: 0.1185\n",
      "Epoch 41, 100% \t Train loss: 0.0953 took: 1.82s  Val. loss: 0.1153\n",
      "Epoch 42, 100% \t Train loss: 0.0950 took: 1.81s  Val. loss: 0.1103\n",
      "Epoch 43, 100% \t Train loss: 0.0909 took: 1.82s  Val. loss: 0.1092\n",
      "Epoch 44, 100% \t Train loss: 0.0912 took: 1.83s  Val. loss: 0.1047\n",
      "Epoch 45, 100% \t Train loss: 0.0889 took: 1.83s  Val. loss: 0.1110\n",
      "Epoch 46, 100% \t Train loss: 0.0880 took: 1.83s  Val. loss: 0.1053\n",
      "Epoch 47, 100% \t Train loss: 0.0873 took: 1.84s  Val. loss: 0.1047\n",
      "Epoch 48, 100% \t Train loss: 0.0847 took: 1.85s  Val. loss: 0.1068\n",
      "Epoch 49, 100% \t Train loss: 0.0860 took: 1.84s  Val. loss: 0.1048\n",
      "Epoch 50, 100% \t Train loss: 0.0843 took: 1.84s  Val. loss: 0.1022\n",
      "Training finished, took 96.03s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2581 took: 1.80s  Val. loss: 0.2630\n",
      "Epoch 2, 100% \t Train loss: 0.2575 took: 1.81s  Val. loss: 0.2635\n",
      "Epoch 3, 100% \t Train loss: 0.2575 took: 1.80s  Val. loss: 0.2634\n",
      "Epoch 4, 100% \t Train loss: 0.2577 took: 1.79s  Val. loss: 0.2642\n",
      "Epoch 5, 100% \t Train loss: 0.2575 took: 1.79s  Val. loss: 0.2635\n",
      "Epoch 6, 100% \t Train loss: 0.2575 took: 1.79s  Val. loss: 0.2634\n",
      "Epoch 7, 100% \t Train loss: 0.2575 took: 1.80s  Val. loss: 0.2637\n",
      "Epoch 8, 100% \t Train loss: 0.2574 took: 1.79s  Val. loss: 0.2627\n",
      "Epoch 9, 100% \t Train loss: 0.2574 took: 1.80s  Val. loss: 0.2632\n",
      "Epoch 10, 100% \t Train loss: 0.2572 took: 1.80s  Val. loss: 0.2630\n",
      "Epoch 11, 100% \t Train loss: 0.2570 took: 1.80s  Val. loss: 0.2623\n",
      "Epoch 12, 100% \t Train loss: 0.2564 took: 1.78s  Val. loss: 0.2611\n",
      "Epoch 13, 100% \t Train loss: 0.2539 took: 1.78s  Val. loss: 0.2547\n",
      "Epoch 14, 100% \t Train loss: 0.2384 took: 1.79s  Val. loss: 0.2271\n",
      "Epoch 15, 100% \t Train loss: 0.2058 took: 1.80s  Val. loss: 0.1962\n",
      "Epoch 16, 100% \t Train loss: 0.1841 took: 1.79s  Val. loss: 0.1864\n",
      "Epoch 17, 100% \t Train loss: 0.1792 took: 1.78s  Val. loss: 0.1798\n",
      "Epoch 18, 100% \t Train loss: 0.1755 took: 1.79s  Val. loss: 0.1776\n",
      "Epoch 19, 100% \t Train loss: 0.1751 took: 1.80s  Val. loss: 0.1763\n",
      "Epoch 20, 100% \t Train loss: 0.1719 took: 1.79s  Val. loss: 0.1780\n",
      "Epoch 21, 100% \t Train loss: 0.1710 took: 1.79s  Val. loss: 0.1757\n",
      "Epoch 22, 100% \t Train loss: 0.1702 took: 1.79s  Val. loss: 0.1755\n",
      "Epoch 23, 100% \t Train loss: 0.1697 took: 1.78s  Val. loss: 0.1740\n",
      "Epoch 24, 100% \t Train loss: 0.1698 took: 1.80s  Val. loss: 0.1743\n",
      "Epoch 25, 100% \t Train loss: 0.1667 took: 1.79s  Val. loss: 0.1771\n",
      "Epoch 26, 100% \t Train loss: 0.1685 took: 1.80s  Val. loss: 0.1740\n",
      "Epoch 27, 100% \t Train loss: 0.1668 took: 1.80s  Val. loss: 0.1763\n",
      "Epoch 28, 100% \t Train loss: 0.1650 took: 1.79s  Val. loss: 0.1709\n",
      "Epoch 29, 100% \t Train loss: 0.1660 took: 1.81s  Val. loss: 0.1720\n",
      "Epoch 30, 100% \t Train loss: 0.1655 took: 1.80s  Val. loss: 0.1772\n",
      "Epoch 31, 100% \t Train loss: 0.1629 took: 1.81s  Val. loss: 0.1714\n",
      "Epoch 32, 100% \t Train loss: 0.1642 took: 1.82s  Val. loss: 0.1731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, 100% \t Train loss: 0.1626 took: 1.84s  Val. loss: 0.1752\n",
      "Epoch 34, 100% \t Train loss: 0.1638 took: 1.80s  Val. loss: 0.1761\n",
      "Epoch 35, 100% \t Train loss: 0.1618 took: 1.83s  Val. loss: 0.1719\n",
      "Epoch 36, 100% \t Train loss: 0.1628 took: 1.82s  Val. loss: 0.1705\n",
      "Epoch 37, 100% \t Train loss: 0.1617 took: 1.80s  Val. loss: 0.1698\n",
      "Epoch 38, 100% \t Train loss: 0.1612 took: 1.80s  Val. loss: 0.1764\n",
      "Epoch 39, 100% \t Train loss: 0.1598 took: 1.81s  Val. loss: 0.1706\n",
      "Epoch 40, 100% \t Train loss: 0.1582 took: 1.80s  Val. loss: 0.1705\n",
      "Epoch 41, 100% \t Train loss: 0.1601 took: 1.81s  Val. loss: 0.1684\n",
      "Epoch 42, 100% \t Train loss: 0.1583 took: 1.79s  Val. loss: 0.1699\n",
      "Epoch 43, 100% \t Train loss: 0.1586 took: 1.79s  Val. loss: 0.1690\n",
      "Epoch 44, 100% \t Train loss: 0.1584 took: 1.78s  Val. loss: 0.1770\n",
      "Epoch 45, 100% \t Train loss: 0.1591 took: 1.54s  Val. loss: 0.1743\n",
      "Epoch 46, 100% \t Train loss: 0.1581 took: 1.04s  Val. loss: 0.1730\n",
      "Epoch 47, 100% \t Train loss: 0.1569 took: 1.04s  Val. loss: 0.1686\n",
      "Epoch 48, 100% \t Train loss: 0.1569 took: 1.04s  Val. loss: 0.1691\n",
      "Epoch 49, 100% \t Train loss: 0.1569 took: 1.79s  Val. loss: 0.1706\n",
      "Epoch 50, 100% \t Train loss: 0.1554 took: 1.81s  Val. loss: 0.1703\n",
      "Training finished, took 99.45s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.28\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.841267\n",
      "lambda: 0.0010 - V: 0.843423\n",
      "lambda: 0.0005 - V: 0.801684\n",
      "Average V: 0.828791\n",
      "Time elapsed: 268.72 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.29\n",
      "\tmask_channels :  4  - prob: 0.28\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2599 took: 2.40s  Val. loss: 0.2626\n",
      "Epoch 2, 100% \t Train loss: 0.2592 took: 2.37s  Val. loss: 0.2618\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 2.37s  Val. loss: 0.2624\n",
      "Epoch 4, 100% \t Train loss: 0.2588 took: 2.38s  Val. loss: 0.2613\n",
      "Epoch 5, 100% \t Train loss: 0.2588 took: 2.39s  Val. loss: 0.2623\n",
      "Epoch 6, 100% \t Train loss: 0.2588 took: 2.39s  Val. loss: 0.2615\n",
      "Epoch 7, 100% \t Train loss: 0.2588 took: 2.38s  Val. loss: 0.2620\n",
      "Epoch 8, 100% \t Train loss: 0.2588 took: 2.40s  Val. loss: 0.2619\n",
      "Epoch 9, 100% \t Train loss: 0.2585 took: 2.40s  Val. loss: 0.2622\n",
      "Epoch 10, 100% \t Train loss: 0.2588 took: 2.39s  Val. loss: 0.2620\n",
      "Epoch 11, 100% \t Train loss: 0.2587 took: 2.39s  Val. loss: 0.2621\n",
      "Epoch 12, 100% \t Train loss: 0.2588 took: 2.39s  Val. loss: 0.2613\n",
      "Epoch 13, 100% \t Train loss: 0.2587 took: 2.39s  Val. loss: 0.2614\n",
      "Epoch 14, 100% \t Train loss: 0.2586 took: 2.41s  Val. loss: 0.2620\n",
      "Epoch 15, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2619\n",
      "Epoch 16, 100% \t Train loss: 0.2588 took: 2.40s  Val. loss: 0.2620\n",
      "Epoch 17, 100% \t Train loss: 0.2588 took: 2.40s  Val. loss: 0.2621\n",
      "Epoch 18, 100% \t Train loss: 0.2586 took: 2.40s  Val. loss: 0.2620\n",
      "Epoch 19, 100% \t Train loss: 0.2586 took: 2.39s  Val. loss: 0.2630\n",
      "Epoch 20, 100% \t Train loss: 0.2587 took: 2.38s  Val. loss: 0.2619\n",
      "Epoch 21, 100% \t Train loss: 0.2587 took: 2.38s  Val. loss: 0.2616\n",
      "Epoch 22, 100% \t Train loss: 0.2587 took: 2.39s  Val. loss: 0.2628\n",
      "Epoch 23, 100% \t Train loss: 0.2588 took: 2.39s  Val. loss: 0.2616\n",
      "Epoch 24, 100% \t Train loss: 0.2586 took: 2.39s  Val. loss: 0.2623\n",
      "Epoch 25, 100% \t Train loss: 0.2586 took: 2.38s  Val. loss: 0.2609\n",
      "Epoch 26, 100% \t Train loss: 0.2586 took: 2.38s  Val. loss: 0.2625\n",
      "Epoch 27, 100% \t Train loss: 0.2586 took: 2.38s  Val. loss: 0.2618\n",
      "Epoch 28, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2612\n",
      "Epoch 29, 100% \t Train loss: 0.2586 took: 2.41s  Val. loss: 0.2626\n",
      "Epoch 30, 100% \t Train loss: 0.2586 took: 2.43s  Val. loss: 0.2614\n",
      "Epoch 31, 100% \t Train loss: 0.2586 took: 2.44s  Val. loss: 0.2625\n",
      "Epoch 32, 100% \t Train loss: 0.2586 took: 2.55s  Val. loss: 0.2617\n",
      "Epoch 33, 100% \t Train loss: 0.2586 took: 2.78s  Val. loss: 0.2628\n",
      "Epoch 34, 100% \t Train loss: 0.2586 took: 2.83s  Val. loss: 0.2615\n",
      "Epoch 35, 100% \t Train loss: 0.2586 took: 2.85s  Val. loss: 0.2625\n",
      "Epoch 36, 100% \t Train loss: 0.2586 took: 2.87s  Val. loss: 0.2627\n",
      "Epoch 37, 100% \t Train loss: 0.2586 took: 3.06s  Val. loss: 0.2624\n",
      "Epoch 38, 100% \t Train loss: 0.2587 took: 2.95s  Val. loss: 0.2618\n",
      "Epoch 39, 100% \t Train loss: 0.2586 took: 2.99s  Val. loss: 0.2621\n",
      "Epoch 40, 100% \t Train loss: 0.2586 took: 3.01s  Val. loss: 0.2627\n",
      "Epoch 41, 100% \t Train loss: 0.2586 took: 3.06s  Val. loss: 0.2614\n",
      "Epoch 42, 100% \t Train loss: 0.2586 took: 3.15s  Val. loss: 0.2624\n",
      "Epoch 43, 100% \t Train loss: 0.2586 took: 3.15s  Val. loss: 0.2627\n",
      "Epoch 44, 100% \t Train loss: 0.2586 took: 3.13s  Val. loss: 0.2626\n",
      "Epoch 45, 100% \t Train loss: 0.2586 took: 3.21s  Val. loss: 0.2619\n",
      "Epoch 46, 100% \t Train loss: 0.2586 took: 3.17s  Val. loss: 0.2619\n",
      "Epoch 47, 100% \t Train loss: 0.2586 took: 3.21s  Val. loss: 0.2619\n",
      "Epoch 48, 100% \t Train loss: 0.2586 took: 3.19s  Val. loss: 0.2613\n",
      "Epoch 49, 100% \t Train loss: 0.2586 took: 3.22s  Val. loss: 0.2618\n",
      "Epoch 50, 100% \t Train loss: 0.2586 took: 3.21s  Val. loss: 0.2625\n",
      "Training finished, took 146.23s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 2.41s  Val. loss: 0.2582\n",
      "Epoch 2, 100% \t Train loss: 0.2594 took: 2.40s  Val. loss: 0.2599\n",
      "Epoch 3, 100% \t Train loss: 0.2594 took: 2.39s  Val. loss: 0.2583\n",
      "Epoch 4, 100% \t Train loss: 0.2594 took: 2.38s  Val. loss: 0.2583\n",
      "Epoch 5, 100% \t Train loss: 0.2595 took: 2.38s  Val. loss: 0.2616\n",
      "Epoch 6, 100% \t Train loss: 0.2594 took: 2.38s  Val. loss: 0.2591\n",
      "Epoch 7, 100% \t Train loss: 0.2595 took: 2.39s  Val. loss: 0.2583\n",
      "Epoch 8, 100% \t Train loss: 0.2594 took: 2.38s  Val. loss: 0.2579\n",
      "Epoch 9, 100% \t Train loss: 0.2594 took: 2.38s  Val. loss: 0.2599\n",
      "Epoch 10, 100% \t Train loss: 0.2596 took: 2.41s  Val. loss: 0.2594\n",
      "Epoch 11, 100% \t Train loss: 0.2594 took: 2.40s  Val. loss: 0.2608\n",
      "Epoch 12, 100% \t Train loss: 0.2593 took: 2.40s  Val. loss: 0.2622\n",
      "Epoch 13, 100% \t Train loss: 0.2595 took: 2.40s  Val. loss: 0.2614\n",
      "Epoch 14, 100% \t Train loss: 0.2596 took: 2.39s  Val. loss: 0.2584\n",
      "Epoch 15, 100% \t Train loss: 0.2594 took: 2.40s  Val. loss: 0.2600\n",
      "Epoch 16, 100% \t Train loss: 0.2595 took: 2.39s  Val. loss: 0.2599\n",
      "Epoch 17, 100% \t Train loss: 0.2594 took: 2.39s  Val. loss: 0.2600\n",
      "Epoch 18, 100% \t Train loss: 0.2593 took: 2.39s  Val. loss: 0.2613\n",
      "Epoch 19, 100% \t Train loss: 0.2598 took: 2.39s  Val. loss: 0.2591\n",
      "Epoch 20, 100% \t Train loss: 0.2594 took: 2.41s  Val. loss: 0.2583\n",
      "Epoch 21, 100% \t Train loss: 0.2593 took: 2.41s  Val. loss: 0.2591\n",
      "Epoch 22, 100% \t Train loss: 0.2594 took: 2.41s  Val. loss: 0.2593\n",
      "Epoch 23, 100% \t Train loss: 0.2593 took: 2.39s  Val. loss: 0.2617\n",
      "Epoch 24, 100% \t Train loss: 0.2593 took: 2.40s  Val. loss: 0.2587\n",
      "Epoch 25, 100% \t Train loss: 0.2594 took: 2.39s  Val. loss: 0.2608\n",
      "Epoch 26, 100% \t Train loss: 0.2594 took: 2.41s  Val. loss: 0.2595\n",
      "Epoch 27, 100% \t Train loss: 0.2594 took: 2.42s  Val. loss: 0.2584\n",
      "Epoch 28, 100% \t Train loss: 0.2594 took: 2.44s  Val. loss: 0.2579\n",
      "Epoch 29, 100% \t Train loss: 0.2594 took: 2.45s  Val. loss: 0.2599\n",
      "Epoch 30, 100% \t Train loss: 0.2594 took: 2.46s  Val. loss: 0.2599\n",
      "Epoch 31, 100% \t Train loss: 0.2594 took: 2.49s  Val. loss: 0.2587\n",
      "Epoch 32, 100% \t Train loss: 0.2595 took: 2.51s  Val. loss: 0.2602\n",
      "Epoch 33, 100% \t Train loss: 0.2593 took: 2.50s  Val. loss: 0.2594\n",
      "Epoch 34, 100% \t Train loss: 0.2594 took: 2.55s  Val. loss: 0.2596\n",
      "Epoch 35, 100% \t Train loss: 0.2594 took: 2.57s  Val. loss: 0.2584\n",
      "Epoch 36, 100% \t Train loss: 0.2595 took: 2.63s  Val. loss: 0.2597\n",
      "Epoch 37, 100% \t Train loss: 0.2593 took: 2.69s  Val. loss: 0.2587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, 100% \t Train loss: 0.2593 took: 2.73s  Val. loss: 0.2600\n",
      "Epoch 39, 100% \t Train loss: 0.2593 took: 2.71s  Val. loss: 0.2596\n",
      "Epoch 40, 100% \t Train loss: 0.2592 took: 2.70s  Val. loss: 0.2587\n",
      "Epoch 41, 100% \t Train loss: 0.2595 took: 2.47s  Val. loss: 0.2601\n",
      "Epoch 42, 100% \t Train loss: 0.2593 took: 2.49s  Val. loss: 0.2586\n",
      "Epoch 43, 100% \t Train loss: 0.2595 took: 2.46s  Val. loss: 0.2590\n",
      "Epoch 44, 100% \t Train loss: 0.2594 took: 2.51s  Val. loss: 0.2595\n",
      "Epoch 45, 100% \t Train loss: 0.2593 took: 2.54s  Val. loss: 0.2597\n",
      "Epoch 46, 100% \t Train loss: 0.2594 took: 2.71s  Val. loss: 0.2595\n",
      "Epoch 47, 100% \t Train loss: 0.2592 took: 2.56s  Val. loss: 0.2599\n",
      "Epoch 48, 100% \t Train loss: 0.2593 took: 2.57s  Val. loss: 0.2600\n",
      "Epoch 49, 100% \t Train loss: 0.2593 took: 2.59s  Val. loss: 0.2607\n",
      "Epoch 50, 100% \t Train loss: 0.2593 took: 2.58s  Val. loss: 0.2608\n",
      "Training finished, took 136.85s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2593 took: 2.39s  Val. loss: 0.2629\n",
      "Epoch 2, 100% \t Train loss: 0.2581 took: 2.37s  Val. loss: 0.2624\n",
      "Epoch 3, 100% \t Train loss: 0.2582 took: 2.38s  Val. loss: 0.2634\n",
      "Epoch 4, 100% \t Train loss: 0.2582 took: 2.38s  Val. loss: 0.2631\n",
      "Epoch 5, 100% \t Train loss: 0.2581 took: 2.37s  Val. loss: 0.2617\n",
      "Epoch 6, 100% \t Train loss: 0.2584 took: 2.39s  Val. loss: 0.2617\n",
      "Epoch 7, 100% \t Train loss: 0.2582 took: 2.38s  Val. loss: 0.2626\n",
      "Epoch 8, 100% \t Train loss: 0.2582 took: 2.37s  Val. loss: 0.2629\n",
      "Epoch 9, 100% \t Train loss: 0.2583 took: 2.39s  Val. loss: 0.2632\n",
      "Epoch 10, 100% \t Train loss: 0.2581 took: 2.37s  Val. loss: 0.2626\n",
      "Epoch 11, 100% \t Train loss: 0.2581 took: 2.38s  Val. loss: 0.2630\n",
      "Epoch 12, 100% \t Train loss: 0.2581 took: 2.38s  Val. loss: 0.2629\n",
      "Epoch 13, 100% \t Train loss: 0.2582 took: 2.38s  Val. loss: 0.2624\n",
      "Epoch 14, 100% \t Train loss: 0.2581 took: 2.38s  Val. loss: 0.2634\n",
      "Epoch 15, 100% \t Train loss: 0.2582 took: 2.38s  Val. loss: 0.2630\n",
      "Epoch 16, 100% \t Train loss: 0.2582 took: 2.39s  Val. loss: 0.2628\n",
      "Epoch 17, 100% \t Train loss: 0.2581 took: 2.38s  Val. loss: 0.2617\n",
      "Epoch 18, 100% \t Train loss: 0.2581 took: 2.38s  Val. loss: 0.2625\n",
      "Epoch 19, 100% \t Train loss: 0.2582 took: 2.38s  Val. loss: 0.2626\n",
      "Epoch 20, 100% \t Train loss: 0.2581 took: 2.38s  Val. loss: 0.2629\n",
      "Epoch 21, 100% \t Train loss: 0.2582 took: 2.39s  Val. loss: 0.2634\n",
      "Epoch 22, 100% \t Train loss: 0.2581 took: 2.38s  Val. loss: 0.2617\n",
      "Epoch 23, 100% \t Train loss: 0.2582 took: 2.37s  Val. loss: 0.2641\n",
      "Epoch 24, 100% \t Train loss: 0.2583 took: 2.38s  Val. loss: 0.2627\n",
      "Epoch 25, 100% \t Train loss: 0.2582 took: 2.37s  Val. loss: 0.2630\n",
      "Epoch 26, 100% \t Train loss: 0.2581 took: 2.38s  Val. loss: 0.2627\n",
      "Epoch 27, 100% \t Train loss: 0.2581 took: 2.39s  Val. loss: 0.2631\n",
      "Epoch 28, 100% \t Train loss: 0.2582 took: 2.41s  Val. loss: 0.2628\n",
      "Epoch 29, 100% \t Train loss: 0.2581 took: 2.42s  Val. loss: 0.2626\n",
      "Epoch 30, 100% \t Train loss: 0.2582 took: 2.44s  Val. loss: 0.2619\n",
      "Epoch 31, 100% \t Train loss: 0.2583 took: 2.45s  Val. loss: 0.2620\n",
      "Epoch 32, 100% \t Train loss: 0.2582 took: 2.45s  Val. loss: 0.2631\n",
      "Epoch 33, 100% \t Train loss: 0.2581 took: 2.46s  Val. loss: 0.2630\n",
      "Epoch 34, 100% \t Train loss: 0.2582 took: 2.49s  Val. loss: 0.2626\n",
      "Epoch 35, 100% \t Train loss: 0.2581 took: 2.49s  Val. loss: 0.2625\n",
      "Epoch 36, 100% \t Train loss: 0.2582 took: 2.50s  Val. loss: 0.2630\n",
      "Epoch 37, 100% \t Train loss: 0.2581 took: 2.49s  Val. loss: 0.2625\n",
      "Epoch 38, 100% \t Train loss: 0.2582 took: 2.49s  Val. loss: 0.2620\n",
      "Epoch 39, 100% \t Train loss: 0.2582 took: 2.51s  Val. loss: 0.2624\n",
      "Epoch 40, 100% \t Train loss: 0.2582 took: 2.49s  Val. loss: 0.2620\n",
      "Epoch 41, 100% \t Train loss: 0.2581 took: 2.54s  Val. loss: 0.2626\n",
      "Epoch 42, 100% \t Train loss: 0.2581 took: 2.55s  Val. loss: 0.2612\n",
      "Epoch 43, 100% \t Train loss: 0.2581 took: 2.56s  Val. loss: 0.2613\n",
      "Epoch 44, 100% \t Train loss: 0.2583 took: 2.55s  Val. loss: 0.2621\n",
      "Epoch 45, 100% \t Train loss: 0.2581 took: 2.56s  Val. loss: 0.2621\n",
      "Epoch 46, 100% \t Train loss: 0.2581 took: 2.58s  Val. loss: 0.2633\n",
      "Epoch 47, 100% \t Train loss: 0.2581 took: 2.58s  Val. loss: 0.2618\n",
      "Epoch 48, 100% \t Train loss: 0.2581 took: 2.60s  Val. loss: 0.2618\n",
      "Epoch 49, 100% \t Train loss: 0.2582 took: 2.62s  Val. loss: 0.2633\n",
      "Epoch 50, 100% \t Train loss: 0.2582 took: 2.66s  Val. loss: 0.2626\n",
      "Training finished, took 135.45s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  2  - prob: 0.37\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.29\n",
      "\tmask_channels :  4  - prob: 0.28\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.737972\n",
      "lambda: 0.0010 - V: 0.740439\n",
      "lambda: 0.0005 - V: 0.737424\n",
      "Average V: 0.738612\n",
      "Time elapsed: 422.03 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.29\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.30\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 2.44s  Val. loss: 0.2579\n",
      "Epoch 2, 100% \t Train loss: 0.2588 took: 2.42s  Val. loss: 0.2573\n",
      "Epoch 3, 100% \t Train loss: 0.2587 took: 2.41s  Val. loss: 0.2571\n",
      "Epoch 4, 100% \t Train loss: 0.2586 took: 2.40s  Val. loss: 0.2577\n",
      "Epoch 5, 100% \t Train loss: 0.2586 took: 2.42s  Val. loss: 0.2575\n",
      "Epoch 6, 100% \t Train loss: 0.2586 took: 2.43s  Val. loss: 0.2570\n",
      "Epoch 7, 100% \t Train loss: 0.2585 took: 2.42s  Val. loss: 0.2568\n",
      "Epoch 8, 100% \t Train loss: 0.2585 took: 2.42s  Val. loss: 0.2571\n",
      "Epoch 9, 100% \t Train loss: 0.2585 took: 2.45s  Val. loss: 0.2563\n",
      "Epoch 10, 100% \t Train loss: 0.2585 took: 2.41s  Val. loss: 0.2566\n",
      "Epoch 11, 100% \t Train loss: 0.2586 took: 2.43s  Val. loss: 0.2574\n",
      "Epoch 12, 100% \t Train loss: 0.2586 took: 2.44s  Val. loss: 0.2564\n",
      "Epoch 13, 100% \t Train loss: 0.2585 took: 2.43s  Val. loss: 0.2573\n",
      "Epoch 14, 100% \t Train loss: 0.2584 took: 2.43s  Val. loss: 0.2576\n",
      "Epoch 15, 100% \t Train loss: 0.2585 took: 2.46s  Val. loss: 0.2569\n",
      "Epoch 16, 100% \t Train loss: 0.2584 took: 2.46s  Val. loss: 0.2571\n",
      "Epoch 17, 100% \t Train loss: 0.2585 took: 2.53s  Val. loss: 0.2571\n",
      "Epoch 18, 100% \t Train loss: 0.2585 took: 2.50s  Val. loss: 0.2568\n",
      "Epoch 19, 100% \t Train loss: 0.2585 took: 2.54s  Val. loss: 0.2562\n",
      "Epoch 20, 100% \t Train loss: 0.2584 took: 2.54s  Val. loss: 0.2559\n",
      "Epoch 21, 100% \t Train loss: 0.2585 took: 2.54s  Val. loss: 0.2574\n",
      "Epoch 22, 100% \t Train loss: 0.2585 took: 2.51s  Val. loss: 0.2565\n",
      "Epoch 23, 100% \t Train loss: 0.2585 took: 2.43s  Val. loss: 0.2572\n",
      "Epoch 24, 100% \t Train loss: 0.2585 took: 2.43s  Val. loss: 0.2572\n",
      "Epoch 25, 100% \t Train loss: 0.2585 took: 2.45s  Val. loss: 0.2573\n",
      "Epoch 26, 100% \t Train loss: 0.2584 took: 2.44s  Val. loss: 0.2562\n",
      "Epoch 27, 100% \t Train loss: 0.2584 took: 2.48s  Val. loss: 0.2570\n",
      "Epoch 28, 100% \t Train loss: 0.2585 took: 2.52s  Val. loss: 0.2580\n",
      "Epoch 29, 100% \t Train loss: 0.2584 took: 2.63s  Val. loss: 0.2569\n",
      "Epoch 30, 100% \t Train loss: 0.2584 took: 2.74s  Val. loss: 0.2569\n",
      "Epoch 31, 100% \t Train loss: 0.2584 took: 2.85s  Val. loss: 0.2570\n",
      "Epoch 32, 100% \t Train loss: 0.2584 took: 2.95s  Val. loss: 0.2573\n",
      "Epoch 33, 100% \t Train loss: 0.2584 took: 3.20s  Val. loss: 0.2576\n",
      "Epoch 34, 100% \t Train loss: 0.2584 took: 3.27s  Val. loss: 0.2574\n",
      "Epoch 35, 100% \t Train loss: 0.2585 took: 3.41s  Val. loss: 0.2566\n",
      "Epoch 36, 100% \t Train loss: 0.2584 took: 3.24s  Val. loss: 0.2565\n",
      "Epoch 37, 100% \t Train loss: 0.2584 took: 3.38s  Val. loss: 0.2557\n",
      "Epoch 38, 100% \t Train loss: 0.2584 took: 3.43s  Val. loss: 0.2579\n",
      "Epoch 39, 100% \t Train loss: 0.2584 took: 3.46s  Val. loss: 0.2569\n",
      "Epoch 40, 100% \t Train loss: 0.2584 took: 3.37s  Val. loss: 0.2575\n",
      "Epoch 41, 100% \t Train loss: 0.2584 took: 3.47s  Val. loss: 0.2569\n",
      "Epoch 42, 100% \t Train loss: 0.2584 took: 3.36s  Val. loss: 0.2573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, 100% \t Train loss: 0.2584 took: 3.39s  Val. loss: 0.2566\n",
      "Epoch 44, 100% \t Train loss: 0.2584 took: 3.39s  Val. loss: 0.2567\n",
      "Epoch 45, 100% \t Train loss: 0.2584 took: 3.42s  Val. loss: 0.2571\n",
      "Epoch 46, 100% \t Train loss: 0.2584 took: 3.41s  Val. loss: 0.2567\n",
      "Epoch 47, 100% \t Train loss: 0.2584 took: 3.36s  Val. loss: 0.2563\n",
      "Epoch 48, 100% \t Train loss: 0.2584 took: 3.33s  Val. loss: 0.2565\n",
      "Epoch 49, 100% \t Train loss: 0.2584 took: 3.36s  Val. loss: 0.2564\n",
      "Epoch 50, 100% \t Train loss: 0.2583 took: 3.23s  Val. loss: 0.2571\n",
      "Training finished, took 155.10s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2611 took: 2.44s  Val. loss: 0.2634\n",
      "Epoch 2, 100% \t Train loss: 0.2606 took: 2.42s  Val. loss: 0.2652\n",
      "Epoch 3, 100% \t Train loss: 0.2606 took: 2.43s  Val. loss: 0.2651\n",
      "Epoch 4, 100% \t Train loss: 0.2606 took: 2.42s  Val. loss: 0.2640\n",
      "Epoch 5, 100% \t Train loss: 0.2606 took: 2.38s  Val. loss: 0.2646\n",
      "Epoch 6, 100% \t Train loss: 0.2606 took: 2.44s  Val. loss: 0.2663\n",
      "Epoch 7, 100% \t Train loss: 0.2606 took: 2.43s  Val. loss: 0.2646\n",
      "Epoch 8, 100% \t Train loss: 0.2605 took: 2.44s  Val. loss: 0.2640\n",
      "Epoch 9, 100% \t Train loss: 0.2606 took: 2.44s  Val. loss: 0.2643\n",
      "Epoch 10, 100% \t Train loss: 0.2605 took: 2.43s  Val. loss: 0.2644\n",
      "Epoch 11, 100% \t Train loss: 0.2606 took: 2.46s  Val. loss: 0.2640\n",
      "Epoch 12, 100% \t Train loss: 0.2605 took: 2.43s  Val. loss: 0.2628\n",
      "Epoch 13, 100% \t Train loss: 0.2606 took: 2.43s  Val. loss: 0.2638\n",
      "Epoch 14, 100% \t Train loss: 0.2606 took: 2.44s  Val. loss: 0.2627\n",
      "Epoch 15, 100% \t Train loss: 0.2605 took: 2.42s  Val. loss: 0.2645\n",
      "Epoch 16, 100% \t Train loss: 0.2606 took: 2.43s  Val. loss: 0.2629\n",
      "Epoch 17, 100% \t Train loss: 0.2605 took: 2.43s  Val. loss: 0.2651\n",
      "Epoch 18, 100% \t Train loss: 0.2605 took: 2.43s  Val. loss: 0.2631\n",
      "Epoch 19, 100% \t Train loss: 0.2605 took: 2.44s  Val. loss: 0.2642\n",
      "Epoch 20, 100% \t Train loss: 0.2606 took: 2.43s  Val. loss: 0.2633\n",
      "Epoch 21, 100% \t Train loss: 0.2605 took: 2.43s  Val. loss: 0.2657\n",
      "Epoch 22, 100% \t Train loss: 0.2605 took: 2.42s  Val. loss: 0.2633\n",
      "Epoch 23, 100% \t Train loss: 0.2605 took: 2.43s  Val. loss: 0.2634\n",
      "Epoch 24, 100% \t Train loss: 0.2606 took: 2.41s  Val. loss: 0.2634\n",
      "Epoch 25, 100% \t Train loss: 0.2605 took: 2.41s  Val. loss: 0.2635\n",
      "Epoch 26, 100% \t Train loss: 0.2606 took: 1.48s  Val. loss: 0.2635\n",
      "Epoch 27, 100% \t Train loss: 0.2606 took: 1.50s  Val. loss: 0.2633\n",
      "Epoch 28, 100% \t Train loss: 0.2606 took: 1.57s  Val. loss: 0.2621\n",
      "Epoch 29, 100% \t Train loss: 0.2605 took: 2.46s  Val. loss: 0.2628\n",
      "Epoch 30, 100% \t Train loss: 0.2605 took: 2.48s  Val. loss: 0.2644\n",
      "Epoch 31, 100% \t Train loss: 0.2605 took: 2.48s  Val. loss: 0.2638\n",
      "Epoch 32, 100% \t Train loss: 0.2605 took: 2.54s  Val. loss: 0.2656\n",
      "Epoch 33, 100% \t Train loss: 0.2605 took: 2.55s  Val. loss: 0.2638\n",
      "Epoch 34, 100% \t Train loss: 0.2605 took: 2.55s  Val. loss: 0.2637\n",
      "Epoch 35, 100% \t Train loss: 0.2605 took: 2.56s  Val. loss: 0.2640\n",
      "Epoch 36, 100% \t Train loss: 0.2605 took: 2.61s  Val. loss: 0.2652\n",
      "Epoch 37, 100% \t Train loss: 0.2606 took: 2.62s  Val. loss: 0.2649\n",
      "Epoch 38, 100% \t Train loss: 0.2605 took: 2.62s  Val. loss: 0.2634\n",
      "Epoch 39, 100% \t Train loss: 0.2605 took: 2.62s  Val. loss: 0.2636\n",
      "Epoch 40, 100% \t Train loss: 0.2605 took: 2.62s  Val. loss: 0.2650\n",
      "Epoch 41, 100% \t Train loss: 0.2605 took: 2.66s  Val. loss: 0.2637\n",
      "Epoch 42, 100% \t Train loss: 0.2605 took: 2.67s  Val. loss: 0.2631\n",
      "Epoch 43, 100% \t Train loss: 0.2605 took: 2.64s  Val. loss: 0.2638\n",
      "Epoch 44, 100% \t Train loss: 0.2605 took: 2.59s  Val. loss: 0.2641\n",
      "Epoch 45, 100% \t Train loss: 0.2605 took: 2.76s  Val. loss: 0.2641\n",
      "Epoch 46, 100% \t Train loss: 0.2605 took: 2.80s  Val. loss: 0.2653\n",
      "Epoch 47, 100% \t Train loss: 0.2605 took: 2.58s  Val. loss: 0.2644\n",
      "Epoch 48, 100% \t Train loss: 0.2605 took: 2.64s  Val. loss: 0.2633\n",
      "Epoch 49, 100% \t Train loss: 0.2605 took: 2.65s  Val. loss: 0.2637\n",
      "Epoch 50, 100% \t Train loss: 0.2605 took: 1.60s  Val. loss: 0.2634\n",
      "Training finished, took 134.55s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 2.40s  Val. loss: 0.2491\n",
      "Epoch 2, 100% \t Train loss: 0.2559 took: 2.43s  Val. loss: 0.2489\n",
      "Epoch 3, 100% \t Train loss: 0.2558 took: 2.41s  Val. loss: 0.2493\n",
      "Epoch 4, 100% \t Train loss: 0.2559 took: 2.42s  Val. loss: 0.2490\n",
      "Epoch 5, 100% \t Train loss: 0.2559 took: 2.41s  Val. loss: 0.2498\n",
      "Epoch 6, 100% \t Train loss: 0.2559 took: 2.39s  Val. loss: 0.2493\n",
      "Epoch 7, 100% \t Train loss: 0.2559 took: 2.42s  Val. loss: 0.2498\n",
      "Epoch 8, 100% \t Train loss: 0.2559 took: 2.40s  Val. loss: 0.2491\n",
      "Epoch 9, 100% \t Train loss: 0.2559 took: 1.46s  Val. loss: 0.2483\n",
      "Epoch 10, 100% \t Train loss: 0.2559 took: 1.46s  Val. loss: 0.2484\n",
      "Epoch 11, 100% \t Train loss: 0.2559 took: 1.47s  Val. loss: 0.2493\n",
      "Epoch 12, 100% \t Train loss: 0.2559 took: 1.46s  Val. loss: 0.2495\n",
      "Epoch 13, 100% \t Train loss: 0.2559 took: 1.47s  Val. loss: 0.2493\n",
      "Epoch 14, 100% \t Train loss: 0.2559 took: 1.47s  Val. loss: 0.2498\n",
      "Epoch 15, 100% \t Train loss: 0.2558 took: 1.47s  Val. loss: 0.2491\n",
      "Epoch 16, 100% \t Train loss: 0.2559 took: 1.47s  Val. loss: 0.2494\n",
      "Epoch 17, 100% \t Train loss: 0.2559 took: 1.47s  Val. loss: 0.2504\n",
      "Epoch 18, 100% \t Train loss: 0.2560 took: 1.47s  Val. loss: 0.2485\n",
      "Epoch 19, 100% \t Train loss: 0.2559 took: 1.47s  Val. loss: 0.2490\n",
      "Epoch 20, 100% \t Train loss: 0.2559 took: 1.47s  Val. loss: 0.2501\n",
      "Epoch 21, 100% \t Train loss: 0.2558 took: 1.48s  Val. loss: 0.2488\n",
      "Epoch 22, 100% \t Train loss: 0.2559 took: 1.48s  Val. loss: 0.2490\n",
      "Epoch 23, 100% \t Train loss: 0.2558 took: 1.48s  Val. loss: 0.2490\n",
      "Epoch 24, 100% \t Train loss: 0.2559 took: 1.47s  Val. loss: 0.2489\n",
      "Epoch 25, 100% \t Train loss: 0.2558 took: 1.47s  Val. loss: 0.2485\n",
      "Epoch 26, 100% \t Train loss: 0.2558 took: 1.48s  Val. loss: 0.2491\n",
      "Epoch 27, 100% \t Train loss: 0.2555 took: 1.49s  Val. loss: 0.2484\n",
      "Epoch 28, 100% \t Train loss: 0.2542 took: 1.49s  Val. loss: 0.2458\n",
      "Epoch 29, 100% \t Train loss: 0.2452 took: 1.49s  Val. loss: 0.2273\n",
      "Epoch 30, 100% \t Train loss: 0.2152 took: 1.95s  Val. loss: 0.1977\n",
      "Epoch 31, 100% \t Train loss: 0.1895 took: 2.46s  Val. loss: 0.1820\n",
      "Epoch 32, 100% \t Train loss: 0.1792 took: 2.47s  Val. loss: 0.1785\n",
      "Epoch 33, 100% \t Train loss: 0.1761 took: 2.47s  Val. loss: 0.1743\n",
      "Epoch 34, 100% \t Train loss: 0.1740 took: 2.47s  Val. loss: 0.1726\n",
      "Epoch 35, 100% \t Train loss: 0.1724 took: 2.47s  Val. loss: 0.1687\n",
      "Epoch 36, 100% \t Train loss: 0.1696 took: 2.46s  Val. loss: 0.1669\n",
      "Epoch 37, 100% \t Train loss: 0.1672 took: 2.46s  Val. loss: 0.1656\n",
      "Epoch 38, 100% \t Train loss: 0.1656 took: 2.48s  Val. loss: 0.1651\n",
      "Epoch 39, 100% \t Train loss: 0.1647 took: 2.46s  Val. loss: 0.1628\n",
      "Epoch 40, 100% \t Train loss: 0.1634 took: 2.49s  Val. loss: 0.1613\n",
      "Epoch 41, 100% \t Train loss: 0.1619 took: 2.48s  Val. loss: 0.1590\n",
      "Epoch 42, 100% \t Train loss: 0.1615 took: 2.47s  Val. loss: 0.1617\n",
      "Epoch 43, 100% \t Train loss: 0.1606 took: 2.46s  Val. loss: 0.1590\n",
      "Epoch 44, 100% \t Train loss: 0.1603 took: 2.50s  Val. loss: 0.1567\n",
      "Epoch 45, 100% \t Train loss: 0.1592 took: 2.50s  Val. loss: 0.1572\n",
      "Epoch 46, 100% \t Train loss: 0.1588 took: 2.49s  Val. loss: 0.1573\n",
      "Epoch 47, 100% \t Train loss: 0.1581 took: 2.53s  Val. loss: 0.1567\n",
      "Epoch 48, 100% \t Train loss: 0.1576 took: 2.56s  Val. loss: 0.1576\n",
      "Epoch 49, 100% \t Train loss: 0.1576 took: 2.59s  Val. loss: 0.1548\n",
      "Epoch 50, 100% \t Train loss: 0.1570 took: 2.47s  Val. loss: 0.1547\n",
      "Training finished, took 112.97s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.29\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.30\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.743036\n",
      "lambda: 0.0010 - V: 0.736007\n",
      "lambda: 0.0005 - V: 0.786590\n",
      "Average V: 0.755211\n",
      "Time elapsed: 406.01 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.37\n",
      "\tmask_channels :  8  - prob: 0.38\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 2.77s  Val. loss: 0.2573\n",
      "Epoch 2, 100% \t Train loss: 0.2562 took: 2.77s  Val. loss: 0.2564\n",
      "Epoch 3, 100% \t Train loss: 0.2559 took: 2.78s  Val. loss: 0.2546\n",
      "Epoch 4, 100% \t Train loss: 0.2560 took: 2.77s  Val. loss: 0.2559\n",
      "Epoch 5, 100% \t Train loss: 0.2557 took: 2.78s  Val. loss: 0.2587\n",
      "Epoch 6, 100% \t Train loss: 0.2561 took: 2.77s  Val. loss: 0.2542\n",
      "Epoch 7, 100% \t Train loss: 0.2560 took: 2.75s  Val. loss: 0.2556\n",
      "Epoch 8, 100% \t Train loss: 0.2559 took: 2.79s  Val. loss: 0.2553\n",
      "Epoch 9, 100% \t Train loss: 0.2558 took: 2.78s  Val. loss: 0.2544\n",
      "Epoch 10, 100% \t Train loss: 0.2559 took: 2.80s  Val. loss: 0.2557\n",
      "Epoch 11, 100% \t Train loss: 0.2559 took: 2.81s  Val. loss: 0.2551\n",
      "Epoch 12, 100% \t Train loss: 0.2558 took: 2.80s  Val. loss: 0.2563\n",
      "Epoch 13, 100% \t Train loss: 0.2559 took: 2.82s  Val. loss: 0.2548\n",
      "Epoch 14, 100% \t Train loss: 0.2559 took: 2.81s  Val. loss: 0.2556\n",
      "Epoch 15, 100% \t Train loss: 0.2558 took: 2.86s  Val. loss: 0.2568\n",
      "Epoch 16, 100% \t Train loss: 0.2559 took: 2.94s  Val. loss: 0.2569\n",
      "Epoch 17, 100% \t Train loss: 0.2558 took: 2.55s  Val. loss: 0.2563\n",
      "Epoch 18, 100% \t Train loss: 0.2558 took: 2.91s  Val. loss: 0.2552\n",
      "Epoch 19, 100% \t Train loss: 0.2558 took: 1.86s  Val. loss: 0.2555\n",
      "Epoch 20, 100% \t Train loss: 0.2558 took: 1.91s  Val. loss: 0.2561\n",
      "Epoch 21, 100% \t Train loss: 0.2559 took: 1.88s  Val. loss: 0.2555\n",
      "Epoch 22, 100% \t Train loss: 0.2559 took: 2.38s  Val. loss: 0.2556\n",
      "Epoch 23, 100% \t Train loss: 0.2558 took: 3.08s  Val. loss: 0.2546\n",
      "Epoch 24, 100% \t Train loss: 0.2558 took: 3.22s  Val. loss: 0.2562\n",
      "Epoch 25, 100% \t Train loss: 0.2558 took: 3.43s  Val. loss: 0.2558\n",
      "Epoch 26, 100% \t Train loss: 0.2557 took: 3.62s  Val. loss: 0.2552\n",
      "Epoch 27, 100% \t Train loss: 0.2558 took: 3.68s  Val. loss: 0.2555\n",
      "Epoch 28, 100% \t Train loss: 0.2558 took: 3.78s  Val. loss: 0.2557\n",
      "Epoch 29, 100% \t Train loss: 0.2558 took: 3.81s  Val. loss: 0.2562\n",
      "Epoch 30, 100% \t Train loss: 0.2558 took: 4.13s  Val. loss: 0.2555\n",
      "Epoch 31, 100% \t Train loss: 0.2557 took: 5.13s  Val. loss: 0.2551\n",
      "Epoch 32, 100% \t Train loss: 0.2558 took: 5.88s  Val. loss: 0.2552\n",
      "Epoch 33, 100% \t Train loss: 0.2558 took: 6.35s  Val. loss: 0.2548\n",
      "Epoch 34, 100% \t Train loss: 0.2558 took: 6.41s  Val. loss: 0.2564\n",
      "Epoch 35, 100% \t Train loss: 0.2557 took: 6.85s  Val. loss: 0.2554\n",
      "Epoch 36, 100% \t Train loss: 0.2558 took: 6.27s  Val. loss: 0.2566\n",
      "Epoch 37, 100% \t Train loss: 0.2557 took: 6.48s  Val. loss: 0.2559\n",
      "Epoch 38, 100% \t Train loss: 0.2558 took: 6.31s  Val. loss: 0.2554\n",
      "Epoch 39, 100% \t Train loss: 0.2557 took: 6.34s  Val. loss: 0.2562\n",
      "Epoch 40, 100% \t Train loss: 0.2558 took: 5.82s  Val. loss: 0.2549\n",
      "Epoch 41, 100% \t Train loss: 0.2557 took: 5.52s  Val. loss: 0.2556\n",
      "Epoch 42, 100% \t Train loss: 0.2558 took: 5.42s  Val. loss: 0.2558\n",
      "Epoch 43, 100% \t Train loss: 0.2557 took: 5.72s  Val. loss: 0.2557\n",
      "Epoch 44, 100% \t Train loss: 0.2557 took: 6.15s  Val. loss: 0.2560\n",
      "Epoch 45, 100% \t Train loss: 0.2558 took: 4.76s  Val. loss: 0.2546\n",
      "Epoch 46, 100% \t Train loss: 0.2558 took: 5.64s  Val. loss: 0.2553\n",
      "Epoch 47, 100% \t Train loss: 0.2557 took: 5.72s  Val. loss: 0.2556\n",
      "Epoch 48, 100% \t Train loss: 0.2558 took: 5.61s  Val. loss: 0.2550\n",
      "Epoch 49, 100% \t Train loss: 0.2558 took: 5.67s  Val. loss: 0.2550\n",
      "Epoch 50, 100% \t Train loss: 0.2557 took: 5.75s  Val. loss: 0.2558\n",
      "Training finished, took 226.61s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 2.83s  Val. loss: 0.2487\n",
      "Epoch 2, 100% \t Train loss: 0.2561 took: 2.80s  Val. loss: 0.2471\n",
      "Epoch 3, 100% \t Train loss: 0.2510 took: 2.80s  Val. loss: 0.2165\n",
      "Epoch 4, 100% \t Train loss: 0.1899 took: 2.79s  Val. loss: 0.1616\n",
      "Epoch 5, 100% \t Train loss: 0.1713 took: 2.67s  Val. loss: 0.1583\n",
      "Epoch 6, 100% \t Train loss: 0.1644 took: 1.76s  Val. loss: 0.1520\n",
      "Epoch 7, 100% \t Train loss: 0.1619 took: 1.77s  Val. loss: 0.1522\n",
      "Epoch 8, 100% \t Train loss: 0.1589 took: 1.76s  Val. loss: 0.1496\n",
      "Epoch 9, 100% \t Train loss: 0.1568 took: 1.76s  Val. loss: 0.1530\n",
      "Epoch 10, 100% \t Train loss: 0.1569 took: 1.76s  Val. loss: 0.1458\n",
      "Epoch 11, 100% \t Train loss: 0.1555 took: 1.77s  Val. loss: 0.1487\n",
      "Epoch 12, 100% \t Train loss: 0.1551 took: 1.77s  Val. loss: 0.1462\n",
      "Epoch 13, 100% \t Train loss: 0.1540 took: 1.76s  Val. loss: 0.1517\n",
      "Epoch 14, 100% \t Train loss: 0.1540 took: 1.76s  Val. loss: 0.1475\n",
      "Epoch 15, 100% \t Train loss: 0.1528 took: 1.76s  Val. loss: 0.1473\n",
      "Epoch 16, 100% \t Train loss: 0.1531 took: 1.76s  Val. loss: 0.1462\n",
      "Epoch 17, 100% \t Train loss: 0.1522 took: 1.76s  Val. loss: 0.1445\n",
      "Epoch 18, 100% \t Train loss: 0.1517 took: 1.76s  Val. loss: 0.1467\n",
      "Epoch 19, 100% \t Train loss: 0.1516 took: 1.76s  Val. loss: 0.1446\n",
      "Epoch 20, 100% \t Train loss: 0.1513 took: 1.76s  Val. loss: 0.1449\n",
      "Epoch 21, 100% \t Train loss: 0.1513 took: 1.76s  Val. loss: 0.1460\n",
      "Epoch 22, 100% \t Train loss: 0.1508 took: 1.76s  Val. loss: 0.1457\n",
      "Epoch 23, 100% \t Train loss: 0.1503 took: 1.76s  Val. loss: 0.1460\n",
      "Epoch 24, 100% \t Train loss: 0.1499 took: 1.76s  Val. loss: 0.1452\n",
      "Epoch 25, 100% \t Train loss: 0.1499 took: 1.77s  Val. loss: 0.1458\n",
      "Epoch 26, 100% \t Train loss: 0.1498 took: 1.77s  Val. loss: 0.1481\n",
      "Epoch 27, 100% \t Train loss: 0.1491 took: 1.78s  Val. loss: 0.1452\n",
      "Epoch 28, 100% \t Train loss: 0.1483 took: 1.81s  Val. loss: 0.1432\n",
      "Epoch 29, 100% \t Train loss: 0.1477 took: 1.84s  Val. loss: 0.1449\n",
      "Epoch 30, 100% \t Train loss: 0.1468 took: 1.91s  Val. loss: 0.1458\n",
      "Epoch 31, 100% \t Train loss: 0.1456 took: 2.08s  Val. loss: 0.1442\n",
      "Epoch 32, 100% \t Train loss: 0.1435 took: 2.34s  Val. loss: 0.1416\n",
      "Epoch 33, 100% \t Train loss: 0.1420 took: 3.23s  Val. loss: 0.1398\n",
      "Epoch 34, 100% \t Train loss: 0.1392 took: 3.73s  Val. loss: 0.1369\n",
      "Epoch 35, 100% \t Train loss: 0.1377 took: 3.80s  Val. loss: 0.1395\n",
      "Epoch 36, 100% \t Train loss: 0.1348 took: 2.84s  Val. loss: 0.1349\n",
      "Epoch 37, 100% \t Train loss: 0.1340 took: 3.93s  Val. loss: 0.1315\n",
      "Epoch 38, 100% \t Train loss: 0.1309 took: 4.03s  Val. loss: 0.1302\n",
      "Epoch 39, 100% \t Train loss: 0.1288 took: 4.12s  Val. loss: 0.1308\n",
      "Epoch 40, 100% \t Train loss: 0.1277 took: 3.19s  Val. loss: 0.1287\n",
      "Epoch 41, 100% \t Train loss: 0.1261 took: 4.46s  Val. loss: 0.1277\n",
      "Epoch 42, 100% \t Train loss: 0.1250 took: 4.52s  Val. loss: 0.1251\n",
      "Epoch 43, 100% \t Train loss: 0.1233 took: 3.58s  Val. loss: 0.1208\n",
      "Epoch 44, 100% \t Train loss: 0.1210 took: 3.64s  Val. loss: 0.1175\n",
      "Epoch 45, 100% \t Train loss: 0.1183 took: 4.73s  Val. loss: 0.1172\n",
      "Epoch 46, 100% \t Train loss: 0.1168 took: 4.71s  Val. loss: 0.1154\n",
      "Epoch 47, 100% \t Train loss: 0.1148 took: 4.64s  Val. loss: 0.1110\n",
      "Epoch 48, 100% \t Train loss: 0.1128 took: 4.61s  Val. loss: 0.1107\n",
      "Epoch 49, 100% \t Train loss: 0.1093 took: 4.60s  Val. loss: 0.1081\n",
      "Epoch 50, 100% \t Train loss: 0.1065 took: 4.12s  Val. loss: 0.1058\n",
      "Training finished, took 148.30s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2587 took: 2.82s  Val. loss: 0.2602\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 2.81s  Val. loss: 0.2592\n",
      "Epoch 3, 100% \t Train loss: 0.2577 took: 2.78s  Val. loss: 0.2595\n",
      "Epoch 4, 100% \t Train loss: 0.2576 took: 2.77s  Val. loss: 0.2603\n",
      "Epoch 5, 100% \t Train loss: 0.2576 took: 2.77s  Val. loss: 0.2598\n",
      "Epoch 6, 100% \t Train loss: 0.2576 took: 2.78s  Val. loss: 0.2589\n",
      "Epoch 7, 100% \t Train loss: 0.2576 took: 2.81s  Val. loss: 0.2609\n",
      "Epoch 8, 100% \t Train loss: 0.2575 took: 2.75s  Val. loss: 0.2607\n",
      "Epoch 9, 100% \t Train loss: 0.2575 took: 2.78s  Val. loss: 0.2592\n",
      "Epoch 10, 100% \t Train loss: 0.2574 took: 2.77s  Val. loss: 0.2601\n",
      "Epoch 11, 100% \t Train loss: 0.2572 took: 2.77s  Val. loss: 0.2604\n",
      "Epoch 12, 100% \t Train loss: 0.2529 took: 2.74s  Val. loss: 0.2445\n",
      "Epoch 13, 100% \t Train loss: 0.2147 took: 2.76s  Val. loss: 0.1801\n",
      "Epoch 14, 100% \t Train loss: 0.1891 took: 1.73s  Val. loss: 0.1703\n",
      "Epoch 15, 100% \t Train loss: 0.1828 took: 1.73s  Val. loss: 0.1691\n",
      "Epoch 16, 100% \t Train loss: 0.1786 took: 1.73s  Val. loss: 0.1638\n",
      "Epoch 17, 100% \t Train loss: 0.1764 took: 2.67s  Val. loss: 0.1590\n",
      "Epoch 18, 100% \t Train loss: 0.1759 took: 2.81s  Val. loss: 0.1603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1734 took: 2.79s  Val. loss: 0.1561\n",
      "Epoch 20, 100% \t Train loss: 0.1723 took: 2.79s  Val. loss: 0.1575\n",
      "Epoch 21, 100% \t Train loss: 0.1706 took: 2.76s  Val. loss: 0.1544\n",
      "Epoch 22, 100% \t Train loss: 0.1697 took: 2.75s  Val. loss: 0.1538\n",
      "Epoch 23, 100% \t Train loss: 0.1699 took: 2.80s  Val. loss: 0.1515\n",
      "Epoch 24, 100% \t Train loss: 0.1688 took: 2.79s  Val. loss: 0.1574\n",
      "Epoch 25, 100% \t Train loss: 0.1682 took: 2.79s  Val. loss: 0.1524\n",
      "Epoch 26, 100% \t Train loss: 0.1680 took: 2.80s  Val. loss: 0.1574\n",
      "Epoch 27, 100% \t Train loss: 0.1676 took: 2.78s  Val. loss: 0.1525\n",
      "Epoch 28, 100% \t Train loss: 0.1684 took: 2.80s  Val. loss: 0.1528\n",
      "Epoch 29, 100% \t Train loss: 0.1676 took: 2.81s  Val. loss: 0.1515\n",
      "Epoch 30, 100% \t Train loss: 0.1668 took: 2.86s  Val. loss: 0.1515\n",
      "Epoch 31, 100% \t Train loss: 0.1666 took: 2.85s  Val. loss: 0.1511\n",
      "Epoch 32, 100% \t Train loss: 0.1657 took: 1.90s  Val. loss: 0.1502\n",
      "Epoch 33, 100% \t Train loss: 0.1661 took: 2.88s  Val. loss: 0.1519\n",
      "Epoch 34, 100% \t Train loss: 0.1659 took: 2.89s  Val. loss: 0.1514\n",
      "Epoch 35, 100% \t Train loss: 0.1655 took: 2.87s  Val. loss: 0.1537\n",
      "Epoch 36, 100% \t Train loss: 0.1647 took: 2.89s  Val. loss: 0.1504\n",
      "Epoch 37, 100% \t Train loss: 0.1661 took: 2.91s  Val. loss: 0.1518\n",
      "Epoch 38, 100% \t Train loss: 0.1649 took: 2.97s  Val. loss: 0.1540\n",
      "Epoch 39, 100% \t Train loss: 0.1646 took: 2.98s  Val. loss: 0.1522\n",
      "Epoch 40, 100% \t Train loss: 0.1655 took: 3.00s  Val. loss: 0.1528\n",
      "Epoch 41, 100% \t Train loss: 0.1648 took: 3.01s  Val. loss: 0.1514\n",
      "Epoch 42, 100% \t Train loss: 0.1635 took: 3.04s  Val. loss: 0.1584\n",
      "Epoch 43, 100% \t Train loss: 0.1654 took: 3.05s  Val. loss: 0.1519\n",
      "Epoch 44, 100% \t Train loss: 0.1644 took: 3.11s  Val. loss: 0.1507\n",
      "Epoch 45, 100% \t Train loss: 0.1632 took: 3.11s  Val. loss: 0.1534\n",
      "Epoch 46, 100% \t Train loss: 0.1635 took: 3.01s  Val. loss: 0.1501\n",
      "Epoch 47, 100% \t Train loss: 0.1624 took: 3.00s  Val. loss: 0.1526\n",
      "Epoch 48, 100% \t Train loss: 0.1636 took: 3.00s  Val. loss: 0.1505\n",
      "Epoch 49, 100% \t Train loss: 0.1639 took: 3.01s  Val. loss: 0.1518\n",
      "Epoch 50, 100% \t Train loss: 0.1635 took: 3.04s  Val. loss: 0.1519\n",
      "Training finished, took 152.29s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.37\n",
      "\tmask_channels :  8  - prob: 0.38\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  3  - prob: 0.29\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.744347\n",
      "lambda: 0.0010 - V: 0.855473\n",
      "lambda: 0.0005 - V: 0.820052\n",
      "Average V: 0.806624\n",
      "Time elapsed: 530.54 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.36\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.29\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.12\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2574 took: 1.80s  Val. loss: 0.2602\n",
      "Epoch 2, 100% \t Train loss: 0.2180 took: 1.79s  Val. loss: 0.1772\n",
      "Epoch 3, 100% \t Train loss: 0.1687 took: 1.78s  Val. loss: 0.1695\n",
      "Epoch 4, 100% \t Train loss: 0.1642 took: 1.79s  Val. loss: 0.1707\n",
      "Epoch 5, 100% \t Train loss: 0.1633 took: 1.78s  Val. loss: 0.1670\n",
      "Epoch 6, 100% \t Train loss: 0.1606 took: 1.78s  Val. loss: 0.1681\n",
      "Epoch 7, 100% \t Train loss: 0.1604 took: 1.78s  Val. loss: 0.1638\n",
      "Epoch 8, 100% \t Train loss: 0.1567 took: 1.78s  Val. loss: 0.1642\n",
      "Epoch 9, 100% \t Train loss: 0.1528 took: 1.77s  Val. loss: 0.1626\n",
      "Epoch 10, 100% \t Train loss: 0.1506 took: 1.06s  Val. loss: 0.1551\n",
      "Epoch 11, 100% \t Train loss: 0.1485 took: 1.03s  Val. loss: 0.1556\n",
      "Epoch 12, 100% \t Train loss: 0.1471 took: 1.03s  Val. loss: 0.1580\n",
      "Epoch 13, 100% \t Train loss: 0.1441 took: 1.03s  Val. loss: 0.1556\n",
      "Epoch 14, 100% \t Train loss: 0.1424 took: 1.04s  Val. loss: 0.1522\n",
      "Epoch 15, 100% \t Train loss: 0.1417 took: 1.04s  Val. loss: 0.1526\n",
      "Epoch 16, 100% \t Train loss: 0.1404 took: 1.04s  Val. loss: 0.1571\n",
      "Epoch 17, 100% \t Train loss: 0.1394 took: 1.04s  Val. loss: 0.1483\n",
      "Epoch 18, 100% \t Train loss: 0.1362 took: 1.04s  Val. loss: 0.1503\n",
      "Epoch 19, 100% \t Train loss: 0.1345 took: 1.04s  Val. loss: 0.1512\n",
      "Epoch 20, 100% \t Train loss: 0.1325 took: 1.04s  Val. loss: 0.1485\n",
      "Epoch 21, 100% \t Train loss: 0.1305 took: 1.04s  Val. loss: 0.1441\n",
      "Epoch 22, 100% \t Train loss: 0.1280 took: 1.04s  Val. loss: 0.1439\n",
      "Epoch 23, 100% \t Train loss: 0.1255 took: 1.04s  Val. loss: 0.1387\n",
      "Epoch 24, 100% \t Train loss: 0.1232 took: 1.03s  Val. loss: 0.1390\n",
      "Epoch 25, 100% \t Train loss: 0.1210 took: 1.04s  Val. loss: 0.1340\n",
      "Epoch 26, 100% \t Train loss: 0.1198 took: 1.04s  Val. loss: 0.1352\n",
      "Epoch 27, 100% \t Train loss: 0.1167 took: 1.07s  Val. loss: 0.1321\n",
      "Epoch 28, 100% \t Train loss: 0.1152 took: 1.05s  Val. loss: 0.1295\n",
      "Epoch 29, 100% \t Train loss: 0.1138 took: 1.07s  Val. loss: 0.1269\n",
      "Epoch 30, 100% \t Train loss: 0.1130 took: 1.10s  Val. loss: 0.1320\n",
      "Epoch 31, 100% \t Train loss: 0.1115 took: 1.16s  Val. loss: 0.1288\n",
      "Epoch 32, 100% \t Train loss: 0.1101 took: 2.10s  Val. loss: 0.1265\n",
      "Epoch 33, 100% \t Train loss: 0.1094 took: 2.25s  Val. loss: 0.1289\n",
      "Epoch 34, 100% \t Train loss: 0.1094 took: 2.28s  Val. loss: 0.1287\n",
      "Epoch 35, 100% \t Train loss: 0.1077 took: 2.31s  Val. loss: 0.1262\n",
      "Epoch 36, 100% \t Train loss: 0.1076 took: 2.35s  Val. loss: 0.1249\n",
      "Epoch 37, 100% \t Train loss: 0.1088 took: 2.37s  Val. loss: 0.1252\n",
      "Epoch 38, 100% \t Train loss: 0.1054 took: 2.33s  Val. loss: 0.1238\n",
      "Epoch 39, 100% \t Train loss: 0.1051 took: 2.35s  Val. loss: 0.1237\n",
      "Epoch 40, 100% \t Train loss: 0.1069 took: 2.35s  Val. loss: 0.1204\n",
      "Epoch 41, 100% \t Train loss: 0.1034 took: 2.35s  Val. loss: 0.1224\n",
      "Epoch 42, 100% \t Train loss: 0.1040 took: 2.37s  Val. loss: 0.1235\n",
      "Epoch 43, 100% \t Train loss: 0.1038 took: 2.38s  Val. loss: 0.1263\n",
      "Epoch 44, 100% \t Train loss: 0.1023 took: 2.40s  Val. loss: 0.1212\n",
      "Epoch 45, 100% \t Train loss: 0.1010 took: 2.44s  Val. loss: 0.1219\n",
      "Epoch 46, 100% \t Train loss: 0.1025 took: 2.44s  Val. loss: 0.1206\n",
      "Epoch 47, 100% \t Train loss: 0.1008 took: 2.47s  Val. loss: 0.1220\n",
      "Epoch 48, 100% \t Train loss: 0.1003 took: 2.48s  Val. loss: 0.1205\n",
      "Epoch 49, 100% \t Train loss: 0.1000 took: 2.46s  Val. loss: 0.1244\n",
      "Epoch 50, 100% \t Train loss: 0.0993 took: 2.46s  Val. loss: 0.1207\n",
      "Training finished, took 95.46s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2550 took: 1.80s  Val. loss: 0.2574\n",
      "Epoch 2, 100% \t Train loss: 0.2546 took: 1.79s  Val. loss: 0.2579\n",
      "Epoch 3, 100% \t Train loss: 0.2542 took: 1.80s  Val. loss: 0.2559\n",
      "Epoch 4, 100% \t Train loss: 0.2532 took: 1.81s  Val. loss: 0.2553\n",
      "Epoch 5, 100% \t Train loss: 0.2417 took: 1.80s  Val. loss: 0.2209\n",
      "Epoch 6, 100% \t Train loss: 0.1876 took: 1.81s  Val. loss: 0.1806\n",
      "Epoch 7, 100% \t Train loss: 0.1689 took: 1.78s  Val. loss: 0.1739\n",
      "Epoch 8, 100% \t Train loss: 0.1661 took: 1.80s  Val. loss: 0.1688\n",
      "Epoch 9, 100% \t Train loss: 0.1650 took: 1.81s  Val. loss: 0.1715\n",
      "Epoch 10, 100% \t Train loss: 0.1639 took: 1.83s  Val. loss: 0.1717\n",
      "Epoch 11, 100% \t Train loss: 0.1633 took: 1.83s  Val. loss: 0.1693\n",
      "Epoch 12, 100% \t Train loss: 0.1616 took: 1.80s  Val. loss: 0.1692\n",
      "Epoch 13, 100% \t Train loss: 0.1611 took: 1.81s  Val. loss: 0.1674\n",
      "Epoch 14, 100% \t Train loss: 0.1593 took: 1.79s  Val. loss: 0.1677\n",
      "Epoch 15, 100% \t Train loss: 0.1587 took: 1.79s  Val. loss: 0.1669\n",
      "Epoch 16, 100% \t Train loss: 0.1582 took: 1.80s  Val. loss: 0.1637\n",
      "Epoch 17, 100% \t Train loss: 0.1583 took: 1.81s  Val. loss: 0.1683\n",
      "Epoch 18, 100% \t Train loss: 0.1565 took: 1.36s  Val. loss: 0.1660\n",
      "Epoch 19, 100% \t Train loss: 0.1566 took: 1.04s  Val. loss: 0.1642\n",
      "Epoch 20, 100% \t Train loss: 0.1534 took: 1.03s  Val. loss: 0.1656\n",
      "Epoch 21, 100% \t Train loss: 0.1524 took: 1.05s  Val. loss: 0.1610\n",
      "Epoch 22, 100% \t Train loss: 0.1528 took: 1.06s  Val. loss: 0.1595\n",
      "Epoch 23, 100% \t Train loss: 0.1513 took: 1.06s  Val. loss: 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1497 took: 1.07s  Val. loss: 0.1580\n",
      "Epoch 25, 100% \t Train loss: 0.1491 took: 1.06s  Val. loss: 0.1606\n",
      "Epoch 26, 100% \t Train loss: 0.1486 took: 1.07s  Val. loss: 0.1569\n",
      "Epoch 27, 100% \t Train loss: 0.1481 took: 1.07s  Val. loss: 0.1589\n",
      "Epoch 28, 100% \t Train loss: 0.1478 took: 1.10s  Val. loss: 0.1571\n",
      "Epoch 29, 100% \t Train loss: 0.1475 took: 1.12s  Val. loss: 0.1587\n",
      "Epoch 30, 100% \t Train loss: 0.1470 took: 1.12s  Val. loss: 0.1607\n",
      "Epoch 31, 100% \t Train loss: 0.1465 took: 1.14s  Val. loss: 0.1600\n",
      "Epoch 32, 100% \t Train loss: 0.1462 took: 1.17s  Val. loss: 0.1574\n",
      "Epoch 33, 100% \t Train loss: 0.1455 took: 1.16s  Val. loss: 0.1573\n",
      "Epoch 34, 100% \t Train loss: 0.1459 took: 1.17s  Val. loss: 0.1575\n",
      "Epoch 35, 100% \t Train loss: 0.1459 took: 1.16s  Val. loss: 0.1576\n",
      "Epoch 36, 100% \t Train loss: 0.1457 took: 1.19s  Val. loss: 0.1587\n",
      "Epoch 37, 100% \t Train loss: 0.1456 took: 1.43s  Val. loss: 0.1583\n",
      "Epoch 38, 100% \t Train loss: 0.1447 took: 1.93s  Val. loss: 0.1579\n",
      "Epoch 39, 100% \t Train loss: 0.1443 took: 1.94s  Val. loss: 0.1571\n",
      "Epoch 40, 100% \t Train loss: 0.1441 took: 1.94s  Val. loss: 0.1582\n",
      "Epoch 41, 100% \t Train loss: 0.1441 took: 1.99s  Val. loss: 0.1607\n",
      "Epoch 42, 100% \t Train loss: 0.1446 took: 1.16s  Val. loss: 0.1583\n",
      "Epoch 43, 100% \t Train loss: 0.1435 took: 1.18s  Val. loss: 0.1567\n",
      "Epoch 44, 100% \t Train loss: 0.1434 took: 1.19s  Val. loss: 0.1571\n",
      "Epoch 45, 100% \t Train loss: 0.1428 took: 1.19s  Val. loss: 0.1587\n",
      "Epoch 46, 100% \t Train loss: 0.1432 took: 1.21s  Val. loss: 0.1585\n",
      "Epoch 47, 100% \t Train loss: 0.1429 took: 1.25s  Val. loss: 0.1583\n",
      "Epoch 48, 100% \t Train loss: 0.1426 took: 1.29s  Val. loss: 0.1582\n",
      "Epoch 49, 100% \t Train loss: 0.1435 took: 1.33s  Val. loss: 0.1574\n",
      "Epoch 50, 100% \t Train loss: 0.1430 took: 1.35s  Val. loss: 0.1598\n",
      "Training finished, took 81.75s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.77s  Val. loss: 0.2623\n",
      "Epoch 2, 100% \t Train loss: 0.2590 took: 1.79s  Val. loss: 0.2625\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 1.05s  Val. loss: 0.2637\n",
      "Epoch 4, 100% \t Train loss: 0.2589 took: 1.04s  Val. loss: 0.2627\n",
      "Epoch 5, 100% \t Train loss: 0.2586 took: 1.05s  Val. loss: 0.2614\n",
      "Epoch 6, 100% \t Train loss: 0.2580 took: 1.04s  Val. loss: 0.2621\n",
      "Epoch 7, 100% \t Train loss: 0.2556 took: 1.04s  Val. loss: 0.2583\n",
      "Epoch 8, 100% \t Train loss: 0.2407 took: 1.04s  Val. loss: 0.2311\n",
      "Epoch 9, 100% \t Train loss: 0.2146 took: 1.05s  Val. loss: 0.2121\n",
      "Epoch 10, 100% \t Train loss: 0.1999 took: 1.05s  Val. loss: 0.2017\n",
      "Epoch 11, 100% \t Train loss: 0.1925 took: 1.05s  Val. loss: 0.1980\n",
      "Epoch 12, 100% \t Train loss: 0.1875 took: 1.05s  Val. loss: 0.1909\n",
      "Epoch 13, 100% \t Train loss: 0.1850 took: 1.07s  Val. loss: 0.1930\n",
      "Epoch 14, 100% \t Train loss: 0.1839 took: 1.78s  Val. loss: 0.1876\n",
      "Epoch 15, 100% \t Train loss: 0.1812 took: 1.80s  Val. loss: 0.1852\n",
      "Epoch 16, 100% \t Train loss: 0.1808 took: 1.82s  Val. loss: 0.1877\n",
      "Epoch 17, 100% \t Train loss: 0.1775 took: 1.80s  Val. loss: 0.1847\n",
      "Epoch 18, 100% \t Train loss: 0.1766 took: 1.79s  Val. loss: 0.1778\n",
      "Epoch 19, 100% \t Train loss: 0.1733 took: 1.80s  Val. loss: 0.1760\n",
      "Epoch 20, 100% \t Train loss: 0.1719 took: 1.78s  Val. loss: 0.1755\n",
      "Epoch 21, 100% \t Train loss: 0.1707 took: 1.79s  Val. loss: 0.1748\n",
      "Epoch 22, 100% \t Train loss: 0.1703 took: 1.79s  Val. loss: 0.1735\n",
      "Epoch 23, 100% \t Train loss: 0.1686 took: 1.78s  Val. loss: 0.1734\n",
      "Epoch 24, 100% \t Train loss: 0.1665 took: 1.78s  Val. loss: 0.1698\n",
      "Epoch 25, 100% \t Train loss: 0.1661 took: 1.78s  Val. loss: 0.1730\n",
      "Epoch 26, 100% \t Train loss: 0.1638 took: 1.79s  Val. loss: 0.1731\n",
      "Epoch 27, 100% \t Train loss: 0.1635 took: 1.79s  Val. loss: 0.1673\n",
      "Epoch 28, 100% \t Train loss: 0.1628 took: 1.79s  Val. loss: 0.1703\n",
      "Epoch 29, 100% \t Train loss: 0.1613 took: 1.81s  Val. loss: 0.1704\n",
      "Epoch 30, 100% \t Train loss: 0.1604 took: 1.81s  Val. loss: 0.1655\n",
      "Epoch 31, 100% \t Train loss: 0.1595 took: 1.84s  Val. loss: 0.1661\n",
      "Epoch 32, 100% \t Train loss: 0.1614 took: 1.84s  Val. loss: 0.1648\n",
      "Epoch 33, 100% \t Train loss: 0.1603 took: 1.87s  Val. loss: 0.1704\n",
      "Epoch 34, 100% \t Train loss: 0.1588 took: 1.85s  Val. loss: 0.1655\n",
      "Epoch 35, 100% \t Train loss: 0.1587 took: 1.85s  Val. loss: 0.1660\n",
      "Epoch 36, 100% \t Train loss: 0.1586 took: 1.11s  Val. loss: 0.1648\n",
      "Epoch 37, 100% \t Train loss: 0.1579 took: 1.12s  Val. loss: 0.1657\n",
      "Epoch 38, 100% \t Train loss: 0.1580 took: 1.13s  Val. loss: 0.1688\n",
      "Epoch 39, 100% \t Train loss: 0.1569 took: 1.13s  Val. loss: 0.1648\n",
      "Epoch 40, 100% \t Train loss: 0.1559 took: 1.14s  Val. loss: 0.1640\n",
      "Epoch 41, 100% \t Train loss: 0.1555 took: 1.14s  Val. loss: 0.1664\n",
      "Epoch 42, 100% \t Train loss: 0.1567 took: 1.15s  Val. loss: 0.1691\n",
      "Epoch 43, 100% \t Train loss: 0.1559 took: 1.16s  Val. loss: 0.1638\n",
      "Epoch 44, 100% \t Train loss: 0.1573 took: 1.68s  Val. loss: 0.1647\n",
      "Epoch 45, 100% \t Train loss: 0.1556 took: 1.16s  Val. loss: 0.1634\n",
      "Epoch 46, 100% \t Train loss: 0.1562 took: 1.17s  Val. loss: 0.1629\n",
      "Epoch 47, 100% \t Train loss: 0.1555 took: 1.18s  Val. loss: 0.1620\n",
      "Epoch 48, 100% \t Train loss: 0.1543 took: 1.18s  Val. loss: 0.1733\n",
      "Epoch 49, 100% \t Train loss: 0.1569 took: 1.17s  Val. loss: 0.1636\n",
      "Epoch 50, 100% \t Train loss: 0.1547 took: 1.15s  Val. loss: 0.1642\n",
      "Training finished, took 82.37s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.36\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.29\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.12\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.857526\n",
      "lambda: 0.0010 - V: 0.829249\n",
      "lambda: 0.0005 - V: 0.812802\n",
      "Average V: 0.833192\n",
      "Time elapsed: 262.95 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.33\n",
      "\tmask_channels :  8  - prob: 0.37\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.28\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2526 took: 1.13s  Val. loss: 0.2152\n",
      "Epoch 2, 100% \t Train loss: 0.1865 took: 1.13s  Val. loss: 0.1770\n",
      "Epoch 3, 100% \t Train loss: 0.1694 took: 1.13s  Val. loss: 0.1767\n",
      "Epoch 4, 100% \t Train loss: 0.1649 took: 1.13s  Val. loss: 0.1662\n",
      "Epoch 5, 100% \t Train loss: 0.1621 took: 1.13s  Val. loss: 0.1607\n",
      "Epoch 6, 100% \t Train loss: 0.1600 took: 1.13s  Val. loss: 0.1631\n",
      "Epoch 7, 100% \t Train loss: 0.1575 took: 1.13s  Val. loss: 0.1598\n",
      "Epoch 8, 100% \t Train loss: 0.1575 took: 1.13s  Val. loss: 0.1646\n",
      "Epoch 9, 100% \t Train loss: 0.1562 took: 1.13s  Val. loss: 0.1620\n",
      "Epoch 10, 100% \t Train loss: 0.1550 took: 1.14s  Val. loss: 0.1609\n",
      "Epoch 11, 100% \t Train loss: 0.1554 took: 1.13s  Val. loss: 0.1610\n",
      "Epoch 12, 100% \t Train loss: 0.1539 took: 1.13s  Val. loss: 0.1614\n",
      "Epoch 13, 100% \t Train loss: 0.1533 took: 1.16s  Val. loss: 0.1650\n",
      "Epoch 14, 100% \t Train loss: 0.1518 took: 1.14s  Val. loss: 0.1619\n",
      "Epoch 15, 100% \t Train loss: 0.1523 took: 1.14s  Val. loss: 0.1616\n",
      "Epoch 16, 100% \t Train loss: 0.1516 took: 1.14s  Val. loss: 0.1623\n",
      "Epoch 17, 100% \t Train loss: 0.1507 took: 1.14s  Val. loss: 0.1581\n",
      "Epoch 18, 100% \t Train loss: 0.1487 took: 1.13s  Val. loss: 0.1566\n",
      "Epoch 19, 100% \t Train loss: 0.1476 took: 1.14s  Val. loss: 0.1604\n",
      "Epoch 20, 100% \t Train loss: 0.1458 took: 1.14s  Val. loss: 0.1585\n",
      "Epoch 21, 100% \t Train loss: 0.1438 took: 1.13s  Val. loss: 0.1507\n",
      "Epoch 22, 100% \t Train loss: 0.1421 took: 1.14s  Val. loss: 0.1461\n",
      "Epoch 23, 100% \t Train loss: 0.1376 took: 1.13s  Val. loss: 0.1504\n",
      "Epoch 24, 100% \t Train loss: 0.1324 took: 1.13s  Val. loss: 0.1434\n",
      "Epoch 25, 100% \t Train loss: 0.1256 took: 1.13s  Val. loss: 0.1295\n",
      "Epoch 26, 100% \t Train loss: 0.1204 took: 1.13s  Val. loss: 0.1294\n",
      "Epoch 27, 100% \t Train loss: 0.1168 took: 1.14s  Val. loss: 0.1244\n",
      "Epoch 28, 100% \t Train loss: 0.1126 took: 1.13s  Val. loss: 0.1235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.1084 took: 1.13s  Val. loss: 0.1180\n",
      "Epoch 30, 100% \t Train loss: 0.1069 took: 1.13s  Val. loss: 0.1143\n",
      "Epoch 31, 100% \t Train loss: 0.1043 took: 1.13s  Val. loss: 0.1115\n",
      "Epoch 32, 100% \t Train loss: 0.1022 took: 1.19s  Val. loss: 0.1158\n",
      "Epoch 33, 100% \t Train loss: 0.1009 took: 1.27s  Val. loss: 0.1068\n",
      "Epoch 34, 100% \t Train loss: 0.0985 took: 1.26s  Val. loss: 0.1103\n",
      "Epoch 35, 100% \t Train loss: 0.0977 took: 1.27s  Val. loss: 0.1070\n",
      "Epoch 36, 100% \t Train loss: 0.0941 took: 1.27s  Val. loss: 0.1057\n",
      "Epoch 37, 100% \t Train loss: 0.0945 took: 1.28s  Val. loss: 0.1078\n",
      "Epoch 38, 100% \t Train loss: 0.0922 took: 1.29s  Val. loss: 0.1033\n",
      "Epoch 39, 100% \t Train loss: 0.0914 took: 1.29s  Val. loss: 0.1006\n",
      "Epoch 40, 100% \t Train loss: 0.0911 took: 1.32s  Val. loss: 0.1051\n",
      "Epoch 41, 100% \t Train loss: 0.0886 took: 1.56s  Val. loss: 0.0995\n",
      "Epoch 42, 100% \t Train loss: 0.0876 took: 2.15s  Val. loss: 0.0956\n",
      "Epoch 43, 100% \t Train loss: 0.0850 took: 2.15s  Val. loss: 0.0966\n",
      "Epoch 44, 100% \t Train loss: 0.0855 took: 1.34s  Val. loss: 0.0974\n",
      "Epoch 45, 100% \t Train loss: 0.0843 took: 1.41s  Val. loss: 0.0952\n",
      "Epoch 46, 100% \t Train loss: 0.0836 took: 1.34s  Val. loss: 0.0937\n",
      "Epoch 47, 100% \t Train loss: 0.0829 took: 1.34s  Val. loss: 0.0943\n",
      "Epoch 48, 100% \t Train loss: 0.0820 took: 1.35s  Val. loss: 0.0902\n",
      "Epoch 49, 100% \t Train loss: 0.0808 took: 2.18s  Val. loss: 0.0888\n",
      "Epoch 50, 100% \t Train loss: 0.0817 took: 2.20s  Val. loss: 0.0931\n",
      "Training finished, took 71.93s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2606 took: 1.97s  Val. loss: 0.2595\n",
      "Epoch 2, 100% \t Train loss: 0.2578 took: 1.94s  Val. loss: 0.2572\n",
      "Epoch 3, 100% \t Train loss: 0.2375 took: 1.93s  Val. loss: 0.2136\n",
      "Epoch 4, 100% \t Train loss: 0.1881 took: 1.92s  Val. loss: 0.1843\n",
      "Epoch 5, 100% \t Train loss: 0.1747 took: 1.97s  Val. loss: 0.1809\n",
      "Epoch 6, 100% \t Train loss: 0.1687 took: 1.97s  Val. loss: 0.1804\n",
      "Epoch 7, 100% \t Train loss: 0.1691 took: 1.95s  Val. loss: 0.1808\n",
      "Epoch 8, 100% \t Train loss: 0.1661 took: 1.95s  Val. loss: 0.1763\n",
      "Epoch 9, 100% \t Train loss: 0.1665 took: 1.96s  Val. loss: 0.1762\n",
      "Epoch 10, 100% \t Train loss: 0.1652 took: 1.95s  Val. loss: 0.1774\n",
      "Epoch 11, 100% \t Train loss: 0.1656 took: 1.95s  Val. loss: 0.1783\n",
      "Epoch 12, 100% \t Train loss: 0.1638 took: 1.95s  Val. loss: 0.1761\n",
      "Epoch 13, 100% \t Train loss: 0.1620 took: 1.93s  Val. loss: 0.1771\n",
      "Epoch 14, 100% \t Train loss: 0.1627 took: 1.95s  Val. loss: 0.1751\n",
      "Epoch 15, 100% \t Train loss: 0.1607 took: 1.95s  Val. loss: 0.1766\n",
      "Epoch 16, 100% \t Train loss: 0.1594 took: 1.93s  Val. loss: 0.1768\n",
      "Epoch 17, 100% \t Train loss: 0.1588 took: 1.94s  Val. loss: 0.1762\n",
      "Epoch 18, 100% \t Train loss: 0.1568 took: 1.94s  Val. loss: 0.1769\n",
      "Epoch 19, 100% \t Train loss: 0.1560 took: 1.94s  Val. loss: 0.1751\n",
      "Epoch 20, 100% \t Train loss: 0.1561 took: 1.94s  Val. loss: 0.1745\n",
      "Epoch 21, 100% \t Train loss: 0.1545 took: 1.95s  Val. loss: 0.1711\n",
      "Epoch 22, 100% \t Train loss: 0.1542 took: 1.95s  Val. loss: 0.1729\n",
      "Epoch 23, 100% \t Train loss: 0.1536 took: 1.95s  Val. loss: 0.1726\n",
      "Epoch 24, 100% \t Train loss: 0.1525 took: 1.93s  Val. loss: 0.1705\n",
      "Epoch 25, 100% \t Train loss: 0.1508 took: 1.94s  Val. loss: 0.1709\n",
      "Epoch 26, 100% \t Train loss: 0.1511 took: 1.93s  Val. loss: 0.1709\n",
      "Epoch 27, 100% \t Train loss: 0.1501 took: 1.99s  Val. loss: 0.1733\n",
      "Epoch 28, 100% \t Train loss: 0.1505 took: 1.95s  Val. loss: 0.1713\n",
      "Epoch 29, 100% \t Train loss: 0.1500 took: 1.97s  Val. loss: 0.1705\n",
      "Epoch 30, 100% \t Train loss: 0.1495 took: 1.96s  Val. loss: 0.1679\n",
      "Epoch 31, 100% \t Train loss: 0.1486 took: 1.95s  Val. loss: 0.1701\n",
      "Epoch 32, 100% \t Train loss: 0.1489 took: 1.96s  Val. loss: 0.1677\n",
      "Epoch 33, 100% \t Train loss: 0.1479 took: 1.15s  Val. loss: 0.1731\n",
      "Epoch 34, 100% \t Train loss: 0.1482 took: 1.15s  Val. loss: 0.1695\n",
      "Epoch 35, 100% \t Train loss: 0.1470 took: 1.15s  Val. loss: 0.1705\n",
      "Epoch 36, 100% \t Train loss: 0.1471 took: 1.16s  Val. loss: 0.1695\n",
      "Epoch 37, 100% \t Train loss: 0.1467 took: 1.17s  Val. loss: 0.1683\n",
      "Epoch 38, 100% \t Train loss: 0.1457 took: 1.18s  Val. loss: 0.1722\n",
      "Epoch 39, 100% \t Train loss: 0.1450 took: 1.17s  Val. loss: 0.1749\n",
      "Epoch 40, 100% \t Train loss: 0.1443 took: 1.18s  Val. loss: 0.1718\n",
      "Epoch 41, 100% \t Train loss: 0.1431 took: 1.17s  Val. loss: 0.1708\n",
      "Epoch 42, 100% \t Train loss: 0.1420 took: 1.17s  Val. loss: 0.1672\n",
      "Epoch 43, 100% \t Train loss: 0.1412 took: 1.17s  Val. loss: 0.1679\n",
      "Epoch 44, 100% \t Train loss: 0.1399 took: 1.18s  Val. loss: 0.1676\n",
      "Epoch 45, 100% \t Train loss: 0.1383 took: 1.18s  Val. loss: 0.1684\n",
      "Epoch 46, 100% \t Train loss: 0.1365 took: 1.19s  Val. loss: 0.1690\n",
      "Epoch 47, 100% \t Train loss: 0.1346 took: 1.19s  Val. loss: 0.1642\n",
      "Epoch 48, 100% \t Train loss: 0.1332 took: 1.19s  Val. loss: 0.1649\n",
      "Epoch 49, 100% \t Train loss: 0.1310 took: 1.19s  Val. loss: 0.1668\n",
      "Epoch 50, 100% \t Train loss: 0.1293 took: 1.19s  Val. loss: 0.1642\n",
      "Training finished, took 94.05s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2587 took: 1.97s  Val. loss: 0.2560\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.95s  Val. loss: 0.2571\n",
      "Epoch 3, 100% \t Train loss: 0.2580 took: 1.96s  Val. loss: 0.2558\n",
      "Epoch 4, 100% \t Train loss: 0.2570 took: 1.96s  Val. loss: 0.2548\n",
      "Epoch 5, 100% \t Train loss: 0.2537 took: 1.97s  Val. loss: 0.2501\n",
      "Epoch 6, 100% \t Train loss: 0.2389 took: 1.95s  Val. loss: 0.2342\n",
      "Epoch 7, 100% \t Train loss: 0.2236 took: 1.95s  Val. loss: 0.2273\n",
      "Epoch 8, 100% \t Train loss: 0.2176 took: 1.95s  Val. loss: 0.2236\n",
      "Epoch 9, 100% \t Train loss: 0.2119 took: 1.96s  Val. loss: 0.2200\n",
      "Epoch 10, 100% \t Train loss: 0.2049 took: 1.96s  Val. loss: 0.2163\n",
      "Epoch 11, 100% \t Train loss: 0.1971 took: 1.94s  Val. loss: 0.2071\n",
      "Epoch 12, 100% \t Train loss: 0.1878 took: 1.96s  Val. loss: 0.1935\n",
      "Epoch 13, 100% \t Train loss: 0.1801 took: 1.98s  Val. loss: 0.1855\n",
      "Epoch 14, 100% \t Train loss: 0.1771 took: 1.96s  Val. loss: 0.1842\n",
      "Epoch 15, 100% \t Train loss: 0.1746 took: 1.95s  Val. loss: 0.2002\n",
      "Epoch 16, 100% \t Train loss: 0.1760 took: 1.96s  Val. loss: 0.1855\n",
      "Epoch 17, 100% \t Train loss: 0.1727 took: 1.96s  Val. loss: 0.1797\n",
      "Epoch 18, 100% \t Train loss: 0.1714 took: 1.95s  Val. loss: 0.1802\n",
      "Epoch 19, 100% \t Train loss: 0.1705 took: 1.95s  Val. loss: 0.1815\n",
      "Epoch 20, 100% \t Train loss: 0.1678 took: 1.96s  Val. loss: 0.1787\n",
      "Epoch 21, 100% \t Train loss: 0.1692 took: 1.96s  Val. loss: 0.1882\n",
      "Epoch 22, 100% \t Train loss: 0.1669 took: 1.96s  Val. loss: 0.1821\n",
      "Epoch 23, 100% \t Train loss: 0.1680 took: 1.96s  Val. loss: 0.1839\n",
      "Epoch 24, 100% \t Train loss: 0.1652 took: 1.94s  Val. loss: 0.1781\n",
      "Epoch 25, 100% \t Train loss: 0.1657 took: 1.95s  Val. loss: 0.1790\n",
      "Epoch 26, 100% \t Train loss: 0.1637 took: 1.94s  Val. loss: 0.1771\n",
      "Epoch 27, 100% \t Train loss: 0.1643 took: 1.96s  Val. loss: 0.1900\n",
      "Epoch 28, 100% \t Train loss: 0.1675 took: 1.94s  Val. loss: 0.1771\n",
      "Epoch 29, 100% \t Train loss: 0.1635 took: 1.97s  Val. loss: 0.1753\n",
      "Epoch 30, 100% \t Train loss: 0.1644 took: 1.40s  Val. loss: 0.1761\n",
      "Epoch 31, 100% \t Train loss: 0.1605 took: 1.17s  Val. loss: 0.1798\n",
      "Epoch 32, 100% \t Train loss: 0.1622 took: 1.18s  Val. loss: 0.1803\n",
      "Epoch 33, 100% \t Train loss: 0.1626 took: 1.19s  Val. loss: 0.1748\n",
      "Epoch 34, 100% \t Train loss: 0.1603 took: 1.20s  Val. loss: 0.1763\n",
      "Epoch 35, 100% \t Train loss: 0.1606 took: 1.20s  Val. loss: 0.1786\n",
      "Epoch 36, 100% \t Train loss: 0.1599 took: 1.21s  Val. loss: 0.1771\n",
      "Epoch 37, 100% \t Train loss: 0.1599 took: 1.22s  Val. loss: 0.1736\n",
      "Epoch 38, 100% \t Train loss: 0.1594 took: 1.22s  Val. loss: 0.1743\n",
      "Epoch 39, 100% \t Train loss: 0.1572 took: 1.22s  Val. loss: 0.1729\n",
      "Epoch 40, 100% \t Train loss: 0.1580 took: 2.04s  Val. loss: 0.1785\n",
      "Epoch 41, 100% \t Train loss: 0.1565 took: 2.04s  Val. loss: 0.1724\n",
      "Epoch 42, 100% \t Train loss: 0.1562 took: 2.02s  Val. loss: 0.1746\n",
      "Epoch 43, 100% \t Train loss: 0.1592 took: 2.00s  Val. loss: 0.1731\n",
      "Epoch 44, 100% \t Train loss: 0.1590 took: 1.99s  Val. loss: 0.1741\n",
      "Epoch 45, 100% \t Train loss: 0.1557 took: 1.99s  Val. loss: 0.1682\n",
      "Epoch 46, 100% \t Train loss: 0.1559 took: 1.97s  Val. loss: 0.1681\n",
      "Epoch 47, 100% \t Train loss: 0.1555 took: 2.01s  Val. loss: 0.1712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1537 took: 1.99s  Val. loss: 0.1687\n",
      "Epoch 49, 100% \t Train loss: 0.1534 took: 2.03s  Val. loss: 0.1850\n",
      "Epoch 50, 100% \t Train loss: 0.1559 took: 2.02s  Val. loss: 0.1676\n",
      "Training finished, took 102.77s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.33\n",
      "\tmask_channels :  8  - prob: 0.37\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.28\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.866779\n",
      "lambda: 0.0010 - V: 0.823203\n",
      "lambda: 0.0005 - V: 0.808654\n",
      "Average V: 0.832879\n",
      "Time elapsed: 272.19 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.30\n",
      "\tmask_channels :  8  - prob: 0.37\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.16\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2556 took: 1.76s  Val. loss: 0.2541\n",
      "Epoch 2, 100% \t Train loss: 0.2098 took: 1.77s  Val. loss: 0.1861\n",
      "Epoch 3, 100% \t Train loss: 0.1721 took: 1.77s  Val. loss: 0.1797\n",
      "Epoch 4, 100% \t Train loss: 0.1689 took: 1.76s  Val. loss: 0.1804\n",
      "Epoch 5, 100% \t Train loss: 0.1670 took: 1.76s  Val. loss: 0.1789\n",
      "Epoch 6, 100% \t Train loss: 0.1662 took: 1.80s  Val. loss: 0.1751\n",
      "Epoch 7, 100% \t Train loss: 0.1648 took: 1.82s  Val. loss: 0.1755\n",
      "Epoch 8, 100% \t Train loss: 0.1647 took: 1.77s  Val. loss: 0.1747\n",
      "Epoch 9, 100% \t Train loss: 0.1626 took: 1.74s  Val. loss: 0.1745\n",
      "Epoch 10, 100% \t Train loss: 0.1607 took: 1.74s  Val. loss: 0.1723\n",
      "Epoch 11, 100% \t Train loss: 0.1574 took: 1.73s  Val. loss: 0.1662\n",
      "Epoch 12, 100% \t Train loss: 0.1512 took: 1.75s  Val. loss: 0.1615\n",
      "Epoch 13, 100% \t Train loss: 0.1445 took: 1.73s  Val. loss: 0.1487\n",
      "Epoch 14, 100% \t Train loss: 0.1363 took: 1.84s  Val. loss: 0.1434\n",
      "Epoch 15, 100% \t Train loss: 0.1275 took: 1.76s  Val. loss: 0.1333\n",
      "Epoch 16, 100% \t Train loss: 0.1235 took: 1.78s  Val. loss: 0.1294\n",
      "Epoch 17, 100% \t Train loss: 0.1173 took: 1.64s  Val. loss: 0.1224\n",
      "Epoch 18, 100% \t Train loss: 0.1123 took: 1.80s  Val. loss: 0.1213\n",
      "Epoch 19, 100% \t Train loss: 0.1100 took: 1.77s  Val. loss: 0.1199\n",
      "Epoch 20, 100% \t Train loss: 0.1061 took: 1.82s  Val. loss: 0.1114\n",
      "Epoch 21, 100% \t Train loss: 0.1054 took: 1.82s  Val. loss: 0.1153\n",
      "Epoch 22, 100% \t Train loss: 0.1043 took: 1.92s  Val. loss: 0.1211\n",
      "Epoch 23, 100% \t Train loss: 0.1026 took: 1.82s  Val. loss: 0.1129\n",
      "Epoch 24, 100% \t Train loss: 0.1004 took: 1.81s  Val. loss: 0.1086\n",
      "Epoch 25, 100% \t Train loss: 0.0994 took: 1.83s  Val. loss: 0.1094\n",
      "Epoch 26, 100% \t Train loss: 0.0994 took: 1.87s  Val. loss: 0.1082\n",
      "Epoch 27, 100% \t Train loss: 0.0965 took: 1.76s  Val. loss: 0.1102\n",
      "Epoch 28, 100% \t Train loss: 0.0970 took: 1.65s  Val. loss: 0.1056\n",
      "Epoch 29, 100% \t Train loss: 0.0951 took: 1.76s  Val. loss: 0.1082\n",
      "Epoch 30, 100% \t Train loss: 0.0955 took: 1.78s  Val. loss: 0.1025\n",
      "Epoch 31, 100% \t Train loss: 0.0935 took: 1.78s  Val. loss: 0.1075\n",
      "Epoch 32, 100% \t Train loss: 0.0942 took: 1.83s  Val. loss: 0.1090\n",
      "Epoch 33, 100% \t Train loss: 0.0932 took: 1.92s  Val. loss: 0.1068\n",
      "Epoch 34, 100% \t Train loss: 0.0927 took: 1.94s  Val. loss: 0.1062\n",
      "Epoch 35, 100% \t Train loss: 0.0929 took: 1.97s  Val. loss: 0.1059\n",
      "Epoch 36, 100% \t Train loss: 0.0920 took: 1.98s  Val. loss: 0.1019\n",
      "Epoch 37, 100% \t Train loss: 0.0903 took: 2.01s  Val. loss: 0.1024\n",
      "Epoch 38, 100% \t Train loss: 0.0899 took: 2.03s  Val. loss: 0.1017\n",
      "Epoch 39, 100% \t Train loss: 0.0906 took: 2.03s  Val. loss: 0.1025\n",
      "Epoch 40, 100% \t Train loss: 0.0885 took: 2.04s  Val. loss: 0.1024\n",
      "Epoch 41, 100% \t Train loss: 0.0890 took: 2.07s  Val. loss: 0.1086\n",
      "Epoch 42, 100% \t Train loss: 0.0882 took: 2.07s  Val. loss: 0.0990\n",
      "Epoch 43, 100% \t Train loss: 0.0879 took: 2.11s  Val. loss: 0.1010\n",
      "Epoch 44, 100% \t Train loss: 0.0879 took: 1.96s  Val. loss: 0.0987\n",
      "Epoch 45, 100% \t Train loss: 0.0867 took: 1.95s  Val. loss: 0.0974\n",
      "Epoch 46, 100% \t Train loss: 0.0860 took: 1.95s  Val. loss: 0.0998\n",
      "Epoch 47, 100% \t Train loss: 0.0874 took: 1.97s  Val. loss: 0.1002\n",
      "Epoch 48, 100% \t Train loss: 0.0861 took: 1.97s  Val. loss: 0.0949\n",
      "Epoch 49, 100% \t Train loss: 0.0841 took: 1.98s  Val. loss: 0.0973\n",
      "Epoch 50, 100% \t Train loss: 0.0857 took: 2.01s  Val. loss: 0.1008\n",
      "Training finished, took 105.77s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2557 took: 1.75s  Val. loss: 0.2604\n",
      "Epoch 2, 100% \t Train loss: 0.2550 took: 1.75s  Val. loss: 0.2578\n",
      "Epoch 3, 100% \t Train loss: 0.2515 took: 1.76s  Val. loss: 0.2469\n",
      "Epoch 4, 100% \t Train loss: 0.2220 took: 1.74s  Val. loss: 0.1876\n",
      "Epoch 5, 100% \t Train loss: 0.1855 took: 1.73s  Val. loss: 0.1713\n",
      "Epoch 6, 100% \t Train loss: 0.1748 took: 1.73s  Val. loss: 0.1655\n",
      "Epoch 7, 100% \t Train loss: 0.1718 took: 1.74s  Val. loss: 0.1662\n",
      "Epoch 8, 100% \t Train loss: 0.1682 took: 1.76s  Val. loss: 0.1660\n",
      "Epoch 9, 100% \t Train loss: 0.1658 took: 1.74s  Val. loss: 0.1609\n",
      "Epoch 10, 100% \t Train loss: 0.1636 took: 1.76s  Val. loss: 0.1622\n",
      "Epoch 11, 100% \t Train loss: 0.1622 took: 1.76s  Val. loss: 0.1646\n",
      "Epoch 12, 100% \t Train loss: 0.1620 took: 1.76s  Val. loss: 0.1573\n",
      "Epoch 13, 100% \t Train loss: 0.1601 took: 1.75s  Val. loss: 0.1595\n",
      "Epoch 14, 100% \t Train loss: 0.1599 took: 1.76s  Val. loss: 0.1624\n",
      "Epoch 15, 100% \t Train loss: 0.1578 took: 1.75s  Val. loss: 0.1613\n",
      "Epoch 16, 100% \t Train loss: 0.1578 took: 1.74s  Val. loss: 0.1579\n",
      "Epoch 17, 100% \t Train loss: 0.1571 took: 1.73s  Val. loss: 0.1587\n",
      "Epoch 18, 100% \t Train loss: 0.1557 took: 1.73s  Val. loss: 0.1568\n",
      "Epoch 19, 100% \t Train loss: 0.1551 took: 1.75s  Val. loss: 0.1562\n",
      "Epoch 20, 100% \t Train loss: 0.1552 took: 1.75s  Val. loss: 0.1579\n",
      "Epoch 21, 100% \t Train loss: 0.1539 took: 1.76s  Val. loss: 0.1615\n",
      "Epoch 22, 100% \t Train loss: 0.1538 took: 1.73s  Val. loss: 0.1560\n",
      "Epoch 23, 100% \t Train loss: 0.1533 took: 1.74s  Val. loss: 0.1571\n",
      "Epoch 24, 100% \t Train loss: 0.1518 took: 1.74s  Val. loss: 0.1559\n",
      "Epoch 25, 100% \t Train loss: 0.1509 took: 1.74s  Val. loss: 0.1616\n",
      "Epoch 26, 100% \t Train loss: 0.1504 took: 1.74s  Val. loss: 0.1566\n",
      "Epoch 27, 100% \t Train loss: 0.1484 took: 1.75s  Val. loss: 0.1558\n",
      "Epoch 28, 100% \t Train loss: 0.1486 took: 1.77s  Val. loss: 0.1554\n",
      "Epoch 29, 100% \t Train loss: 0.1467 took: 1.80s  Val. loss: 0.1570\n",
      "Epoch 30, 100% \t Train loss: 0.1472 took: 1.82s  Val. loss: 0.1525\n",
      "Epoch 31, 100% \t Train loss: 0.1450 took: 1.82s  Val. loss: 0.1533\n",
      "Epoch 32, 100% \t Train loss: 0.1434 took: 1.79s  Val. loss: 0.1536\n",
      "Epoch 33, 100% \t Train loss: 0.1414 took: 1.81s  Val. loss: 0.1503\n",
      "Epoch 34, 100% \t Train loss: 0.1390 took: 1.79s  Val. loss: 0.1479\n",
      "Epoch 35, 100% \t Train loss: 0.1380 took: 1.80s  Val. loss: 0.1438\n",
      "Epoch 36, 100% \t Train loss: 0.1338 took: 1.80s  Val. loss: 0.1415\n",
      "Epoch 37, 100% \t Train loss: 0.1312 took: 1.79s  Val. loss: 0.1370\n",
      "Epoch 38, 100% \t Train loss: 0.1281 took: 1.79s  Val. loss: 0.1323\n",
      "Epoch 39, 100% \t Train loss: 0.1249 took: 1.79s  Val. loss: 0.1303\n",
      "Epoch 40, 100% \t Train loss: 0.1222 took: 1.79s  Val. loss: 0.1277\n",
      "Epoch 41, 100% \t Train loss: 0.1189 took: 1.81s  Val. loss: 0.1232\n",
      "Epoch 42, 100% \t Train loss: 0.1150 took: 1.81s  Val. loss: 0.1208\n",
      "Epoch 43, 100% \t Train loss: 0.1128 took: 1.83s  Val. loss: 0.1151\n",
      "Epoch 44, 100% \t Train loss: 0.1103 took: 1.81s  Val. loss: 0.1146\n",
      "Epoch 45, 100% \t Train loss: 0.1077 took: 1.81s  Val. loss: 0.1107\n",
      "Epoch 46, 100% \t Train loss: 0.1052 took: 1.83s  Val. loss: 0.1115\n",
      "Epoch 47, 100% \t Train loss: 0.1037 took: 1.82s  Val. loss: 0.1064\n",
      "Epoch 48, 100% \t Train loss: 0.1020 took: 1.82s  Val. loss: 0.1046\n",
      "Epoch 49, 100% \t Train loss: 0.0995 took: 1.75s  Val. loss: 0.1011\n",
      "Epoch 50, 100% \t Train loss: 0.0976 took: 1.74s  Val. loss: 0.1010\n",
      "Training finished, took 100.65s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2606 took: 1.74s  Val. loss: 0.2578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2602 took: 1.75s  Val. loss: 0.2559\n",
      "Epoch 3, 100% \t Train loss: 0.2597 took: 1.74s  Val. loss: 0.2549\n",
      "Epoch 4, 100% \t Train loss: 0.2582 took: 1.75s  Val. loss: 0.2526\n",
      "Epoch 5, 100% \t Train loss: 0.2539 took: 1.73s  Val. loss: 0.2461\n",
      "Epoch 6, 100% \t Train loss: 0.2386 took: 1.74s  Val. loss: 0.2226\n",
      "Epoch 7, 100% \t Train loss: 0.2019 took: 1.75s  Val. loss: 0.1908\n",
      "Epoch 8, 100% \t Train loss: 0.1824 took: 1.77s  Val. loss: 0.1878\n",
      "Epoch 9, 100% \t Train loss: 0.1772 took: 1.75s  Val. loss: 0.1847\n",
      "Epoch 10, 100% \t Train loss: 0.1743 took: 1.75s  Val. loss: 0.1825\n",
      "Epoch 11, 100% \t Train loss: 0.1723 took: 1.74s  Val. loss: 0.1791\n",
      "Epoch 12, 100% \t Train loss: 0.1700 took: 1.76s  Val. loss: 0.1783\n",
      "Epoch 13, 100% \t Train loss: 0.1681 took: 1.00s  Val. loss: 0.1783\n",
      "Epoch 14, 100% \t Train loss: 0.1675 took: 1.00s  Val. loss: 0.1808\n",
      "Epoch 15, 100% \t Train loss: 0.1666 took: 1.00s  Val. loss: 0.1803\n",
      "Epoch 16, 100% \t Train loss: 0.1654 took: 1.00s  Val. loss: 0.1775\n",
      "Epoch 17, 100% \t Train loss: 0.1649 took: 1.00s  Val. loss: 0.1750\n",
      "Epoch 18, 100% \t Train loss: 0.1656 took: 1.00s  Val. loss: 0.1778\n",
      "Epoch 19, 100% \t Train loss: 0.1645 took: 1.00s  Val. loss: 0.1757\n",
      "Epoch 20, 100% \t Train loss: 0.1646 took: 1.00s  Val. loss: 0.1742\n",
      "Epoch 21, 100% \t Train loss: 0.1639 took: 1.00s  Val. loss: 0.1750\n",
      "Epoch 22, 100% \t Train loss: 0.1639 took: 1.00s  Val. loss: 0.1763\n",
      "Epoch 23, 100% \t Train loss: 0.1630 took: 1.01s  Val. loss: 0.1756\n",
      "Epoch 24, 100% \t Train loss: 0.1634 took: 1.00s  Val. loss: 0.1750\n",
      "Epoch 25, 100% \t Train loss: 0.1626 took: 1.00s  Val. loss: 0.1756\n",
      "Epoch 26, 100% \t Train loss: 0.1639 took: 1.01s  Val. loss: 0.1810\n",
      "Epoch 27, 100% \t Train loss: 0.1632 took: 1.00s  Val. loss: 0.1781\n",
      "Epoch 28, 100% \t Train loss: 0.1622 took: 1.00s  Val. loss: 0.1791\n",
      "Epoch 29, 100% \t Train loss: 0.1621 took: 1.01s  Val. loss: 0.1739\n",
      "Epoch 30, 100% \t Train loss: 0.1612 took: 1.00s  Val. loss: 0.1750\n",
      "Epoch 31, 100% \t Train loss: 0.1614 took: 1.76s  Val. loss: 0.1745\n",
      "Epoch 32, 100% \t Train loss: 0.1618 took: 1.77s  Val. loss: 0.1744\n",
      "Epoch 33, 100% \t Train loss: 0.1607 took: 1.76s  Val. loss: 0.1768\n",
      "Epoch 34, 100% \t Train loss: 0.1606 took: 1.77s  Val. loss: 0.1787\n",
      "Epoch 35, 100% \t Train loss: 0.1611 took: 1.80s  Val. loss: 0.1746\n",
      "Epoch 36, 100% \t Train loss: 0.1604 took: 1.76s  Val. loss: 0.1764\n",
      "Epoch 37, 100% \t Train loss: 0.1604 took: 1.76s  Val. loss: 0.1798\n",
      "Epoch 38, 100% \t Train loss: 0.1602 took: 1.76s  Val. loss: 0.1788\n",
      "Epoch 39, 100% \t Train loss: 0.1608 took: 1.76s  Val. loss: 0.1752\n",
      "Epoch 40, 100% \t Train loss: 0.1591 took: 1.76s  Val. loss: 0.1771\n",
      "Epoch 41, 100% \t Train loss: 0.1596 took: 1.76s  Val. loss: 0.1798\n",
      "Epoch 42, 100% \t Train loss: 0.1589 took: 1.77s  Val. loss: 0.1774\n",
      "Epoch 43, 100% \t Train loss: 0.1611 took: 1.77s  Val. loss: 0.1745\n",
      "Epoch 44, 100% \t Train loss: 0.1587 took: 1.77s  Val. loss: 0.1756\n",
      "Epoch 45, 100% \t Train loss: 0.1584 took: 1.76s  Val. loss: 0.1764\n",
      "Epoch 46, 100% \t Train loss: 0.1580 took: 1.76s  Val. loss: 0.1756\n",
      "Epoch 47, 100% \t Train loss: 0.1582 took: 1.77s  Val. loss: 0.1735\n",
      "Epoch 48, 100% \t Train loss: 0.1590 took: 1.77s  Val. loss: 0.1751\n",
      "Epoch 49, 100% \t Train loss: 0.1579 took: 1.77s  Val. loss: 0.1783\n",
      "Epoch 50, 100% \t Train loss: 0.1587 took: 1.75s  Val. loss: 0.1768\n",
      "Training finished, took 84.73s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.30\n",
      "\tmask_channels :  8  - prob: 0.37\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.16\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.872903\n",
      "lambda: 0.0010 - V: 0.847342\n",
      "lambda: 0.0005 - V: 0.813872\n",
      "Average V: 0.844706\n",
      "Time elapsed: 294.51 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.36\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.37\n",
      "\tmask_channels :  8  - prob: 0.37\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.28\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 1.89s  Val. loss: 0.2612\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 1.88s  Val. loss: 0.2371\n",
      "Epoch 3, 100% \t Train loss: 0.1865 took: 1.88s  Val. loss: 0.1819\n",
      "Epoch 4, 100% \t Train loss: 0.1658 took: 1.89s  Val. loss: 0.1772\n",
      "Epoch 5, 100% \t Train loss: 0.1587 took: 1.88s  Val. loss: 0.1721\n",
      "Epoch 6, 100% \t Train loss: 0.1540 took: 1.89s  Val. loss: 0.1645\n",
      "Epoch 7, 100% \t Train loss: 0.1510 took: 1.88s  Val. loss: 0.1623\n",
      "Epoch 8, 100% \t Train loss: 0.1483 took: 1.91s  Val. loss: 0.1651\n",
      "Epoch 9, 100% \t Train loss: 0.1448 took: 1.88s  Val. loss: 0.1595\n",
      "Epoch 10, 100% \t Train loss: 0.1373 took: 1.88s  Val. loss: 0.1452\n",
      "Epoch 11, 100% \t Train loss: 0.1208 took: 1.90s  Val. loss: 0.1244\n",
      "Epoch 12, 100% \t Train loss: 0.1056 took: 1.89s  Val. loss: 0.1066\n",
      "Epoch 13, 100% \t Train loss: 0.0934 took: 1.89s  Val. loss: 0.1008\n",
      "Epoch 14, 100% \t Train loss: 0.0853 took: 1.89s  Val. loss: 0.0964\n",
      "Epoch 15, 100% \t Train loss: 0.0805 took: 1.91s  Val. loss: 0.0911\n",
      "Epoch 16, 100% \t Train loss: 0.0773 took: 1.90s  Val. loss: 0.0885\n",
      "Epoch 17, 100% \t Train loss: 0.0758 took: 1.90s  Val. loss: 0.0928\n",
      "Epoch 18, 100% \t Train loss: 0.0745 took: 1.87s  Val. loss: 0.0933\n",
      "Epoch 19, 100% \t Train loss: 0.0735 took: 1.89s  Val. loss: 0.0854\n",
      "Epoch 20, 100% \t Train loss: 0.0712 took: 1.88s  Val. loss: 0.0838\n",
      "Epoch 21, 100% \t Train loss: 0.0699 took: 1.89s  Val. loss: 0.0871\n",
      "Epoch 22, 100% \t Train loss: 0.0703 took: 1.91s  Val. loss: 0.0918\n",
      "Epoch 23, 100% \t Train loss: 0.0700 took: 1.88s  Val. loss: 0.0890\n",
      "Epoch 24, 100% \t Train loss: 0.0684 took: 1.90s  Val. loss: 0.0894\n",
      "Epoch 25, 100% \t Train loss: 0.0678 took: 1.90s  Val. loss: 0.0892\n",
      "Epoch 26, 100% \t Train loss: 0.0673 took: 1.88s  Val. loss: 0.0935\n",
      "Epoch 27, 100% \t Train loss: 0.0666 took: 1.88s  Val. loss: 0.0883\n",
      "Epoch 28, 100% \t Train loss: 0.0661 took: 1.88s  Val. loss: 0.0943\n",
      "Epoch 29, 100% \t Train loss: 0.0659 took: 1.88s  Val. loss: 0.0871\n",
      "Epoch 30, 100% \t Train loss: 0.0644 took: 1.87s  Val. loss: 0.0915\n",
      "Epoch 31, 100% \t Train loss: 0.0647 took: 1.87s  Val. loss: 0.0962\n",
      "Epoch 32, 100% \t Train loss: 0.0656 took: 1.88s  Val. loss: 0.0894\n",
      "Epoch 33, 100% \t Train loss: 0.0652 took: 1.89s  Val. loss: 0.0895\n",
      "Epoch 34, 100% \t Train loss: 0.0640 took: 1.91s  Val. loss: 0.0953\n",
      "Epoch 35, 100% \t Train loss: 0.0645 took: 1.91s  Val. loss: 0.0890\n",
      "Epoch 36, 100% \t Train loss: 0.0642 took: 1.91s  Val. loss: 0.0900\n",
      "Epoch 37, 100% \t Train loss: 0.0632 took: 1.91s  Val. loss: 0.0885\n",
      "Epoch 38, 100% \t Train loss: 0.0631 took: 1.91s  Val. loss: 0.0901\n",
      "Epoch 39, 100% \t Train loss: 0.0631 took: 1.91s  Val. loss: 0.0958\n",
      "Epoch 40, 100% \t Train loss: 0.0630 took: 1.90s  Val. loss: 0.0890\n",
      "Epoch 41, 100% \t Train loss: 0.0618 took: 1.89s  Val. loss: 0.0884\n",
      "Epoch 42, 100% \t Train loss: 0.0621 took: 1.90s  Val. loss: 0.0942\n",
      "Epoch 43, 100% \t Train loss: 0.0611 took: 1.90s  Val. loss: 0.0979\n",
      "Epoch 44, 100% \t Train loss: 0.0628 took: 1.89s  Val. loss: 0.0942\n",
      "Epoch 45, 100% \t Train loss: 0.0621 took: 1.88s  Val. loss: 0.0949\n",
      "Epoch 46, 100% \t Train loss: 0.0603 took: 1.90s  Val. loss: 0.0985\n",
      "Epoch 47, 100% \t Train loss: 0.0610 took: 1.93s  Val. loss: 0.0914\n",
      "Epoch 48, 100% \t Train loss: 0.0610 took: 1.90s  Val. loss: 0.0941\n",
      "Epoch 49, 100% \t Train loss: 0.0605 took: 1.89s  Val. loss: 0.0951\n",
      "Epoch 50, 100% \t Train loss: 0.0601 took: 1.90s  Val. loss: 0.0920\n",
      "Training finished, took 107.32s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 1.92s  Val. loss: 0.2567\n",
      "Epoch 2, 100% \t Train loss: 0.2567 took: 1.90s  Val. loss: 0.2512\n",
      "Epoch 3, 100% \t Train loss: 0.2301 took: 1.89s  Val. loss: 0.2044\n",
      "Epoch 4, 100% \t Train loss: 0.1847 took: 1.90s  Val. loss: 0.1939\n",
      "Epoch 5, 100% \t Train loss: 0.1729 took: 1.91s  Val. loss: 0.1913\n",
      "Epoch 6, 100% \t Train loss: 0.1684 took: 1.88s  Val. loss: 0.1895\n",
      "Epoch 7, 100% \t Train loss: 0.1662 took: 1.88s  Val. loss: 0.1862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.1660 took: 1.87s  Val. loss: 0.1879\n",
      "Epoch 9, 100% \t Train loss: 0.1623 took: 1.90s  Val. loss: 0.1847\n",
      "Epoch 10, 100% \t Train loss: 0.1592 took: 1.89s  Val. loss: 0.1829\n",
      "Epoch 11, 100% \t Train loss: 0.1578 took: 1.90s  Val. loss: 0.1830\n",
      "Epoch 12, 100% \t Train loss: 0.1574 took: 1.90s  Val. loss: 0.1827\n",
      "Epoch 13, 100% \t Train loss: 0.1553 took: 1.89s  Val. loss: 0.1808\n",
      "Epoch 14, 100% \t Train loss: 0.1541 took: 1.90s  Val. loss: 0.1807\n",
      "Epoch 15, 100% \t Train loss: 0.1533 took: 1.88s  Val. loss: 0.1848\n",
      "Epoch 16, 100% \t Train loss: 0.1518 took: 1.88s  Val. loss: 0.1911\n",
      "Epoch 17, 100% \t Train loss: 0.1561 took: 1.88s  Val. loss: 0.1830\n",
      "Epoch 18, 100% \t Train loss: 0.1510 took: 1.88s  Val. loss: 0.1817\n",
      "Epoch 19, 100% \t Train loss: 0.1503 took: 1.89s  Val. loss: 0.1842\n",
      "Epoch 20, 100% \t Train loss: 0.1508 took: 1.87s  Val. loss: 0.1792\n",
      "Epoch 21, 100% \t Train loss: 0.1499 took: 1.73s  Val. loss: 0.1798\n",
      "Epoch 22, 100% \t Train loss: 0.1497 took: 1.90s  Val. loss: 0.1826\n",
      "Epoch 23, 100% \t Train loss: 0.1470 took: 1.89s  Val. loss: 0.1835\n",
      "Epoch 24, 100% \t Train loss: 0.1469 took: 1.90s  Val. loss: 0.1797\n",
      "Epoch 25, 100% \t Train loss: 0.1451 took: 1.87s  Val. loss: 0.1784\n",
      "Epoch 26, 100% \t Train loss: 0.1439 took: 1.88s  Val. loss: 0.1748\n",
      "Epoch 27, 100% \t Train loss: 0.1429 took: 1.87s  Val. loss: 0.1744\n",
      "Epoch 28, 100% \t Train loss: 0.1406 took: 1.88s  Val. loss: 0.1732\n",
      "Epoch 29, 100% \t Train loss: 0.1380 took: 1.91s  Val. loss: 0.1678\n",
      "Epoch 30, 100% \t Train loss: 0.1341 took: 1.86s  Val. loss: 0.1639\n",
      "Epoch 31, 100% \t Train loss: 0.1303 took: 1.89s  Val. loss: 0.1614\n",
      "Epoch 32, 100% \t Train loss: 0.1272 took: 1.89s  Val. loss: 0.1574\n",
      "Epoch 33, 100% \t Train loss: 0.1238 took: 1.90s  Val. loss: 0.1520\n",
      "Epoch 34, 100% \t Train loss: 0.1212 took: 1.90s  Val. loss: 0.1456\n",
      "Epoch 35, 100% \t Train loss: 0.1172 took: 1.91s  Val. loss: 0.1398\n",
      "Epoch 36, 100% \t Train loss: 0.1153 took: 1.92s  Val. loss: 0.1418\n",
      "Epoch 37, 100% \t Train loss: 0.1117 took: 1.91s  Val. loss: 0.1421\n",
      "Epoch 38, 100% \t Train loss: 0.1096 took: 1.90s  Val. loss: 0.1315\n",
      "Epoch 39, 100% \t Train loss: 0.1061 took: 1.91s  Val. loss: 0.1296\n",
      "Epoch 40, 100% \t Train loss: 0.1035 took: 1.88s  Val. loss: 0.1275\n",
      "Epoch 41, 100% \t Train loss: 0.1018 took: 1.88s  Val. loss: 0.1285\n",
      "Epoch 42, 100% \t Train loss: 0.1004 took: 1.88s  Val. loss: 0.1237\n",
      "Epoch 43, 100% \t Train loss: 0.0976 took: 1.88s  Val. loss: 0.1205\n",
      "Epoch 44, 100% \t Train loss: 0.0951 took: 1.11s  Val. loss: 0.1178\n",
      "Epoch 45, 100% \t Train loss: 0.0942 took: 1.54s  Val. loss: 0.1134\n",
      "Epoch 46, 100% \t Train loss: 0.0909 took: 1.11s  Val. loss: 0.1163\n",
      "Epoch 47, 100% \t Train loss: 0.0903 took: 1.11s  Val. loss: 0.1200\n",
      "Epoch 48, 100% \t Train loss: 0.0891 took: 1.11s  Val. loss: 0.1164\n",
      "Epoch 49, 100% \t Train loss: 0.0871 took: 1.11s  Val. loss: 0.1095\n",
      "Epoch 50, 100% \t Train loss: 0.0870 took: 1.11s  Val. loss: 0.1109\n",
      "Training finished, took 101.54s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 1.10s  Val. loss: 0.2549\n",
      "Epoch 2, 100% \t Train loss: 0.2569 took: 1.10s  Val. loss: 0.2530\n",
      "Epoch 3, 100% \t Train loss: 0.2462 took: 1.10s  Val. loss: 0.2251\n",
      "Epoch 4, 100% \t Train loss: 0.2061 took: 1.10s  Val. loss: 0.1830\n",
      "Epoch 5, 100% \t Train loss: 0.1854 took: 1.10s  Val. loss: 0.1735\n",
      "Epoch 6, 100% \t Train loss: 0.1781 took: 1.09s  Val. loss: 0.1715\n",
      "Epoch 7, 100% \t Train loss: 0.1763 took: 1.09s  Val. loss: 0.1681\n",
      "Epoch 8, 100% \t Train loss: 0.1748 took: 1.09s  Val. loss: 0.1680\n",
      "Epoch 9, 100% \t Train loss: 0.1710 took: 1.09s  Val. loss: 0.1676\n",
      "Epoch 10, 100% \t Train loss: 0.1691 took: 1.10s  Val. loss: 0.1716\n",
      "Epoch 11, 100% \t Train loss: 0.1678 took: 1.11s  Val. loss: 0.1640\n",
      "Epoch 12, 100% \t Train loss: 0.1655 took: 1.10s  Val. loss: 0.1671\n",
      "Epoch 13, 100% \t Train loss: 0.1648 took: 1.11s  Val. loss: 0.1613\n",
      "Epoch 14, 100% \t Train loss: 0.1647 took: 1.10s  Val. loss: 0.1731\n",
      "Epoch 15, 100% \t Train loss: 0.1631 took: 1.09s  Val. loss: 0.1634\n",
      "Epoch 16, 100% \t Train loss: 0.1629 took: 1.10s  Val. loss: 0.1614\n",
      "Epoch 17, 100% \t Train loss: 0.1600 took: 1.10s  Val. loss: 0.1619\n",
      "Epoch 18, 100% \t Train loss: 0.1588 took: 1.10s  Val. loss: 0.1640\n",
      "Epoch 19, 100% \t Train loss: 0.1597 took: 1.10s  Val. loss: 0.1600\n",
      "Epoch 20, 100% \t Train loss: 0.1597 took: 1.09s  Val. loss: 0.1641\n",
      "Epoch 21, 100% \t Train loss: 0.1592 took: 1.10s  Val. loss: 0.1601\n",
      "Epoch 22, 100% \t Train loss: 0.1580 took: 1.10s  Val. loss: 0.1577\n",
      "Epoch 23, 100% \t Train loss: 0.1562 took: 1.10s  Val. loss: 0.1571\n",
      "Epoch 24, 100% \t Train loss: 0.1573 took: 1.10s  Val. loss: 0.1602\n",
      "Epoch 25, 100% \t Train loss: 0.1552 took: 1.10s  Val. loss: 0.1586\n",
      "Epoch 26, 100% \t Train loss: 0.1555 took: 1.10s  Val. loss: 0.1564\n",
      "Epoch 27, 100% \t Train loss: 0.1557 took: 1.11s  Val. loss: 0.1631\n",
      "Epoch 28, 100% \t Train loss: 0.1554 took: 1.11s  Val. loss: 0.1585\n",
      "Epoch 29, 100% \t Train loss: 0.1538 took: 1.12s  Val. loss: 0.1593\n",
      "Epoch 30, 100% \t Train loss: 0.1551 took: 1.12s  Val. loss: 0.1619\n",
      "Epoch 31, 100% \t Train loss: 0.1545 took: 1.12s  Val. loss: 0.1600\n",
      "Epoch 32, 100% \t Train loss: 0.1547 took: 1.12s  Val. loss: 0.1622\n",
      "Epoch 33, 100% \t Train loss: 0.1549 took: 1.80s  Val. loss: 0.1587\n",
      "Epoch 34, 100% \t Train loss: 0.1527 took: 1.89s  Val. loss: 0.1582\n",
      "Epoch 35, 100% \t Train loss: 0.1518 took: 1.90s  Val. loss: 0.1584\n",
      "Epoch 36, 100% \t Train loss: 0.1529 took: 1.90s  Val. loss: 0.1575\n",
      "Epoch 37, 100% \t Train loss: 0.1526 took: 1.94s  Val. loss: 0.1595\n",
      "Epoch 38, 100% \t Train loss: 0.1522 took: 1.90s  Val. loss: 0.1584\n",
      "Epoch 39, 100% \t Train loss: 0.1517 took: 1.94s  Val. loss: 0.1586\n",
      "Epoch 40, 100% \t Train loss: 0.1511 took: 1.99s  Val. loss: 0.1584\n",
      "Epoch 41, 100% \t Train loss: 0.1513 took: 2.00s  Val. loss: 0.1609\n",
      "Epoch 42, 100% \t Train loss: 0.1503 took: 2.01s  Val. loss: 0.1569\n",
      "Epoch 43, 100% \t Train loss: 0.1500 took: 2.01s  Val. loss: 0.1587\n",
      "Epoch 44, 100% \t Train loss: 0.1509 took: 2.01s  Val. loss: 0.1568\n",
      "Epoch 45, 100% \t Train loss: 0.1501 took: 2.00s  Val. loss: 0.1577\n",
      "Epoch 46, 100% \t Train loss: 0.1511 took: 1.99s  Val. loss: 0.1614\n",
      "Epoch 47, 100% \t Train loss: 0.1493 took: 2.01s  Val. loss: 0.1584\n",
      "Epoch 48, 100% \t Train loss: 0.1489 took: 2.01s  Val. loss: 0.1584\n",
      "Epoch 49, 100% \t Train loss: 0.1503 took: 2.02s  Val. loss: 0.1590\n",
      "Epoch 50, 100% \t Train loss: 0.1494 took: 2.04s  Val. loss: 0.1583\n",
      "Training finished, took 79.77s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.36\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.37\n",
      "\tmask_channels :  8  - prob: 0.37\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.28\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.889129\n",
      "lambda: 0.0010 - V: 0.835529\n",
      "lambda: 0.0005 - V: 0.833072\n",
      "Average V: 0.852577\n",
      "Time elapsed: 292.00 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.37\n",
      "\tmask_channels :  4  - prob: 0.28\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.27\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 1.83s  Val. loss: 0.2586\n",
      "Epoch 2, 100% \t Train loss: 0.2573 took: 1.82s  Val. loss: 0.2599\n",
      "Epoch 3, 100% \t Train loss: 0.2530 took: 1.81s  Val. loss: 0.2353\n",
      "Epoch 4, 100% \t Train loss: 0.2080 took: 1.81s  Val. loss: 0.1808\n",
      "Epoch 5, 100% \t Train loss: 0.1739 took: 1.80s  Val. loss: 0.1713\n",
      "Epoch 6, 100% \t Train loss: 0.1663 took: 1.80s  Val. loss: 0.1706\n",
      "Epoch 7, 100% \t Train loss: 0.1613 took: 1.79s  Val. loss: 0.1676\n",
      "Epoch 8, 100% \t Train loss: 0.1585 took: 1.79s  Val. loss: 0.1664\n",
      "Epoch 9, 100% \t Train loss: 0.1572 took: 1.81s  Val. loss: 0.1625\n",
      "Epoch 10, 100% \t Train loss: 0.1529 took: 1.80s  Val. loss: 0.1608\n",
      "Epoch 11, 100% \t Train loss: 0.1516 took: 1.79s  Val. loss: 0.1557\n",
      "Epoch 12, 100% \t Train loss: 0.1464 took: 1.80s  Val. loss: 0.1531\n",
      "Epoch 13, 100% \t Train loss: 0.1397 took: 1.80s  Val. loss: 0.1477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.1315 took: 1.79s  Val. loss: 0.1420\n",
      "Epoch 15, 100% \t Train loss: 0.1223 took: 1.80s  Val. loss: 0.1324\n",
      "Epoch 16, 100% \t Train loss: 0.1153 took: 1.80s  Val. loss: 0.1244\n",
      "Epoch 17, 100% \t Train loss: 0.1090 took: 1.80s  Val. loss: 0.1144\n",
      "Epoch 18, 100% \t Train loss: 0.1046 took: 1.80s  Val. loss: 0.1050\n",
      "Epoch 19, 100% \t Train loss: 0.0990 took: 1.81s  Val. loss: 0.1064\n",
      "Epoch 20, 100% \t Train loss: 0.0948 took: 1.82s  Val. loss: 0.1032\n",
      "Epoch 21, 100% \t Train loss: 0.0927 took: 1.84s  Val. loss: 0.0964\n",
      "Epoch 22, 100% \t Train loss: 0.0903 took: 1.81s  Val. loss: 0.0994\n",
      "Epoch 23, 100% \t Train loss: 0.0887 took: 1.80s  Val. loss: 0.0950\n",
      "Epoch 24, 100% \t Train loss: 0.0865 took: 1.79s  Val. loss: 0.0945\n",
      "Epoch 25, 100% \t Train loss: 0.0857 took: 1.81s  Val. loss: 0.0952\n",
      "Epoch 26, 100% \t Train loss: 0.0866 took: 1.81s  Val. loss: 0.0967\n",
      "Epoch 27, 100% \t Train loss: 0.0852 took: 1.81s  Val. loss: 0.0951\n",
      "Epoch 28, 100% \t Train loss: 0.0840 took: 1.82s  Val. loss: 0.0924\n",
      "Epoch 29, 100% \t Train loss: 0.0834 took: 1.79s  Val. loss: 0.0943\n",
      "Epoch 30, 100% \t Train loss: 0.0837 took: 1.84s  Val. loss: 0.0956\n",
      "Epoch 31, 100% \t Train loss: 0.0825 took: 1.83s  Val. loss: 0.0926\n",
      "Epoch 32, 100% \t Train loss: 0.0827 took: 1.91s  Val. loss: 0.0927\n",
      "Epoch 33, 100% \t Train loss: 0.0816 took: 2.10s  Val. loss: 0.0952\n",
      "Epoch 34, 100% \t Train loss: 0.0810 took: 2.12s  Val. loss: 0.0902\n",
      "Epoch 35, 100% \t Train loss: 0.0817 took: 2.13s  Val. loss: 0.0924\n",
      "Epoch 36, 100% \t Train loss: 0.0824 took: 2.18s  Val. loss: 0.0963\n",
      "Epoch 37, 100% \t Train loss: 0.0817 took: 2.19s  Val. loss: 0.0903\n",
      "Epoch 38, 100% \t Train loss: 0.0793 took: 2.24s  Val. loss: 0.0897\n",
      "Epoch 39, 100% \t Train loss: 0.0783 took: 2.23s  Val. loss: 0.0882\n",
      "Epoch 40, 100% \t Train loss: 0.0781 took: 2.24s  Val. loss: 0.0899\n",
      "Epoch 41, 100% \t Train loss: 0.0780 took: 2.24s  Val. loss: 0.0952\n",
      "Epoch 42, 100% \t Train loss: 0.0776 took: 2.25s  Val. loss: 0.0902\n",
      "Epoch 43, 100% \t Train loss: 0.0765 took: 2.22s  Val. loss: 0.0878\n",
      "Epoch 44, 100% \t Train loss: 0.0763 took: 2.24s  Val. loss: 0.0890\n",
      "Epoch 45, 100% \t Train loss: 0.0761 took: 2.23s  Val. loss: 0.0896\n",
      "Epoch 46, 100% \t Train loss: 0.0760 took: 2.24s  Val. loss: 0.0885\n",
      "Epoch 47, 100% \t Train loss: 0.0750 took: 2.22s  Val. loss: 0.0921\n",
      "Epoch 48, 100% \t Train loss: 0.0757 took: 2.22s  Val. loss: 0.0896\n",
      "Epoch 49, 100% \t Train loss: 0.0753 took: 2.23s  Val. loss: 0.0912\n",
      "Epoch 50, 100% \t Train loss: 0.0746 took: 2.23s  Val. loss: 0.0901\n",
      "Training finished, took 111.42s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2567 took: 1.83s  Val. loss: 0.2563\n",
      "Epoch 2, 100% \t Train loss: 0.2560 took: 1.84s  Val. loss: 0.2562\n",
      "Epoch 3, 100% \t Train loss: 0.2560 took: 1.84s  Val. loss: 0.2558\n",
      "Epoch 4, 100% \t Train loss: 0.2556 took: 1.82s  Val. loss: 0.2563\n",
      "Epoch 5, 100% \t Train loss: 0.2510 took: 1.83s  Val. loss: 0.2419\n",
      "Epoch 6, 100% \t Train loss: 0.2215 took: 1.82s  Val. loss: 0.2153\n",
      "Epoch 7, 100% \t Train loss: 0.1896 took: 1.81s  Val. loss: 0.1916\n",
      "Epoch 8, 100% \t Train loss: 0.1762 took: 1.82s  Val. loss: 0.1849\n",
      "Epoch 9, 100% \t Train loss: 0.1714 took: 1.85s  Val. loss: 0.1819\n",
      "Epoch 10, 100% \t Train loss: 0.1690 took: 1.82s  Val. loss: 0.1845\n",
      "Epoch 11, 100% \t Train loss: 0.1661 took: 1.82s  Val. loss: 0.1820\n",
      "Epoch 12, 100% \t Train loss: 0.1687 took: 1.83s  Val. loss: 0.1775\n",
      "Epoch 13, 100% \t Train loss: 0.1661 took: 1.81s  Val. loss: 0.1784\n",
      "Epoch 14, 100% \t Train loss: 0.1624 took: 1.82s  Val. loss: 0.1856\n",
      "Epoch 15, 100% \t Train loss: 0.1654 took: 1.82s  Val. loss: 0.1730\n",
      "Epoch 16, 100% \t Train loss: 0.1632 took: 1.83s  Val. loss: 0.1771\n",
      "Epoch 17, 100% \t Train loss: 0.1593 took: 1.81s  Val. loss: 0.1741\n",
      "Epoch 18, 100% \t Train loss: 0.1591 took: 1.81s  Val. loss: 0.1755\n",
      "Epoch 19, 100% \t Train loss: 0.1591 took: 1.83s  Val. loss: 0.1696\n",
      "Epoch 20, 100% \t Train loss: 0.1569 took: 1.84s  Val. loss: 0.1705\n",
      "Epoch 21, 100% \t Train loss: 0.1558 took: 1.82s  Val. loss: 0.1744\n",
      "Epoch 22, 100% \t Train loss: 0.1572 took: 1.82s  Val. loss: 0.1660\n",
      "Epoch 23, 100% \t Train loss: 0.1566 took: 1.84s  Val. loss: 0.1795\n",
      "Epoch 24, 100% \t Train loss: 0.1551 took: 1.83s  Val. loss: 0.1732\n",
      "Epoch 25, 100% \t Train loss: 0.1528 took: 1.82s  Val. loss: 0.1758\n",
      "Epoch 26, 100% \t Train loss: 0.1541 took: 1.83s  Val. loss: 0.1692\n",
      "Epoch 27, 100% \t Train loss: 0.1527 took: 1.82s  Val. loss: 0.1658\n",
      "Epoch 28, 100% \t Train loss: 0.1509 took: 1.82s  Val. loss: 0.1668\n",
      "Epoch 29, 100% \t Train loss: 0.1490 took: 1.84s  Val. loss: 0.1626\n",
      "Epoch 30, 100% \t Train loss: 0.1489 took: 1.84s  Val. loss: 0.1600\n",
      "Epoch 31, 100% \t Train loss: 0.1473 took: 1.84s  Val. loss: 0.1709\n",
      "Epoch 32, 100% \t Train loss: 0.1452 took: 1.86s  Val. loss: 0.1643\n",
      "Epoch 33, 100% \t Train loss: 0.1428 took: 1.86s  Val. loss: 0.1635\n",
      "Epoch 34, 100% \t Train loss: 0.1392 took: 1.87s  Val. loss: 0.1612\n",
      "Epoch 35, 100% \t Train loss: 0.1396 took: 1.85s  Val. loss: 0.1672\n",
      "Epoch 36, 100% \t Train loss: 0.1353 took: 1.85s  Val. loss: 0.1539\n",
      "Epoch 37, 100% \t Train loss: 0.1313 took: 1.87s  Val. loss: 0.1550\n",
      "Epoch 38, 100% \t Train loss: 0.1297 took: 1.89s  Val. loss: 0.1484\n",
      "Epoch 39, 100% \t Train loss: 0.1255 took: 1.88s  Val. loss: 0.1472\n",
      "Epoch 40, 100% \t Train loss: 0.1227 took: 1.89s  Val. loss: 0.1406\n",
      "Epoch 41, 100% \t Train loss: 0.1198 took: 1.86s  Val. loss: 0.1352\n",
      "Epoch 42, 100% \t Train loss: 0.1167 took: 1.86s  Val. loss: 0.1319\n",
      "Epoch 43, 100% \t Train loss: 0.1129 took: 1.89s  Val. loss: 0.1261\n",
      "Epoch 44, 100% \t Train loss: 0.1096 took: 1.91s  Val. loss: 0.1271\n",
      "Epoch 45, 100% \t Train loss: 0.1072 took: 1.88s  Val. loss: 0.1211\n",
      "Epoch 46, 100% \t Train loss: 0.1062 took: 1.90s  Val. loss: 0.1204\n",
      "Epoch 47, 100% \t Train loss: 0.1028 took: 1.88s  Val. loss: 0.1182\n",
      "Epoch 48, 100% \t Train loss: 0.1014 took: 1.89s  Val. loss: 0.1133\n",
      "Epoch 49, 100% \t Train loss: 0.1003 took: 1.89s  Val. loss: 0.1170\n",
      "Epoch 50, 100% \t Train loss: 0.0983 took: 1.88s  Val. loss: 0.1069\n",
      "Training finished, took 105.01s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2599 took: 1.80s  Val. loss: 0.2610\n",
      "Epoch 2, 100% \t Train loss: 0.2586 took: 1.80s  Val. loss: 0.2611\n",
      "Epoch 3, 100% \t Train loss: 0.2585 took: 1.81s  Val. loss: 0.2618\n",
      "Epoch 4, 100% \t Train loss: 0.2584 took: 1.79s  Val. loss: 0.2615\n",
      "Epoch 5, 100% \t Train loss: 0.2584 took: 1.80s  Val. loss: 0.2615\n",
      "Epoch 6, 100% \t Train loss: 0.2583 took: 1.81s  Val. loss: 0.2604\n",
      "Epoch 7, 100% \t Train loss: 0.2580 took: 1.80s  Val. loss: 0.2604\n",
      "Epoch 8, 100% \t Train loss: 0.2573 took: 1.79s  Val. loss: 0.2608\n",
      "Epoch 9, 100% \t Train loss: 0.2543 took: 1.80s  Val. loss: 0.2540\n",
      "Epoch 10, 100% \t Train loss: 0.2393 took: 1.80s  Val. loss: 0.2320\n",
      "Epoch 11, 100% \t Train loss: 0.2196 took: 1.78s  Val. loss: 0.2203\n",
      "Epoch 12, 100% \t Train loss: 0.2072 took: 1.79s  Val. loss: 0.2051\n",
      "Epoch 13, 100% \t Train loss: 0.1934 took: 1.79s  Val. loss: 0.1999\n",
      "Epoch 14, 100% \t Train loss: 0.1845 took: 1.80s  Val. loss: 0.1887\n",
      "Epoch 15, 100% \t Train loss: 0.1808 took: 1.80s  Val. loss: 0.1862\n",
      "Epoch 16, 100% \t Train loss: 0.1797 took: 1.79s  Val. loss: 0.1842\n",
      "Epoch 17, 100% \t Train loss: 0.1781 took: 1.12s  Val. loss: 0.1832\n",
      "Epoch 18, 100% \t Train loss: 0.1764 took: 1.03s  Val. loss: 0.1812\n",
      "Epoch 19, 100% \t Train loss: 0.1763 took: 1.04s  Val. loss: 0.1823\n",
      "Epoch 20, 100% \t Train loss: 0.1749 took: 1.04s  Val. loss: 0.1787\n",
      "Epoch 21, 100% \t Train loss: 0.1740 took: 1.04s  Val. loss: 0.1777\n",
      "Epoch 22, 100% \t Train loss: 0.1731 took: 1.03s  Val. loss: 0.1785\n",
      "Epoch 23, 100% \t Train loss: 0.1731 took: 1.04s  Val. loss: 0.1770\n",
      "Epoch 24, 100% \t Train loss: 0.1716 took: 1.03s  Val. loss: 0.1740\n",
      "Epoch 25, 100% \t Train loss: 0.1718 took: 1.03s  Val. loss: 0.1813\n",
      "Epoch 26, 100% \t Train loss: 0.1718 took: 1.03s  Val. loss: 0.1746\n",
      "Epoch 27, 100% \t Train loss: 0.1726 took: 1.04s  Val. loss: 0.1755\n",
      "Epoch 28, 100% \t Train loss: 0.1706 took: 1.05s  Val. loss: 0.1742\n",
      "Epoch 29, 100% \t Train loss: 0.1705 took: 1.05s  Val. loss: 0.1739\n",
      "Epoch 30, 100% \t Train loss: 0.1698 took: 1.05s  Val. loss: 0.1763\n",
      "Epoch 31, 100% \t Train loss: 0.1708 took: 1.06s  Val. loss: 0.1766\n",
      "Epoch 32, 100% \t Train loss: 0.1696 took: 1.06s  Val. loss: 0.1745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, 100% \t Train loss: 0.1686 took: 1.47s  Val. loss: 0.1748\n",
      "Epoch 34, 100% \t Train loss: 0.1677 took: 1.81s  Val. loss: 0.1717\n",
      "Epoch 35, 100% \t Train loss: 0.1690 took: 1.82s  Val. loss: 0.1719\n",
      "Epoch 36, 100% \t Train loss: 0.1679 took: 1.83s  Val. loss: 0.1730\n",
      "Epoch 37, 100% \t Train loss: 0.1664 took: 1.83s  Val. loss: 0.1724\n",
      "Epoch 38, 100% \t Train loss: 0.1692 took: 1.84s  Val. loss: 0.1720\n",
      "Epoch 39, 100% \t Train loss: 0.1667 took: 1.83s  Val. loss: 0.1723\n",
      "Epoch 40, 100% \t Train loss: 0.1665 took: 1.84s  Val. loss: 0.1739\n",
      "Epoch 41, 100% \t Train loss: 0.1652 took: 1.85s  Val. loss: 0.1738\n",
      "Epoch 42, 100% \t Train loss: 0.1648 took: 1.83s  Val. loss: 0.1700\n",
      "Epoch 43, 100% \t Train loss: 0.1647 took: 1.85s  Val. loss: 0.1736\n",
      "Epoch 44, 100% \t Train loss: 0.1637 took: 1.84s  Val. loss: 0.1708\n",
      "Epoch 45, 100% \t Train loss: 0.1629 took: 1.86s  Val. loss: 0.1690\n",
      "Epoch 46, 100% \t Train loss: 0.1620 took: 1.87s  Val. loss: 0.1683\n",
      "Epoch 47, 100% \t Train loss: 0.1648 took: 1.87s  Val. loss: 0.1670\n",
      "Epoch 48, 100% \t Train loss: 0.1631 took: 1.89s  Val. loss: 0.1665\n",
      "Epoch 49, 100% \t Train loss: 0.1626 took: 1.90s  Val. loss: 0.1722\n",
      "Epoch 50, 100% \t Train loss: 0.1622 took: 1.91s  Val. loss: 0.1670\n",
      "Training finished, took 88.98s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.37\n",
      "\tmask_channels :  4  - prob: 0.28\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.27\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.880126\n",
      "lambda: 0.0010 - V: 0.830586\n",
      "lambda: 0.0005 - V: 0.806426\n",
      "Average V: 0.839046\n",
      "Time elapsed: 308.75 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  8  - prob: 0.37\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.18\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2589 took: 1.85s  Val. loss: 0.2590\n",
      "Epoch 2, 100% \t Train loss: 0.2578 took: 1.87s  Val. loss: 0.2638\n",
      "Epoch 3, 100% \t Train loss: 0.2308 took: 1.87s  Val. loss: 0.2074\n",
      "Epoch 4, 100% \t Train loss: 0.1988 took: 1.85s  Val. loss: 0.1973\n",
      "Epoch 5, 100% \t Train loss: 0.1939 took: 1.84s  Val. loss: 0.1943\n",
      "Epoch 6, 100% \t Train loss: 0.1922 took: 1.83s  Val. loss: 0.1895\n",
      "Epoch 7, 100% \t Train loss: 0.1896 took: 1.82s  Val. loss: 0.1909\n",
      "Epoch 8, 100% \t Train loss: 0.1870 took: 1.83s  Val. loss: 0.1867\n",
      "Epoch 9, 100% \t Train loss: 0.1861 took: 1.19s  Val. loss: 0.1918\n",
      "Epoch 10, 100% \t Train loss: 0.1856 took: 1.07s  Val. loss: 0.1900\n",
      "Epoch 11, 100% \t Train loss: 0.1835 took: 1.08s  Val. loss: 0.1877\n",
      "Epoch 12, 100% \t Train loss: 0.1828 took: 1.07s  Val. loss: 0.1851\n",
      "Epoch 13, 100% \t Train loss: 0.1821 took: 1.70s  Val. loss: 0.1908\n",
      "Epoch 14, 100% \t Train loss: 0.1807 took: 1.82s  Val. loss: 0.1840\n",
      "Epoch 15, 100% \t Train loss: 0.1781 took: 1.83s  Val. loss: 0.1824\n",
      "Epoch 16, 100% \t Train loss: 0.1738 took: 1.81s  Val. loss: 0.1780\n",
      "Epoch 17, 100% \t Train loss: 0.1668 took: 1.81s  Val. loss: 0.1680\n",
      "Epoch 18, 100% \t Train loss: 0.1608 took: 1.82s  Val. loss: 0.1588\n",
      "Epoch 19, 100% \t Train loss: 0.1551 took: 1.83s  Val. loss: 0.1506\n",
      "Epoch 20, 100% \t Train loss: 0.1486 took: 1.84s  Val. loss: 0.1470\n",
      "Epoch 21, 100% \t Train loss: 0.1432 took: 1.07s  Val. loss: 0.1501\n",
      "Epoch 22, 100% \t Train loss: 0.1409 took: 1.07s  Val. loss: 0.1414\n",
      "Epoch 23, 100% \t Train loss: 0.1383 took: 1.07s  Val. loss: 0.1471\n",
      "Epoch 24, 100% \t Train loss: 0.1366 took: 1.07s  Val. loss: 0.1404\n",
      "Epoch 25, 100% \t Train loss: 0.1331 took: 1.07s  Val. loss: 0.1407\n",
      "Epoch 26, 100% \t Train loss: 0.1314 took: 1.07s  Val. loss: 0.1370\n",
      "Epoch 27, 100% \t Train loss: 0.1301 took: 1.07s  Val. loss: 0.1398\n",
      "Epoch 28, 100% \t Train loss: 0.1292 took: 1.07s  Val. loss: 0.1321\n",
      "Epoch 29, 100% \t Train loss: 0.1278 took: 1.09s  Val. loss: 0.1354\n",
      "Epoch 30, 100% \t Train loss: 0.1264 took: 1.07s  Val. loss: 0.1320\n",
      "Epoch 31, 100% \t Train loss: 0.1253 took: 1.09s  Val. loss: 0.1343\n",
      "Epoch 32, 100% \t Train loss: 0.1250 took: 1.13s  Val. loss: 0.1324\n",
      "Epoch 33, 100% \t Train loss: 0.1241 took: 1.87s  Val. loss: 0.1322\n",
      "Epoch 34, 100% \t Train loss: 0.1231 took: 1.99s  Val. loss: 0.1314\n",
      "Epoch 35, 100% \t Train loss: 0.1227 took: 2.01s  Val. loss: 0.1317\n",
      "Epoch 36, 100% \t Train loss: 0.1224 took: 2.01s  Val. loss: 0.1321\n",
      "Epoch 37, 100% \t Train loss: 0.1222 took: 2.01s  Val. loss: 0.1307\n",
      "Epoch 38, 100% \t Train loss: 0.1212 took: 2.02s  Val. loss: 0.1311\n",
      "Epoch 39, 100% \t Train loss: 0.1213 took: 2.03s  Val. loss: 0.1319\n",
      "Epoch 40, 100% \t Train loss: 0.1211 took: 2.02s  Val. loss: 0.1308\n",
      "Epoch 41, 100% \t Train loss: 0.1210 took: 2.03s  Val. loss: 0.1313\n",
      "Epoch 42, 100% \t Train loss: 0.1194 took: 2.02s  Val. loss: 0.1298\n",
      "Epoch 43, 100% \t Train loss: 0.1209 took: 2.02s  Val. loss: 0.1317\n",
      "Epoch 44, 100% \t Train loss: 0.1191 took: 2.02s  Val. loss: 0.1338\n",
      "Epoch 45, 100% \t Train loss: 0.1187 took: 2.02s  Val. loss: 0.1299\n",
      "Epoch 46, 100% \t Train loss: 0.1190 took: 2.01s  Val. loss: 0.1305\n",
      "Epoch 47, 100% \t Train loss: 0.1192 took: 2.01s  Val. loss: 0.1310\n",
      "Epoch 48, 100% \t Train loss: 0.1180 took: 2.03s  Val. loss: 0.1274\n",
      "Epoch 49, 100% \t Train loss: 0.1175 took: 2.02s  Val. loss: 0.1313\n",
      "Epoch 50, 100% \t Train loss: 0.1190 took: 2.03s  Val. loss: 0.1313\n",
      "Training finished, took 94.02s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2589 took: 1.81s  Val. loss: 0.2613\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.82s  Val. loss: 0.2606\n",
      "Epoch 3, 100% \t Train loss: 0.2574 took: 1.81s  Val. loss: 0.2588\n",
      "Epoch 4, 100% \t Train loss: 0.2524 took: 1.81s  Val. loss: 0.2480\n",
      "Epoch 5, 100% \t Train loss: 0.2323 took: 1.81s  Val. loss: 0.2230\n",
      "Epoch 6, 100% \t Train loss: 0.2089 took: 1.81s  Val. loss: 0.2133\n",
      "Epoch 7, 100% \t Train loss: 0.1991 took: 1.06s  Val. loss: 0.2066\n",
      "Epoch 8, 100% \t Train loss: 0.1944 took: 1.06s  Val. loss: 0.2059\n",
      "Epoch 9, 100% \t Train loss: 0.1948 took: 1.06s  Val. loss: 0.2078\n",
      "Epoch 10, 100% \t Train loss: 0.1930 took: 1.06s  Val. loss: 0.2041\n",
      "Epoch 11, 100% \t Train loss: 0.1909 took: 1.07s  Val. loss: 0.2026\n",
      "Epoch 12, 100% \t Train loss: 0.1907 took: 1.06s  Val. loss: 0.2016\n",
      "Epoch 13, 100% \t Train loss: 0.1900 took: 1.07s  Val. loss: 0.2075\n",
      "Epoch 14, 100% \t Train loss: 0.1910 took: 1.07s  Val. loss: 0.2042\n",
      "Epoch 15, 100% \t Train loss: 0.1879 took: 1.07s  Val. loss: 0.2056\n",
      "Epoch 16, 100% \t Train loss: 0.1880 took: 1.07s  Val. loss: 0.2036\n",
      "Epoch 17, 100% \t Train loss: 0.1893 took: 1.07s  Val. loss: 0.2012\n",
      "Epoch 18, 100% \t Train loss: 0.1877 took: 1.07s  Val. loss: 0.2016\n",
      "Epoch 19, 100% \t Train loss: 0.1883 took: 1.07s  Val. loss: 0.2041\n",
      "Epoch 20, 100% \t Train loss: 0.1860 took: 1.06s  Val. loss: 0.1988\n",
      "Epoch 21, 100% \t Train loss: 0.1862 took: 1.06s  Val. loss: 0.1977\n",
      "Epoch 22, 100% \t Train loss: 0.1868 took: 1.06s  Val. loss: 0.1969\n",
      "Epoch 23, 100% \t Train loss: 0.1858 took: 1.07s  Val. loss: 0.2010\n",
      "Epoch 24, 100% \t Train loss: 0.1853 took: 1.06s  Val. loss: 0.1968\n",
      "Epoch 25, 100% \t Train loss: 0.1847 took: 1.07s  Val. loss: 0.1976\n",
      "Epoch 26, 100% \t Train loss: 0.1864 took: 1.07s  Val. loss: 0.1978\n",
      "Epoch 27, 100% \t Train loss: 0.1843 took: 1.06s  Val. loss: 0.1976\n",
      "Epoch 28, 100% \t Train loss: 0.1848 took: 1.08s  Val. loss: 0.1963\n",
      "Epoch 29, 100% \t Train loss: 0.1843 took: 1.10s  Val. loss: 0.2023\n",
      "Epoch 30, 100% \t Train loss: 0.1836 took: 1.11s  Val. loss: 0.1975\n",
      "Epoch 31, 100% \t Train loss: 0.1831 took: 1.86s  Val. loss: 0.1963\n",
      "Epoch 32, 100% \t Train loss: 0.1833 took: 1.87s  Val. loss: 0.2043\n",
      "Epoch 33, 100% \t Train loss: 0.1833 took: 1.56s  Val. loss: 0.2044\n",
      "Epoch 34, 100% \t Train loss: 0.1824 took: 1.13s  Val. loss: 0.2064\n",
      "Epoch 35, 100% \t Train loss: 0.1826 took: 1.13s  Val. loss: 0.1983\n",
      "Epoch 36, 100% \t Train loss: 0.1817 took: 1.13s  Val. loss: 0.2023\n",
      "Epoch 37, 100% \t Train loss: 0.1822 took: 1.14s  Val. loss: 0.1950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, 100% \t Train loss: 0.1810 took: 1.15s  Val. loss: 0.1953\n",
      "Epoch 39, 100% \t Train loss: 0.1804 took: 1.16s  Val. loss: 0.1965\n",
      "Epoch 40, 100% \t Train loss: 0.1813 took: 1.17s  Val. loss: 0.2048\n",
      "Epoch 41, 100% \t Train loss: 0.1807 took: 1.17s  Val. loss: 0.1970\n",
      "Epoch 42, 100% \t Train loss: 0.1805 took: 1.17s  Val. loss: 0.1975\n",
      "Epoch 43, 100% \t Train loss: 0.1805 took: 1.18s  Val. loss: 0.1983\n",
      "Epoch 44, 100% \t Train loss: 0.1794 took: 1.17s  Val. loss: 0.1977\n",
      "Epoch 45, 100% \t Train loss: 0.1800 took: 1.18s  Val. loss: 0.2001\n",
      "Epoch 46, 100% \t Train loss: 0.1797 took: 1.18s  Val. loss: 0.2015\n",
      "Epoch 47, 100% \t Train loss: 0.1792 took: 1.19s  Val. loss: 0.1939\n",
      "Epoch 48, 100% \t Train loss: 0.1791 took: 1.19s  Val. loss: 0.1943\n",
      "Epoch 49, 100% \t Train loss: 0.1778 took: 1.18s  Val. loss: 0.1944\n",
      "Epoch 50, 100% \t Train loss: 0.1776 took: 1.11s  Val. loss: 0.1951\n",
      "Training finished, took 69.57s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 1.85s  Val. loss: 0.2599\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.83s  Val. loss: 0.2603\n",
      "Epoch 3, 100% \t Train loss: 0.2583 took: 1.82s  Val. loss: 0.2608\n",
      "Epoch 4, 100% \t Train loss: 0.2583 took: 1.81s  Val. loss: 0.2604\n",
      "Epoch 5, 100% \t Train loss: 0.2583 took: 1.84s  Val. loss: 0.2614\n",
      "Epoch 6, 100% \t Train loss: 0.2583 took: 1.82s  Val. loss: 0.2598\n",
      "Epoch 7, 100% \t Train loss: 0.2582 took: 1.84s  Val. loss: 0.2600\n",
      "Epoch 8, 100% \t Train loss: 0.2580 took: 1.82s  Val. loss: 0.2601\n",
      "Epoch 9, 100% \t Train loss: 0.2572 took: 1.82s  Val. loss: 0.2586\n",
      "Epoch 10, 100% \t Train loss: 0.2547 took: 1.83s  Val. loss: 0.2548\n",
      "Epoch 11, 100% \t Train loss: 0.2466 took: 1.83s  Val. loss: 0.2436\n",
      "Epoch 12, 100% \t Train loss: 0.2287 took: 1.82s  Val. loss: 0.2265\n",
      "Epoch 13, 100% \t Train loss: 0.2121 took: 1.82s  Val. loss: 0.2151\n",
      "Epoch 14, 100% \t Train loss: 0.2029 took: 1.82s  Val. loss: 0.2095\n",
      "Epoch 15, 100% \t Train loss: 0.1969 took: 1.82s  Val. loss: 0.2055\n",
      "Epoch 16, 100% \t Train loss: 0.1934 took: 1.81s  Val. loss: 0.2015\n",
      "Epoch 17, 100% \t Train loss: 0.1911 took: 1.83s  Val. loss: 0.2004\n",
      "Epoch 18, 100% \t Train loss: 0.1895 took: 1.81s  Val. loss: 0.1978\n",
      "Epoch 19, 100% \t Train loss: 0.1881 took: 1.82s  Val. loss: 0.1969\n",
      "Epoch 20, 100% \t Train loss: 0.1879 took: 1.82s  Val. loss: 0.1990\n",
      "Epoch 21, 100% \t Train loss: 0.1866 took: 1.82s  Val. loss: 0.1951\n",
      "Epoch 22, 100% \t Train loss: 0.1856 took: 1.82s  Val. loss: 0.1944\n",
      "Epoch 23, 100% \t Train loss: 0.1853 took: 1.81s  Val. loss: 0.1964\n",
      "Epoch 24, 100% \t Train loss: 0.1847 took: 1.85s  Val. loss: 0.1954\n",
      "Epoch 25, 100% \t Train loss: 0.1840 took: 1.84s  Val. loss: 0.1938\n",
      "Epoch 26, 100% \t Train loss: 0.1836 took: 1.85s  Val. loss: 0.1944\n",
      "Epoch 27, 100% \t Train loss: 0.1834 took: 1.86s  Val. loss: 0.1939\n",
      "Epoch 28, 100% \t Train loss: 0.1825 took: 1.84s  Val. loss: 0.1943\n",
      "Epoch 29, 100% \t Train loss: 0.1825 took: 1.84s  Val. loss: 0.1948\n",
      "Epoch 30, 100% \t Train loss: 0.1822 took: 1.86s  Val. loss: 0.1935\n",
      "Epoch 31, 100% \t Train loss: 0.1818 took: 1.84s  Val. loss: 0.1950\n",
      "Epoch 32, 100% \t Train loss: 0.1813 took: 1.85s  Val. loss: 0.1941\n",
      "Epoch 33, 100% \t Train loss: 0.1816 took: 1.84s  Val. loss: 0.1940\n",
      "Epoch 34, 100% \t Train loss: 0.1818 took: 1.85s  Val. loss: 0.1964\n",
      "Epoch 35, 100% \t Train loss: 0.1806 took: 1.83s  Val. loss: 0.1934\n",
      "Epoch 36, 100% \t Train loss: 0.1806 took: 1.82s  Val. loss: 0.1948\n",
      "Epoch 37, 100% \t Train loss: 0.1803 took: 1.82s  Val. loss: 0.1920\n",
      "Epoch 38, 100% \t Train loss: 0.1799 took: 1.83s  Val. loss: 0.1935\n",
      "Epoch 39, 100% \t Train loss: 0.1798 took: 1.84s  Val. loss: 0.1921\n",
      "Epoch 40, 100% \t Train loss: 0.1796 took: 1.83s  Val. loss: 0.1929\n",
      "Epoch 41, 100% \t Train loss: 0.1791 took: 1.83s  Val. loss: 0.1923\n",
      "Epoch 42, 100% \t Train loss: 0.1791 took: 1.85s  Val. loss: 0.1928\n",
      "Epoch 43, 100% \t Train loss: 0.1788 took: 1.82s  Val. loss: 0.1927\n",
      "Epoch 44, 100% \t Train loss: 0.1785 took: 1.85s  Val. loss: 0.1928\n",
      "Epoch 45, 100% \t Train loss: 0.1789 took: 1.83s  Val. loss: 0.1930\n",
      "Epoch 46, 100% \t Train loss: 0.1783 took: 1.84s  Val. loss: 0.1917\n",
      "Epoch 47, 100% \t Train loss: 0.1792 took: 1.86s  Val. loss: 0.1946\n",
      "Epoch 48, 100% \t Train loss: 0.1781 took: 1.84s  Val. loss: 0.1932\n",
      "Epoch 49, 100% \t Train loss: 0.1780 took: 1.84s  Val. loss: 0.1929\n",
      "Epoch 50, 100% \t Train loss: 0.1776 took: 1.84s  Val. loss: 0.1931\n",
      "Training finished, took 104.44s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  8  - prob: 0.37\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.18\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.843487\n",
      "lambda: 0.0010 - V: 0.794492\n",
      "lambda: 0.0005 - V: 0.789897\n",
      "Average V: 0.809292\n",
      "Time elapsed: 271.51 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.36\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.33\n",
      "\tmask_channels :  4  - prob: 0.29\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.27\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 1.82s  Val. loss: 0.2556\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.80s  Val. loss: 0.2563\n",
      "Epoch 3, 100% \t Train loss: 0.2575 took: 1.81s  Val. loss: 0.2552\n",
      "Epoch 4, 100% \t Train loss: 0.2574 took: 1.81s  Val. loss: 0.2561\n",
      "Epoch 5, 100% \t Train loss: 0.2486 took: 1.81s  Val. loss: 0.2345\n",
      "Epoch 6, 100% \t Train loss: 0.1932 took: 1.84s  Val. loss: 0.1819\n",
      "Epoch 7, 100% \t Train loss: 0.1671 took: 1.84s  Val. loss: 0.1682\n",
      "Epoch 8, 100% \t Train loss: 0.1636 took: 1.83s  Val. loss: 0.1696\n",
      "Epoch 9, 100% \t Train loss: 0.1597 took: 1.82s  Val. loss: 0.1655\n",
      "Epoch 10, 100% \t Train loss: 0.1591 took: 1.82s  Val. loss: 0.1680\n",
      "Epoch 11, 100% \t Train loss: 0.1556 took: 1.83s  Val. loss: 0.1634\n",
      "Epoch 12, 100% \t Train loss: 0.1557 took: 1.83s  Val. loss: 0.1628\n",
      "Epoch 13, 100% \t Train loss: 0.1523 took: 1.82s  Val. loss: 0.1615\n",
      "Epoch 14, 100% \t Train loss: 0.1494 took: 1.81s  Val. loss: 0.1620\n",
      "Epoch 15, 100% \t Train loss: 0.1478 took: 1.81s  Val. loss: 0.1600\n",
      "Epoch 16, 100% \t Train loss: 0.1440 took: 1.83s  Val. loss: 0.1526\n",
      "Epoch 17, 100% \t Train loss: 0.1387 took: 1.81s  Val. loss: 0.1527\n",
      "Epoch 18, 100% \t Train loss: 0.1329 took: 1.81s  Val. loss: 0.1429\n",
      "Epoch 19, 100% \t Train loss: 0.1264 took: 1.81s  Val. loss: 0.1449\n",
      "Epoch 20, 100% \t Train loss: 0.1189 took: 1.81s  Val. loss: 0.1284\n",
      "Epoch 21, 100% \t Train loss: 0.1098 took: 1.81s  Val. loss: 0.1172\n",
      "Epoch 22, 100% \t Train loss: 0.1026 took: 1.80s  Val. loss: 0.1148\n",
      "Epoch 23, 100% \t Train loss: 0.0957 took: 1.81s  Val. loss: 0.1046\n",
      "Epoch 24, 100% \t Train loss: 0.0900 took: 1.81s  Val. loss: 0.1072\n",
      "Epoch 25, 100% \t Train loss: 0.0875 took: 1.80s  Val. loss: 0.0973\n",
      "Epoch 26, 100% \t Train loss: 0.0841 took: 1.80s  Val. loss: 0.0983\n",
      "Epoch 27, 100% \t Train loss: 0.0833 took: 1.81s  Val. loss: 0.0941\n",
      "Epoch 28, 100% \t Train loss: 0.0794 took: 1.83s  Val. loss: 0.0903\n",
      "Epoch 29, 100% \t Train loss: 0.0792 took: 1.85s  Val. loss: 0.0941\n",
      "Epoch 30, 100% \t Train loss: 0.0776 took: 1.89s  Val. loss: 0.0895\n",
      "Epoch 31, 100% \t Train loss: 0.0757 took: 1.90s  Val. loss: 0.0887\n",
      "Epoch 32, 100% \t Train loss: 0.0764 took: 2.03s  Val. loss: 0.0916\n",
      "Epoch 33, 100% \t Train loss: 0.0758 took: 2.11s  Val. loss: 0.0913\n",
      "Epoch 34, 100% \t Train loss: 0.0739 took: 2.12s  Val. loss: 0.0908\n",
      "Epoch 35, 100% \t Train loss: 0.0737 took: 2.12s  Val. loss: 0.0918\n",
      "Epoch 36, 100% \t Train loss: 0.0746 took: 2.11s  Val. loss: 0.0911\n",
      "Epoch 37, 100% \t Train loss: 0.0734 took: 2.10s  Val. loss: 0.0898\n",
      "Epoch 38, 100% \t Train loss: 0.0717 took: 2.11s  Val. loss: 0.0921\n",
      "Epoch 39, 100% \t Train loss: 0.0716 took: 2.12s  Val. loss: 0.0902\n",
      "Epoch 40, 100% \t Train loss: 0.0719 took: 2.10s  Val. loss: 0.0877\n",
      "Epoch 41, 100% \t Train loss: 0.0721 took: 2.11s  Val. loss: 0.0928\n",
      "Epoch 42, 100% \t Train loss: 0.0716 took: 2.11s  Val. loss: 0.0901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, 100% \t Train loss: 0.0709 took: 2.09s  Val. loss: 0.0912\n",
      "Epoch 44, 100% \t Train loss: 0.0702 took: 2.09s  Val. loss: 0.0902\n",
      "Epoch 45, 100% \t Train loss: 0.0691 took: 2.09s  Val. loss: 0.0898\n",
      "Epoch 46, 100% \t Train loss: 0.0693 took: 2.10s  Val. loss: 0.0913\n",
      "Epoch 47, 100% \t Train loss: 0.0699 took: 2.11s  Val. loss: 0.0907\n",
      "Epoch 48, 100% \t Train loss: 0.0679 took: 2.11s  Val. loss: 0.0926\n",
      "Epoch 49, 100% \t Train loss: 0.0677 took: 2.09s  Val. loss: 0.0891\n",
      "Epoch 50, 100% \t Train loss: 0.0669 took: 2.12s  Val. loss: 0.0914\n",
      "Training finished, took 109.54s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2578 took: 1.80s  Val. loss: 0.2572\n",
      "Epoch 2, 100% \t Train loss: 0.2569 took: 1.78s  Val. loss: 0.2558\n",
      "Epoch 3, 100% \t Train loss: 0.2450 took: 1.81s  Val. loss: 0.2193\n",
      "Epoch 4, 100% \t Train loss: 0.1934 took: 1.79s  Val. loss: 0.1800\n",
      "Epoch 5, 100% \t Train loss: 0.1763 took: 1.79s  Val. loss: 0.1729\n",
      "Epoch 6, 100% \t Train loss: 0.1722 took: 1.79s  Val. loss: 0.1686\n",
      "Epoch 7, 100% \t Train loss: 0.1677 took: 1.79s  Val. loss: 0.1657\n",
      "Epoch 8, 100% \t Train loss: 0.1649 took: 1.81s  Val. loss: 0.1602\n",
      "Epoch 9, 100% \t Train loss: 0.1610 took: 1.80s  Val. loss: 0.1642\n",
      "Epoch 10, 100% \t Train loss: 0.1594 took: 1.79s  Val. loss: 0.1596\n",
      "Epoch 11, 100% \t Train loss: 0.1597 took: 1.80s  Val. loss: 0.1596\n",
      "Epoch 12, 100% \t Train loss: 0.1581 took: 1.80s  Val. loss: 0.1568\n",
      "Epoch 13, 100% \t Train loss: 0.1550 took: 1.80s  Val. loss: 0.1642\n",
      "Epoch 14, 100% \t Train loss: 0.1576 took: 1.79s  Val. loss: 0.1579\n",
      "Epoch 15, 100% \t Train loss: 0.1545 took: 1.81s  Val. loss: 0.1611\n",
      "Epoch 16, 100% \t Train loss: 0.1527 took: 1.79s  Val. loss: 0.1564\n",
      "Epoch 17, 100% \t Train loss: 0.1517 took: 1.80s  Val. loss: 0.1558\n",
      "Epoch 18, 100% \t Train loss: 0.1515 took: 1.79s  Val. loss: 0.1555\n",
      "Epoch 19, 100% \t Train loss: 0.1508 took: 1.80s  Val. loss: 0.1560\n",
      "Epoch 20, 100% \t Train loss: 0.1498 took: 1.80s  Val. loss: 0.1604\n",
      "Epoch 21, 100% \t Train loss: 0.1493 took: 1.80s  Val. loss: 0.1598\n",
      "Epoch 22, 100% \t Train loss: 0.1490 took: 1.79s  Val. loss: 0.1560\n",
      "Epoch 23, 100% \t Train loss: 0.1477 took: 1.78s  Val. loss: 0.1562\n",
      "Epoch 24, 100% \t Train loss: 0.1469 took: 1.78s  Val. loss: 0.1552\n",
      "Epoch 25, 100% \t Train loss: 0.1462 took: 1.78s  Val. loss: 0.1554\n",
      "Epoch 26, 100% \t Train loss: 0.1446 took: 1.78s  Val. loss: 0.1555\n",
      "Epoch 27, 100% \t Train loss: 0.1444 took: 1.80s  Val. loss: 0.1597\n",
      "Epoch 28, 100% \t Train loss: 0.1438 took: 1.80s  Val. loss: 0.1555\n",
      "Epoch 29, 100% \t Train loss: 0.1435 took: 1.80s  Val. loss: 0.1543\n",
      "Epoch 30, 100% \t Train loss: 0.1410 took: 1.05s  Val. loss: 0.1510\n",
      "Epoch 31, 100% \t Train loss: 0.1407 took: 1.06s  Val. loss: 0.1501\n",
      "Epoch 32, 100% \t Train loss: 0.1393 took: 1.08s  Val. loss: 0.1490\n",
      "Epoch 33, 100% \t Train loss: 0.1382 took: 1.09s  Val. loss: 0.1464\n",
      "Epoch 34, 100% \t Train loss: 0.1365 took: 1.10s  Val. loss: 0.1460\n",
      "Epoch 35, 100% \t Train loss: 0.1342 took: 1.10s  Val. loss: 0.1443\n",
      "Epoch 36, 100% \t Train loss: 0.1321 took: 1.10s  Val. loss: 0.1409\n",
      "Epoch 37, 100% \t Train loss: 0.1294 took: 1.09s  Val. loss: 0.1371\n",
      "Epoch 38, 100% \t Train loss: 0.1269 took: 1.09s  Val. loss: 0.1386\n",
      "Epoch 39, 100% \t Train loss: 0.1256 took: 1.10s  Val. loss: 0.1404\n",
      "Epoch 40, 100% \t Train loss: 0.1220 took: 1.10s  Val. loss: 0.1323\n",
      "Epoch 41, 100% \t Train loss: 0.1185 took: 1.10s  Val. loss: 0.1308\n",
      "Epoch 42, 100% \t Train loss: 0.1161 took: 1.10s  Val. loss: 0.1249\n",
      "Epoch 43, 100% \t Train loss: 0.1125 took: 1.10s  Val. loss: 0.1225\n",
      "Epoch 44, 100% \t Train loss: 0.1093 took: 1.10s  Val. loss: 0.1204\n",
      "Epoch 45, 100% \t Train loss: 0.1074 took: 1.09s  Val. loss: 0.1158\n",
      "Epoch 46, 100% \t Train loss: 0.1037 took: 1.10s  Val. loss: 0.1146\n",
      "Epoch 47, 100% \t Train loss: 0.1014 took: 1.11s  Val. loss: 0.1083\n",
      "Epoch 48, 100% \t Train loss: 0.0981 took: 1.11s  Val. loss: 0.1104\n",
      "Epoch 49, 100% \t Train loss: 0.0960 took: 1.11s  Val. loss: 0.1022\n",
      "Epoch 50, 100% \t Train loss: 0.0950 took: 1.11s  Val. loss: 0.1050\n",
      "Training finished, took 85.19s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2620 took: 1.77s  Val. loss: 0.2624\n",
      "Epoch 2, 100% \t Train loss: 0.2619 took: 1.79s  Val. loss: 0.2630\n",
      "Epoch 3, 100% \t Train loss: 0.2617 took: 1.80s  Val. loss: 0.2625\n",
      "Epoch 4, 100% \t Train loss: 0.2617 took: 1.78s  Val. loss: 0.2628\n",
      "Epoch 5, 100% \t Train loss: 0.2614 took: 1.78s  Val. loss: 0.2628\n",
      "Epoch 6, 100% \t Train loss: 0.2606 took: 1.78s  Val. loss: 0.2602\n",
      "Epoch 7, 100% \t Train loss: 0.2542 took: 1.80s  Val. loss: 0.2442\n",
      "Epoch 8, 100% \t Train loss: 0.2218 took: 1.31s  Val. loss: 0.2002\n",
      "Epoch 9, 100% \t Train loss: 0.1895 took: 1.04s  Val. loss: 0.1849\n",
      "Epoch 10, 100% \t Train loss: 0.1782 took: 1.04s  Val. loss: 0.1839\n",
      "Epoch 11, 100% \t Train loss: 0.1744 took: 1.03s  Val. loss: 0.1788\n",
      "Epoch 12, 100% \t Train loss: 0.1720 took: 1.04s  Val. loss: 0.1729\n",
      "Epoch 13, 100% \t Train loss: 0.1708 took: 1.04s  Val. loss: 0.1751\n",
      "Epoch 14, 100% \t Train loss: 0.1682 took: 1.04s  Val. loss: 0.1698\n",
      "Epoch 15, 100% \t Train loss: 0.1687 took: 1.04s  Val. loss: 0.1691\n",
      "Epoch 16, 100% \t Train loss: 0.1645 took: 1.04s  Val. loss: 0.1751\n",
      "Epoch 17, 100% \t Train loss: 0.1635 took: 1.03s  Val. loss: 0.1721\n",
      "Epoch 18, 100% \t Train loss: 0.1643 took: 1.02s  Val. loss: 0.1668\n",
      "Epoch 19, 100% \t Train loss: 0.1625 took: 1.04s  Val. loss: 0.1668\n",
      "Epoch 20, 100% \t Train loss: 0.1619 took: 1.03s  Val. loss: 0.1742\n",
      "Epoch 21, 100% \t Train loss: 0.1614 took: 1.04s  Val. loss: 0.1759\n",
      "Epoch 22, 100% \t Train loss: 0.1632 took: 1.03s  Val. loss: 0.1769\n",
      "Epoch 23, 100% \t Train loss: 0.1601 took: 1.08s  Val. loss: 0.1686\n",
      "Epoch 24, 100% \t Train loss: 0.1593 took: 1.03s  Val. loss: 0.1657\n",
      "Epoch 25, 100% \t Train loss: 0.1566 took: 1.04s  Val. loss: 0.1629\n",
      "Epoch 26, 100% \t Train loss: 0.1564 took: 1.04s  Val. loss: 0.1652\n",
      "Epoch 27, 100% \t Train loss: 0.1562 took: 1.04s  Val. loss: 0.1672\n",
      "Epoch 28, 100% \t Train loss: 0.1569 took: 1.04s  Val. loss: 0.1641\n",
      "Epoch 29, 100% \t Train loss: 0.1559 took: 1.04s  Val. loss: 0.1625\n",
      "Epoch 30, 100% \t Train loss: 0.1563 took: 1.06s  Val. loss: 0.1644\n",
      "Epoch 31, 100% \t Train loss: 0.1558 took: 1.07s  Val. loss: 0.1624\n",
      "Epoch 32, 100% \t Train loss: 0.1539 took: 1.08s  Val. loss: 0.1647\n",
      "Epoch 33, 100% \t Train loss: 0.1547 took: 1.08s  Val. loss: 0.1630\n",
      "Epoch 34, 100% \t Train loss: 0.1529 took: 1.08s  Val. loss: 0.1606\n",
      "Epoch 35, 100% \t Train loss: 0.1540 took: 1.08s  Val. loss: 0.1608\n",
      "Epoch 36, 100% \t Train loss: 0.1521 took: 1.09s  Val. loss: 0.1606\n",
      "Epoch 37, 100% \t Train loss: 0.1526 took: 1.09s  Val. loss: 0.1625\n",
      "Epoch 38, 100% \t Train loss: 0.1522 took: 1.10s  Val. loss: 0.1647\n",
      "Epoch 39, 100% \t Train loss: 0.1518 took: 1.09s  Val. loss: 0.1660\n",
      "Epoch 40, 100% \t Train loss: 0.1507 took: 1.09s  Val. loss: 0.1607\n",
      "Epoch 41, 100% \t Train loss: 0.1507 took: 1.09s  Val. loss: 0.1616\n",
      "Epoch 42, 100% \t Train loss: 0.1511 took: 1.10s  Val. loss: 0.1642\n",
      "Epoch 43, 100% \t Train loss: 0.1502 took: 1.07s  Val. loss: 0.1620\n",
      "Epoch 44, 100% \t Train loss: 0.1500 took: 1.05s  Val. loss: 0.1606\n",
      "Epoch 45, 100% \t Train loss: 0.1502 took: 1.04s  Val. loss: 0.1671\n",
      "Epoch 46, 100% \t Train loss: 0.1491 took: 1.05s  Val. loss: 0.1587\n",
      "Epoch 47, 100% \t Train loss: 0.1485 took: 1.04s  Val. loss: 0.1591\n",
      "Epoch 48, 100% \t Train loss: 0.1483 took: 1.04s  Val. loss: 0.1600\n",
      "Epoch 49, 100% \t Train loss: 0.1480 took: 1.07s  Val. loss: 0.1608\n",
      "Epoch 50, 100% \t Train loss: 0.1483 took: 1.04s  Val. loss: 0.1599\n",
      "Training finished, took 65.59s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.36\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.33\n",
      "\tmask_channels :  4  - prob: 0.29\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.27\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.870717\n",
      "lambda: 0.0010 - V: 0.847483\n",
      "lambda: 0.0005 - V: 0.819577\n",
      "Average V: 0.845926\n",
      "Time elapsed: 263.71 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.19\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2582 took: 1.75s  Val. loss: 0.2481\n",
      "Epoch 2, 100% \t Train loss: 0.1945 took: 1.73s  Val. loss: 0.1669\n",
      "Epoch 3, 100% \t Train loss: 0.1693 took: 1.60s  Val. loss: 0.1662\n",
      "Epoch 4, 100% \t Train loss: 0.1654 took: 1.00s  Val. loss: 0.1601\n",
      "Epoch 5, 100% \t Train loss: 0.1627 took: 1.00s  Val. loss: 0.1643\n",
      "Epoch 6, 100% \t Train loss: 0.1596 took: 1.00s  Val. loss: 0.1596\n",
      "Epoch 7, 100% \t Train loss: 0.1567 took: 1.00s  Val. loss: 0.1593\n",
      "Epoch 8, 100% \t Train loss: 0.1553 took: 1.00s  Val. loss: 0.1631\n",
      "Epoch 9, 100% \t Train loss: 0.1526 took: 1.01s  Val. loss: 0.1528\n",
      "Epoch 10, 100% \t Train loss: 0.1513 took: 1.00s  Val. loss: 0.1543\n",
      "Epoch 11, 100% \t Train loss: 0.1485 took: 1.00s  Val. loss: 0.1522\n",
      "Epoch 12, 100% \t Train loss: 0.1468 took: 1.00s  Val. loss: 0.1530\n",
      "Epoch 13, 100% \t Train loss: 0.1443 took: 1.00s  Val. loss: 0.1516\n",
      "Epoch 14, 100% \t Train loss: 0.1416 took: 1.00s  Val. loss: 0.1494\n",
      "Epoch 15, 100% \t Train loss: 0.1370 took: 1.00s  Val. loss: 0.1499\n",
      "Epoch 16, 100% \t Train loss: 0.1324 took: 1.01s  Val. loss: 0.1423\n",
      "Epoch 17, 100% \t Train loss: 0.1269 took: 1.00s  Val. loss: 0.1401\n",
      "Epoch 18, 100% \t Train loss: 0.1215 took: 1.00s  Val. loss: 0.1335\n",
      "Epoch 19, 100% \t Train loss: 0.1176 took: 1.00s  Val. loss: 0.1295\n",
      "Epoch 20, 100% \t Train loss: 0.1115 took: 1.00s  Val. loss: 0.1226\n",
      "Epoch 21, 100% \t Train loss: 0.1077 took: 1.00s  Val. loss: 0.1181\n",
      "Epoch 22, 100% \t Train loss: 0.1016 took: 1.73s  Val. loss: 0.1095\n",
      "Epoch 23, 100% \t Train loss: 0.0972 took: 1.72s  Val. loss: 0.1050\n",
      "Epoch 24, 100% \t Train loss: 0.0933 took: 1.73s  Val. loss: 0.1009\n",
      "Epoch 25, 100% \t Train loss: 0.0909 took: 1.74s  Val. loss: 0.1010\n",
      "Epoch 26, 100% \t Train loss: 0.0885 took: 1.72s  Val. loss: 0.0952\n",
      "Epoch 27, 100% \t Train loss: 0.0860 took: 1.74s  Val. loss: 0.0944\n",
      "Epoch 28, 100% \t Train loss: 0.0856 took: 1.75s  Val. loss: 0.0940\n",
      "Epoch 29, 100% \t Train loss: 0.0834 took: 1.78s  Val. loss: 0.0940\n",
      "Epoch 30, 100% \t Train loss: 0.0835 took: 1.77s  Val. loss: 0.0936\n",
      "Epoch 31, 100% \t Train loss: 0.0829 took: 1.79s  Val. loss: 0.0933\n",
      "Epoch 32, 100% \t Train loss: 0.0810 took: 1.88s  Val. loss: 0.0897\n",
      "Epoch 33, 100% \t Train loss: 0.0798 took: 2.02s  Val. loss: 0.0913\n",
      "Epoch 34, 100% \t Train loss: 0.0797 took: 1.92s  Val. loss: 0.0921\n",
      "Epoch 35, 100% \t Train loss: 0.0786 took: 1.93s  Val. loss: 0.0921\n",
      "Epoch 36, 100% \t Train loss: 0.0788 took: 1.97s  Val. loss: 0.0892\n",
      "Epoch 37, 100% \t Train loss: 0.0787 took: 1.95s  Val. loss: 0.0878\n",
      "Epoch 38, 100% \t Train loss: 0.0783 took: 1.95s  Val. loss: 0.0890\n",
      "Epoch 39, 100% \t Train loss: 0.0771 took: 1.94s  Val. loss: 0.0910\n",
      "Epoch 40, 100% \t Train loss: 0.0768 took: 1.93s  Val. loss: 0.0917\n",
      "Epoch 41, 100% \t Train loss: 0.0762 took: 1.93s  Val. loss: 0.0869\n",
      "Epoch 42, 100% \t Train loss: 0.0755 took: 1.88s  Val. loss: 0.0896\n",
      "Epoch 43, 100% \t Train loss: 0.0749 took: 1.75s  Val. loss: 0.0870\n",
      "Epoch 44, 100% \t Train loss: 0.0754 took: 1.74s  Val. loss: 0.0877\n",
      "Epoch 45, 100% \t Train loss: 0.0741 took: 1.75s  Val. loss: 0.0855\n",
      "Epoch 46, 100% \t Train loss: 0.0751 took: 1.74s  Val. loss: 0.0886\n",
      "Epoch 47, 100% \t Train loss: 0.0742 took: 1.73s  Val. loss: 0.0873\n",
      "Epoch 48, 100% \t Train loss: 0.0742 took: 1.73s  Val. loss: 0.0889\n",
      "Epoch 49, 100% \t Train loss: 0.0744 took: 1.73s  Val. loss: 0.0871\n",
      "Epoch 50, 100% \t Train loss: 0.0732 took: 1.75s  Val. loss: 0.0837\n",
      "Training finished, took 86.36s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2589 took: 1.75s  Val. loss: 0.2658\n",
      "Epoch 2, 100% \t Train loss: 0.2587 took: 1.73s  Val. loss: 0.2654\n",
      "Epoch 3, 100% \t Train loss: 0.2586 took: 1.10s  Val. loss: 0.2654\n",
      "Epoch 4, 100% \t Train loss: 0.2586 took: 1.01s  Val. loss: 0.2654\n",
      "Epoch 5, 100% \t Train loss: 0.2586 took: 1.00s  Val. loss: 0.2640\n",
      "Epoch 6, 100% \t Train loss: 0.2586 took: 1.00s  Val. loss: 0.2647\n",
      "Epoch 7, 100% \t Train loss: 0.2585 took: 1.00s  Val. loss: 0.2662\n",
      "Epoch 8, 100% \t Train loss: 0.2583 took: 1.00s  Val. loss: 0.2647\n",
      "Epoch 9, 100% \t Train loss: 0.2578 took: 1.00s  Val. loss: 0.2630\n",
      "Epoch 10, 100% \t Train loss: 0.2546 took: 1.00s  Val. loss: 0.2574\n",
      "Epoch 11, 100% \t Train loss: 0.2324 took: 1.00s  Val. loss: 0.2235\n",
      "Epoch 12, 100% \t Train loss: 0.1992 took: 1.00s  Val. loss: 0.2000\n",
      "Epoch 13, 100% \t Train loss: 0.1816 took: 1.00s  Val. loss: 0.1911\n",
      "Epoch 14, 100% \t Train loss: 0.1753 took: 1.00s  Val. loss: 0.1865\n",
      "Epoch 15, 100% \t Train loss: 0.1736 took: 1.00s  Val. loss: 0.1819\n",
      "Epoch 16, 100% \t Train loss: 0.1703 took: 1.00s  Val. loss: 0.1790\n",
      "Epoch 17, 100% \t Train loss: 0.1677 took: 1.00s  Val. loss: 0.1844\n",
      "Epoch 18, 100% \t Train loss: 0.1673 took: 1.00s  Val. loss: 0.1774\n",
      "Epoch 19, 100% \t Train loss: 0.1659 took: 1.00s  Val. loss: 0.1760\n",
      "Epoch 20, 100% \t Train loss: 0.1625 took: 1.00s  Val. loss: 0.1757\n",
      "Epoch 21, 100% \t Train loss: 0.1607 took: 1.00s  Val. loss: 0.1718\n",
      "Epoch 22, 100% \t Train loss: 0.1595 took: 1.03s  Val. loss: 0.1737\n",
      "Epoch 23, 100% \t Train loss: 0.1581 took: 1.00s  Val. loss: 0.1710\n",
      "Epoch 24, 100% \t Train loss: 0.1581 took: 1.00s  Val. loss: 0.1746\n",
      "Epoch 25, 100% \t Train loss: 0.1568 took: 1.00s  Val. loss: 0.1727\n",
      "Epoch 26, 100% \t Train loss: 0.1562 took: 1.00s  Val. loss: 0.1693\n",
      "Epoch 27, 100% \t Train loss: 0.1540 took: 1.01s  Val. loss: 0.1677\n",
      "Epoch 28, 100% \t Train loss: 0.1538 took: 1.00s  Val. loss: 0.1684\n",
      "Epoch 29, 100% \t Train loss: 0.1543 took: 1.01s  Val. loss: 0.1661\n",
      "Epoch 30, 100% \t Train loss: 0.1512 took: 1.01s  Val. loss: 0.1625\n",
      "Epoch 31, 100% \t Train loss: 0.1502 took: 1.02s  Val. loss: 0.1627\n",
      "Epoch 32, 100% \t Train loss: 0.1494 took: 1.02s  Val. loss: 0.1654\n",
      "Epoch 33, 100% \t Train loss: 0.1481 took: 1.03s  Val. loss: 0.1623\n",
      "Epoch 34, 100% \t Train loss: 0.1479 took: 1.04s  Val. loss: 0.1611\n",
      "Epoch 35, 100% \t Train loss: 0.1461 took: 1.04s  Val. loss: 0.1606\n",
      "Epoch 36, 100% \t Train loss: 0.1462 took: 1.02s  Val. loss: 0.1600\n",
      "Epoch 37, 100% \t Train loss: 0.1442 took: 1.03s  Val. loss: 0.1588\n",
      "Epoch 38, 100% \t Train loss: 0.1434 took: 1.03s  Val. loss: 0.1575\n",
      "Epoch 39, 100% \t Train loss: 0.1421 took: 1.03s  Val. loss: 0.1550\n",
      "Epoch 40, 100% \t Train loss: 0.1409 took: 1.03s  Val. loss: 0.1539\n",
      "Epoch 41, 100% \t Train loss: 0.1403 took: 1.03s  Val. loss: 0.1550\n",
      "Epoch 42, 100% \t Train loss: 0.1398 took: 1.03s  Val. loss: 0.1545\n",
      "Epoch 43, 100% \t Train loss: 0.1381 took: 1.02s  Val. loss: 0.1534\n",
      "Epoch 44, 100% \t Train loss: 0.1369 took: 1.03s  Val. loss: 0.1546\n",
      "Epoch 45, 100% \t Train loss: 0.1356 took: 1.03s  Val. loss: 0.1542\n",
      "Epoch 46, 100% \t Train loss: 0.1347 took: 1.04s  Val. loss: 0.1482\n",
      "Epoch 47, 100% \t Train loss: 0.1326 took: 1.03s  Val. loss: 0.1446\n",
      "Epoch 48, 100% \t Train loss: 0.1311 took: 1.04s  Val. loss: 0.1481\n",
      "Epoch 49, 100% \t Train loss: 0.1304 took: 1.03s  Val. loss: 0.1452\n",
      "Epoch 50, 100% \t Train loss: 0.1290 took: 1.36s  Val. loss: 0.1423\n",
      "Training finished, took 59.66s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.74s  Val. loss: 0.2619\n",
      "Epoch 2, 100% \t Train loss: 0.2588 took: 1.72s  Val. loss: 0.2625\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 1.74s  Val. loss: 0.2623\n",
      "Epoch 4, 100% \t Train loss: 0.2587 took: 1.73s  Val. loss: 0.2625\n",
      "Epoch 5, 100% \t Train loss: 0.2587 took: 1.73s  Val. loss: 0.2622\n",
      "Epoch 6, 100% \t Train loss: 0.2586 took: 1.75s  Val. loss: 0.2622\n",
      "Epoch 7, 100% \t Train loss: 0.2586 took: 1.73s  Val. loss: 0.2622\n",
      "Epoch 8, 100% \t Train loss: 0.2584 took: 1.74s  Val. loss: 0.2617\n",
      "Epoch 9, 100% \t Train loss: 0.2580 took: 1.74s  Val. loss: 0.2607\n",
      "Epoch 10, 100% \t Train loss: 0.2569 took: 1.75s  Val. loss: 0.2592\n",
      "Epoch 11, 100% \t Train loss: 0.2529 took: 1.73s  Val. loss: 0.2543\n",
      "Epoch 12, 100% \t Train loss: 0.2408 took: 1.73s  Val. loss: 0.2360\n",
      "Epoch 13, 100% \t Train loss: 0.2160 took: 1.74s  Val. loss: 0.2124\n",
      "Epoch 14, 100% \t Train loss: 0.1935 took: 1.74s  Val. loss: 0.1972\n",
      "Epoch 15, 100% \t Train loss: 0.1855 took: 1.75s  Val. loss: 0.1946\n",
      "Epoch 16, 100% \t Train loss: 0.1814 took: 1.75s  Val. loss: 0.1922\n",
      "Epoch 17, 100% \t Train loss: 0.1783 took: 1.75s  Val. loss: 0.1874\n",
      "Epoch 18, 100% \t Train loss: 0.1759 took: 1.74s  Val. loss: 0.1869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1739 took: 1.76s  Val. loss: 0.1841\n",
      "Epoch 20, 100% \t Train loss: 0.1724 took: 1.74s  Val. loss: 0.1838\n",
      "Epoch 21, 100% \t Train loss: 0.1702 took: 1.73s  Val. loss: 0.1816\n",
      "Epoch 22, 100% \t Train loss: 0.1689 took: 1.75s  Val. loss: 0.1799\n",
      "Epoch 23, 100% \t Train loss: 0.1668 took: 1.75s  Val. loss: 0.1796\n",
      "Epoch 24, 100% \t Train loss: 0.1667 took: 1.75s  Val. loss: 0.1789\n",
      "Epoch 25, 100% \t Train loss: 0.1649 took: 1.75s  Val. loss: 0.1779\n",
      "Epoch 26, 100% \t Train loss: 0.1633 took: 1.73s  Val. loss: 0.1765\n",
      "Epoch 27, 100% \t Train loss: 0.1626 took: 1.75s  Val. loss: 0.1767\n",
      "Epoch 28, 100% \t Train loss: 0.1620 took: 1.74s  Val. loss: 0.1755\n",
      "Epoch 29, 100% \t Train loss: 0.1627 took: 1.74s  Val. loss: 0.1755\n",
      "Epoch 30, 100% \t Train loss: 0.1617 took: 1.03s  Val. loss: 0.1749\n",
      "Epoch 31, 100% \t Train loss: 0.1611 took: 1.01s  Val. loss: 0.1741\n",
      "Epoch 32, 100% \t Train loss: 0.1603 took: 1.01s  Val. loss: 0.1747\n",
      "Epoch 33, 100% \t Train loss: 0.1596 took: 1.01s  Val. loss: 0.1756\n",
      "Epoch 34, 100% \t Train loss: 0.1589 took: 1.01s  Val. loss: 0.1748\n",
      "Epoch 35, 100% \t Train loss: 0.1604 took: 1.02s  Val. loss: 0.1765\n",
      "Epoch 36, 100% \t Train loss: 0.1620 took: 1.03s  Val. loss: 0.1789\n",
      "Epoch 37, 100% \t Train loss: 0.1592 took: 1.03s  Val. loss: 0.1729\n",
      "Epoch 38, 100% \t Train loss: 0.1583 took: 1.03s  Val. loss: 0.1763\n",
      "Epoch 39, 100% \t Train loss: 0.1592 took: 1.03s  Val. loss: 0.1733\n",
      "Epoch 40, 100% \t Train loss: 0.1581 took: 1.03s  Val. loss: 0.1737\n",
      "Epoch 41, 100% \t Train loss: 0.1574 took: 1.03s  Val. loss: 0.1746\n",
      "Epoch 42, 100% \t Train loss: 0.1573 took: 1.03s  Val. loss: 0.1767\n",
      "Epoch 43, 100% \t Train loss: 0.1591 took: 1.04s  Val. loss: 0.1747\n",
      "Epoch 44, 100% \t Train loss: 0.1577 took: 1.04s  Val. loss: 0.1741\n",
      "Epoch 45, 100% \t Train loss: 0.1579 took: 1.03s  Val. loss: 0.1738\n",
      "Epoch 46, 100% \t Train loss: 0.1562 took: 1.02s  Val. loss: 0.1734\n",
      "Epoch 47, 100% \t Train loss: 0.1570 took: 1.02s  Val. loss: 0.1752\n",
      "Epoch 48, 100% \t Train loss: 0.1573 took: 1.02s  Val. loss: 0.1727\n",
      "Epoch 49, 100% \t Train loss: 0.1563 took: 1.02s  Val. loss: 0.1745\n",
      "Epoch 50, 100% \t Train loss: 0.1568 took: 1.03s  Val. loss: 0.1754\n",
      "Training finished, took 82.27s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.19\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.881918\n",
      "lambda: 0.0010 - V: 0.813750\n",
      "lambda: 0.0005 - V: 0.801615\n",
      "Average V: 0.832428\n",
      "Time elapsed: 231.77 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.30\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.27\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2608 took: 1.04s  Val. loss: 0.2606\n",
      "Epoch 2, 100% \t Train loss: 0.2594 took: 1.05s  Val. loss: 0.2608\n",
      "Epoch 3, 100% \t Train loss: 0.2585 took: 1.02s  Val. loss: 0.2541\n",
      "Epoch 4, 100% \t Train loss: 0.2056 took: 1.02s  Val. loss: 0.1823\n",
      "Epoch 5, 100% \t Train loss: 0.1741 took: 1.02s  Val. loss: 0.1781\n",
      "Epoch 6, 100% \t Train loss: 0.1695 took: 1.03s  Val. loss: 0.1801\n",
      "Epoch 7, 100% \t Train loss: 0.1624 took: 1.03s  Val. loss: 0.1704\n",
      "Epoch 8, 100% \t Train loss: 0.1582 took: 1.02s  Val. loss: 0.1693\n",
      "Epoch 9, 100% \t Train loss: 0.1568 took: 1.03s  Val. loss: 0.1679\n",
      "Epoch 10, 100% \t Train loss: 0.1552 took: 1.03s  Val. loss: 0.1701\n",
      "Epoch 11, 100% \t Train loss: 0.1553 took: 1.03s  Val. loss: 0.1672\n",
      "Epoch 12, 100% \t Train loss: 0.1531 took: 1.03s  Val. loss: 0.1669\n",
      "Epoch 13, 100% \t Train loss: 0.1524 took: 1.04s  Val. loss: 0.1646\n",
      "Epoch 14, 100% \t Train loss: 0.1512 took: 1.04s  Val. loss: 0.1620\n",
      "Epoch 15, 100% \t Train loss: 0.1511 took: 1.03s  Val. loss: 0.1622\n",
      "Epoch 16, 100% \t Train loss: 0.1504 took: 1.03s  Val. loss: 0.1649\n",
      "Epoch 17, 100% \t Train loss: 0.1490 took: 1.03s  Val. loss: 0.1628\n",
      "Epoch 18, 100% \t Train loss: 0.1495 took: 1.04s  Val. loss: 0.1641\n",
      "Epoch 19, 100% \t Train loss: 0.1487 took: 1.04s  Val. loss: 0.1653\n",
      "Epoch 20, 100% \t Train loss: 0.1479 took: 1.04s  Val. loss: 0.1607\n",
      "Epoch 21, 100% \t Train loss: 0.1467 took: 1.03s  Val. loss: 0.1609\n",
      "Epoch 22, 100% \t Train loss: 0.1454 took: 1.03s  Val. loss: 0.1631\n",
      "Epoch 23, 100% \t Train loss: 0.1455 took: 1.03s  Val. loss: 0.1618\n",
      "Epoch 24, 100% \t Train loss: 0.1437 took: 1.03s  Val. loss: 0.1599\n",
      "Epoch 25, 100% \t Train loss: 0.1431 took: 1.03s  Val. loss: 0.1591\n",
      "Epoch 26, 100% \t Train loss: 0.1414 took: 1.03s  Val. loss: 0.1592\n",
      "Epoch 27, 100% \t Train loss: 0.1383 took: 1.03s  Val. loss: 0.1561\n",
      "Epoch 28, 100% \t Train loss: 0.1349 took: 1.03s  Val. loss: 0.1526\n",
      "Epoch 29, 100% \t Train loss: 0.1320 took: 1.03s  Val. loss: 0.1522\n",
      "Epoch 30, 100% \t Train loss: 0.1284 took: 1.28s  Val. loss: 0.1449\n",
      "Epoch 31, 100% \t Train loss: 0.1266 took: 1.80s  Val. loss: 0.1440\n",
      "Epoch 32, 100% \t Train loss: 0.1225 took: 1.80s  Val. loss: 0.1371\n",
      "Epoch 33, 100% \t Train loss: 0.1171 took: 1.85s  Val. loss: 0.1343\n",
      "Epoch 34, 100% \t Train loss: 0.1159 took: 1.84s  Val. loss: 0.1332\n",
      "Epoch 35, 100% \t Train loss: 0.1120 took: 1.80s  Val. loss: 0.1300\n",
      "Epoch 36, 100% \t Train loss: 0.1104 took: 1.80s  Val. loss: 0.1282\n",
      "Epoch 37, 100% \t Train loss: 0.1085 took: 1.06s  Val. loss: 0.1261\n",
      "Epoch 38, 100% \t Train loss: 0.1060 took: 1.06s  Val. loss: 0.1177\n",
      "Epoch 39, 100% \t Train loss: 0.1057 took: 1.08s  Val. loss: 0.1231\n",
      "Epoch 40, 100% \t Train loss: 0.1030 took: 1.07s  Val. loss: 0.1196\n",
      "Epoch 41, 100% \t Train loss: 0.1020 took: 1.07s  Val. loss: 0.1156\n",
      "Epoch 42, 100% \t Train loss: 0.1012 took: 1.08s  Val. loss: 0.1200\n",
      "Epoch 43, 100% \t Train loss: 0.0990 took: 1.08s  Val. loss: 0.1155\n",
      "Epoch 44, 100% \t Train loss: 0.0969 took: 1.08s  Val. loss: 0.1122\n",
      "Epoch 45, 100% \t Train loss: 0.0967 took: 1.08s  Val. loss: 0.1112\n",
      "Epoch 46, 100% \t Train loss: 0.0956 took: 1.08s  Val. loss: 0.1123\n",
      "Epoch 47, 100% \t Train loss: 0.0947 took: 1.10s  Val. loss: 0.1097\n",
      "Epoch 48, 100% \t Train loss: 0.0940 took: 1.09s  Val. loss: 0.1094\n",
      "Epoch 49, 100% \t Train loss: 0.0922 took: 1.09s  Val. loss: 0.1080\n",
      "Epoch 50, 100% \t Train loss: 0.0925 took: 1.09s  Val. loss: 0.1080\n",
      "Training finished, took 64.78s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2602 took: 1.03s  Val. loss: 0.2574\n",
      "Epoch 2, 100% \t Train loss: 0.2591 took: 1.03s  Val. loss: 0.2557\n",
      "Epoch 3, 100% \t Train loss: 0.2527 took: 1.03s  Val. loss: 0.2387\n",
      "Epoch 4, 100% \t Train loss: 0.2123 took: 1.03s  Val. loss: 0.1947\n",
      "Epoch 5, 100% \t Train loss: 0.1847 took: 1.03s  Val. loss: 0.1847\n",
      "Epoch 6, 100% \t Train loss: 0.1799 took: 1.03s  Val. loss: 0.1774\n",
      "Epoch 7, 100% \t Train loss: 0.1769 took: 1.03s  Val. loss: 0.1781\n",
      "Epoch 8, 100% \t Train loss: 0.1729 took: 1.02s  Val. loss: 0.1722\n",
      "Epoch 9, 100% \t Train loss: 0.1715 took: 1.03s  Val. loss: 0.1720\n",
      "Epoch 10, 100% \t Train loss: 0.1689 took: 1.02s  Val. loss: 0.1726\n",
      "Epoch 11, 100% \t Train loss: 0.1672 took: 1.03s  Val. loss: 0.1737\n",
      "Epoch 12, 100% \t Train loss: 0.1650 took: 1.02s  Val. loss: 0.1695\n",
      "Epoch 13, 100% \t Train loss: 0.1645 took: 1.03s  Val. loss: 0.1704\n",
      "Epoch 14, 100% \t Train loss: 0.1626 took: 1.03s  Val. loss: 0.1698\n",
      "Epoch 15, 100% \t Train loss: 0.1624 took: 1.03s  Val. loss: 0.1694\n",
      "Epoch 16, 100% \t Train loss: 0.1614 took: 1.03s  Val. loss: 0.1683\n",
      "Epoch 17, 100% \t Train loss: 0.1607 took: 1.03s  Val. loss: 0.1677\n",
      "Epoch 18, 100% \t Train loss: 0.1605 took: 1.03s  Val. loss: 0.1702\n",
      "Epoch 19, 100% \t Train loss: 0.1596 took: 1.03s  Val. loss: 0.1708\n",
      "Epoch 20, 100% \t Train loss: 0.1592 took: 1.03s  Val. loss: 0.1673\n",
      "Epoch 21, 100% \t Train loss: 0.1598 took: 1.03s  Val. loss: 0.1697\n",
      "Epoch 22, 100% \t Train loss: 0.1587 took: 1.03s  Val. loss: 0.1681\n",
      "Epoch 23, 100% \t Train loss: 0.1587 took: 1.02s  Val. loss: 0.1677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1587 took: 1.03s  Val. loss: 0.1695\n",
      "Epoch 25, 100% \t Train loss: 0.1583 took: 1.26s  Val. loss: 0.1666\n",
      "Epoch 26, 100% \t Train loss: 0.1581 took: 1.79s  Val. loss: 0.1673\n",
      "Epoch 27, 100% \t Train loss: 0.1575 took: 1.75s  Val. loss: 0.1676\n",
      "Epoch 28, 100% \t Train loss: 0.1572 took: 1.81s  Val. loss: 0.1665\n",
      "Epoch 29, 100% \t Train loss: 0.1572 took: 1.82s  Val. loss: 0.1675\n",
      "Epoch 30, 100% \t Train loss: 0.1571 took: 1.80s  Val. loss: 0.1671\n",
      "Epoch 31, 100% \t Train loss: 0.1561 took: 1.80s  Val. loss: 0.1690\n",
      "Epoch 32, 100% \t Train loss: 0.1561 took: 1.80s  Val. loss: 0.1680\n",
      "Epoch 33, 100% \t Train loss: 0.1564 took: 1.80s  Val. loss: 0.1684\n",
      "Epoch 34, 100% \t Train loss: 0.1556 took: 1.80s  Val. loss: 0.1678\n",
      "Epoch 35, 100% \t Train loss: 0.1559 took: 1.80s  Val. loss: 0.1681\n",
      "Epoch 36, 100% \t Train loss: 0.1559 took: 1.82s  Val. loss: 0.1653\n",
      "Epoch 37, 100% \t Train loss: 0.1565 took: 1.80s  Val. loss: 0.1688\n",
      "Epoch 38, 100% \t Train loss: 0.1550 took: 1.81s  Val. loss: 0.1683\n",
      "Epoch 39, 100% \t Train loss: 0.1550 took: 1.79s  Val. loss: 0.1686\n",
      "Epoch 40, 100% \t Train loss: 0.1550 took: 1.81s  Val. loss: 0.1693\n",
      "Epoch 41, 100% \t Train loss: 0.1555 took: 1.80s  Val. loss: 0.1669\n",
      "Epoch 42, 100% \t Train loss: 0.1543 took: 1.81s  Val. loss: 0.1676\n",
      "Epoch 43, 100% \t Train loss: 0.1551 took: 1.81s  Val. loss: 0.1661\n",
      "Epoch 44, 100% \t Train loss: 0.1540 took: 1.82s  Val. loss: 0.1654\n",
      "Epoch 45, 100% \t Train loss: 0.1552 took: 1.82s  Val. loss: 0.1663\n",
      "Epoch 46, 100% \t Train loss: 0.1536 took: 1.81s  Val. loss: 0.1668\n",
      "Epoch 47, 100% \t Train loss: 0.1537 took: 1.83s  Val. loss: 0.1675\n",
      "Epoch 48, 100% \t Train loss: 0.1531 took: 1.84s  Val. loss: 0.1657\n",
      "Epoch 49, 100% \t Train loss: 0.1527 took: 1.83s  Val. loss: 0.1667\n",
      "Epoch 50, 100% \t Train loss: 0.1527 took: 1.82s  Val. loss: 0.1634\n",
      "Training finished, took 80.92s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2556 took: 1.81s  Val. loss: 0.2551\n",
      "Epoch 2, 100% \t Train loss: 0.2552 took: 1.80s  Val. loss: 0.2545\n",
      "Epoch 3, 100% \t Train loss: 0.2551 took: 1.80s  Val. loss: 0.2546\n",
      "Epoch 4, 100% \t Train loss: 0.2551 took: 1.80s  Val. loss: 0.2535\n",
      "Epoch 5, 100% \t Train loss: 0.2551 took: 1.80s  Val. loss: 0.2548\n",
      "Epoch 6, 100% \t Train loss: 0.2552 took: 1.83s  Val. loss: 0.2543\n",
      "Epoch 7, 100% \t Train loss: 0.2551 took: 1.81s  Val. loss: 0.2547\n",
      "Epoch 8, 100% \t Train loss: 0.2551 took: 1.81s  Val. loss: 0.2543\n",
      "Epoch 9, 100% \t Train loss: 0.2548 took: 1.82s  Val. loss: 0.2541\n",
      "Epoch 10, 100% \t Train loss: 0.2543 took: 1.82s  Val. loss: 0.2531\n",
      "Epoch 11, 100% \t Train loss: 0.2528 took: 1.80s  Val. loss: 0.2499\n",
      "Epoch 12, 100% \t Train loss: 0.2470 took: 1.79s  Val. loss: 0.2399\n",
      "Epoch 13, 100% \t Train loss: 0.2320 took: 1.80s  Val. loss: 0.2185\n",
      "Epoch 14, 100% \t Train loss: 0.2161 took: 1.79s  Val. loss: 0.2054\n",
      "Epoch 15, 100% \t Train loss: 0.2045 took: 1.03s  Val. loss: 0.1949\n",
      "Epoch 16, 100% \t Train loss: 0.1928 took: 1.03s  Val. loss: 0.1889\n",
      "Epoch 17, 100% \t Train loss: 0.1825 took: 1.03s  Val. loss: 0.1797\n",
      "Epoch 18, 100% \t Train loss: 0.1760 took: 1.03s  Val. loss: 0.1762\n",
      "Epoch 19, 100% \t Train loss: 0.1722 took: 1.03s  Val. loss: 0.1778\n",
      "Epoch 20, 100% \t Train loss: 0.1694 took: 1.03s  Val. loss: 0.1697\n",
      "Epoch 21, 100% \t Train loss: 0.1678 took: 1.03s  Val. loss: 0.1698\n",
      "Epoch 22, 100% \t Train loss: 0.1665 took: 1.03s  Val. loss: 0.1727\n",
      "Epoch 23, 100% \t Train loss: 0.1658 took: 1.03s  Val. loss: 0.1694\n",
      "Epoch 24, 100% \t Train loss: 0.1646 took: 1.03s  Val. loss: 0.1717\n",
      "Epoch 25, 100% \t Train loss: 0.1650 took: 1.03s  Val. loss: 0.1702\n",
      "Epoch 26, 100% \t Train loss: 0.1633 took: 1.03s  Val. loss: 0.1659\n",
      "Epoch 27, 100% \t Train loss: 0.1638 took: 1.03s  Val. loss: 0.1658\n",
      "Epoch 28, 100% \t Train loss: 0.1631 took: 1.04s  Val. loss: 0.1657\n",
      "Epoch 29, 100% \t Train loss: 0.1637 took: 1.04s  Val. loss: 0.1687\n",
      "Epoch 30, 100% \t Train loss: 0.1620 took: 1.04s  Val. loss: 0.1654\n",
      "Epoch 31, 100% \t Train loss: 0.1613 took: 1.05s  Val. loss: 0.1730\n",
      "Epoch 32, 100% \t Train loss: 0.1624 took: 1.06s  Val. loss: 0.1656\n",
      "Epoch 33, 100% \t Train loss: 0.1612 took: 1.06s  Val. loss: 0.1666\n",
      "Epoch 34, 100% \t Train loss: 0.1603 took: 1.07s  Val. loss: 0.1656\n",
      "Epoch 35, 100% \t Train loss: 0.1605 took: 1.07s  Val. loss: 0.1647\n",
      "Epoch 36, 100% \t Train loss: 0.1595 took: 1.07s  Val. loss: 0.1648\n",
      "Epoch 37, 100% \t Train loss: 0.1590 took: 1.08s  Val. loss: 0.1623\n",
      "Epoch 38, 100% \t Train loss: 0.1594 took: 1.08s  Val. loss: 0.1695\n",
      "Epoch 39, 100% \t Train loss: 0.1590 took: 1.08s  Val. loss: 0.1649\n",
      "Epoch 40, 100% \t Train loss: 0.1579 took: 1.08s  Val. loss: 0.1611\n",
      "Epoch 41, 100% \t Train loss: 0.1574 took: 1.07s  Val. loss: 0.1627\n",
      "Epoch 42, 100% \t Train loss: 0.1566 took: 1.20s  Val. loss: 0.1605\n",
      "Epoch 43, 100% \t Train loss: 0.1558 took: 1.86s  Val. loss: 0.1623\n",
      "Epoch 44, 100% \t Train loss: 0.1566 took: 1.85s  Val. loss: 0.1606\n",
      "Epoch 45, 100% \t Train loss: 0.1557 took: 1.86s  Val. loss: 0.1595\n",
      "Epoch 46, 100% \t Train loss: 0.1547 took: 1.60s  Val. loss: 0.1612\n",
      "Epoch 47, 100% \t Train loss: 0.1555 took: 1.07s  Val. loss: 0.1595\n",
      "Epoch 48, 100% \t Train loss: 0.1545 took: 1.08s  Val. loss: 0.1598\n",
      "Epoch 49, 100% \t Train loss: 0.1534 took: 1.10s  Val. loss: 0.1597\n",
      "Epoch 50, 100% \t Train loss: 0.1534 took: 1.10s  Val. loss: 0.1602\n",
      "Training finished, took 75.06s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.30\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.27\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.847625\n",
      "lambda: 0.0010 - V: 0.825556\n",
      "lambda: 0.0005 - V: 0.810128\n",
      "Average V: 0.827769\n",
      "Time elapsed: 224.18 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.27\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2589 took: 1.07s  Val. loss: 0.2589\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.08s  Val. loss: 0.2578\n",
      "Epoch 3, 100% \t Train loss: 0.2580 took: 1.08s  Val. loss: 0.2581\n",
      "Epoch 4, 100% \t Train loss: 0.2570 took: 1.08s  Val. loss: 0.2515\n",
      "Epoch 5, 100% \t Train loss: 0.2218 took: 1.08s  Val. loss: 0.1895\n",
      "Epoch 6, 100% \t Train loss: 0.1757 took: 1.08s  Val. loss: 0.1719\n",
      "Epoch 7, 100% \t Train loss: 0.1661 took: 1.07s  Val. loss: 0.1695\n",
      "Epoch 8, 100% \t Train loss: 0.1611 took: 1.07s  Val. loss: 0.1669\n",
      "Epoch 9, 100% \t Train loss: 0.1589 took: 1.07s  Val. loss: 0.1654\n",
      "Epoch 10, 100% \t Train loss: 0.1569 took: 1.07s  Val. loss: 0.1667\n",
      "Epoch 11, 100% \t Train loss: 0.1555 took: 1.08s  Val. loss: 0.1647\n",
      "Epoch 12, 100% \t Train loss: 0.1539 took: 1.07s  Val. loss: 0.1650\n",
      "Epoch 13, 100% \t Train loss: 0.1531 took: 1.07s  Val. loss: 0.1657\n",
      "Epoch 14, 100% \t Train loss: 0.1530 took: 1.07s  Val. loss: 0.1609\n",
      "Epoch 15, 100% \t Train loss: 0.1519 took: 1.10s  Val. loss: 0.1629\n",
      "Epoch 16, 100% \t Train loss: 0.1517 took: 1.08s  Val. loss: 0.1620\n",
      "Epoch 17, 100% \t Train loss: 0.1510 took: 1.08s  Val. loss: 0.1617\n",
      "Epoch 18, 100% \t Train loss: 0.1500 took: 1.09s  Val. loss: 0.1618\n",
      "Epoch 19, 100% \t Train loss: 0.1499 took: 1.09s  Val. loss: 0.1637\n",
      "Epoch 20, 100% \t Train loss: 0.1499 took: 1.08s  Val. loss: 0.1615\n",
      "Epoch 21, 100% \t Train loss: 0.1493 took: 1.08s  Val. loss: 0.1636\n",
      "Epoch 22, 100% \t Train loss: 0.1486 took: 1.08s  Val. loss: 0.1643\n",
      "Epoch 23, 100% \t Train loss: 0.1483 took: 1.08s  Val. loss: 0.1615\n",
      "Epoch 24, 100% \t Train loss: 0.1478 took: 1.08s  Val. loss: 0.1607\n",
      "Epoch 25, 100% \t Train loss: 0.1478 took: 1.08s  Val. loss: 0.1612\n",
      "Epoch 26, 100% \t Train loss: 0.1468 took: 1.08s  Val. loss: 0.1624\n",
      "Epoch 27, 100% \t Train loss: 0.1468 took: 1.08s  Val. loss: 0.1641\n",
      "Epoch 28, 100% \t Train loss: 0.1469 took: 1.09s  Val. loss: 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.1467 took: 1.10s  Val. loss: 0.1583\n",
      "Epoch 30, 100% \t Train loss: 0.1468 took: 1.11s  Val. loss: 0.1633\n",
      "Epoch 31, 100% \t Train loss: 0.1455 took: 1.13s  Val. loss: 0.1637\n",
      "Epoch 32, 100% \t Train loss: 0.1455 took: 1.28s  Val. loss: 0.1660\n",
      "Epoch 33, 100% \t Train loss: 0.1456 took: 1.51s  Val. loss: 0.1599\n",
      "Epoch 34, 100% \t Train loss: 0.1439 took: 2.35s  Val. loss: 0.1655\n",
      "Epoch 35, 100% \t Train loss: 0.1426 took: 2.37s  Val. loss: 0.1604\n",
      "Epoch 36, 100% \t Train loss: 0.1419 took: 2.34s  Val. loss: 0.1598\n",
      "Epoch 37, 100% \t Train loss: 0.1406 took: 2.36s  Val. loss: 0.1622\n",
      "Epoch 38, 100% \t Train loss: 0.1380 took: 2.36s  Val. loss: 0.1560\n",
      "Epoch 39, 100% \t Train loss: 0.1345 took: 2.36s  Val. loss: 0.1522\n",
      "Epoch 40, 100% \t Train loss: 0.1327 took: 2.40s  Val. loss: 0.1528\n",
      "Epoch 41, 100% \t Train loss: 0.1295 took: 2.40s  Val. loss: 0.1493\n",
      "Epoch 42, 100% \t Train loss: 0.1261 took: 2.41s  Val. loss: 0.1495\n",
      "Epoch 43, 100% \t Train loss: 0.1239 took: 2.41s  Val. loss: 0.1412\n",
      "Epoch 44, 100% \t Train loss: 0.1199 took: 2.40s  Val. loss: 0.1370\n",
      "Epoch 45, 100% \t Train loss: 0.1177 took: 2.40s  Val. loss: 0.1322\n",
      "Epoch 46, 100% \t Train loss: 0.1147 took: 2.41s  Val. loss: 0.1278\n",
      "Epoch 47, 100% \t Train loss: 0.1118 took: 2.41s  Val. loss: 0.1252\n",
      "Epoch 48, 100% \t Train loss: 0.1085 took: 2.38s  Val. loss: 0.1251\n",
      "Epoch 49, 100% \t Train loss: 0.1053 took: 2.40s  Val. loss: 0.1195\n",
      "Epoch 50, 100% \t Train loss: 0.1029 took: 2.40s  Val. loss: 0.1167\n",
      "Training finished, took 87.19s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.86s  Val. loss: 0.2600\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.85s  Val. loss: 0.2603\n",
      "Epoch 3, 100% \t Train loss: 0.2572 took: 1.86s  Val. loss: 0.2574\n",
      "Epoch 4, 100% \t Train loss: 0.2513 took: 1.87s  Val. loss: 0.2429\n",
      "Epoch 5, 100% \t Train loss: 0.2300 took: 1.86s  Val. loss: 0.2146\n",
      "Epoch 6, 100% \t Train loss: 0.2046 took: 1.85s  Val. loss: 0.1946\n",
      "Epoch 7, 100% \t Train loss: 0.1856 took: 1.84s  Val. loss: 0.1851\n",
      "Epoch 8, 100% \t Train loss: 0.1796 took: 1.87s  Val. loss: 0.1939\n",
      "Epoch 9, 100% \t Train loss: 0.1777 took: 1.87s  Val. loss: 0.1798\n",
      "Epoch 10, 100% \t Train loss: 0.1743 took: 1.86s  Val. loss: 0.1795\n",
      "Epoch 11, 100% \t Train loss: 0.1746 took: 1.84s  Val. loss: 0.1780\n",
      "Epoch 12, 100% \t Train loss: 0.1716 took: 1.84s  Val. loss: 0.1768\n",
      "Epoch 13, 100% \t Train loss: 0.1701 took: 1.85s  Val. loss: 0.1737\n",
      "Epoch 14, 100% \t Train loss: 0.1678 took: 1.85s  Val. loss: 0.1751\n",
      "Epoch 15, 100% \t Train loss: 0.1663 took: 1.85s  Val. loss: 0.1721\n",
      "Epoch 16, 100% \t Train loss: 0.1676 took: 1.86s  Val. loss: 0.1709\n",
      "Epoch 17, 100% \t Train loss: 0.1634 took: 1.84s  Val. loss: 0.1698\n",
      "Epoch 18, 100% \t Train loss: 0.1630 took: 1.84s  Val. loss: 0.1682\n",
      "Epoch 19, 100% \t Train loss: 0.1620 took: 1.85s  Val. loss: 0.1663\n",
      "Epoch 20, 100% \t Train loss: 0.1613 took: 1.85s  Val. loss: 0.1664\n",
      "Epoch 21, 100% \t Train loss: 0.1611 took: 1.86s  Val. loss: 0.1731\n",
      "Epoch 22, 100% \t Train loss: 0.1610 took: 1.86s  Val. loss: 0.1662\n",
      "Epoch 23, 100% \t Train loss: 0.1626 took: 1.84s  Val. loss: 0.1631\n",
      "Epoch 24, 100% \t Train loss: 0.1596 took: 1.85s  Val. loss: 0.1644\n",
      "Epoch 25, 100% \t Train loss: 0.1586 took: 1.86s  Val. loss: 0.1639\n",
      "Epoch 26, 100% \t Train loss: 0.1597 took: 1.87s  Val. loss: 0.1624\n",
      "Epoch 27, 100% \t Train loss: 0.1587 took: 1.86s  Val. loss: 0.1628\n",
      "Epoch 28, 100% \t Train loss: 0.1570 took: 1.86s  Val. loss: 0.1657\n",
      "Epoch 29, 100% \t Train loss: 0.1577 took: 1.88s  Val. loss: 0.1615\n",
      "Epoch 30, 100% \t Train loss: 0.1571 took: 1.85s  Val. loss: 0.1690\n",
      "Epoch 31, 100% \t Train loss: 0.1566 took: 1.85s  Val. loss: 0.1615\n",
      "Epoch 32, 100% \t Train loss: 0.1548 took: 1.85s  Val. loss: 0.1605\n",
      "Epoch 33, 100% \t Train loss: 0.1560 took: 1.86s  Val. loss: 0.1610\n",
      "Epoch 34, 100% \t Train loss: 0.1546 took: 1.85s  Val. loss: 0.1584\n",
      "Epoch 35, 100% \t Train loss: 0.1537 took: 1.85s  Val. loss: 0.1630\n",
      "Epoch 36, 100% \t Train loss: 0.1539 took: 1.86s  Val. loss: 0.1600\n",
      "Epoch 37, 100% \t Train loss: 0.1539 took: 1.85s  Val. loss: 0.1612\n",
      "Epoch 38, 100% \t Train loss: 0.1533 took: 1.84s  Val. loss: 0.1606\n",
      "Epoch 39, 100% \t Train loss: 0.1527 took: 1.87s  Val. loss: 0.1560\n",
      "Epoch 40, 100% \t Train loss: 0.1540 took: 1.85s  Val. loss: 0.1606\n",
      "Epoch 41, 100% \t Train loss: 0.1522 took: 1.87s  Val. loss: 0.1587\n",
      "Epoch 42, 100% \t Train loss: 0.1511 took: 1.85s  Val. loss: 0.1595\n",
      "Epoch 43, 100% \t Train loss: 0.1514 took: 1.87s  Val. loss: 0.1562\n",
      "Epoch 44, 100% \t Train loss: 0.1513 took: 1.85s  Val. loss: 0.1562\n",
      "Epoch 45, 100% \t Train loss: 0.1498 took: 1.85s  Val. loss: 0.1546\n",
      "Epoch 46, 100% \t Train loss: 0.1496 took: 1.84s  Val. loss: 0.1569\n",
      "Epoch 47, 100% \t Train loss: 0.1488 took: 1.85s  Val. loss: 0.1546\n",
      "Epoch 48, 100% \t Train loss: 0.1482 took: 1.85s  Val. loss: 0.1538\n",
      "Epoch 49, 100% \t Train loss: 0.1480 took: 1.87s  Val. loss: 0.1525\n",
      "Epoch 50, 100% \t Train loss: 0.1460 took: 1.87s  Val. loss: 0.1521\n",
      "Training finished, took 105.46s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2567 took: 1.85s  Val. loss: 0.2590\n",
      "Epoch 2, 100% \t Train loss: 0.2565 took: 1.87s  Val. loss: 0.2584\n",
      "Epoch 3, 100% \t Train loss: 0.2562 took: 1.86s  Val. loss: 0.2585\n",
      "Epoch 4, 100% \t Train loss: 0.2552 took: 1.86s  Val. loss: 0.2572\n",
      "Epoch 5, 100% \t Train loss: 0.2504 took: 1.87s  Val. loss: 0.2486\n",
      "Epoch 6, 100% \t Train loss: 0.2339 took: 1.85s  Val. loss: 0.2275\n",
      "Epoch 7, 100% \t Train loss: 0.2096 took: 1.85s  Val. loss: 0.2032\n",
      "Epoch 8, 100% \t Train loss: 0.1895 took: 1.84s  Val. loss: 0.1877\n",
      "Epoch 9, 100% \t Train loss: 0.1788 took: 1.84s  Val. loss: 0.1842\n",
      "Epoch 10, 100% \t Train loss: 0.1739 took: 1.87s  Val. loss: 0.1789\n",
      "Epoch 11, 100% \t Train loss: 0.1724 took: 1.87s  Val. loss: 0.1769\n",
      "Epoch 12, 100% \t Train loss: 0.1711 took: 1.87s  Val. loss: 0.1781\n",
      "Epoch 13, 100% \t Train loss: 0.1707 took: 1.87s  Val. loss: 0.1761\n",
      "Epoch 14, 100% \t Train loss: 0.1693 took: 1.87s  Val. loss: 0.1747\n",
      "Epoch 15, 100% \t Train loss: 0.1687 took: 1.85s  Val. loss: 0.1750\n",
      "Epoch 16, 100% \t Train loss: 0.1680 took: 1.85s  Val. loss: 0.1734\n",
      "Epoch 17, 100% \t Train loss: 0.1673 took: 1.85s  Val. loss: 0.1745\n",
      "Epoch 18, 100% \t Train loss: 0.1659 took: 1.84s  Val. loss: 0.1724\n",
      "Epoch 19, 100% \t Train loss: 0.1651 took: 1.84s  Val. loss: 0.1698\n",
      "Epoch 20, 100% \t Train loss: 0.1653 took: 1.85s  Val. loss: 0.1714\n",
      "Epoch 21, 100% \t Train loss: 0.1634 took: 1.85s  Val. loss: 0.1704\n",
      "Epoch 22, 100% \t Train loss: 0.1632 took: 1.85s  Val. loss: 0.1709\n",
      "Epoch 23, 100% \t Train loss: 0.1625 took: 1.86s  Val. loss: 0.1660\n",
      "Epoch 24, 100% \t Train loss: 0.1612 took: 1.87s  Val. loss: 0.1674\n",
      "Epoch 25, 100% \t Train loss: 0.1601 took: 1.86s  Val. loss: 0.1676\n",
      "Epoch 26, 100% \t Train loss: 0.1593 took: 1.87s  Val. loss: 0.1680\n",
      "Epoch 27, 100% \t Train loss: 0.1596 took: 1.86s  Val. loss: 0.1663\n",
      "Epoch 28, 100% \t Train loss: 0.1586 took: 1.86s  Val. loss: 0.1685\n",
      "Epoch 29, 100% \t Train loss: 0.1588 took: 1.87s  Val. loss: 0.1687\n",
      "Epoch 30, 100% \t Train loss: 0.1574 took: 1.88s  Val. loss: 0.1652\n",
      "Epoch 31, 100% \t Train loss: 0.1581 took: 1.88s  Val. loss: 0.1679\n",
      "Epoch 32, 100% \t Train loss: 0.1572 took: 1.87s  Val. loss: 0.1677\n",
      "Epoch 33, 100% \t Train loss: 0.1570 took: 1.87s  Val. loss: 0.1667\n",
      "Epoch 34, 100% \t Train loss: 0.1561 took: 1.87s  Val. loss: 0.1703\n",
      "Epoch 35, 100% \t Train loss: 0.1560 took: 1.90s  Val. loss: 0.1666\n",
      "Epoch 36, 100% \t Train loss: 0.1561 took: 1.88s  Val. loss: 0.1663\n",
      "Epoch 37, 100% \t Train loss: 0.1559 took: 1.88s  Val. loss: 0.1668\n",
      "Epoch 38, 100% \t Train loss: 0.1549 took: 1.89s  Val. loss: 0.1640\n",
      "Epoch 39, 100% \t Train loss: 0.1546 took: 1.88s  Val. loss: 0.1668\n",
      "Epoch 40, 100% \t Train loss: 0.1544 took: 1.92s  Val. loss: 0.1683\n",
      "Epoch 41, 100% \t Train loss: 0.1545 took: 1.89s  Val. loss: 0.1669\n",
      "Epoch 42, 100% \t Train loss: 0.1538 took: 1.90s  Val. loss: 0.1665\n",
      "Epoch 43, 100% \t Train loss: 0.1534 took: 1.90s  Val. loss: 0.1643\n",
      "Epoch 44, 100% \t Train loss: 0.1539 took: 1.90s  Val. loss: 0.1645\n",
      "Epoch 45, 100% \t Train loss: 0.1535 took: 1.92s  Val. loss: 0.1668\n",
      "Epoch 46, 100% \t Train loss: 0.1532 took: 1.91s  Val. loss: 0.1642\n",
      "Epoch 47, 100% \t Train loss: 0.1521 took: 1.91s  Val. loss: 0.1654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1526 took: 1.93s  Val. loss: 0.1681\n",
      "Epoch 49, 100% \t Train loss: 0.1528 took: 1.93s  Val. loss: 0.1686\n",
      "Epoch 50, 100% \t Train loss: 0.1540 took: 1.96s  Val. loss: 0.1655\n",
      "Training finished, took 106.30s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.27\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.835383\n",
      "lambda: 0.0010 - V: 0.826093\n",
      "lambda: 0.0005 - V: 0.819669\n",
      "Average V: 0.827048\n",
      "Time elapsed: 302.32 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.30\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.20\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2574 took: 1.80s  Val. loss: 0.2561\n",
      "Epoch 2, 100% \t Train loss: 0.2574 took: 1.78s  Val. loss: 0.2572\n",
      "Epoch 3, 100% \t Train loss: 0.2566 took: 1.79s  Val. loss: 0.2528\n",
      "Epoch 4, 100% \t Train loss: 0.2417 took: 1.78s  Val. loss: 0.2208\n",
      "Epoch 5, 100% \t Train loss: 0.2180 took: 1.80s  Val. loss: 0.2060\n",
      "Epoch 6, 100% \t Train loss: 0.2142 took: 1.79s  Val. loss: 0.2054\n",
      "Epoch 7, 100% \t Train loss: 0.2140 took: 1.78s  Val. loss: 0.2019\n",
      "Epoch 8, 100% \t Train loss: 0.2123 took: 1.78s  Val. loss: 0.2000\n",
      "Epoch 9, 100% \t Train loss: 0.2109 took: 1.78s  Val. loss: 0.1969\n",
      "Epoch 10, 100% \t Train loss: 0.2057 took: 1.79s  Val. loss: 0.1843\n",
      "Epoch 11, 100% \t Train loss: 0.2004 took: 1.77s  Val. loss: 0.1823\n",
      "Epoch 12, 100% \t Train loss: 0.1991 took: 1.77s  Val. loss: 0.1848\n",
      "Epoch 13, 100% \t Train loss: 0.1961 took: 1.77s  Val. loss: 0.1781\n",
      "Epoch 14, 100% \t Train loss: 0.1943 took: 1.77s  Val. loss: 0.1787\n",
      "Epoch 15, 100% \t Train loss: 0.1911 took: 1.78s  Val. loss: 0.1812\n",
      "Epoch 16, 100% \t Train loss: 0.1904 took: 1.78s  Val. loss: 0.1825\n",
      "Epoch 17, 100% \t Train loss: 0.1878 took: 1.79s  Val. loss: 0.1779\n",
      "Epoch 18, 100% \t Train loss: 0.1862 took: 1.79s  Val. loss: 0.1764\n",
      "Epoch 19, 100% \t Train loss: 0.1841 took: 1.77s  Val. loss: 0.1722\n",
      "Epoch 20, 100% \t Train loss: 0.1799 took: 1.78s  Val. loss: 0.1682\n",
      "Epoch 21, 100% \t Train loss: 0.1773 took: 1.78s  Val. loss: 0.1661\n",
      "Epoch 22, 100% \t Train loss: 0.1742 took: 1.77s  Val. loss: 0.1662\n",
      "Epoch 23, 100% \t Train loss: 0.1721 took: 1.79s  Val. loss: 0.1589\n",
      "Epoch 24, 100% \t Train loss: 0.1681 took: 1.78s  Val. loss: 0.1542\n",
      "Epoch 25, 100% \t Train loss: 0.1651 took: 1.81s  Val. loss: 0.1527\n",
      "Epoch 26, 100% \t Train loss: 0.1622 took: 1.80s  Val. loss: 0.1572\n",
      "Epoch 27, 100% \t Train loss: 0.1582 took: 1.79s  Val. loss: 0.1520\n",
      "Epoch 28, 100% \t Train loss: 0.1552 took: 1.78s  Val. loss: 0.1479\n",
      "Epoch 29, 100% \t Train loss: 0.1535 took: 1.79s  Val. loss: 0.1487\n",
      "Epoch 30, 100% \t Train loss: 0.1502 took: 1.79s  Val. loss: 0.1483\n",
      "Epoch 31, 100% \t Train loss: 0.1476 took: 1.86s  Val. loss: 0.1431\n",
      "Epoch 32, 100% \t Train loss: 0.1447 took: 2.10s  Val. loss: 0.1425\n",
      "Epoch 33, 100% \t Train loss: 0.1441 took: 2.35s  Val. loss: 0.1445\n",
      "Epoch 34, 100% \t Train loss: 0.1434 took: 2.37s  Val. loss: 0.1469\n",
      "Epoch 35, 100% \t Train loss: 0.1418 took: 2.40s  Val. loss: 0.1412\n",
      "Epoch 36, 100% \t Train loss: 0.1404 took: 2.39s  Val. loss: 0.1374\n",
      "Epoch 37, 100% \t Train loss: 0.1387 took: 2.39s  Val. loss: 0.1391\n",
      "Epoch 38, 100% \t Train loss: 0.1391 took: 2.40s  Val. loss: 0.1367\n",
      "Epoch 39, 100% \t Train loss: 0.1374 took: 2.41s  Val. loss: 0.1367\n",
      "Epoch 40, 100% \t Train loss: 0.1368 took: 2.42s  Val. loss: 0.1351\n",
      "Epoch 41, 100% \t Train loss: 0.1364 took: 2.43s  Val. loss: 0.1352\n",
      "Epoch 42, 100% \t Train loss: 0.1370 took: 2.45s  Val. loss: 0.1343\n",
      "Epoch 43, 100% \t Train loss: 0.1353 took: 2.46s  Val. loss: 0.1334\n",
      "Epoch 44, 100% \t Train loss: 0.1332 took: 2.49s  Val. loss: 0.1328\n",
      "Epoch 45, 100% \t Train loss: 0.1336 took: 2.50s  Val. loss: 0.1319\n",
      "Epoch 46, 100% \t Train loss: 0.1341 took: 2.53s  Val. loss: 0.1347\n",
      "Epoch 47, 100% \t Train loss: 0.1334 took: 1.78s  Val. loss: 0.1334\n",
      "Epoch 48, 100% \t Train loss: 0.1326 took: 1.84s  Val. loss: 0.1325\n",
      "Epoch 49, 100% \t Train loss: 0.1329 took: 2.59s  Val. loss: 0.1321\n",
      "Epoch 50, 100% \t Train loss: 0.1311 took: 2.61s  Val. loss: 0.1330\n",
      "Training finished, took 114.75s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2598 took: 1.79s  Val. loss: 0.2601\n",
      "Epoch 2, 100% \t Train loss: 0.2596 took: 1.79s  Val. loss: 0.2598\n",
      "Epoch 3, 100% \t Train loss: 0.2595 took: 1.79s  Val. loss: 0.2592\n",
      "Epoch 4, 100% \t Train loss: 0.2594 took: 1.03s  Val. loss: 0.2596\n",
      "Epoch 5, 100% \t Train loss: 0.2590 took: 1.03s  Val. loss: 0.2596\n",
      "Epoch 6, 100% \t Train loss: 0.2563 took: 1.03s  Val. loss: 0.2535\n",
      "Epoch 7, 100% \t Train loss: 0.2387 took: 1.03s  Val. loss: 0.2243\n",
      "Epoch 8, 100% \t Train loss: 0.2150 took: 1.03s  Val. loss: 0.2086\n",
      "Epoch 9, 100% \t Train loss: 0.2060 took: 1.03s  Val. loss: 0.2016\n",
      "Epoch 10, 100% \t Train loss: 0.2032 took: 1.03s  Val. loss: 0.1995\n",
      "Epoch 11, 100% \t Train loss: 0.2014 took: 1.04s  Val. loss: 0.1977\n",
      "Epoch 12, 100% \t Train loss: 0.2003 took: 1.04s  Val. loss: 0.1982\n",
      "Epoch 13, 100% \t Train loss: 0.1992 took: 1.04s  Val. loss: 0.1958\n",
      "Epoch 14, 100% \t Train loss: 0.1986 took: 1.03s  Val. loss: 0.1958\n",
      "Epoch 15, 100% \t Train loss: 0.1977 took: 1.04s  Val. loss: 0.1962\n",
      "Epoch 16, 100% \t Train loss: 0.1968 took: 1.04s  Val. loss: 0.1919\n",
      "Epoch 17, 100% \t Train loss: 0.1950 took: 1.04s  Val. loss: 0.1916\n",
      "Epoch 18, 100% \t Train loss: 0.1946 took: 1.04s  Val. loss: 0.1907\n",
      "Epoch 19, 100% \t Train loss: 0.1940 took: 1.03s  Val. loss: 0.1941\n",
      "Epoch 20, 100% \t Train loss: 0.1940 took: 1.04s  Val. loss: 0.1897\n",
      "Epoch 21, 100% \t Train loss: 0.1921 took: 1.04s  Val. loss: 0.1877\n",
      "Epoch 22, 100% \t Train loss: 0.1909 took: 1.04s  Val. loss: 0.1886\n",
      "Epoch 23, 100% \t Train loss: 0.1912 took: 1.03s  Val. loss: 0.1877\n",
      "Epoch 24, 100% \t Train loss: 0.1895 took: 1.04s  Val. loss: 0.1862\n",
      "Epoch 25, 100% \t Train loss: 0.1890 took: 1.03s  Val. loss: 0.1901\n",
      "Epoch 26, 100% \t Train loss: 0.1885 took: 1.03s  Val. loss: 0.1852\n",
      "Epoch 27, 100% \t Train loss: 0.1877 took: 1.04s  Val. loss: 0.1848\n",
      "Epoch 28, 100% \t Train loss: 0.1864 took: 1.04s  Val. loss: 0.1840\n",
      "Epoch 29, 100% \t Train loss: 0.1858 took: 1.05s  Val. loss: 0.1833\n",
      "Epoch 30, 100% \t Train loss: 0.1841 took: 1.06s  Val. loss: 0.1825\n",
      "Epoch 31, 100% \t Train loss: 0.1837 took: 1.10s  Val. loss: 0.1832\n",
      "Epoch 32, 100% \t Train loss: 0.1842 took: 1.13s  Val. loss: 0.1815\n",
      "Epoch 33, 100% \t Train loss: 0.1834 took: 1.14s  Val. loss: 0.1840\n",
      "Epoch 34, 100% \t Train loss: 0.1821 took: 1.14s  Val. loss: 0.1809\n",
      "Epoch 35, 100% \t Train loss: 0.1817 took: 1.15s  Val. loss: 0.1801\n",
      "Epoch 36, 100% \t Train loss: 0.1808 took: 1.17s  Val. loss: 0.1814\n",
      "Epoch 37, 100% \t Train loss: 0.1789 took: 1.18s  Val. loss: 0.1819\n",
      "Epoch 38, 100% \t Train loss: 0.1782 took: 1.18s  Val. loss: 0.1761\n",
      "Epoch 39, 100% \t Train loss: 0.1763 took: 1.19s  Val. loss: 0.1758\n",
      "Epoch 40, 100% \t Train loss: 0.1746 took: 1.19s  Val. loss: 0.1767\n",
      "Epoch 41, 100% \t Train loss: 0.1739 took: 1.20s  Val. loss: 0.1765\n",
      "Epoch 42, 100% \t Train loss: 0.1728 took: 1.89s  Val. loss: 0.1759\n",
      "Epoch 43, 100% \t Train loss: 0.1716 took: 1.96s  Val. loss: 0.1733\n",
      "Epoch 44, 100% \t Train loss: 0.1703 took: 1.96s  Val. loss: 0.1732\n",
      "Epoch 45, 100% \t Train loss: 0.1683 took: 1.95s  Val. loss: 0.1718\n",
      "Epoch 46, 100% \t Train loss: 0.1674 took: 1.95s  Val. loss: 0.1687\n",
      "Epoch 47, 100% \t Train loss: 0.1683 took: 1.97s  Val. loss: 0.1699\n",
      "Epoch 48, 100% \t Train loss: 0.1652 took: 1.96s  Val. loss: 0.1713\n",
      "Epoch 49, 100% \t Train loss: 0.1645 took: 1.95s  Val. loss: 0.1658\n",
      "Epoch 50, 100% \t Train loss: 0.1635 took: 1.95s  Val. loss: 0.1657\n",
      "Training finished, took 72.17s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2574 took: 1.80s  Val. loss: 0.2608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2568 took: 1.02s  Val. loss: 0.2601\n",
      "Epoch 3, 100% \t Train loss: 0.2557 took: 1.03s  Val. loss: 0.2578\n",
      "Epoch 4, 100% \t Train loss: 0.2530 took: 1.03s  Val. loss: 0.2538\n",
      "Epoch 5, 100% \t Train loss: 0.2462 took: 1.06s  Val. loss: 0.2425\n",
      "Epoch 6, 100% \t Train loss: 0.2355 took: 1.03s  Val. loss: 0.2295\n",
      "Epoch 7, 100% \t Train loss: 0.2244 took: 1.03s  Val. loss: 0.2211\n",
      "Epoch 8, 100% \t Train loss: 0.2143 took: 1.03s  Val. loss: 0.2126\n",
      "Epoch 9, 100% \t Train loss: 0.2071 took: 1.03s  Val. loss: 0.2068\n",
      "Epoch 10, 100% \t Train loss: 0.2018 took: 1.03s  Val. loss: 0.2028\n",
      "Epoch 11, 100% \t Train loss: 0.1990 took: 1.03s  Val. loss: 0.2023\n",
      "Epoch 12, 100% \t Train loss: 0.1974 took: 1.03s  Val. loss: 0.2033\n",
      "Epoch 13, 100% \t Train loss: 0.1958 took: 1.02s  Val. loss: 0.2005\n",
      "Epoch 14, 100% \t Train loss: 0.1943 took: 1.02s  Val. loss: 0.2009\n",
      "Epoch 15, 100% \t Train loss: 0.1941 took: 1.02s  Val. loss: 0.1983\n",
      "Epoch 16, 100% \t Train loss: 0.1926 took: 1.02s  Val. loss: 0.2009\n",
      "Epoch 17, 100% \t Train loss: 0.1927 took: 1.02s  Val. loss: 0.2000\n",
      "Epoch 18, 100% \t Train loss: 0.1921 took: 1.02s  Val. loss: 0.1970\n",
      "Epoch 19, 100% \t Train loss: 0.1912 took: 1.02s  Val. loss: 0.2008\n",
      "Epoch 20, 100% \t Train loss: 0.1910 took: 1.02s  Val. loss: 0.2001\n",
      "Epoch 21, 100% \t Train loss: 0.1906 took: 1.31s  Val. loss: 0.1966\n",
      "Epoch 22, 100% \t Train loss: 0.1906 took: 1.79s  Val. loss: 0.1968\n",
      "Epoch 23, 100% \t Train loss: 0.1905 took: 1.25s  Val. loss: 0.2020\n",
      "Epoch 24, 100% \t Train loss: 0.1911 took: 1.03s  Val. loss: 0.2052\n",
      "Epoch 25, 100% \t Train loss: 0.1900 took: 1.03s  Val. loss: 0.1984\n",
      "Epoch 26, 100% \t Train loss: 0.1893 took: 1.02s  Val. loss: 0.1988\n",
      "Epoch 27, 100% \t Train loss: 0.1897 took: 1.03s  Val. loss: 0.1987\n",
      "Epoch 28, 100% \t Train loss: 0.1900 took: 1.03s  Val. loss: 0.1966\n",
      "Epoch 29, 100% \t Train loss: 0.1885 took: 1.04s  Val. loss: 0.1973\n",
      "Epoch 30, 100% \t Train loss: 0.1887 took: 1.04s  Val. loss: 0.1975\n",
      "Epoch 31, 100% \t Train loss: 0.1882 took: 1.06s  Val. loss: 0.1955\n",
      "Epoch 32, 100% \t Train loss: 0.1881 took: 1.37s  Val. loss: 0.1964\n",
      "Epoch 33, 100% \t Train loss: 0.1883 took: 1.81s  Val. loss: 0.1985\n",
      "Epoch 34, 100% \t Train loss: 0.1874 took: 1.82s  Val. loss: 0.1971\n",
      "Epoch 35, 100% \t Train loss: 0.1876 took: 1.12s  Val. loss: 0.1979\n",
      "Epoch 36, 100% \t Train loss: 0.1872 took: 1.10s  Val. loss: 0.1989\n",
      "Epoch 37, 100% \t Train loss: 0.1867 took: 1.10s  Val. loss: 0.1977\n",
      "Epoch 38, 100% \t Train loss: 0.1871 took: 1.10s  Val. loss: 0.1962\n",
      "Epoch 39, 100% \t Train loss: 0.1874 took: 1.11s  Val. loss: 0.1990\n",
      "Epoch 40, 100% \t Train loss: 0.1876 took: 1.11s  Val. loss: 0.1970\n",
      "Epoch 41, 100% \t Train loss: 0.1870 took: 1.12s  Val. loss: 0.1965\n",
      "Epoch 42, 100% \t Train loss: 0.1867 took: 1.12s  Val. loss: 0.1977\n",
      "Epoch 43, 100% \t Train loss: 0.1867 took: 1.13s  Val. loss: 0.1985\n",
      "Epoch 44, 100% \t Train loss: 0.1863 took: 1.13s  Val. loss: 0.1950\n",
      "Epoch 45, 100% \t Train loss: 0.1858 took: 1.13s  Val. loss: 0.1983\n",
      "Epoch 46, 100% \t Train loss: 0.1860 took: 1.12s  Val. loss: 0.1971\n",
      "Epoch 47, 100% \t Train loss: 0.1858 took: 1.13s  Val. loss: 0.1982\n",
      "Epoch 48, 100% \t Train loss: 0.1861 took: 1.13s  Val. loss: 0.1986\n",
      "Epoch 49, 100% \t Train loss: 0.1855 took: 1.12s  Val. loss: 0.1946\n",
      "Epoch 50, 100% \t Train loss: 0.1863 took: 1.11s  Val. loss: 0.1974\n",
      "Training finished, took 64.53s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.30\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.20\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.834951\n",
      "lambda: 0.0010 - V: 0.805972\n",
      "lambda: 0.0005 - V: 0.794274\n",
      "Average V: 0.811732\n",
      "Time elapsed: 255.02 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.30\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 1.81s  Val. loss: 0.2570\n",
      "Epoch 2, 100% \t Train loss: 0.2529 took: 1.83s  Val. loss: 0.2162\n",
      "Epoch 3, 100% \t Train loss: 0.1821 took: 1.81s  Val. loss: 0.1679\n",
      "Epoch 4, 100% \t Train loss: 0.1628 took: 1.81s  Val. loss: 0.1589\n",
      "Epoch 5, 100% \t Train loss: 0.1591 took: 1.81s  Val. loss: 0.1632\n",
      "Epoch 6, 100% \t Train loss: 0.1580 took: 1.05s  Val. loss: 0.1580\n",
      "Epoch 7, 100% \t Train loss: 0.1552 took: 1.05s  Val. loss: 0.1596\n",
      "Epoch 8, 100% \t Train loss: 0.1543 took: 1.05s  Val. loss: 0.1561\n",
      "Epoch 9, 100% \t Train loss: 0.1540 took: 1.05s  Val. loss: 0.1566\n",
      "Epoch 10, 100% \t Train loss: 0.1520 took: 1.06s  Val. loss: 0.1552\n",
      "Epoch 11, 100% \t Train loss: 0.1509 took: 1.05s  Val. loss: 0.1556\n",
      "Epoch 12, 100% \t Train loss: 0.1509 took: 1.05s  Val. loss: 0.1582\n",
      "Epoch 13, 100% \t Train loss: 0.1506 took: 1.06s  Val. loss: 0.1555\n",
      "Epoch 14, 100% \t Train loss: 0.1491 took: 1.05s  Val. loss: 0.1582\n",
      "Epoch 15, 100% \t Train loss: 0.1483 took: 1.05s  Val. loss: 0.1546\n",
      "Epoch 16, 100% \t Train loss: 0.1482 took: 1.05s  Val. loss: 0.1534\n",
      "Epoch 17, 100% \t Train loss: 0.1471 took: 1.05s  Val. loss: 0.1543\n",
      "Epoch 18, 100% \t Train loss: 0.1452 took: 1.05s  Val. loss: 0.1478\n",
      "Epoch 19, 100% \t Train loss: 0.1435 took: 1.05s  Val. loss: 0.1519\n",
      "Epoch 20, 100% \t Train loss: 0.1394 took: 1.08s  Val. loss: 0.1456\n",
      "Epoch 21, 100% \t Train loss: 0.1329 took: 1.80s  Val. loss: 0.1371\n",
      "Epoch 22, 100% \t Train loss: 0.1268 took: 1.81s  Val. loss: 0.1337\n",
      "Epoch 23, 100% \t Train loss: 0.1211 took: 1.83s  Val. loss: 0.1277\n",
      "Epoch 24, 100% \t Train loss: 0.1143 took: 1.80s  Val. loss: 0.1197\n",
      "Epoch 25, 100% \t Train loss: 0.1092 took: 1.80s  Val. loss: 0.1184\n",
      "Epoch 26, 100% \t Train loss: 0.1049 took: 1.80s  Val. loss: 0.1101\n",
      "Epoch 27, 100% \t Train loss: 0.1023 took: 1.81s  Val. loss: 0.1086\n",
      "Epoch 28, 100% \t Train loss: 0.0965 took: 1.82s  Val. loss: 0.1113\n",
      "Epoch 29, 100% \t Train loss: 0.0954 took: 1.82s  Val. loss: 0.1063\n",
      "Epoch 30, 100% \t Train loss: 0.0926 took: 1.83s  Val. loss: 0.1003\n",
      "Epoch 31, 100% \t Train loss: 0.0915 took: 1.84s  Val. loss: 0.1075\n",
      "Epoch 32, 100% \t Train loss: 0.0897 took: 1.91s  Val. loss: 0.1018\n",
      "Epoch 33, 100% \t Train loss: 0.0873 took: 2.00s  Val. loss: 0.1003\n",
      "Epoch 34, 100% \t Train loss: 0.0859 took: 1.99s  Val. loss: 0.1005\n",
      "Epoch 35, 100% \t Train loss: 0.0865 took: 2.00s  Val. loss: 0.0994\n",
      "Epoch 36, 100% \t Train loss: 0.0842 took: 1.98s  Val. loss: 0.0976\n",
      "Epoch 37, 100% \t Train loss: 0.0837 took: 1.96s  Val. loss: 0.0985\n",
      "Epoch 38, 100% \t Train loss: 0.0830 took: 1.97s  Val. loss: 0.0980\n",
      "Epoch 39, 100% \t Train loss: 0.0806 took: 1.98s  Val. loss: 0.0975\n",
      "Epoch 40, 100% \t Train loss: 0.0811 took: 1.98s  Val. loss: 0.0958\n",
      "Epoch 41, 100% \t Train loss: 0.0803 took: 1.97s  Val. loss: 0.0978\n",
      "Epoch 42, 100% \t Train loss: 0.0791 took: 1.97s  Val. loss: 0.0957\n",
      "Epoch 43, 100% \t Train loss: 0.0780 took: 1.96s  Val. loss: 0.0961\n",
      "Epoch 44, 100% \t Train loss: 0.0786 took: 1.98s  Val. loss: 0.0957\n",
      "Epoch 45, 100% \t Train loss: 0.0787 took: 1.99s  Val. loss: 0.0948\n",
      "Epoch 46, 100% \t Train loss: 0.0784 took: 1.98s  Val. loss: 0.0955\n",
      "Epoch 47, 100% \t Train loss: 0.0785 took: 1.97s  Val. loss: 0.0922\n",
      "Epoch 48, 100% \t Train loss: 0.0778 took: 1.98s  Val. loss: 0.0959\n",
      "Epoch 49, 100% \t Train loss: 0.0766 took: 1.99s  Val. loss: 0.0935\n",
      "Epoch 50, 100% \t Train loss: 0.0770 took: 1.21s  Val. loss: 0.0946\n",
      "Training finished, took 92.86s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2579 took: 1.81s  Val. loss: 0.2597\n",
      "Epoch 2, 100% \t Train loss: 0.2571 took: 1.81s  Val. loss: 0.2600\n",
      "Epoch 3, 100% \t Train loss: 0.2572 took: 1.81s  Val. loss: 0.2598\n",
      "Epoch 4, 100% \t Train loss: 0.2568 took: 1.81s  Val. loss: 0.2590\n",
      "Epoch 5, 100% \t Train loss: 0.2551 took: 1.80s  Val. loss: 0.2532\n",
      "Epoch 6, 100% \t Train loss: 0.2389 took: 1.81s  Val. loss: 0.2226\n",
      "Epoch 7, 100% \t Train loss: 0.2005 took: 1.80s  Val. loss: 0.1966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.1827 took: 1.81s  Val. loss: 0.2005\n",
      "Epoch 9, 100% \t Train loss: 0.1761 took: 1.81s  Val. loss: 0.1909\n",
      "Epoch 10, 100% \t Train loss: 0.1748 took: 1.81s  Val. loss: 0.1938\n",
      "Epoch 11, 100% \t Train loss: 0.1705 took: 1.84s  Val. loss: 0.1830\n",
      "Epoch 12, 100% \t Train loss: 0.1685 took: 1.82s  Val. loss: 0.1816\n",
      "Epoch 13, 100% \t Train loss: 0.1672 took: 1.83s  Val. loss: 0.1814\n",
      "Epoch 14, 100% \t Train loss: 0.1650 took: 1.82s  Val. loss: 0.1831\n",
      "Epoch 15, 100% \t Train loss: 0.1651 took: 1.83s  Val. loss: 0.1817\n",
      "Epoch 16, 100% \t Train loss: 0.1643 took: 1.82s  Val. loss: 0.1786\n",
      "Epoch 17, 100% \t Train loss: 0.1633 took: 1.82s  Val. loss: 0.1770\n",
      "Epoch 18, 100% \t Train loss: 0.1605 took: 1.81s  Val. loss: 0.1796\n",
      "Epoch 19, 100% \t Train loss: 0.1608 took: 1.81s  Val. loss: 0.1744\n",
      "Epoch 20, 100% \t Train loss: 0.1574 took: 1.81s  Val. loss: 0.1732\n",
      "Epoch 21, 100% \t Train loss: 0.1580 took: 1.81s  Val. loss: 0.1754\n",
      "Epoch 22, 100% \t Train loss: 0.1551 took: 1.80s  Val. loss: 0.1741\n",
      "Epoch 23, 100% \t Train loss: 0.1546 took: 1.82s  Val. loss: 0.1687\n",
      "Epoch 24, 100% \t Train loss: 0.1532 took: 1.81s  Val. loss: 0.1670\n",
      "Epoch 25, 100% \t Train loss: 0.1499 took: 1.81s  Val. loss: 0.1636\n",
      "Epoch 26, 100% \t Train loss: 0.1487 took: 1.81s  Val. loss: 0.1636\n",
      "Epoch 27, 100% \t Train loss: 0.1449 took: 1.80s  Val. loss: 0.1575\n",
      "Epoch 28, 100% \t Train loss: 0.1406 took: 1.81s  Val. loss: 0.1575\n",
      "Epoch 29, 100% \t Train loss: 0.1362 took: 1.82s  Val. loss: 0.1523\n",
      "Epoch 30, 100% \t Train loss: 0.1349 took: 1.83s  Val. loss: 0.1541\n",
      "Epoch 31, 100% \t Train loss: 0.1280 took: 1.84s  Val. loss: 0.1491\n",
      "Epoch 32, 100% \t Train loss: 0.1241 took: 1.88s  Val. loss: 0.1376\n",
      "Epoch 33, 100% \t Train loss: 0.1206 took: 1.91s  Val. loss: 0.1290\n",
      "Epoch 34, 100% \t Train loss: 0.1193 took: 1.92s  Val. loss: 0.1270\n",
      "Epoch 35, 100% \t Train loss: 0.1126 took: 1.95s  Val. loss: 0.1232\n",
      "Epoch 36, 100% \t Train loss: 0.1103 took: 1.95s  Val. loss: 0.1186\n",
      "Epoch 37, 100% \t Train loss: 0.1076 took: 1.98s  Val. loss: 0.1169\n",
      "Epoch 38, 100% \t Train loss: 0.1066 took: 1.99s  Val. loss: 0.1171\n",
      "Epoch 39, 100% \t Train loss: 0.1039 took: 2.01s  Val. loss: 0.1151\n",
      "Epoch 40, 100% \t Train loss: 0.1026 took: 2.05s  Val. loss: 0.1119\n",
      "Epoch 41, 100% \t Train loss: 0.0996 took: 2.11s  Val. loss: 0.1118\n",
      "Epoch 42, 100% \t Train loss: 0.0970 took: 2.17s  Val. loss: 0.1091\n",
      "Epoch 43, 100% \t Train loss: 0.0953 took: 2.20s  Val. loss: 0.1075\n",
      "Epoch 44, 100% \t Train loss: 0.0937 took: 2.21s  Val. loss: 0.1037\n",
      "Epoch 45, 100% \t Train loss: 0.0927 took: 2.21s  Val. loss: 0.1053\n",
      "Epoch 46, 100% \t Train loss: 0.0924 took: 2.23s  Val. loss: 0.1071\n",
      "Epoch 47, 100% \t Train loss: 0.0899 took: 2.23s  Val. loss: 0.1002\n",
      "Epoch 48, 100% \t Train loss: 0.0891 took: 2.22s  Val. loss: 0.1029\n",
      "Epoch 49, 100% \t Train loss: 0.0882 took: 2.24s  Val. loss: 0.0984\n",
      "Epoch 50, 100% \t Train loss: 0.0866 took: 2.30s  Val. loss: 0.1044\n",
      "Training finished, took 109.06s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2572 took: 1.84s  Val. loss: 0.2625\n",
      "Epoch 2, 100% \t Train loss: 0.2568 took: 1.83s  Val. loss: 0.2619\n",
      "Epoch 3, 100% \t Train loss: 0.2566 took: 1.83s  Val. loss: 0.2633\n",
      "Epoch 4, 100% \t Train loss: 0.2566 took: 1.83s  Val. loss: 0.2622\n",
      "Epoch 5, 100% \t Train loss: 0.2560 took: 1.84s  Val. loss: 0.2625\n",
      "Epoch 6, 100% \t Train loss: 0.2550 took: 1.84s  Val. loss: 0.2615\n",
      "Epoch 7, 100% \t Train loss: 0.2525 took: 1.83s  Val. loss: 0.2559\n",
      "Epoch 8, 100% \t Train loss: 0.2430 took: 1.82s  Val. loss: 0.2450\n",
      "Epoch 9, 100% \t Train loss: 0.2258 took: 1.82s  Val. loss: 0.2263\n",
      "Epoch 10, 100% \t Train loss: 0.2038 took: 1.83s  Val. loss: 0.2046\n",
      "Epoch 11, 100% \t Train loss: 0.1869 took: 1.83s  Val. loss: 0.1908\n",
      "Epoch 12, 100% \t Train loss: 0.1777 took: 1.85s  Val. loss: 0.1873\n",
      "Epoch 13, 100% \t Train loss: 0.1722 took: 1.83s  Val. loss: 0.1793\n",
      "Epoch 14, 100% \t Train loss: 0.1670 took: 1.83s  Val. loss: 0.1798\n",
      "Epoch 15, 100% \t Train loss: 0.1661 took: 1.82s  Val. loss: 0.1836\n",
      "Epoch 16, 100% \t Train loss: 0.1662 took: 1.82s  Val. loss: 0.1741\n",
      "Epoch 17, 100% \t Train loss: 0.1630 took: 1.82s  Val. loss: 0.1743\n",
      "Epoch 18, 100% \t Train loss: 0.1608 took: 1.82s  Val. loss: 0.1829\n",
      "Epoch 19, 100% \t Train loss: 0.1612 took: 1.82s  Val. loss: 0.1754\n",
      "Epoch 20, 100% \t Train loss: 0.1608 took: 1.83s  Val. loss: 0.1717\n",
      "Epoch 21, 100% \t Train loss: 0.1579 took: 1.82s  Val. loss: 0.1717\n",
      "Epoch 22, 100% \t Train loss: 0.1575 took: 1.84s  Val. loss: 0.1739\n",
      "Epoch 23, 100% \t Train loss: 0.1584 took: 1.82s  Val. loss: 0.1716\n",
      "Epoch 24, 100% \t Train loss: 0.1570 took: 1.85s  Val. loss: 0.1686\n",
      "Epoch 25, 100% \t Train loss: 0.1568 took: 1.06s  Val. loss: 0.1683\n",
      "Epoch 26, 100% \t Train loss: 0.1561 took: 1.06s  Val. loss: 0.1682\n",
      "Epoch 27, 100% \t Train loss: 0.1545 took: 1.06s  Val. loss: 0.1697\n",
      "Epoch 28, 100% \t Train loss: 0.1532 took: 1.06s  Val. loss: 0.1656\n",
      "Epoch 29, 100% \t Train loss: 0.1533 took: 1.15s  Val. loss: 0.1643\n",
      "Epoch 30, 100% \t Train loss: 0.1517 took: 1.07s  Val. loss: 0.1690\n",
      "Epoch 31, 100% \t Train loss: 0.1510 took: 1.10s  Val. loss: 0.1702\n",
      "Epoch 32, 100% \t Train loss: 0.1525 took: 1.12s  Val. loss: 0.1633\n",
      "Epoch 33, 100% \t Train loss: 0.1503 took: 1.13s  Val. loss: 0.1661\n",
      "Epoch 34, 100% \t Train loss: 0.1507 took: 1.13s  Val. loss: 0.1641\n",
      "Epoch 35, 100% \t Train loss: 0.1501 took: 1.14s  Val. loss: 0.1642\n",
      "Epoch 36, 100% \t Train loss: 0.1514 took: 1.68s  Val. loss: 0.1631\n",
      "Epoch 37, 100% \t Train loss: 0.1488 took: 1.84s  Val. loss: 0.1642\n",
      "Epoch 38, 100% \t Train loss: 0.1478 took: 1.84s  Val. loss: 0.1637\n",
      "Epoch 39, 100% \t Train loss: 0.1476 took: 1.84s  Val. loss: 0.1722\n",
      "Epoch 40, 100% \t Train loss: 0.1480 took: 1.84s  Val. loss: 0.1669\n",
      "Epoch 41, 100% \t Train loss: 0.1478 took: 1.85s  Val. loss: 0.1641\n",
      "Epoch 42, 100% \t Train loss: 0.1471 took: 1.83s  Val. loss: 0.1633\n",
      "Epoch 43, 100% \t Train loss: 0.1467 took: 1.83s  Val. loss: 0.1648\n",
      "Epoch 44, 100% \t Train loss: 0.1487 took: 1.83s  Val. loss: 0.1672\n",
      "Epoch 45, 100% \t Train loss: 0.1460 took: 1.86s  Val. loss: 0.1642\n",
      "Epoch 46, 100% \t Train loss: 0.1454 took: 1.83s  Val. loss: 0.1643\n",
      "Epoch 47, 100% \t Train loss: 0.1450 took: 1.85s  Val. loss: 0.1641\n",
      "Epoch 48, 100% \t Train loss: 0.1447 took: 1.85s  Val. loss: 0.1681\n",
      "Epoch 49, 100% \t Train loss: 0.1452 took: 1.85s  Val. loss: 0.1635\n",
      "Epoch 50, 100% \t Train loss: 0.1449 took: 1.86s  Val. loss: 0.1654\n",
      "Training finished, took 94.59s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.30\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.871891\n",
      "lambda: 0.0010 - V: 0.839614\n",
      "lambda: 0.0005 - V: 0.813945\n",
      "Average V: 0.841817\n",
      "Time elapsed: 300.03 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.27\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2565 took: 1.80s  Val. loss: 0.2545\n",
      "Epoch 2, 100% \t Train loss: 0.2553 took: 1.80s  Val. loss: 0.2509\n",
      "Epoch 3, 100% \t Train loss: 0.2284 took: 1.80s  Val. loss: 0.2013\n",
      "Epoch 4, 100% \t Train loss: 0.2006 took: 1.10s  Val. loss: 0.2009\n",
      "Epoch 5, 100% \t Train loss: 0.1986 took: 1.04s  Val. loss: 0.1963\n",
      "Epoch 6, 100% \t Train loss: 0.1979 took: 1.03s  Val. loss: 0.1995\n",
      "Epoch 7, 100% \t Train loss: 0.1970 took: 1.04s  Val. loss: 0.1937\n",
      "Epoch 8, 100% \t Train loss: 0.1958 took: 1.04s  Val. loss: 0.1964\n",
      "Epoch 9, 100% \t Train loss: 0.1947 took: 1.04s  Val. loss: 0.1927\n",
      "Epoch 10, 100% \t Train loss: 0.1934 took: 1.03s  Val. loss: 0.1927\n",
      "Epoch 11, 100% \t Train loss: 0.1920 took: 1.03s  Val. loss: 0.1899\n",
      "Epoch 12, 100% \t Train loss: 0.1916 took: 1.03s  Val. loss: 0.1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 100% \t Train loss: 0.1906 took: 1.04s  Val. loss: 0.1891\n",
      "Epoch 14, 100% \t Train loss: 0.1896 took: 1.04s  Val. loss: 0.1914\n",
      "Epoch 15, 100% \t Train loss: 0.1891 took: 1.04s  Val. loss: 0.1913\n",
      "Epoch 16, 100% \t Train loss: 0.1881 took: 1.04s  Val. loss: 0.1902\n",
      "Epoch 17, 100% \t Train loss: 0.1869 took: 1.04s  Val. loss: 0.1886\n",
      "Epoch 18, 100% \t Train loss: 0.1860 took: 1.04s  Val. loss: 0.1825\n",
      "Epoch 19, 100% \t Train loss: 0.1830 took: 1.04s  Val. loss: 0.1811\n",
      "Epoch 20, 100% \t Train loss: 0.1794 took: 1.04s  Val. loss: 0.1824\n",
      "Epoch 21, 100% \t Train loss: 0.1753 took: 1.04s  Val. loss: 0.1770\n",
      "Epoch 22, 100% \t Train loss: 0.1725 took: 1.37s  Val. loss: 0.1711\n",
      "Epoch 23, 100% \t Train loss: 0.1722 took: 1.80s  Val. loss: 0.1730\n",
      "Epoch 24, 100% \t Train loss: 0.1691 took: 1.82s  Val. loss: 0.1697\n",
      "Epoch 25, 100% \t Train loss: 0.1675 took: 1.80s  Val. loss: 0.1664\n",
      "Epoch 26, 100% \t Train loss: 0.1660 took: 1.81s  Val. loss: 0.1653\n",
      "Epoch 27, 100% \t Train loss: 0.1634 took: 1.81s  Val. loss: 0.1635\n",
      "Epoch 28, 100% \t Train loss: 0.1639 took: 1.79s  Val. loss: 0.1632\n",
      "Epoch 29, 100% \t Train loss: 0.1613 took: 1.80s  Val. loss: 0.1610\n",
      "Epoch 30, 100% \t Train loss: 0.1610 took: 1.81s  Val. loss: 0.1622\n",
      "Epoch 31, 100% \t Train loss: 0.1600 took: 1.80s  Val. loss: 0.1608\n",
      "Epoch 32, 100% \t Train loss: 0.1603 took: 1.86s  Val. loss: 0.1638\n",
      "Epoch 33, 100% \t Train loss: 0.1589 took: 2.02s  Val. loss: 0.1602\n",
      "Epoch 34, 100% \t Train loss: 0.1585 took: 2.06s  Val. loss: 0.1582\n",
      "Epoch 35, 100% \t Train loss: 0.1576 took: 2.07s  Val. loss: 0.1609\n",
      "Epoch 36, 100% \t Train loss: 0.1569 took: 2.08s  Val. loss: 0.1567\n",
      "Epoch 37, 100% \t Train loss: 0.1569 took: 2.09s  Val. loss: 0.1598\n",
      "Epoch 38, 100% \t Train loss: 0.1568 took: 2.11s  Val. loss: 0.1620\n",
      "Epoch 39, 100% \t Train loss: 0.1562 took: 2.11s  Val. loss: 0.1580\n",
      "Epoch 40, 100% \t Train loss: 0.1558 took: 2.12s  Val. loss: 0.1640\n",
      "Epoch 41, 100% \t Train loss: 0.1552 took: 2.12s  Val. loss: 0.1598\n",
      "Epoch 42, 100% \t Train loss: 0.1555 took: 2.15s  Val. loss: 0.1567\n",
      "Epoch 43, 100% \t Train loss: 0.1551 took: 2.17s  Val. loss: 0.1545\n",
      "Epoch 44, 100% \t Train loss: 0.1540 took: 2.20s  Val. loss: 0.1563\n",
      "Epoch 45, 100% \t Train loss: 0.1548 took: 2.10s  Val. loss: 0.1600\n",
      "Epoch 46, 100% \t Train loss: 0.1545 took: 2.06s  Val. loss: 0.1560\n",
      "Epoch 47, 100% \t Train loss: 0.1539 took: 2.08s  Val. loss: 0.1575\n",
      "Epoch 48, 100% \t Train loss: 0.1533 took: 2.08s  Val. loss: 0.1597\n",
      "Epoch 49, 100% \t Train loss: 0.1539 took: 2.10s  Val. loss: 0.1549\n",
      "Epoch 50, 100% \t Train loss: 0.1543 took: 2.10s  Val. loss: 0.1544\n",
      "Training finished, took 92.83s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.79s  Val. loss: 0.2538\n",
      "Epoch 2, 100% \t Train loss: 0.2579 took: 1.79s  Val. loss: 0.2525\n",
      "Epoch 3, 100% \t Train loss: 0.2510 took: 1.79s  Val. loss: 0.2403\n",
      "Epoch 4, 100% \t Train loss: 0.2229 took: 1.82s  Val. loss: 0.2118\n",
      "Epoch 5, 100% \t Train loss: 0.2011 took: 1.04s  Val. loss: 0.1998\n",
      "Epoch 6, 100% \t Train loss: 0.1945 took: 1.04s  Val. loss: 0.2021\n",
      "Epoch 7, 100% \t Train loss: 0.1919 took: 1.04s  Val. loss: 0.1976\n",
      "Epoch 8, 100% \t Train loss: 0.1907 took: 1.03s  Val. loss: 0.2078\n",
      "Epoch 9, 100% \t Train loss: 0.1898 took: 1.03s  Val. loss: 0.1987\n",
      "Epoch 10, 100% \t Train loss: 0.1892 took: 1.03s  Val. loss: 0.1980\n",
      "Epoch 11, 100% \t Train loss: 0.1883 took: 1.03s  Val. loss: 0.1991\n",
      "Epoch 12, 100% \t Train loss: 0.1881 took: 1.03s  Val. loss: 0.1976\n",
      "Epoch 13, 100% \t Train loss: 0.1878 took: 1.03s  Val. loss: 0.2008\n",
      "Epoch 14, 100% \t Train loss: 0.1870 took: 1.04s  Val. loss: 0.2004\n",
      "Epoch 15, 100% \t Train loss: 0.1871 took: 1.04s  Val. loss: 0.1942\n",
      "Epoch 16, 100% \t Train loss: 0.1873 took: 1.03s  Val. loss: 0.2003\n",
      "Epoch 17, 100% \t Train loss: 0.1863 took: 1.04s  Val. loss: 0.1953\n",
      "Epoch 18, 100% \t Train loss: 0.1855 took: 1.04s  Val. loss: 0.1955\n",
      "Epoch 19, 100% \t Train loss: 0.1849 took: 1.04s  Val. loss: 0.1919\n",
      "Epoch 20, 100% \t Train loss: 0.1851 took: 1.07s  Val. loss: 0.1917\n",
      "Epoch 21, 100% \t Train loss: 0.1848 took: 1.03s  Val. loss: 0.1933\n",
      "Epoch 22, 100% \t Train loss: 0.1844 took: 1.03s  Val. loss: 0.1917\n",
      "Epoch 23, 100% \t Train loss: 0.1840 took: 1.04s  Val. loss: 0.2038\n",
      "Epoch 24, 100% \t Train loss: 0.1850 took: 1.03s  Val. loss: 0.1929\n",
      "Epoch 25, 100% \t Train loss: 0.1839 took: 1.03s  Val. loss: 0.1971\n",
      "Epoch 26, 100% \t Train loss: 0.1842 took: 1.03s  Val. loss: 0.1927\n",
      "Epoch 27, 100% \t Train loss: 0.1834 took: 1.03s  Val. loss: 0.1925\n",
      "Epoch 28, 100% \t Train loss: 0.1829 took: 1.03s  Val. loss: 0.1898\n",
      "Epoch 29, 100% \t Train loss: 0.1825 took: 1.04s  Val. loss: 0.1926\n",
      "Epoch 30, 100% \t Train loss: 0.1821 took: 1.04s  Val. loss: 0.1932\n",
      "Epoch 31, 100% \t Train loss: 0.1827 took: 1.05s  Val. loss: 0.1948\n",
      "Epoch 32, 100% \t Train loss: 0.1822 took: 1.05s  Val. loss: 0.1878\n",
      "Epoch 33, 100% \t Train loss: 0.1822 took: 1.05s  Val. loss: 0.1888\n",
      "Epoch 34, 100% \t Train loss: 0.1815 took: 1.05s  Val. loss: 0.1905\n",
      "Epoch 35, 100% \t Train loss: 0.1811 took: 1.05s  Val. loss: 0.1909\n",
      "Epoch 36, 100% \t Train loss: 0.1814 took: 1.05s  Val. loss: 0.1928\n",
      "Epoch 37, 100% \t Train loss: 0.1817 took: 1.05s  Val. loss: 0.1926\n",
      "Epoch 38, 100% \t Train loss: 0.1817 took: 1.05s  Val. loss: 0.1924\n",
      "Epoch 39, 100% \t Train loss: 0.1809 took: 1.06s  Val. loss: 0.1916\n",
      "Epoch 40, 100% \t Train loss: 0.1810 took: 1.06s  Val. loss: 0.1889\n",
      "Epoch 41, 100% \t Train loss: 0.1809 took: 1.06s  Val. loss: 0.1894\n",
      "Epoch 42, 100% \t Train loss: 0.1806 took: 1.06s  Val. loss: 0.1937\n",
      "Epoch 43, 100% \t Train loss: 0.1802 took: 1.07s  Val. loss: 0.1913\n",
      "Epoch 44, 100% \t Train loss: 0.1804 took: 1.07s  Val. loss: 0.1861\n",
      "Epoch 45, 100% \t Train loss: 0.1802 took: 1.06s  Val. loss: 0.1940\n",
      "Epoch 46, 100% \t Train loss: 0.1808 took: 1.07s  Val. loss: 0.1929\n",
      "Epoch 47, 100% \t Train loss: 0.1800 took: 1.11s  Val. loss: 0.1916\n",
      "Epoch 48, 100% \t Train loss: 0.1800 took: 1.83s  Val. loss: 0.1936\n",
      "Epoch 49, 100% \t Train loss: 0.1802 took: 1.83s  Val. loss: 0.1877\n",
      "Epoch 50, 100% \t Train loss: 0.1799 took: 1.84s  Val. loss: 0.1899\n",
      "Training finished, took 65.50s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2521 took: 1.80s  Val. loss: 0.2555\n",
      "Epoch 2, 100% \t Train loss: 0.2518 took: 1.79s  Val. loss: 0.2563\n",
      "Epoch 3, 100% \t Train loss: 0.2517 took: 1.79s  Val. loss: 0.2556\n",
      "Epoch 4, 100% \t Train loss: 0.2515 took: 1.78s  Val. loss: 0.2550\n",
      "Epoch 5, 100% \t Train loss: 0.2510 took: 1.80s  Val. loss: 0.2545\n",
      "Epoch 6, 100% \t Train loss: 0.2497 took: 1.80s  Val. loss: 0.2526\n",
      "Epoch 7, 100% \t Train loss: 0.2462 took: 1.80s  Val. loss: 0.2464\n",
      "Epoch 8, 100% \t Train loss: 0.2364 took: 1.79s  Val. loss: 0.2340\n",
      "Epoch 9, 100% \t Train loss: 0.2238 took: 1.79s  Val. loss: 0.2217\n",
      "Epoch 10, 100% \t Train loss: 0.2156 took: 1.79s  Val. loss: 0.2142\n",
      "Epoch 11, 100% \t Train loss: 0.2090 took: 1.79s  Val. loss: 0.2069\n",
      "Epoch 12, 100% \t Train loss: 0.2024 took: 1.79s  Val. loss: 0.2017\n",
      "Epoch 13, 100% \t Train loss: 0.1976 took: 1.78s  Val. loss: 0.1975\n",
      "Epoch 14, 100% \t Train loss: 0.1942 took: 1.77s  Val. loss: 0.1939\n",
      "Epoch 15, 100% \t Train loss: 0.1922 took: 1.76s  Val. loss: 0.1914\n",
      "Epoch 16, 100% \t Train loss: 0.1914 took: 1.79s  Val. loss: 0.1929\n",
      "Epoch 17, 100% \t Train loss: 0.1903 took: 1.80s  Val. loss: 0.1942\n",
      "Epoch 18, 100% \t Train loss: 0.1898 took: 1.82s  Val. loss: 0.1920\n",
      "Epoch 19, 100% \t Train loss: 0.1899 took: 1.80s  Val. loss: 0.1933\n",
      "Epoch 20, 100% \t Train loss: 0.1896 took: 1.81s  Val. loss: 0.1913\n",
      "Epoch 21, 100% \t Train loss: 0.1885 took: 1.80s  Val. loss: 0.1948\n",
      "Epoch 22, 100% \t Train loss: 0.1879 took: 1.80s  Val. loss: 0.1894\n",
      "Epoch 23, 100% \t Train loss: 0.1886 took: 1.78s  Val. loss: 0.1895\n",
      "Epoch 24, 100% \t Train loss: 0.1871 took: 1.79s  Val. loss: 0.1908\n",
      "Epoch 25, 100% \t Train loss: 0.1862 took: 1.79s  Val. loss: 0.1884\n",
      "Epoch 26, 100% \t Train loss: 0.1868 took: 1.81s  Val. loss: 0.1932\n",
      "Epoch 27, 100% \t Train loss: 0.1869 took: 1.80s  Val. loss: 0.1889\n",
      "Epoch 28, 100% \t Train loss: 0.1865 took: 1.79s  Val. loss: 0.1896\n",
      "Epoch 29, 100% \t Train loss: 0.1862 took: 1.83s  Val. loss: 0.1891\n",
      "Epoch 30, 100% \t Train loss: 0.1852 took: 1.82s  Val. loss: 0.1910\n",
      "Epoch 31, 100% \t Train loss: 0.1850 took: 1.83s  Val. loss: 0.1892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, 100% \t Train loss: 0.1848 took: 1.83s  Val. loss: 0.1893\n",
      "Epoch 33, 100% \t Train loss: 0.1853 took: 1.84s  Val. loss: 0.1874\n",
      "Epoch 34, 100% \t Train loss: 0.1847 took: 1.85s  Val. loss: 0.1885\n",
      "Epoch 35, 100% \t Train loss: 0.1839 took: 1.84s  Val. loss: 0.1892\n",
      "Epoch 36, 100% \t Train loss: 0.1848 took: 1.84s  Val. loss: 0.1902\n",
      "Epoch 37, 100% \t Train loss: 0.1839 took: 1.84s  Val. loss: 0.1889\n",
      "Epoch 38, 100% \t Train loss: 0.1837 took: 1.84s  Val. loss: 0.1880\n",
      "Epoch 39, 100% \t Train loss: 0.1834 took: 1.84s  Val. loss: 0.1892\n",
      "Epoch 40, 100% \t Train loss: 0.1839 took: 1.87s  Val. loss: 0.1879\n",
      "Epoch 41, 100% \t Train loss: 0.1837 took: 1.87s  Val. loss: 0.1891\n",
      "Epoch 42, 100% \t Train loss: 0.1826 took: 1.84s  Val. loss: 0.1893\n",
      "Epoch 43, 100% \t Train loss: 0.1833 took: 1.86s  Val. loss: 0.1898\n",
      "Epoch 44, 100% \t Train loss: 0.1832 took: 1.86s  Val. loss: 0.1866\n",
      "Epoch 45, 100% \t Train loss: 0.1828 took: 1.85s  Val. loss: 0.1885\n",
      "Epoch 46, 100% \t Train loss: 0.1828 took: 1.83s  Val. loss: 0.1883\n",
      "Epoch 47, 100% \t Train loss: 0.1833 took: 1.86s  Val. loss: 0.1895\n",
      "Epoch 48, 100% \t Train loss: 0.1823 took: 1.85s  Val. loss: 0.1890\n",
      "Epoch 49, 100% \t Train loss: 0.1814 took: 1.88s  Val. loss: 0.1885\n",
      "Epoch 50, 100% \t Train loss: 0.1826 took: 1.89s  Val. loss: 0.1870\n",
      "Training finished, took 103.34s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.30\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.27\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.824006\n",
      "lambda: 0.0010 - V: 0.802196\n",
      "lambda: 0.0005 - V: 0.798424\n",
      "Average V: 0.808209\n",
      "Time elapsed: 265.04 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2598 took: 1.94s  Val. loss: 0.2608\n",
      "Epoch 2, 100% \t Train loss: 0.2092 took: 1.94s  Val. loss: 0.1751\n",
      "Epoch 3, 100% \t Train loss: 0.1751 took: 1.92s  Val. loss: 0.1680\n",
      "Epoch 4, 100% \t Train loss: 0.1687 took: 1.94s  Val. loss: 0.1580\n",
      "Epoch 5, 100% \t Train loss: 0.1618 took: 1.93s  Val. loss: 0.1511\n",
      "Epoch 6, 100% \t Train loss: 0.1570 took: 1.93s  Val. loss: 0.1538\n",
      "Epoch 7, 100% \t Train loss: 0.1554 took: 1.94s  Val. loss: 0.1498\n",
      "Epoch 8, 100% \t Train loss: 0.1539 took: 1.93s  Val. loss: 0.1473\n",
      "Epoch 9, 100% \t Train loss: 0.1528 took: 1.92s  Val. loss: 0.1485\n",
      "Epoch 10, 100% \t Train loss: 0.1512 took: 1.94s  Val. loss: 0.1490\n",
      "Epoch 11, 100% \t Train loss: 0.1521 took: 1.92s  Val. loss: 0.1470\n",
      "Epoch 12, 100% \t Train loss: 0.1505 took: 1.95s  Val. loss: 0.1495\n",
      "Epoch 13, 100% \t Train loss: 0.1496 took: 1.93s  Val. loss: 0.1477\n",
      "Epoch 14, 100% \t Train loss: 0.1492 took: 1.93s  Val. loss: 0.1502\n",
      "Epoch 15, 100% \t Train loss: 0.1486 took: 1.95s  Val. loss: 0.1466\n",
      "Epoch 16, 100% \t Train loss: 0.1475 took: 1.91s  Val. loss: 0.1477\n",
      "Epoch 17, 100% \t Train loss: 0.1470 took: 1.92s  Val. loss: 0.1463\n",
      "Epoch 18, 100% \t Train loss: 0.1469 took: 1.12s  Val. loss: 0.1487\n",
      "Epoch 19, 100% \t Train loss: 0.1462 took: 1.12s  Val. loss: 0.1467\n",
      "Epoch 20, 100% \t Train loss: 0.1454 took: 1.12s  Val. loss: 0.1452\n",
      "Epoch 21, 100% \t Train loss: 0.1442 took: 1.11s  Val. loss: 0.1452\n",
      "Epoch 22, 100% \t Train loss: 0.1405 took: 1.12s  Val. loss: 0.1443\n",
      "Epoch 23, 100% \t Train loss: 0.1333 took: 1.12s  Val. loss: 0.1388\n",
      "Epoch 24, 100% \t Train loss: 0.1221 took: 1.12s  Val. loss: 0.1237\n",
      "Epoch 25, 100% \t Train loss: 0.1117 took: 1.12s  Val. loss: 0.1176\n",
      "Epoch 26, 100% \t Train loss: 0.1031 took: 1.12s  Val. loss: 0.1068\n",
      "Epoch 27, 100% \t Train loss: 0.0965 took: 1.13s  Val. loss: 0.1006\n",
      "Epoch 28, 100% \t Train loss: 0.0910 took: 1.14s  Val. loss: 0.0965\n",
      "Epoch 29, 100% \t Train loss: 0.0872 took: 1.15s  Val. loss: 0.0948\n",
      "Epoch 30, 100% \t Train loss: 0.0850 took: 1.16s  Val. loss: 0.0939\n",
      "Epoch 31, 100% \t Train loss: 0.0835 took: 1.19s  Val. loss: 0.0908\n",
      "Epoch 32, 100% \t Train loss: 0.0815 took: 1.29s  Val. loss: 0.0922\n",
      "Epoch 33, 100% \t Train loss: 0.0797 took: 1.36s  Val. loss: 0.0881\n",
      "Epoch 34, 100% \t Train loss: 0.0794 took: 1.36s  Val. loss: 0.0878\n",
      "Epoch 35, 100% \t Train loss: 0.0776 took: 1.36s  Val. loss: 0.0863\n",
      "Epoch 36, 100% \t Train loss: 0.0768 took: 1.36s  Val. loss: 0.0866\n",
      "Epoch 37, 100% \t Train loss: 0.0764 took: 1.36s  Val. loss: 0.0879\n",
      "Epoch 38, 100% \t Train loss: 0.0754 took: 1.36s  Val. loss: 0.0860\n",
      "Epoch 39, 100% \t Train loss: 0.0749 took: 1.36s  Val. loss: 0.0832\n",
      "Epoch 40, 100% \t Train loss: 0.0752 took: 1.86s  Val. loss: 0.0852\n",
      "Epoch 41, 100% \t Train loss: 0.0740 took: 2.20s  Val. loss: 0.0822\n",
      "Epoch 42, 100% \t Train loss: 0.0738 took: 2.16s  Val. loss: 0.0812\n",
      "Epoch 43, 100% \t Train loss: 0.0729 took: 2.17s  Val. loss: 0.0830\n",
      "Epoch 44, 100% \t Train loss: 0.0723 took: 2.17s  Val. loss: 0.0816\n",
      "Epoch 45, 100% \t Train loss: 0.0726 took: 2.18s  Val. loss: 0.0837\n",
      "Epoch 46, 100% \t Train loss: 0.0723 took: 2.17s  Val. loss: 0.0844\n",
      "Epoch 47, 100% \t Train loss: 0.0719 took: 2.17s  Val. loss: 0.0839\n",
      "Epoch 48, 100% \t Train loss: 0.0717 took: 2.19s  Val. loss: 0.0810\n",
      "Epoch 49, 100% \t Train loss: 0.0709 took: 2.18s  Val. loss: 0.0827\n",
      "Epoch 50, 100% \t Train loss: 0.0702 took: 2.15s  Val. loss: 0.0810\n",
      "Training finished, took 94.22s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2583 took: 1.94s  Val. loss: 0.2609\n",
      "Epoch 2, 100% \t Train loss: 0.2547 took: 1.93s  Val. loss: 0.2531\n",
      "Epoch 3, 100% \t Train loss: 0.2167 took: 1.92s  Val. loss: 0.1878\n",
      "Epoch 4, 100% \t Train loss: 0.1765 took: 1.91s  Val. loss: 0.1787\n",
      "Epoch 5, 100% \t Train loss: 0.1698 took: 1.90s  Val. loss: 0.1804\n",
      "Epoch 6, 100% \t Train loss: 0.1687 took: 1.91s  Val. loss: 0.1726\n",
      "Epoch 7, 100% \t Train loss: 0.1647 took: 1.92s  Val. loss: 0.1703\n",
      "Epoch 8, 100% \t Train loss: 0.1597 took: 1.90s  Val. loss: 0.1689\n",
      "Epoch 9, 100% \t Train loss: 0.1584 took: 1.92s  Val. loss: 0.1678\n",
      "Epoch 10, 100% \t Train loss: 0.1566 took: 1.93s  Val. loss: 0.1667\n",
      "Epoch 11, 100% \t Train loss: 0.1546 took: 1.94s  Val. loss: 0.1687\n",
      "Epoch 12, 100% \t Train loss: 0.1538 took: 1.94s  Val. loss: 0.1733\n",
      "Epoch 13, 100% \t Train loss: 0.1535 took: 1.94s  Val. loss: 0.1664\n",
      "Epoch 14, 100% \t Train loss: 0.1520 took: 1.93s  Val. loss: 0.1656\n",
      "Epoch 15, 100% \t Train loss: 0.1518 took: 1.95s  Val. loss: 0.1642\n",
      "Epoch 16, 100% \t Train loss: 0.1522 took: 1.96s  Val. loss: 0.1636\n",
      "Epoch 17, 100% \t Train loss: 0.1505 took: 1.94s  Val. loss: 0.1646\n",
      "Epoch 18, 100% \t Train loss: 0.1492 took: 1.94s  Val. loss: 0.1642\n",
      "Epoch 19, 100% \t Train loss: 0.1477 took: 1.93s  Val. loss: 0.1620\n",
      "Epoch 20, 100% \t Train loss: 0.1461 took: 1.94s  Val. loss: 0.1605\n",
      "Epoch 21, 100% \t Train loss: 0.1447 took: 1.94s  Val. loss: 0.1646\n",
      "Epoch 22, 100% \t Train loss: 0.1443 took: 1.94s  Val. loss: 0.1594\n",
      "Epoch 23, 100% \t Train loss: 0.1422 took: 1.95s  Val. loss: 0.1600\n",
      "Epoch 24, 100% \t Train loss: 0.1407 took: 1.93s  Val. loss: 0.1576\n",
      "Epoch 25, 100% \t Train loss: 0.1383 took: 1.93s  Val. loss: 0.1557\n",
      "Epoch 26, 100% \t Train loss: 0.1358 took: 1.93s  Val. loss: 0.1528\n",
      "Epoch 27, 100% \t Train loss: 0.1335 took: 1.94s  Val. loss: 0.1523\n",
      "Epoch 28, 100% \t Train loss: 0.1314 took: 1.94s  Val. loss: 0.1501\n",
      "Epoch 29, 100% \t Train loss: 0.1311 took: 1.93s  Val. loss: 0.1492\n",
      "Epoch 30, 100% \t Train loss: 0.1300 took: 1.93s  Val. loss: 0.1497\n",
      "Epoch 31, 100% \t Train loss: 0.1262 took: 1.96s  Val. loss: 0.1475\n",
      "Epoch 32, 100% \t Train loss: 0.1247 took: 1.97s  Val. loss: 0.1508\n",
      "Epoch 33, 100% \t Train loss: 0.1232 took: 1.96s  Val. loss: 0.1429\n",
      "Epoch 34, 100% \t Train loss: 0.1218 took: 1.96s  Val. loss: 0.1417\n",
      "Epoch 35, 100% \t Train loss: 0.1190 took: 1.96s  Val. loss: 0.1393\n",
      "Epoch 36, 100% \t Train loss: 0.1191 took: 2.00s  Val. loss: 0.1381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, 100% \t Train loss: 0.1160 took: 2.00s  Val. loss: 0.1373\n",
      "Epoch 38, 100% \t Train loss: 0.1138 took: 1.99s  Val. loss: 0.1353\n",
      "Epoch 39, 100% \t Train loss: 0.1116 took: 2.00s  Val. loss: 0.1375\n",
      "Epoch 40, 100% \t Train loss: 0.1114 took: 2.02s  Val. loss: 0.1316\n",
      "Epoch 41, 100% \t Train loss: 0.1082 took: 2.01s  Val. loss: 0.1335\n",
      "Epoch 42, 100% \t Train loss: 0.1092 took: 2.01s  Val. loss: 0.1275\n",
      "Epoch 43, 100% \t Train loss: 0.1078 took: 2.00s  Val. loss: 0.1256\n",
      "Epoch 44, 100% \t Train loss: 0.1047 took: 2.00s  Val. loss: 0.1279\n",
      "Epoch 45, 100% \t Train loss: 0.1052 took: 2.01s  Val. loss: 0.1287\n",
      "Epoch 46, 100% \t Train loss: 0.1030 took: 2.03s  Val. loss: 0.1262\n",
      "Epoch 47, 100% \t Train loss: 0.1015 took: 2.07s  Val. loss: 0.1241\n",
      "Epoch 48, 100% \t Train loss: 0.1016 took: 2.12s  Val. loss: 0.1280\n",
      "Epoch 49, 100% \t Train loss: 0.1021 took: 2.15s  Val. loss: 0.1203\n",
      "Epoch 50, 100% \t Train loss: 0.0998 took: 2.13s  Val. loss: 0.1246\n",
      "Training finished, took 111.36s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2577 took: 1.92s  Val. loss: 0.2560\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 1.94s  Val. loss: 0.2576\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 1.93s  Val. loss: 0.2584\n",
      "Epoch 4, 100% \t Train loss: 0.2579 took: 1.95s  Val. loss: 0.2567\n",
      "Epoch 5, 100% \t Train loss: 0.2576 took: 1.92s  Val. loss: 0.2564\n",
      "Epoch 6, 100% \t Train loss: 0.2578 took: 1.91s  Val. loss: 0.2568\n",
      "Epoch 7, 100% \t Train loss: 0.2578 took: 1.94s  Val. loss: 0.2560\n",
      "Epoch 8, 100% \t Train loss: 0.2576 took: 1.91s  Val. loss: 0.2566\n",
      "Epoch 9, 100% \t Train loss: 0.2577 took: 1.93s  Val. loss: 0.2570\n",
      "Epoch 10, 100% \t Train loss: 0.2576 took: 1.92s  Val. loss: 0.2572\n",
      "Epoch 11, 100% \t Train loss: 0.2576 took: 1.92s  Val. loss: 0.2570\n",
      "Epoch 12, 100% \t Train loss: 0.2574 took: 1.94s  Val. loss: 0.2563\n",
      "Epoch 13, 100% \t Train loss: 0.2575 took: 1.94s  Val. loss: 0.2563\n",
      "Epoch 14, 100% \t Train loss: 0.2572 took: 1.93s  Val. loss: 0.2565\n",
      "Epoch 15, 100% \t Train loss: 0.2567 took: 1.13s  Val. loss: 0.2555\n",
      "Epoch 16, 100% \t Train loss: 0.2538 took: 1.12s  Val. loss: 0.2501\n",
      "Epoch 17, 100% \t Train loss: 0.2450 took: 1.13s  Val. loss: 0.2376\n",
      "Epoch 18, 100% \t Train loss: 0.2311 took: 1.13s  Val. loss: 0.2186\n",
      "Epoch 19, 100% \t Train loss: 0.2129 took: 1.13s  Val. loss: 0.1941\n",
      "Epoch 20, 100% \t Train loss: 0.1956 took: 1.13s  Val. loss: 0.1822\n",
      "Epoch 21, 100% \t Train loss: 0.1863 took: 1.12s  Val. loss: 0.1716\n",
      "Epoch 22, 100% \t Train loss: 0.1833 took: 1.47s  Val. loss: 0.1724\n",
      "Epoch 23, 100% \t Train loss: 0.1821 took: 1.93s  Val. loss: 0.1697\n",
      "Epoch 24, 100% \t Train loss: 0.1785 took: 1.93s  Val. loss: 0.1710\n",
      "Epoch 25, 100% \t Train loss: 0.1798 took: 1.95s  Val. loss: 0.1721\n",
      "Epoch 26, 100% \t Train loss: 0.1760 took: 1.94s  Val. loss: 0.1638\n",
      "Epoch 27, 100% \t Train loss: 0.1729 took: 1.93s  Val. loss: 0.1612\n",
      "Epoch 28, 100% \t Train loss: 0.1725 took: 1.93s  Val. loss: 0.1613\n",
      "Epoch 29, 100% \t Train loss: 0.1708 took: 1.13s  Val. loss: 0.1575\n",
      "Epoch 30, 100% \t Train loss: 0.1730 took: 1.13s  Val. loss: 0.1636\n",
      "Epoch 31, 100% \t Train loss: 0.1710 took: 1.14s  Val. loss: 0.1616\n",
      "Epoch 32, 100% \t Train loss: 0.1720 took: 1.15s  Val. loss: 0.1617\n",
      "Epoch 33, 100% \t Train loss: 0.1681 took: 1.16s  Val. loss: 0.1604\n",
      "Epoch 34, 100% \t Train loss: 0.1675 took: 1.17s  Val. loss: 0.1569\n",
      "Epoch 35, 100% \t Train loss: 0.1663 took: 1.19s  Val. loss: 0.1591\n",
      "Epoch 36, 100% \t Train loss: 0.1670 took: 1.18s  Val. loss: 0.1710\n",
      "Epoch 37, 100% \t Train loss: 0.1661 took: 1.19s  Val. loss: 0.1554\n",
      "Epoch 38, 100% \t Train loss: 0.1638 took: 1.19s  Val. loss: 0.1562\n",
      "Epoch 39, 100% \t Train loss: 0.1657 took: 1.19s  Val. loss: 0.1579\n",
      "Epoch 40, 100% \t Train loss: 0.1648 took: 1.19s  Val. loss: 0.1586\n",
      "Epoch 41, 100% \t Train loss: 0.1652 took: 1.18s  Val. loss: 0.1517\n",
      "Epoch 42, 100% \t Train loss: 0.1613 took: 1.19s  Val. loss: 0.1533\n",
      "Epoch 43, 100% \t Train loss: 0.1609 took: 1.18s  Val. loss: 0.1572\n",
      "Epoch 44, 100% \t Train loss: 0.1621 took: 1.18s  Val. loss: 0.1514\n",
      "Epoch 45, 100% \t Train loss: 0.1622 took: 1.19s  Val. loss: 0.1501\n",
      "Epoch 46, 100% \t Train loss: 0.1607 took: 1.19s  Val. loss: 0.1516\n",
      "Epoch 47, 100% \t Train loss: 0.1597 took: 1.20s  Val. loss: 0.1494\n",
      "Epoch 48, 100% \t Train loss: 0.1614 took: 1.20s  Val. loss: 0.1555\n",
      "Epoch 49, 100% \t Train loss: 0.1596 took: 1.19s  Val. loss: 0.1516\n",
      "Epoch 50, 100% \t Train loss: 0.1600 took: 1.20s  Val. loss: 0.1510\n",
      "Training finished, took 83.32s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.880040\n",
      "lambda: 0.0010 - V: 0.844395\n",
      "lambda: 0.0005 - V: 0.805623\n",
      "Average V: 0.843353\n",
      "Time elapsed: 292.39 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.30\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.20\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2621 took: 1.04s  Val. loss: 0.2628\n",
      "Epoch 2, 100% \t Train loss: 0.2613 took: 1.12s  Val. loss: 0.2616\n",
      "Epoch 3, 100% \t Train loss: 0.2612 took: 1.03s  Val. loss: 0.2625\n",
      "Epoch 4, 100% \t Train loss: 0.2567 took: 1.03s  Val. loss: 0.2409\n",
      "Epoch 5, 100% \t Train loss: 0.2120 took: 1.03s  Val. loss: 0.2067\n",
      "Epoch 6, 100% \t Train loss: 0.1989 took: 1.03s  Val. loss: 0.2007\n",
      "Epoch 7, 100% \t Train loss: 0.1948 took: 1.03s  Val. loss: 0.1984\n",
      "Epoch 8, 100% \t Train loss: 0.1927 took: 1.03s  Val. loss: 0.1980\n",
      "Epoch 9, 100% \t Train loss: 0.1910 took: 1.04s  Val. loss: 0.1981\n",
      "Epoch 10, 100% \t Train loss: 0.1887 took: 1.04s  Val. loss: 0.1928\n",
      "Epoch 11, 100% \t Train loss: 0.1876 took: 1.03s  Val. loss: 0.1930\n",
      "Epoch 12, 100% \t Train loss: 0.1862 took: 1.03s  Val. loss: 0.1927\n",
      "Epoch 13, 100% \t Train loss: 0.1848 took: 1.03s  Val. loss: 0.1931\n",
      "Epoch 14, 100% \t Train loss: 0.1847 took: 1.61s  Val. loss: 0.1918\n",
      "Epoch 15, 100% \t Train loss: 0.1839 took: 1.80s  Val. loss: 0.1923\n",
      "Epoch 16, 100% \t Train loss: 0.1820 took: 1.80s  Val. loss: 0.1909\n",
      "Epoch 17, 100% \t Train loss: 0.1800 took: 1.81s  Val. loss: 0.1875\n",
      "Epoch 18, 100% \t Train loss: 0.1756 took: 1.78s  Val. loss: 0.1829\n",
      "Epoch 19, 100% \t Train loss: 0.1717 took: 1.79s  Val. loss: 0.1767\n",
      "Epoch 20, 100% \t Train loss: 0.1697 took: 1.78s  Val. loss: 0.1780\n",
      "Epoch 21, 100% \t Train loss: 0.1685 took: 1.78s  Val. loss: 0.1787\n",
      "Epoch 22, 100% \t Train loss: 0.1658 took: 1.78s  Val. loss: 0.1733\n",
      "Epoch 23, 100% \t Train loss: 0.1649 took: 1.78s  Val. loss: 0.1764\n",
      "Epoch 24, 100% \t Train loss: 0.1628 took: 1.79s  Val. loss: 0.1697\n",
      "Epoch 25, 100% \t Train loss: 0.1609 took: 1.79s  Val. loss: 0.1708\n",
      "Epoch 26, 100% \t Train loss: 0.1587 took: 1.80s  Val. loss: 0.1703\n",
      "Epoch 27, 100% \t Train loss: 0.1583 took: 1.80s  Val. loss: 0.1723\n",
      "Epoch 28, 100% \t Train loss: 0.1575 took: 1.80s  Val. loss: 0.1676\n",
      "Epoch 29, 100% \t Train loss: 0.1575 took: 1.78s  Val. loss: 0.1666\n",
      "Epoch 30, 100% \t Train loss: 0.1566 took: 1.79s  Val. loss: 0.1693\n",
      "Epoch 31, 100% \t Train loss: 0.1556 took: 1.84s  Val. loss: 0.1640\n",
      "Epoch 32, 100% \t Train loss: 0.1543 took: 2.02s  Val. loss: 0.1642\n",
      "Epoch 33, 100% \t Train loss: 0.1525 took: 2.15s  Val. loss: 0.1625\n",
      "Epoch 34, 100% \t Train loss: 0.1506 took: 2.21s  Val. loss: 0.1613\n",
      "Epoch 35, 100% \t Train loss: 0.1488 took: 2.18s  Val. loss: 0.1566\n",
      "Epoch 36, 100% \t Train loss: 0.1467 took: 2.19s  Val. loss: 0.1566\n",
      "Epoch 37, 100% \t Train loss: 0.1451 took: 2.20s  Val. loss: 0.1582\n",
      "Epoch 38, 100% \t Train loss: 0.1434 took: 2.18s  Val. loss: 0.1558\n",
      "Epoch 39, 100% \t Train loss: 0.1422 took: 1.87s  Val. loss: 0.1562\n",
      "Epoch 40, 100% \t Train loss: 0.1418 took: 2.17s  Val. loss: 0.1504\n",
      "Epoch 41, 100% \t Train loss: 0.1411 took: 2.17s  Val. loss: 0.1512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, 100% \t Train loss: 0.1407 took: 2.17s  Val. loss: 0.1511\n",
      "Epoch 43, 100% \t Train loss: 0.1402 took: 2.17s  Val. loss: 0.1550\n",
      "Epoch 44, 100% \t Train loss: 0.1405 took: 2.19s  Val. loss: 0.1513\n",
      "Epoch 45, 100% \t Train loss: 0.1397 took: 2.19s  Val. loss: 0.1577\n",
      "Epoch 46, 100% \t Train loss: 0.1392 took: 2.20s  Val. loss: 0.1534\n",
      "Epoch 47, 100% \t Train loss: 0.1385 took: 2.20s  Val. loss: 0.1503\n",
      "Epoch 48, 100% \t Train loss: 0.1370 took: 2.19s  Val. loss: 0.1549\n",
      "Epoch 49, 100% \t Train loss: 0.1371 took: 2.17s  Val. loss: 0.1523\n",
      "Epoch 50, 100% \t Train loss: 0.1381 took: 2.18s  Val. loss: 0.1511\n",
      "Training finished, took 98.65s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 1.81s  Val. loss: 0.2652\n",
      "Epoch 2, 100% \t Train loss: 0.2589 took: 1.06s  Val. loss: 0.2645\n",
      "Epoch 3, 100% \t Train loss: 0.2570 took: 1.03s  Val. loss: 0.2583\n",
      "Epoch 4, 100% \t Train loss: 0.2434 took: 1.02s  Val. loss: 0.2247\n",
      "Epoch 5, 100% \t Train loss: 0.2126 took: 1.03s  Val. loss: 0.1935\n",
      "Epoch 6, 100% \t Train loss: 0.2015 took: 1.03s  Val. loss: 0.1891\n",
      "Epoch 7, 100% \t Train loss: 0.1989 took: 1.20s  Val. loss: 0.1877\n",
      "Epoch 8, 100% \t Train loss: 0.1970 took: 1.78s  Val. loss: 0.1879\n",
      "Epoch 9, 100% \t Train loss: 0.1965 took: 1.78s  Val. loss: 0.1848\n",
      "Epoch 10, 100% \t Train loss: 0.1954 took: 1.78s  Val. loss: 0.1846\n",
      "Epoch 11, 100% \t Train loss: 0.1939 took: 1.79s  Val. loss: 0.1836\n",
      "Epoch 12, 100% \t Train loss: 0.1926 took: 1.77s  Val. loss: 0.1832\n",
      "Epoch 13, 100% \t Train loss: 0.1921 took: 1.79s  Val. loss: 0.1881\n",
      "Epoch 14, 100% \t Train loss: 0.1923 took: 1.80s  Val. loss: 0.1848\n",
      "Epoch 15, 100% \t Train loss: 0.1921 took: 1.78s  Val. loss: 0.1856\n",
      "Epoch 16, 100% \t Train loss: 0.1904 took: 1.78s  Val. loss: 0.1813\n",
      "Epoch 17, 100% \t Train loss: 0.1898 took: 1.79s  Val. loss: 0.1813\n",
      "Epoch 18, 100% \t Train loss: 0.1891 took: 1.78s  Val. loss: 0.1837\n",
      "Epoch 19, 100% \t Train loss: 0.1899 took: 1.78s  Val. loss: 0.1827\n",
      "Epoch 20, 100% \t Train loss: 0.1891 took: 1.77s  Val. loss: 0.1818\n",
      "Epoch 21, 100% \t Train loss: 0.1882 took: 1.77s  Val. loss: 0.1841\n",
      "Epoch 22, 100% \t Train loss: 0.1886 took: 1.78s  Val. loss: 0.1815\n",
      "Epoch 23, 100% \t Train loss: 0.1877 took: 1.79s  Val. loss: 0.1836\n",
      "Epoch 24, 100% \t Train loss: 0.1876 took: 1.80s  Val. loss: 0.1804\n",
      "Epoch 25, 100% \t Train loss: 0.1874 took: 1.78s  Val. loss: 0.1823\n",
      "Epoch 26, 100% \t Train loss: 0.1881 took: 1.81s  Val. loss: 0.1817\n",
      "Epoch 27, 100% \t Train loss: 0.1880 took: 1.04s  Val. loss: 0.1815\n",
      "Epoch 28, 100% \t Train loss: 0.1883 took: 1.03s  Val. loss: 0.1812\n",
      "Epoch 29, 100% \t Train loss: 0.1868 took: 1.04s  Val. loss: 0.1811\n",
      "Epoch 30, 100% \t Train loss: 0.1866 took: 1.04s  Val. loss: 0.1847\n",
      "Epoch 31, 100% \t Train loss: 0.1868 took: 1.05s  Val. loss: 0.1817\n",
      "Epoch 32, 100% \t Train loss: 0.1867 took: 1.10s  Val. loss: 0.1903\n",
      "Epoch 33, 100% \t Train loss: 0.1869 took: 1.10s  Val. loss: 0.1820\n",
      "Epoch 34, 100% \t Train loss: 0.1868 took: 1.10s  Val. loss: 0.1801\n",
      "Epoch 35, 100% \t Train loss: 0.1869 took: 1.11s  Val. loss: 0.1816\n",
      "Epoch 36, 100% \t Train loss: 0.1861 took: 1.13s  Val. loss: 0.1845\n",
      "Epoch 37, 100% \t Train loss: 0.1866 took: 1.11s  Val. loss: 0.1817\n",
      "Epoch 38, 100% \t Train loss: 0.1852 took: 1.11s  Val. loss: 0.1801\n",
      "Epoch 39, 100% \t Train loss: 0.1856 took: 1.86s  Val. loss: 0.1823\n",
      "Epoch 40, 100% \t Train loss: 0.1857 took: 1.86s  Val. loss: 0.1823\n",
      "Epoch 41, 100% \t Train loss: 0.1856 took: 1.86s  Val. loss: 0.1811\n",
      "Epoch 42, 100% \t Train loss: 0.1862 took: 1.87s  Val. loss: 0.1789\n",
      "Epoch 43, 100% \t Train loss: 0.1857 took: 1.86s  Val. loss: 0.1796\n",
      "Epoch 44, 100% \t Train loss: 0.1854 took: 1.84s  Val. loss: 0.1808\n",
      "Epoch 45, 100% \t Train loss: 0.1848 took: 1.85s  Val. loss: 0.1801\n",
      "Epoch 46, 100% \t Train loss: 0.1848 took: 1.86s  Val. loss: 0.1784\n",
      "Epoch 47, 100% \t Train loss: 0.1850 took: 1.87s  Val. loss: 0.1794\n",
      "Epoch 48, 100% \t Train loss: 0.1851 took: 1.87s  Val. loss: 0.1804\n",
      "Epoch 49, 100% \t Train loss: 0.1845 took: 1.88s  Val. loss: 0.1814\n",
      "Epoch 50, 100% \t Train loss: 0.1849 took: 1.87s  Val. loss: 0.1832\n",
      "Training finished, took 88.25s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2581 took: 1.79s  Val. loss: 0.2557\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 1.80s  Val. loss: 0.2576\n",
      "Epoch 3, 100% \t Train loss: 0.2564 took: 1.79s  Val. loss: 0.2560\n",
      "Epoch 4, 100% \t Train loss: 0.2564 took: 1.79s  Val. loss: 0.2563\n",
      "Epoch 5, 100% \t Train loss: 0.2564 took: 1.79s  Val. loss: 0.2561\n",
      "Epoch 6, 100% \t Train loss: 0.2563 took: 1.77s  Val. loss: 0.2565\n",
      "Epoch 7, 100% \t Train loss: 0.2564 took: 1.81s  Val. loss: 0.2565\n",
      "Epoch 8, 100% \t Train loss: 0.2563 took: 1.81s  Val. loss: 0.2568\n",
      "Epoch 9, 100% \t Train loss: 0.2562 took: 1.80s  Val. loss: 0.2564\n",
      "Epoch 10, 100% \t Train loss: 0.2560 took: 1.81s  Val. loss: 0.2552\n",
      "Epoch 11, 100% \t Train loss: 0.2555 took: 1.79s  Val. loss: 0.2544\n",
      "Epoch 12, 100% \t Train loss: 0.2542 took: 1.80s  Val. loss: 0.2520\n",
      "Epoch 13, 100% \t Train loss: 0.2511 took: 1.84s  Val. loss: 0.2463\n",
      "Epoch 14, 100% \t Train loss: 0.2438 took: 1.78s  Val. loss: 0.2365\n",
      "Epoch 15, 100% \t Train loss: 0.2313 took: 1.78s  Val. loss: 0.2230\n",
      "Epoch 16, 100% \t Train loss: 0.2195 took: 1.78s  Val. loss: 0.2117\n",
      "Epoch 17, 100% \t Train loss: 0.2124 took: 1.02s  Val. loss: 0.2087\n",
      "Epoch 18, 100% \t Train loss: 0.2084 took: 1.02s  Val. loss: 0.2096\n",
      "Epoch 19, 100% \t Train loss: 0.2064 took: 1.03s  Val. loss: 0.2056\n",
      "Epoch 20, 100% \t Train loss: 0.2053 took: 1.03s  Val. loss: 0.2038\n",
      "Epoch 21, 100% \t Train loss: 0.2046 took: 1.02s  Val. loss: 0.2037\n",
      "Epoch 22, 100% \t Train loss: 0.2038 took: 1.02s  Val. loss: 0.2047\n",
      "Epoch 23, 100% \t Train loss: 0.2033 took: 1.03s  Val. loss: 0.2039\n",
      "Epoch 24, 100% \t Train loss: 0.2032 took: 1.03s  Val. loss: 0.2023\n",
      "Epoch 25, 100% \t Train loss: 0.2026 took: 1.03s  Val. loss: 0.2024\n",
      "Epoch 26, 100% \t Train loss: 0.2019 took: 1.03s  Val. loss: 0.2026\n",
      "Epoch 27, 100% \t Train loss: 0.2014 took: 1.04s  Val. loss: 0.2023\n",
      "Epoch 28, 100% \t Train loss: 0.2011 took: 1.04s  Val. loss: 0.1991\n",
      "Epoch 29, 100% \t Train loss: 0.2006 took: 1.05s  Val. loss: 0.2025\n",
      "Epoch 30, 100% \t Train loss: 0.2003 took: 1.05s  Val. loss: 0.1987\n",
      "Epoch 31, 100% \t Train loss: 0.1995 took: 1.07s  Val. loss: 0.1996\n",
      "Epoch 32, 100% \t Train loss: 0.1990 took: 1.09s  Val. loss: 0.1994\n",
      "Epoch 33, 100% \t Train loss: 0.1982 took: 1.09s  Val. loss: 0.1974\n",
      "Epoch 34, 100% \t Train loss: 0.1974 took: 1.09s  Val. loss: 0.1982\n",
      "Epoch 35, 100% \t Train loss: 0.1970 took: 1.09s  Val. loss: 0.2000\n",
      "Epoch 36, 100% \t Train loss: 0.1957 took: 1.09s  Val. loss: 0.1978\n",
      "Epoch 37, 100% \t Train loss: 0.1948 took: 1.10s  Val. loss: 0.1923\n",
      "Epoch 38, 100% \t Train loss: 0.1941 took: 1.10s  Val. loss: 0.1912\n",
      "Epoch 39, 100% \t Train loss: 0.1928 took: 1.11s  Val. loss: 0.1897\n",
      "Epoch 40, 100% \t Train loss: 0.1920 took: 1.12s  Val. loss: 0.1877\n",
      "Epoch 41, 100% \t Train loss: 0.1910 took: 1.13s  Val. loss: 0.1927\n",
      "Epoch 42, 100% \t Train loss: 0.1905 took: 1.12s  Val. loss: 0.1882\n",
      "Epoch 43, 100% \t Train loss: 0.1897 took: 1.13s  Val. loss: 0.1876\n",
      "Epoch 44, 100% \t Train loss: 0.1891 took: 1.13s  Val. loss: 0.1869\n",
      "Epoch 45, 100% \t Train loss: 0.1890 took: 1.81s  Val. loss: 0.1852\n",
      "Epoch 46, 100% \t Train loss: 0.1893 took: 1.89s  Val. loss: 0.1851\n",
      "Epoch 47, 100% \t Train loss: 0.1881 took: 1.85s  Val. loss: 0.1858\n",
      "Epoch 48, 100% \t Train loss: 0.1877 took: 1.87s  Val. loss: 0.1846\n",
      "Epoch 49, 100% \t Train loss: 0.1875 took: 1.88s  Val. loss: 0.1837\n",
      "Epoch 50, 100% \t Train loss: 0.1872 took: 1.87s  Val. loss: 0.1833\n",
      "Training finished, took 79.22s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.30\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.20\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.821394\n",
      "lambda: 0.0010 - V: 0.811430\n",
      "lambda: 0.0005 - V: 0.786933\n",
      "Average V: 0.806585\n",
      "Time elapsed: 269.62 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2586 took: 2.69s  Val. loss: 0.2549\n",
      "Epoch 2, 100% \t Train loss: 0.2576 took: 2.68s  Val. loss: 0.2563\n",
      "Epoch 3, 100% \t Train loss: 0.2573 took: 2.65s  Val. loss: 0.2566\n",
      "Epoch 4, 100% \t Train loss: 0.2574 took: 2.67s  Val. loss: 0.2551\n",
      "Epoch 5, 100% \t Train loss: 0.2572 took: 2.68s  Val. loss: 0.2556\n",
      "Epoch 6, 100% \t Train loss: 0.2571 took: 2.66s  Val. loss: 0.2579\n",
      "Epoch 7, 100% \t Train loss: 0.2574 took: 2.67s  Val. loss: 0.2553\n",
      "Epoch 8, 100% \t Train loss: 0.2571 took: 2.66s  Val. loss: 0.2572\n",
      "Epoch 9, 100% \t Train loss: 0.2573 took: 2.67s  Val. loss: 0.2563\n",
      "Epoch 10, 100% \t Train loss: 0.2571 took: 2.65s  Val. loss: 0.2553\n",
      "Epoch 11, 100% \t Train loss: 0.2572 took: 2.67s  Val. loss: 0.2553\n",
      "Epoch 12, 100% \t Train loss: 0.2572 took: 2.67s  Val. loss: 0.2565\n",
      "Epoch 13, 100% \t Train loss: 0.2571 took: 2.67s  Val. loss: 0.2567\n",
      "Epoch 14, 100% \t Train loss: 0.2571 took: 2.71s  Val. loss: 0.2563\n",
      "Epoch 15, 100% \t Train loss: 0.2573 took: 2.74s  Val. loss: 0.2563\n",
      "Epoch 16, 100% \t Train loss: 0.2572 took: 2.67s  Val. loss: 0.2557\n",
      "Epoch 17, 100% \t Train loss: 0.2574 took: 2.67s  Val. loss: 0.2565\n",
      "Epoch 18, 100% \t Train loss: 0.2571 took: 2.69s  Val. loss: 0.2567\n",
      "Epoch 19, 100% \t Train loss: 0.2573 took: 2.70s  Val. loss: 0.2559\n",
      "Epoch 20, 100% \t Train loss: 0.2571 took: 2.72s  Val. loss: 0.2562\n",
      "Epoch 21, 100% \t Train loss: 0.2572 took: 2.76s  Val. loss: 0.2560\n",
      "Epoch 22, 100% \t Train loss: 0.2572 took: 2.79s  Val. loss: 0.2557\n",
      "Epoch 23, 100% \t Train loss: 0.2571 took: 2.29s  Val. loss: 0.2557\n",
      "Epoch 24, 100% \t Train loss: 0.2571 took: 2.69s  Val. loss: 0.2552\n",
      "Epoch 25, 100% \t Train loss: 0.2571 took: 3.04s  Val. loss: 0.2551\n",
      "Epoch 26, 100% \t Train loss: 0.2571 took: 3.00s  Val. loss: 0.2560\n",
      "Epoch 27, 100% \t Train loss: 0.2571 took: 2.84s  Val. loss: 0.2555\n",
      "Epoch 28, 100% \t Train loss: 0.2571 took: 2.63s  Val. loss: 0.2550\n",
      "Epoch 29, 100% \t Train loss: 0.2571 took: 2.35s  Val. loss: 0.2560\n",
      "Epoch 30, 100% \t Train loss: 0.2570 took: 2.33s  Val. loss: 0.2561\n",
      "Epoch 31, 100% \t Train loss: 0.2571 took: 2.43s  Val. loss: 0.2554\n",
      "Epoch 32, 100% \t Train loss: 0.2571 took: 2.92s  Val. loss: 0.2557\n",
      "Epoch 33, 100% \t Train loss: 0.2570 took: 3.57s  Val. loss: 0.2547\n",
      "Epoch 34, 100% \t Train loss: 0.2571 took: 3.78s  Val. loss: 0.2554\n",
      "Epoch 35, 100% \t Train loss: 0.2571 took: 4.79s  Val. loss: 0.2566\n",
      "Epoch 36, 100% \t Train loss: 0.2571 took: 4.62s  Val. loss: 0.2560\n",
      "Epoch 37, 100% \t Train loss: 0.2570 took: 4.87s  Val. loss: 0.2546\n",
      "Epoch 38, 100% \t Train loss: 0.2571 took: 4.79s  Val. loss: 0.2558\n",
      "Epoch 39, 100% \t Train loss: 0.2572 took: 4.71s  Val. loss: 0.2553\n",
      "Epoch 40, 100% \t Train loss: 0.2570 took: 4.85s  Val. loss: 0.2551\n",
      "Epoch 41, 100% \t Train loss: 0.2570 took: 4.88s  Val. loss: 0.2559\n",
      "Epoch 42, 100% \t Train loss: 0.2570 took: 5.40s  Val. loss: 0.2557\n",
      "Epoch 43, 100% \t Train loss: 0.2571 took: 5.50s  Val. loss: 0.2560\n",
      "Epoch 44, 100% \t Train loss: 0.2570 took: 5.71s  Val. loss: 0.2558\n",
      "Epoch 45, 100% \t Train loss: 0.2570 took: 4.30s  Val. loss: 0.2554\n",
      "Epoch 46, 100% \t Train loss: 0.2571 took: 4.26s  Val. loss: 0.2571\n",
      "Epoch 47, 100% \t Train loss: 0.2571 took: 5.17s  Val. loss: 0.2560\n",
      "Epoch 48, 100% \t Train loss: 0.2570 took: 5.20s  Val. loss: 0.2563\n",
      "Epoch 49, 100% \t Train loss: 0.2570 took: 5.15s  Val. loss: 0.2554\n",
      "Epoch 50, 100% \t Train loss: 0.2570 took: 5.05s  Val. loss: 0.2557\n",
      "Training finished, took 190.02s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 2.70s  Val. loss: 0.2550\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 2.69s  Val. loss: 0.2556\n",
      "Epoch 3, 100% \t Train loss: 0.2586 took: 2.66s  Val. loss: 0.2562\n",
      "Epoch 4, 100% \t Train loss: 0.2585 took: 2.66s  Val. loss: 0.2548\n",
      "Epoch 5, 100% \t Train loss: 0.2585 took: 2.66s  Val. loss: 0.2569\n",
      "Epoch 6, 100% \t Train loss: 0.2585 took: 2.66s  Val. loss: 0.2541\n",
      "Epoch 7, 100% \t Train loss: 0.2511 took: 2.68s  Val. loss: 0.2274\n",
      "Epoch 8, 100% \t Train loss: 0.2095 took: 2.66s  Val. loss: 0.1870\n",
      "Epoch 9, 100% \t Train loss: 0.1861 took: 2.66s  Val. loss: 0.1795\n",
      "Epoch 10, 100% \t Train loss: 0.1814 took: 2.69s  Val. loss: 0.1756\n",
      "Epoch 11, 100% \t Train loss: 0.1773 took: 2.67s  Val. loss: 0.1729\n",
      "Epoch 12, 100% \t Train loss: 0.1754 took: 2.66s  Val. loss: 0.1687\n",
      "Epoch 13, 100% \t Train loss: 0.1718 took: 2.67s  Val. loss: 0.1735\n",
      "Epoch 14, 100% \t Train loss: 0.1698 took: 2.66s  Val. loss: 0.1660\n",
      "Epoch 15, 100% \t Train loss: 0.1683 took: 2.67s  Val. loss: 0.1642\n",
      "Epoch 16, 100% \t Train loss: 0.1683 took: 1.64s  Val. loss: 0.1694\n",
      "Epoch 17, 100% \t Train loss: 0.1675 took: 1.64s  Val. loss: 0.1612\n",
      "Epoch 18, 100% \t Train loss: 0.1660 took: 1.64s  Val. loss: 0.1607\n",
      "Epoch 19, 100% \t Train loss: 0.1649 took: 1.64s  Val. loss: 0.1584\n",
      "Epoch 20, 100% \t Train loss: 0.1645 took: 1.64s  Val. loss: 0.1590\n",
      "Epoch 21, 100% \t Train loss: 0.1639 took: 1.64s  Val. loss: 0.1595\n",
      "Epoch 22, 100% \t Train loss: 0.1628 took: 1.64s  Val. loss: 0.1581\n",
      "Epoch 23, 100% \t Train loss: 0.1620 took: 1.64s  Val. loss: 0.1605\n",
      "Epoch 24, 100% \t Train loss: 0.1617 took: 1.63s  Val. loss: 0.1581\n",
      "Epoch 25, 100% \t Train loss: 0.1623 took: 1.64s  Val. loss: 0.1569\n",
      "Epoch 26, 100% \t Train loss: 0.1612 took: 2.70s  Val. loss: 0.1556\n",
      "Epoch 27, 100% \t Train loss: 0.1599 took: 2.71s  Val. loss: 0.1562\n",
      "Epoch 28, 100% \t Train loss: 0.1597 took: 2.77s  Val. loss: 0.1591\n",
      "Epoch 29, 100% \t Train loss: 0.1601 took: 2.78s  Val. loss: 0.1614\n",
      "Epoch 30, 100% \t Train loss: 0.1594 took: 2.82s  Val. loss: 0.1578\n",
      "Epoch 31, 100% \t Train loss: 0.1602 took: 2.92s  Val. loss: 0.1565\n",
      "Epoch 32, 100% \t Train loss: 0.1577 took: 3.03s  Val. loss: 0.1556\n",
      "Epoch 33, 100% \t Train loss: 0.1582 took: 3.11s  Val. loss: 0.1608\n",
      "Epoch 34, 100% \t Train loss: 0.1581 took: 3.00s  Val. loss: 0.1563\n",
      "Epoch 35, 100% \t Train loss: 0.1575 took: 3.02s  Val. loss: 0.1574\n",
      "Epoch 36, 100% \t Train loss: 0.1585 took: 3.07s  Val. loss: 0.1599\n",
      "Epoch 37, 100% \t Train loss: 0.1570 took: 3.06s  Val. loss: 0.1579\n",
      "Epoch 38, 100% \t Train loss: 0.1574 took: 3.09s  Val. loss: 0.1655\n",
      "Epoch 39, 100% \t Train loss: 0.1575 took: 3.17s  Val. loss: 0.1579\n",
      "Epoch 40, 100% \t Train loss: 0.1562 took: 3.21s  Val. loss: 0.1555\n",
      "Epoch 41, 100% \t Train loss: 0.1550 took: 3.23s  Val. loss: 0.1570\n",
      "Epoch 42, 100% \t Train loss: 0.1546 took: 3.33s  Val. loss: 0.1575\n",
      "Epoch 43, 100% \t Train loss: 0.1549 took: 3.39s  Val. loss: 0.1581\n",
      "Epoch 44, 100% \t Train loss: 0.1542 took: 3.66s  Val. loss: 0.1559\n",
      "Epoch 45, 100% \t Train loss: 0.1538 took: 3.92s  Val. loss: 0.1570\n",
      "Epoch 46, 100% \t Train loss: 0.1527 took: 3.99s  Val. loss: 0.1548\n",
      "Epoch 47, 100% \t Train loss: 0.1520 took: 4.14s  Val. loss: 0.1572\n",
      "Epoch 48, 100% \t Train loss: 0.1514 took: 4.31s  Val. loss: 0.1526\n",
      "Epoch 49, 100% \t Train loss: 0.1502 took: 4.42s  Val. loss: 0.1576\n",
      "Epoch 50, 100% \t Train loss: 0.1496 took: 4.44s  Val. loss: 0.1510\n",
      "Training finished, took 153.34s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2569 took: 2.67s  Val. loss: 0.2633\n",
      "Epoch 2, 100% \t Train loss: 0.2565 took: 2.69s  Val. loss: 0.2645\n",
      "Epoch 3, 100% \t Train loss: 0.2564 took: 2.69s  Val. loss: 0.2641\n",
      "Epoch 4, 100% \t Train loss: 0.2564 took: 2.68s  Val. loss: 0.2645\n",
      "Epoch 5, 100% \t Train loss: 0.2564 took: 2.69s  Val. loss: 0.2654\n",
      "Epoch 6, 100% \t Train loss: 0.2563 took: 2.69s  Val. loss: 0.2647\n",
      "Epoch 7, 100% \t Train loss: 0.2563 took: 2.68s  Val. loss: 0.2647\n",
      "Epoch 8, 100% \t Train loss: 0.2562 took: 2.66s  Val. loss: 0.2638\n",
      "Epoch 9, 100% \t Train loss: 0.2539 took: 2.66s  Val. loss: 0.2576\n",
      "Epoch 10, 100% \t Train loss: 0.2299 took: 2.69s  Val. loss: 0.2225\n",
      "Epoch 11, 100% \t Train loss: 0.1921 took: 2.67s  Val. loss: 0.2026\n",
      "Epoch 12, 100% \t Train loss: 0.1785 took: 2.66s  Val. loss: 0.1948\n",
      "Epoch 13, 100% \t Train loss: 0.1748 took: 2.69s  Val. loss: 0.1945\n",
      "Epoch 14, 100% \t Train loss: 0.1718 took: 2.67s  Val. loss: 0.1997\n",
      "Epoch 15, 100% \t Train loss: 0.1735 took: 2.69s  Val. loss: 0.2009\n",
      "Epoch 16, 100% \t Train loss: 0.1699 took: 2.69s  Val. loss: 0.1929\n",
      "Epoch 17, 100% \t Train loss: 0.1693 took: 2.68s  Val. loss: 0.1937\n",
      "Epoch 18, 100% \t Train loss: 0.1681 took: 2.66s  Val. loss: 0.1915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1675 took: 2.67s  Val. loss: 0.1927\n",
      "Epoch 20, 100% \t Train loss: 0.1676 took: 2.67s  Val. loss: 0.1908\n",
      "Epoch 21, 100% \t Train loss: 0.1662 took: 2.68s  Val. loss: 0.1863\n",
      "Epoch 22, 100% \t Train loss: 0.1667 took: 2.67s  Val. loss: 0.1903\n",
      "Epoch 23, 100% \t Train loss: 0.1653 took: 2.68s  Val. loss: 0.1890\n",
      "Epoch 24, 100% \t Train loss: 0.1657 took: 2.67s  Val. loss: 0.1859\n",
      "Epoch 25, 100% \t Train loss: 0.1644 took: 2.66s  Val. loss: 0.1837\n",
      "Epoch 26, 100% \t Train loss: 0.1647 took: 2.66s  Val. loss: 0.1869\n",
      "Epoch 27, 100% \t Train loss: 0.1630 took: 2.72s  Val. loss: 0.1862\n",
      "Epoch 28, 100% \t Train loss: 0.1628 took: 2.72s  Val. loss: 0.1878\n",
      "Epoch 29, 100% \t Train loss: 0.1620 took: 2.74s  Val. loss: 0.1841\n",
      "Epoch 30, 100% \t Train loss: 0.1616 took: 2.75s  Val. loss: 0.1854\n",
      "Epoch 31, 100% \t Train loss: 0.1617 took: 2.75s  Val. loss: 0.1821\n",
      "Epoch 32, 100% \t Train loss: 0.1614 took: 2.77s  Val. loss: 0.1833\n",
      "Epoch 33, 100% \t Train loss: 0.1594 took: 2.77s  Val. loss: 0.1870\n",
      "Epoch 34, 100% \t Train loss: 0.1599 took: 2.77s  Val. loss: 0.1821\n",
      "Epoch 35, 100% \t Train loss: 0.1588 took: 2.82s  Val. loss: 0.1809\n",
      "Epoch 36, 100% \t Train loss: 0.1590 took: 2.83s  Val. loss: 0.1803\n",
      "Epoch 37, 100% \t Train loss: 0.1585 took: 2.87s  Val. loss: 0.1807\n",
      "Epoch 38, 100% \t Train loss: 0.1583 took: 2.91s  Val. loss: 0.1810\n",
      "Epoch 39, 100% \t Train loss: 0.1574 took: 2.88s  Val. loss: 0.1800\n",
      "Epoch 40, 100% \t Train loss: 0.1578 took: 2.92s  Val. loss: 0.1814\n",
      "Epoch 41, 100% \t Train loss: 0.1567 took: 2.94s  Val. loss: 0.1793\n",
      "Epoch 42, 100% \t Train loss: 0.1568 took: 2.97s  Val. loss: 0.1792\n",
      "Epoch 43, 100% \t Train loss: 0.1582 took: 3.01s  Val. loss: 0.1820\n",
      "Epoch 44, 100% \t Train loss: 0.1565 took: 3.08s  Val. loss: 0.1777\n",
      "Epoch 45, 100% \t Train loss: 0.1565 took: 3.18s  Val. loss: 0.1830\n",
      "Epoch 46, 100% \t Train loss: 0.1567 took: 3.18s  Val. loss: 0.1804\n",
      "Epoch 47, 100% \t Train loss: 0.1556 took: 3.13s  Val. loss: 0.1786\n",
      "Epoch 48, 100% \t Train loss: 0.1567 took: 3.07s  Val. loss: 0.1813\n",
      "Epoch 49, 100% \t Train loss: 0.1567 took: 3.11s  Val. loss: 0.1784\n",
      "Epoch 50, 100% \t Train loss: 0.1562 took: 2.43s  Val. loss: 0.1781\n",
      "Training finished, took 152.86s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.744142\n",
      "lambda: 0.0010 - V: 0.826371\n",
      "lambda: 0.0005 - V: 0.799364\n",
      "Average V: 0.789959\n",
      "Time elapsed: 499.60 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2414 took: 1.99s  Val. loss: 0.2016\n",
      "Epoch 2, 100% \t Train loss: 0.2000 took: 1.96s  Val. loss: 0.1940\n",
      "Epoch 3, 100% \t Train loss: 0.1944 took: 1.96s  Val. loss: 0.1898\n",
      "Epoch 4, 100% \t Train loss: 0.1889 took: 1.96s  Val. loss: 0.1835\n",
      "Epoch 5, 100% \t Train loss: 0.1871 took: 1.96s  Val. loss: 0.1931\n",
      "Epoch 6, 100% \t Train loss: 0.1840 took: 1.96s  Val. loss: 0.1867\n",
      "Epoch 7, 100% \t Train loss: 0.1818 took: 1.99s  Val. loss: 0.1847\n",
      "Epoch 8, 100% \t Train loss: 0.1809 took: 1.94s  Val. loss: 0.1921\n",
      "Epoch 9, 100% \t Train loss: 0.1817 took: 1.96s  Val. loss: 0.1821\n",
      "Epoch 10, 100% \t Train loss: 0.1770 took: 1.96s  Val. loss: 0.1785\n",
      "Epoch 11, 100% \t Train loss: 0.1688 took: 1.96s  Val. loss: 0.1707\n",
      "Epoch 12, 100% \t Train loss: 0.1612 took: 1.98s  Val. loss: 0.1646\n",
      "Epoch 13, 100% \t Train loss: 0.1552 took: 1.97s  Val. loss: 0.1564\n",
      "Epoch 14, 100% \t Train loss: 0.1457 took: 1.96s  Val. loss: 0.1468\n",
      "Epoch 15, 100% \t Train loss: 0.1427 took: 1.96s  Val. loss: 0.1451\n",
      "Epoch 16, 100% \t Train loss: 0.1386 took: 1.98s  Val. loss: 0.1411\n",
      "Epoch 17, 100% \t Train loss: 0.1352 took: 1.97s  Val. loss: 0.1444\n",
      "Epoch 18, 100% \t Train loss: 0.1324 took: 1.96s  Val. loss: 0.1408\n",
      "Epoch 19, 100% \t Train loss: 0.1290 took: 1.97s  Val. loss: 0.1362\n",
      "Epoch 20, 100% \t Train loss: 0.1288 took: 1.96s  Val. loss: 0.1364\n",
      "Epoch 21, 100% \t Train loss: 0.1282 took: 1.96s  Val. loss: 0.1313\n",
      "Epoch 22, 100% \t Train loss: 0.1256 took: 1.96s  Val. loss: 0.1342\n",
      "Epoch 23, 100% \t Train loss: 0.1266 took: 1.95s  Val. loss: 0.1392\n",
      "Epoch 24, 100% \t Train loss: 0.1249 took: 1.95s  Val. loss: 0.1309\n",
      "Epoch 25, 100% \t Train loss: 0.1227 took: 1.95s  Val. loss: 0.1281\n",
      "Epoch 26, 100% \t Train loss: 0.1224 took: 1.95s  Val. loss: 0.1296\n",
      "Epoch 27, 100% \t Train loss: 0.1234 took: 1.95s  Val. loss: 0.1287\n",
      "Epoch 28, 100% \t Train loss: 0.1222 took: 1.94s  Val. loss: 0.1286\n",
      "Epoch 29, 100% \t Train loss: 0.1202 took: 1.96s  Val. loss: 0.1266\n",
      "Epoch 30, 100% \t Train loss: 0.1194 took: 1.96s  Val. loss: 0.1278\n",
      "Epoch 31, 100% \t Train loss: 0.1192 took: 1.96s  Val. loss: 0.1304\n",
      "Epoch 32, 100% \t Train loss: 0.1184 took: 1.96s  Val. loss: 0.1266\n",
      "Epoch 33, 100% \t Train loss: 0.1177 took: 2.04s  Val. loss: 0.1293\n",
      "Epoch 34, 100% \t Train loss: 0.1179 took: 2.06s  Val. loss: 0.1255\n",
      "Epoch 35, 100% \t Train loss: 0.1177 took: 2.06s  Val. loss: 0.1302\n",
      "Epoch 36, 100% \t Train loss: 0.1181 took: 2.07s  Val. loss: 0.1267\n",
      "Epoch 37, 100% \t Train loss: 0.1172 took: 2.07s  Val. loss: 0.1361\n",
      "Epoch 38, 100% \t Train loss: 0.1181 took: 2.07s  Val. loss: 0.1277\n",
      "Epoch 39, 100% \t Train loss: 0.1161 took: 2.09s  Val. loss: 0.1260\n",
      "Epoch 40, 100% \t Train loss: 0.1165 took: 2.09s  Val. loss: 0.1262\n",
      "Epoch 41, 100% \t Train loss: 0.1164 took: 2.09s  Val. loss: 0.1251\n",
      "Epoch 42, 100% \t Train loss: 0.1157 took: 2.13s  Val. loss: 0.1264\n",
      "Epoch 43, 100% \t Train loss: 0.1165 took: 2.12s  Val. loss: 0.1272\n",
      "Epoch 44, 100% \t Train loss: 0.1157 took: 2.14s  Val. loss: 0.1250\n",
      "Epoch 45, 100% \t Train loss: 0.1154 took: 2.15s  Val. loss: 0.1283\n",
      "Epoch 46, 100% \t Train loss: 0.1149 took: 2.15s  Val. loss: 0.1277\n",
      "Epoch 47, 100% \t Train loss: 0.1148 took: 2.15s  Val. loss: 0.1256\n",
      "Epoch 48, 100% \t Train loss: 0.1143 took: 2.14s  Val. loss: 0.1250\n",
      "Epoch 49, 100% \t Train loss: 0.1144 took: 2.18s  Val. loss: 0.1285\n",
      "Epoch 50, 100% \t Train loss: 0.1134 took: 2.20s  Val. loss: 0.1290\n",
      "Training finished, took 114.25s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2575 took: 1.97s  Val. loss: 0.2577\n",
      "Epoch 2, 100% \t Train loss: 0.2566 took: 1.96s  Val. loss: 0.2567\n",
      "Epoch 3, 100% \t Train loss: 0.2529 took: 1.96s  Val. loss: 0.2445\n",
      "Epoch 4, 100% \t Train loss: 0.2225 took: 1.96s  Val. loss: 0.1963\n",
      "Epoch 5, 100% \t Train loss: 0.1997 took: 1.95s  Val. loss: 0.1979\n",
      "Epoch 6, 100% \t Train loss: 0.1956 took: 1.98s  Val. loss: 0.1885\n",
      "Epoch 7, 100% \t Train loss: 0.1942 took: 1.94s  Val. loss: 0.1885\n",
      "Epoch 8, 100% \t Train loss: 0.1919 took: 1.97s  Val. loss: 0.1902\n",
      "Epoch 9, 100% \t Train loss: 0.1923 took: 1.99s  Val. loss: 0.1888\n",
      "Epoch 10, 100% \t Train loss: 0.1912 took: 1.96s  Val. loss: 0.1848\n",
      "Epoch 11, 100% \t Train loss: 0.1896 took: 1.95s  Val. loss: 0.1871\n",
      "Epoch 12, 100% \t Train loss: 0.1884 took: 1.96s  Val. loss: 0.1829\n",
      "Epoch 13, 100% \t Train loss: 0.1868 took: 1.94s  Val. loss: 0.1819\n",
      "Epoch 14, 100% \t Train loss: 0.1875 took: 1.96s  Val. loss: 0.1814\n",
      "Epoch 15, 100% \t Train loss: 0.1851 took: 1.95s  Val. loss: 0.1803\n",
      "Epoch 16, 100% \t Train loss: 0.1819 took: 1.95s  Val. loss: 0.1823\n",
      "Epoch 17, 100% \t Train loss: 0.1794 took: 1.96s  Val. loss: 0.1770\n",
      "Epoch 18, 100% \t Train loss: 0.1786 took: 1.95s  Val. loss: 0.1795\n",
      "Epoch 19, 100% \t Train loss: 0.1720 took: 1.93s  Val. loss: 0.1738\n",
      "Epoch 20, 100% \t Train loss: 0.1699 took: 1.93s  Val. loss: 0.1650\n",
      "Epoch 21, 100% \t Train loss: 0.1636 took: 1.94s  Val. loss: 0.1698\n",
      "Epoch 22, 100% \t Train loss: 0.1625 took: 1.93s  Val. loss: 0.1599\n",
      "Epoch 23, 100% \t Train loss: 0.1591 took: 1.93s  Val. loss: 0.1580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1566 took: 1.94s  Val. loss: 0.1548\n",
      "Epoch 25, 100% \t Train loss: 0.1590 took: 1.95s  Val. loss: 0.1543\n",
      "Epoch 26, 100% \t Train loss: 0.1523 took: 1.96s  Val. loss: 0.1525\n",
      "Epoch 27, 100% \t Train loss: 0.1517 took: 1.95s  Val. loss: 0.1547\n",
      "Epoch 28, 100% \t Train loss: 0.1490 took: 1.95s  Val. loss: 0.1525\n",
      "Epoch 29, 100% \t Train loss: 0.1475 took: 1.94s  Val. loss: 0.1455\n",
      "Epoch 30, 100% \t Train loss: 0.1460 took: 1.94s  Val. loss: 0.1516\n",
      "Epoch 31, 100% \t Train loss: 0.1461 took: 1.93s  Val. loss: 0.1494\n",
      "Epoch 32, 100% \t Train loss: 0.1434 took: 1.94s  Val. loss: 0.1455\n",
      "Epoch 33, 100% \t Train loss: 0.1425 took: 1.92s  Val. loss: 0.1439\n",
      "Epoch 34, 100% \t Train loss: 0.1422 took: 1.94s  Val. loss: 0.1463\n",
      "Epoch 35, 100% \t Train loss: 0.1400 took: 1.97s  Val. loss: 0.1447\n",
      "Epoch 36, 100% \t Train loss: 0.1387 took: 1.98s  Val. loss: 0.1413\n",
      "Epoch 37, 100% \t Train loss: 0.1393 took: 1.96s  Val. loss: 0.1400\n",
      "Epoch 38, 100% \t Train loss: 0.1372 took: 1.95s  Val. loss: 0.1363\n",
      "Epoch 39, 100% \t Train loss: 0.1376 took: 1.95s  Val. loss: 0.1369\n",
      "Epoch 40, 100% \t Train loss: 0.1354 took: 1.94s  Val. loss: 0.1392\n",
      "Epoch 41, 100% \t Train loss: 0.1347 took: 1.94s  Val. loss: 0.1420\n",
      "Epoch 42, 100% \t Train loss: 0.1352 took: 1.97s  Val. loss: 0.1346\n",
      "Epoch 43, 100% \t Train loss: 0.1325 took: 1.96s  Val. loss: 0.1362\n",
      "Epoch 44, 100% \t Train loss: 0.1337 took: 1.95s  Val. loss: 0.1364\n",
      "Epoch 45, 100% \t Train loss: 0.1339 took: 1.97s  Val. loss: 0.1371\n",
      "Epoch 46, 100% \t Train loss: 0.1321 took: 1.95s  Val. loss: 0.1312\n",
      "Epoch 47, 100% \t Train loss: 0.1310 took: 1.96s  Val. loss: 0.1374\n",
      "Epoch 48, 100% \t Train loss: 0.1308 took: 1.96s  Val. loss: 0.1371\n",
      "Epoch 49, 100% \t Train loss: 0.1306 took: 1.95s  Val. loss: 0.1335\n",
      "Epoch 50, 100% \t Train loss: 0.1323 took: 1.95s  Val. loss: 0.1352\n",
      "Training finished, took 109.95s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 1.98s  Val. loss: 0.2597\n",
      "Epoch 2, 100% \t Train loss: 0.2585 took: 1.96s  Val. loss: 0.2598\n",
      "Epoch 3, 100% \t Train loss: 0.2574 took: 1.95s  Val. loss: 0.2571\n",
      "Epoch 4, 100% \t Train loss: 0.2490 took: 1.98s  Val. loss: 0.2396\n",
      "Epoch 5, 100% \t Train loss: 0.2267 took: 1.95s  Val. loss: 0.2229\n",
      "Epoch 6, 100% \t Train loss: 0.2127 took: 1.94s  Val. loss: 0.2089\n",
      "Epoch 7, 100% \t Train loss: 0.2048 took: 1.94s  Val. loss: 0.2028\n",
      "Epoch 8, 100% \t Train loss: 0.2006 took: 1.95s  Val. loss: 0.2041\n",
      "Epoch 9, 100% \t Train loss: 0.2013 took: 1.94s  Val. loss: 0.2016\n",
      "Epoch 10, 100% \t Train loss: 0.1997 took: 1.94s  Val. loss: 0.2001\n",
      "Epoch 11, 100% \t Train loss: 0.1986 took: 1.94s  Val. loss: 0.2028\n",
      "Epoch 12, 100% \t Train loss: 0.1974 took: 1.94s  Val. loss: 0.1983\n",
      "Epoch 13, 100% \t Train loss: 0.1962 took: 1.97s  Val. loss: 0.2007\n",
      "Epoch 14, 100% \t Train loss: 0.1965 took: 1.96s  Val. loss: 0.1999\n",
      "Epoch 15, 100% \t Train loss: 0.1952 took: 1.95s  Val. loss: 0.2012\n",
      "Epoch 16, 100% \t Train loss: 0.1947 took: 1.96s  Val. loss: 0.2013\n",
      "Epoch 17, 100% \t Train loss: 0.1945 took: 1.98s  Val. loss: 0.2007\n",
      "Epoch 18, 100% \t Train loss: 0.1941 took: 1.95s  Val. loss: 0.2030\n",
      "Epoch 19, 100% \t Train loss: 0.1941 took: 1.96s  Val. loss: 0.1960\n",
      "Epoch 20, 100% \t Train loss: 0.1913 took: 1.96s  Val. loss: 0.1936\n",
      "Epoch 21, 100% \t Train loss: 0.1926 took: 1.95s  Val. loss: 0.1990\n",
      "Epoch 22, 100% \t Train loss: 0.1919 took: 1.97s  Val. loss: 0.1959\n",
      "Epoch 23, 100% \t Train loss: 0.1907 took: 1.94s  Val. loss: 0.1931\n",
      "Epoch 24, 100% \t Train loss: 0.1894 took: 1.94s  Val. loss: 0.1931\n",
      "Epoch 25, 100% \t Train loss: 0.1889 took: 1.96s  Val. loss: 0.1906\n",
      "Epoch 26, 100% \t Train loss: 0.1875 took: 1.94s  Val. loss: 0.1926\n",
      "Epoch 27, 100% \t Train loss: 0.1866 took: 1.97s  Val. loss: 0.1905\n",
      "Epoch 28, 100% \t Train loss: 0.1858 took: 1.95s  Val. loss: 0.1966\n",
      "Epoch 29, 100% \t Train loss: 0.1858 took: 1.97s  Val. loss: 0.1909\n",
      "Epoch 30, 100% \t Train loss: 0.1832 took: 1.97s  Val. loss: 0.1863\n",
      "Epoch 31, 100% \t Train loss: 0.1826 took: 1.97s  Val. loss: 0.1927\n",
      "Epoch 32, 100% \t Train loss: 0.1805 took: 1.97s  Val. loss: 0.1880\n",
      "Epoch 33, 100% \t Train loss: 0.1767 took: 1.99s  Val. loss: 0.1842\n",
      "Epoch 34, 100% \t Train loss: 0.1738 took: 1.98s  Val. loss: 0.1817\n",
      "Epoch 35, 100% \t Train loss: 0.1704 took: 1.98s  Val. loss: 0.1832\n",
      "Epoch 36, 100% \t Train loss: 0.1682 took: 1.99s  Val. loss: 0.1738\n",
      "Epoch 37, 100% \t Train loss: 0.1655 took: 2.00s  Val. loss: 0.1736\n",
      "Epoch 38, 100% \t Train loss: 0.1639 took: 1.98s  Val. loss: 0.1745\n",
      "Epoch 39, 100% \t Train loss: 0.1627 took: 1.98s  Val. loss: 0.1808\n",
      "Epoch 40, 100% \t Train loss: 0.1607 took: 1.98s  Val. loss: 0.1708\n",
      "Epoch 41, 100% \t Train loss: 0.1588 took: 1.96s  Val. loss: 0.1667\n",
      "Epoch 42, 100% \t Train loss: 0.1578 took: 1.97s  Val. loss: 0.1671\n",
      "Epoch 43, 100% \t Train loss: 0.1567 took: 1.96s  Val. loss: 0.1676\n",
      "Epoch 44, 100% \t Train loss: 0.1539 took: 1.97s  Val. loss: 0.1619\n",
      "Epoch 45, 100% \t Train loss: 0.1535 took: 1.96s  Val. loss: 0.1643\n",
      "Epoch 46, 100% \t Train loss: 0.1520 took: 1.96s  Val. loss: 0.1586\n",
      "Epoch 47, 100% \t Train loss: 0.1511 took: 1.97s  Val. loss: 0.1590\n",
      "Epoch 48, 100% \t Train loss: 0.1497 took: 1.97s  Val. loss: 0.1611\n",
      "Epoch 49, 100% \t Train loss: 0.1471 took: 1.92s  Val. loss: 0.1556\n",
      "Epoch 50, 100% \t Train loss: 0.1456 took: 1.97s  Val. loss: 0.1572\n",
      "Training finished, took 110.85s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.855477\n",
      "lambda: 0.0010 - V: 0.835541\n",
      "lambda: 0.0005 - V: 0.807896\n",
      "Average V: 0.832971\n",
      "Time elapsed: 338.59 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2607 took: 1.88s  Val. loss: 0.2603\n",
      "Epoch 2, 100% \t Train loss: 0.2596 took: 1.87s  Val. loss: 0.2596\n",
      "Epoch 3, 100% \t Train loss: 0.2414 took: 1.86s  Val. loss: 0.1895\n",
      "Epoch 4, 100% \t Train loss: 0.1791 took: 1.85s  Val. loss: 0.1689\n",
      "Epoch 5, 100% \t Train loss: 0.1721 took: 1.86s  Val. loss: 0.1649\n",
      "Epoch 6, 100% \t Train loss: 0.1666 took: 1.86s  Val. loss: 0.1689\n",
      "Epoch 7, 100% \t Train loss: 0.1635 took: 1.86s  Val. loss: 0.1578\n",
      "Epoch 8, 100% \t Train loss: 0.1592 took: 1.85s  Val. loss: 0.1573\n",
      "Epoch 9, 100% \t Train loss: 0.1573 took: 1.86s  Val. loss: 0.1546\n",
      "Epoch 10, 100% \t Train loss: 0.1549 took: 1.85s  Val. loss: 0.1556\n",
      "Epoch 11, 100% \t Train loss: 0.1534 took: 1.85s  Val. loss: 0.1541\n",
      "Epoch 12, 100% \t Train loss: 0.1524 took: 1.85s  Val. loss: 0.1514\n",
      "Epoch 13, 100% \t Train loss: 0.1530 took: 1.07s  Val. loss: 0.1481\n",
      "Epoch 14, 100% \t Train loss: 0.1514 took: 1.07s  Val. loss: 0.1496\n",
      "Epoch 15, 100% \t Train loss: 0.1507 took: 1.08s  Val. loss: 0.1528\n",
      "Epoch 16, 100% \t Train loss: 0.1501 took: 1.08s  Val. loss: 0.1504\n",
      "Epoch 17, 100% \t Train loss: 0.1493 took: 1.09s  Val. loss: 0.1521\n",
      "Epoch 18, 100% \t Train loss: 0.1488 took: 1.08s  Val. loss: 0.1478\n",
      "Epoch 19, 100% \t Train loss: 0.1488 took: 1.09s  Val. loss: 0.1510\n",
      "Epoch 20, 100% \t Train loss: 0.1487 took: 1.08s  Val. loss: 0.1515\n",
      "Epoch 21, 100% \t Train loss: 0.1484 took: 1.08s  Val. loss: 0.1498\n",
      "Epoch 22, 100% \t Train loss: 0.1475 took: 1.08s  Val. loss: 0.1527\n",
      "Epoch 23, 100% \t Train loss: 0.1475 took: 1.07s  Val. loss: 0.1499\n",
      "Epoch 24, 100% \t Train loss: 0.1473 took: 1.07s  Val. loss: 0.1511\n",
      "Epoch 25, 100% \t Train loss: 0.1471 took: 1.07s  Val. loss: 0.1484\n",
      "Epoch 26, 100% \t Train loss: 0.1463 took: 1.08s  Val. loss: 0.1487\n",
      "Epoch 27, 100% \t Train loss: 0.1460 took: 1.09s  Val. loss: 0.1489\n",
      "Epoch 28, 100% \t Train loss: 0.1460 took: 1.08s  Val. loss: 0.1498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.1463 took: 1.09s  Val. loss: 0.1493\n",
      "Epoch 30, 100% \t Train loss: 0.1448 took: 1.09s  Val. loss: 0.1457\n",
      "Epoch 31, 100% \t Train loss: 0.1451 took: 1.54s  Val. loss: 0.1470\n",
      "Epoch 32, 100% \t Train loss: 0.1444 took: 1.90s  Val. loss: 0.1508\n",
      "Epoch 33, 100% \t Train loss: 0.1445 took: 1.95s  Val. loss: 0.1527\n",
      "Epoch 34, 100% \t Train loss: 0.1438 took: 1.96s  Val. loss: 0.1444\n",
      "Epoch 35, 100% \t Train loss: 0.1432 took: 1.96s  Val. loss: 0.1480\n",
      "Epoch 36, 100% \t Train loss: 0.1428 took: 1.97s  Val. loss: 0.1462\n",
      "Epoch 37, 100% \t Train loss: 0.1422 took: 1.96s  Val. loss: 0.1425\n",
      "Epoch 38, 100% \t Train loss: 0.1410 took: 1.95s  Val. loss: 0.1435\n",
      "Epoch 39, 100% \t Train loss: 0.1389 took: 1.96s  Val. loss: 0.1438\n",
      "Epoch 40, 100% \t Train loss: 0.1372 took: 1.97s  Val. loss: 0.1374\n",
      "Epoch 41, 100% \t Train loss: 0.1354 took: 1.97s  Val. loss: 0.1339\n",
      "Epoch 42, 100% \t Train loss: 0.1322 took: 1.98s  Val. loss: 0.1327\n",
      "Epoch 43, 100% \t Train loss: 0.1282 took: 1.98s  Val. loss: 0.1328\n",
      "Epoch 44, 100% \t Train loss: 0.1244 took: 1.97s  Val. loss: 0.1284\n",
      "Epoch 45, 100% \t Train loss: 0.1200 took: 1.98s  Val. loss: 0.1278\n",
      "Epoch 46, 100% \t Train loss: 0.1171 took: 2.03s  Val. loss: 0.1212\n",
      "Epoch 47, 100% \t Train loss: 0.1140 took: 2.03s  Val. loss: 0.1197\n",
      "Epoch 48, 100% \t Train loss: 0.1099 took: 2.04s  Val. loss: 0.1189\n",
      "Epoch 49, 100% \t Train loss: 0.1085 took: 2.08s  Val. loss: 0.1121\n",
      "Epoch 50, 100% \t Train loss: 0.1054 took: 2.10s  Val. loss: 0.1158\n",
      "Training finished, took 91.92s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2596 took: 1.86s  Val. loss: 0.2529\n",
      "Epoch 2, 100% \t Train loss: 0.2581 took: 1.84s  Val. loss: 0.2532\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 1.84s  Val. loss: 0.2520\n",
      "Epoch 4, 100% \t Train loss: 0.2559 took: 1.85s  Val. loss: 0.2492\n",
      "Epoch 5, 100% \t Train loss: 0.2436 took: 1.85s  Val. loss: 0.2243\n",
      "Epoch 6, 100% \t Train loss: 0.2145 took: 1.86s  Val. loss: 0.1971\n",
      "Epoch 7, 100% \t Train loss: 0.1957 took: 1.86s  Val. loss: 0.1843\n",
      "Epoch 8, 100% \t Train loss: 0.1867 took: 1.86s  Val. loss: 0.1778\n",
      "Epoch 9, 100% \t Train loss: 0.1825 took: 1.85s  Val. loss: 0.1753\n",
      "Epoch 10, 100% \t Train loss: 0.1818 took: 1.85s  Val. loss: 0.1817\n",
      "Epoch 11, 100% \t Train loss: 0.1778 took: 1.87s  Val. loss: 0.1834\n",
      "Epoch 12, 100% \t Train loss: 0.1780 took: 1.86s  Val. loss: 0.1705\n",
      "Epoch 13, 100% \t Train loss: 0.1760 took: 1.86s  Val. loss: 0.1702\n",
      "Epoch 14, 100% \t Train loss: 0.1752 took: 1.86s  Val. loss: 0.1692\n",
      "Epoch 15, 100% \t Train loss: 0.1719 took: 1.86s  Val. loss: 0.1694\n",
      "Epoch 16, 100% \t Train loss: 0.1716 took: 1.85s  Val. loss: 0.1670\n",
      "Epoch 17, 100% \t Train loss: 0.1726 took: 1.85s  Val. loss: 0.1669\n",
      "Epoch 18, 100% \t Train loss: 0.1702 took: 1.86s  Val. loss: 0.1704\n",
      "Epoch 19, 100% \t Train loss: 0.1689 took: 1.86s  Val. loss: 0.1655\n",
      "Epoch 20, 100% \t Train loss: 0.1693 took: 1.85s  Val. loss: 0.1644\n",
      "Epoch 21, 100% \t Train loss: 0.1680 took: 1.85s  Val. loss: 0.1658\n",
      "Epoch 22, 100% \t Train loss: 0.1667 took: 1.85s  Val. loss: 0.1653\n",
      "Epoch 23, 100% \t Train loss: 0.1675 took: 1.85s  Val. loss: 0.1624\n",
      "Epoch 24, 100% \t Train loss: 0.1671 took: 1.86s  Val. loss: 0.1690\n",
      "Epoch 25, 100% \t Train loss: 0.1665 took: 1.85s  Val. loss: 0.1601\n",
      "Epoch 26, 100% \t Train loss: 0.1639 took: 1.85s  Val. loss: 0.1603\n",
      "Epoch 27, 100% \t Train loss: 0.1629 took: 1.84s  Val. loss: 0.1605\n",
      "Epoch 28, 100% \t Train loss: 0.1628 took: 1.87s  Val. loss: 0.1615\n",
      "Epoch 29, 100% \t Train loss: 0.1622 took: 1.87s  Val. loss: 0.1645\n",
      "Epoch 30, 100% \t Train loss: 0.1636 took: 1.84s  Val. loss: 0.1570\n",
      "Epoch 31, 100% \t Train loss: 0.1607 took: 1.87s  Val. loss: 0.1569\n",
      "Epoch 32, 100% \t Train loss: 0.1617 took: 1.85s  Val. loss: 0.1555\n",
      "Epoch 33, 100% \t Train loss: 0.1612 took: 1.85s  Val. loss: 0.1639\n",
      "Epoch 34, 100% \t Train loss: 0.1605 took: 1.85s  Val. loss: 0.1576\n",
      "Epoch 35, 100% \t Train loss: 0.1589 took: 1.86s  Val. loss: 0.1558\n",
      "Epoch 36, 100% \t Train loss: 0.1584 took: 1.86s  Val. loss: 0.1551\n",
      "Epoch 37, 100% \t Train loss: 0.1589 took: 1.85s  Val. loss: 0.1564\n",
      "Epoch 38, 100% \t Train loss: 0.1567 took: 1.85s  Val. loss: 0.1536\n",
      "Epoch 39, 100% \t Train loss: 0.1566 took: 1.85s  Val. loss: 0.1518\n",
      "Epoch 40, 100% \t Train loss: 0.1565 took: 1.85s  Val. loss: 0.1519\n",
      "Epoch 41, 100% \t Train loss: 0.1560 took: 1.84s  Val. loss: 0.1607\n",
      "Epoch 42, 100% \t Train loss: 0.1557 took: 1.84s  Val. loss: 0.1515\n",
      "Epoch 43, 100% \t Train loss: 0.1534 took: 1.86s  Val. loss: 0.1495\n",
      "Epoch 44, 100% \t Train loss: 0.1536 took: 1.86s  Val. loss: 0.1476\n",
      "Epoch 45, 100% \t Train loss: 0.1517 took: 1.85s  Val. loss: 0.1475\n",
      "Epoch 46, 100% \t Train loss: 0.1500 took: 1.86s  Val. loss: 0.1457\n",
      "Epoch 47, 100% \t Train loss: 0.1493 took: 1.87s  Val. loss: 0.1519\n",
      "Epoch 48, 100% \t Train loss: 0.1503 took: 1.83s  Val. loss: 0.1464\n",
      "Epoch 49, 100% \t Train loss: 0.1480 took: 1.87s  Val. loss: 0.1413\n",
      "Epoch 50, 100% \t Train loss: 0.1488 took: 1.85s  Val. loss: 0.1450\n",
      "Training finished, took 105.32s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2558 took: 1.87s  Val. loss: 0.2605\n",
      "Epoch 2, 100% \t Train loss: 0.2554 took: 1.87s  Val. loss: 0.2601\n",
      "Epoch 3, 100% \t Train loss: 0.2554 took: 1.86s  Val. loss: 0.2608\n",
      "Epoch 4, 100% \t Train loss: 0.2551 took: 1.85s  Val. loss: 0.2596\n",
      "Epoch 5, 100% \t Train loss: 0.2542 took: 1.86s  Val. loss: 0.2575\n",
      "Epoch 6, 100% \t Train loss: 0.2508 took: 1.85s  Val. loss: 0.2521\n",
      "Epoch 7, 100% \t Train loss: 0.2396 took: 1.88s  Val. loss: 0.2365\n",
      "Epoch 8, 100% \t Train loss: 0.2239 took: 1.86s  Val. loss: 0.2247\n",
      "Epoch 9, 100% \t Train loss: 0.2120 took: 1.86s  Val. loss: 0.2106\n",
      "Epoch 10, 100% \t Train loss: 0.2003 took: 1.84s  Val. loss: 0.1965\n",
      "Epoch 11, 100% \t Train loss: 0.1885 took: 1.88s  Val. loss: 0.1854\n",
      "Epoch 12, 100% \t Train loss: 0.1809 took: 1.88s  Val. loss: 0.1790\n",
      "Epoch 13, 100% \t Train loss: 0.1767 took: 1.85s  Val. loss: 0.1776\n",
      "Epoch 14, 100% \t Train loss: 0.1738 took: 1.85s  Val. loss: 0.1753\n",
      "Epoch 15, 100% \t Train loss: 0.1739 took: 1.85s  Val. loss: 0.1749\n",
      "Epoch 16, 100% \t Train loss: 0.1718 took: 1.86s  Val. loss: 0.1745\n",
      "Epoch 17, 100% \t Train loss: 0.1702 took: 1.85s  Val. loss: 0.1738\n",
      "Epoch 18, 100% \t Train loss: 0.1701 took: 1.87s  Val. loss: 0.1718\n",
      "Epoch 19, 100% \t Train loss: 0.1689 took: 1.87s  Val. loss: 0.1740\n",
      "Epoch 20, 100% \t Train loss: 0.1691 took: 1.86s  Val. loss: 0.1714\n",
      "Epoch 21, 100% \t Train loss: 0.1673 took: 1.86s  Val. loss: 0.1708\n",
      "Epoch 22, 100% \t Train loss: 0.1669 took: 1.86s  Val. loss: 0.1684\n",
      "Epoch 23, 100% \t Train loss: 0.1669 took: 1.88s  Val. loss: 0.1681\n",
      "Epoch 24, 100% \t Train loss: 0.1653 took: 1.88s  Val. loss: 0.1712\n",
      "Epoch 25, 100% \t Train loss: 0.1661 took: 1.87s  Val. loss: 0.1667\n",
      "Epoch 26, 100% \t Train loss: 0.1638 took: 1.08s  Val. loss: 0.1710\n",
      "Epoch 27, 100% \t Train loss: 0.1631 took: 1.09s  Val. loss: 0.1714\n",
      "Epoch 28, 100% \t Train loss: 0.1636 took: 1.11s  Val. loss: 0.1664\n",
      "Epoch 29, 100% \t Train loss: 0.1621 took: 1.08s  Val. loss: 0.1673\n",
      "Epoch 30, 100% \t Train loss: 0.1622 took: 1.08s  Val. loss: 0.1669\n",
      "Epoch 31, 100% \t Train loss: 0.1607 took: 1.08s  Val. loss: 0.1669\n",
      "Epoch 32, 100% \t Train loss: 0.1607 took: 1.09s  Val. loss: 0.1678\n",
      "Epoch 33, 100% \t Train loss: 0.1607 took: 1.09s  Val. loss: 0.1641\n",
      "Epoch 34, 100% \t Train loss: 0.1598 took: 1.09s  Val. loss: 0.1706\n",
      "Epoch 35, 100% \t Train loss: 0.1593 took: 1.08s  Val. loss: 0.1674\n",
      "Epoch 36, 100% \t Train loss: 0.1607 took: 1.08s  Val. loss: 0.1668\n",
      "Epoch 37, 100% \t Train loss: 0.1587 took: 1.09s  Val. loss: 0.1634\n",
      "Epoch 38, 100% \t Train loss: 0.1581 took: 1.08s  Val. loss: 0.1625\n",
      "Epoch 39, 100% \t Train loss: 0.1585 took: 1.08s  Val. loss: 0.1675\n",
      "Epoch 40, 100% \t Train loss: 0.1578 took: 1.09s  Val. loss: 0.1633\n",
      "Epoch 41, 100% \t Train loss: 0.1567 took: 1.08s  Val. loss: 0.1627\n",
      "Epoch 42, 100% \t Train loss: 0.1564 took: 1.10s  Val. loss: 0.1625\n",
      "Epoch 43, 100% \t Train loss: 0.1577 took: 1.10s  Val. loss: 0.1616\n",
      "Epoch 44, 100% \t Train loss: 0.1567 took: 1.10s  Val. loss: 0.1618\n",
      "Epoch 45, 100% \t Train loss: 0.1556 took: 1.10s  Val. loss: 0.1616\n",
      "Epoch 46, 100% \t Train loss: 0.1558 took: 1.09s  Val. loss: 0.1636\n",
      "Epoch 47, 100% \t Train loss: 0.1557 took: 1.09s  Val. loss: 0.1636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1562 took: 1.09s  Val. loss: 0.1633\n",
      "Epoch 49, 100% \t Train loss: 0.1555 took: 1.10s  Val. loss: 0.1648\n",
      "Epoch 50, 100% \t Train loss: 0.1541 took: 1.20s  Val. loss: 0.1631\n",
      "Training finished, took 83.75s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.849203\n",
      "lambda: 0.0010 - V: 0.829673\n",
      "lambda: 0.0005 - V: 0.816929\n",
      "Average V: 0.831935\n",
      "Time elapsed: 284.34 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.27\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 1.80s  Val. loss: 0.2588\n",
      "Epoch 2, 100% \t Train loss: 0.2590 took: 1.77s  Val. loss: 0.2577\n",
      "Epoch 3, 100% \t Train loss: 0.2380 took: 1.78s  Val. loss: 0.2123\n",
      "Epoch 4, 100% \t Train loss: 0.2002 took: 1.79s  Val. loss: 0.2087\n",
      "Epoch 5, 100% \t Train loss: 0.1969 took: 1.80s  Val. loss: 0.2076\n",
      "Epoch 6, 100% \t Train loss: 0.1945 took: 1.80s  Val. loss: 0.2053\n",
      "Epoch 7, 100% \t Train loss: 0.1925 took: 1.80s  Val. loss: 0.2022\n",
      "Epoch 8, 100% \t Train loss: 0.1917 took: 1.81s  Val. loss: 0.1983\n",
      "Epoch 9, 100% \t Train loss: 0.1907 took: 1.80s  Val. loss: 0.1979\n",
      "Epoch 10, 100% \t Train loss: 0.1897 took: 1.79s  Val. loss: 0.2004\n",
      "Epoch 11, 100% \t Train loss: 0.1885 took: 1.80s  Val. loss: 0.1939\n",
      "Epoch 12, 100% \t Train loss: 0.1872 took: 1.79s  Val. loss: 0.1978\n",
      "Epoch 13, 100% \t Train loss: 0.1866 took: 1.79s  Val. loss: 0.2002\n",
      "Epoch 14, 100% \t Train loss: 0.1865 took: 1.78s  Val. loss: 0.1961\n",
      "Epoch 15, 100% \t Train loss: 0.1840 took: 1.78s  Val. loss: 0.1973\n",
      "Epoch 16, 100% \t Train loss: 0.1830 took: 1.78s  Val. loss: 0.1955\n",
      "Epoch 17, 100% \t Train loss: 0.1822 took: 1.79s  Val. loss: 0.1951\n",
      "Epoch 18, 100% \t Train loss: 0.1803 took: 1.80s  Val. loss: 0.1944\n",
      "Epoch 19, 100% \t Train loss: 0.1802 took: 1.81s  Val. loss: 0.1921\n",
      "Epoch 20, 100% \t Train loss: 0.1780 took: 1.81s  Val. loss: 0.1913\n",
      "Epoch 21, 100% \t Train loss: 0.1767 took: 1.78s  Val. loss: 0.1909\n",
      "Epoch 22, 100% \t Train loss: 0.1754 took: 1.79s  Val. loss: 0.1881\n",
      "Epoch 23, 100% \t Train loss: 0.1738 took: 1.81s  Val. loss: 0.1895\n",
      "Epoch 24, 100% \t Train loss: 0.1722 took: 1.79s  Val. loss: 0.1852\n",
      "Epoch 25, 100% \t Train loss: 0.1704 took: 1.79s  Val. loss: 0.1871\n",
      "Epoch 26, 100% \t Train loss: 0.1701 took: 1.80s  Val. loss: 0.1860\n",
      "Epoch 27, 100% \t Train loss: 0.1683 took: 1.78s  Val. loss: 0.1836\n",
      "Epoch 28, 100% \t Train loss: 0.1676 took: 1.81s  Val. loss: 0.1793\n",
      "Epoch 29, 100% \t Train loss: 0.1650 took: 1.79s  Val. loss: 0.1771\n",
      "Epoch 30, 100% \t Train loss: 0.1621 took: 1.82s  Val. loss: 0.1743\n",
      "Epoch 31, 100% \t Train loss: 0.1621 took: 1.79s  Val. loss: 0.1755\n",
      "Epoch 32, 100% \t Train loss: 0.1579 took: 1.80s  Val. loss: 0.1731\n",
      "Epoch 33, 100% \t Train loss: 0.1567 took: 1.80s  Val. loss: 0.1687\n",
      "Epoch 34, 100% \t Train loss: 0.1538 took: 1.85s  Val. loss: 0.1716\n",
      "Epoch 35, 100% \t Train loss: 0.1504 took: 1.85s  Val. loss: 0.1686\n",
      "Epoch 36, 100% \t Train loss: 0.1501 took: 1.85s  Val. loss: 0.1681\n",
      "Epoch 37, 100% \t Train loss: 0.1483 took: 1.85s  Val. loss: 0.1589\n",
      "Epoch 38, 100% \t Train loss: 0.1467 took: 1.34s  Val. loss: 0.1601\n",
      "Epoch 39, 100% \t Train loss: 0.1466 took: 1.09s  Val. loss: 0.1567\n",
      "Epoch 40, 100% \t Train loss: 0.1443 took: 1.09s  Val. loss: 0.1612\n",
      "Epoch 41, 100% \t Train loss: 0.1441 took: 1.09s  Val. loss: 0.1621\n",
      "Epoch 42, 100% \t Train loss: 0.1430 took: 1.10s  Val. loss: 0.1540\n",
      "Epoch 43, 100% \t Train loss: 0.1418 took: 1.09s  Val. loss: 0.1543\n",
      "Epoch 44, 100% \t Train loss: 0.1408 took: 1.09s  Val. loss: 0.1544\n",
      "Epoch 45, 100% \t Train loss: 0.1409 took: 1.09s  Val. loss: 0.1553\n",
      "Epoch 46, 100% \t Train loss: 0.1399 took: 1.09s  Val. loss: 0.1552\n",
      "Epoch 47, 100% \t Train loss: 0.1399 took: 1.09s  Val. loss: 0.1544\n",
      "Epoch 48, 100% \t Train loss: 0.1389 took: 1.09s  Val. loss: 0.1542\n",
      "Epoch 49, 100% \t Train loss: 0.1378 took: 1.14s  Val. loss: 0.1548\n",
      "Epoch 50, 100% \t Train loss: 0.1387 took: 1.11s  Val. loss: 0.1566\n",
      "Training finished, took 92.35s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2590 took: 1.80s  Val. loss: 0.2568\n",
      "Epoch 2, 100% \t Train loss: 0.2579 took: 1.80s  Val. loss: 0.2566\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 1.81s  Val. loss: 0.2566\n",
      "Epoch 4, 100% \t Train loss: 0.2560 took: 1.79s  Val. loss: 0.2532\n",
      "Epoch 5, 100% \t Train loss: 0.2500 took: 1.80s  Val. loss: 0.2395\n",
      "Epoch 6, 100% \t Train loss: 0.2279 took: 1.80s  Val. loss: 0.2103\n",
      "Epoch 7, 100% \t Train loss: 0.2041 took: 1.80s  Val. loss: 0.2024\n",
      "Epoch 8, 100% \t Train loss: 0.1961 took: 1.82s  Val. loss: 0.1992\n",
      "Epoch 9, 100% \t Train loss: 0.1936 took: 1.80s  Val. loss: 0.1987\n",
      "Epoch 10, 100% \t Train loss: 0.1908 took: 1.80s  Val. loss: 0.1954\n",
      "Epoch 11, 100% \t Train loss: 0.1897 took: 1.79s  Val. loss: 0.1994\n",
      "Epoch 12, 100% \t Train loss: 0.1899 took: 1.79s  Val. loss: 0.1980\n",
      "Epoch 13, 100% \t Train loss: 0.1892 took: 1.80s  Val. loss: 0.1976\n",
      "Epoch 14, 100% \t Train loss: 0.1874 took: 1.80s  Val. loss: 0.1972\n",
      "Epoch 15, 100% \t Train loss: 0.1872 took: 1.70s  Val. loss: 0.1961\n",
      "Epoch 16, 100% \t Train loss: 0.1862 took: 1.03s  Val. loss: 0.1917\n",
      "Epoch 17, 100% \t Train loss: 0.1876 took: 1.04s  Val. loss: 0.1951\n",
      "Epoch 18, 100% \t Train loss: 0.1860 took: 1.03s  Val. loss: 0.1920\n",
      "Epoch 19, 100% \t Train loss: 0.1844 took: 1.03s  Val. loss: 0.1912\n",
      "Epoch 20, 100% \t Train loss: 0.1847 took: 1.03s  Val. loss: 0.1941\n",
      "Epoch 21, 100% \t Train loss: 0.1840 took: 1.04s  Val. loss: 0.1931\n",
      "Epoch 22, 100% \t Train loss: 0.1835 took: 1.04s  Val. loss: 0.1956\n",
      "Epoch 23, 100% \t Train loss: 0.1826 took: 1.03s  Val. loss: 0.1960\n",
      "Epoch 24, 100% \t Train loss: 0.1823 took: 1.04s  Val. loss: 0.1961\n",
      "Epoch 25, 100% \t Train loss: 0.1839 took: 1.04s  Val. loss: 0.1912\n",
      "Epoch 26, 100% \t Train loss: 0.1818 took: 1.04s  Val. loss: 0.1888\n",
      "Epoch 27, 100% \t Train loss: 0.1816 took: 1.04s  Val. loss: 0.1920\n",
      "Epoch 28, 100% \t Train loss: 0.1804 took: 1.04s  Val. loss: 0.1883\n",
      "Epoch 29, 100% \t Train loss: 0.1814 took: 1.04s  Val. loss: 0.1908\n",
      "Epoch 30, 100% \t Train loss: 0.1799 took: 1.04s  Val. loss: 0.1930\n",
      "Epoch 31, 100% \t Train loss: 0.1808 took: 1.04s  Val. loss: 0.1886\n",
      "Epoch 32, 100% \t Train loss: 0.1795 took: 1.05s  Val. loss: 0.1903\n",
      "Epoch 33, 100% \t Train loss: 0.1790 took: 1.04s  Val. loss: 0.1890\n",
      "Epoch 34, 100% \t Train loss: 0.1803 took: 1.05s  Val. loss: 0.1909\n",
      "Epoch 35, 100% \t Train loss: 0.1793 took: 1.05s  Val. loss: 0.1903\n",
      "Epoch 36, 100% \t Train loss: 0.1784 took: 1.05s  Val. loss: 0.1902\n",
      "Epoch 37, 100% \t Train loss: 0.1778 took: 1.06s  Val. loss: 0.1903\n",
      "Epoch 38, 100% \t Train loss: 0.1789 took: 1.05s  Val. loss: 0.1892\n",
      "Epoch 39, 100% \t Train loss: 0.1786 took: 1.05s  Val. loss: 0.1886\n",
      "Epoch 40, 100% \t Train loss: 0.1766 took: 1.05s  Val. loss: 0.1888\n",
      "Epoch 41, 100% \t Train loss: 0.1772 took: 1.05s  Val. loss: 0.1871\n",
      "Epoch 42, 100% \t Train loss: 0.1776 took: 1.04s  Val. loss: 0.1891\n",
      "Epoch 43, 100% \t Train loss: 0.1764 took: 1.04s  Val. loss: 0.1899\n",
      "Epoch 44, 100% \t Train loss: 0.1768 took: 1.04s  Val. loss: 0.1891\n",
      "Epoch 45, 100% \t Train loss: 0.1762 took: 1.04s  Val. loss: 0.1928\n",
      "Epoch 46, 100% \t Train loss: 0.1760 took: 1.03s  Val. loss: 0.1909\n",
      "Epoch 47, 100% \t Train loss: 0.1766 took: 1.03s  Val. loss: 0.1870\n",
      "Epoch 48, 100% \t Train loss: 0.1767 took: 1.04s  Val. loss: 0.1892\n",
      "Epoch 49, 100% \t Train loss: 0.1757 took: 1.03s  Val. loss: 0.1893\n",
      "Epoch 50, 100% \t Train loss: 0.1750 took: 1.05s  Val. loss: 0.1887\n",
      "Training finished, took 71.74s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2571 took: 1.79s  Val. loss: 0.2524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2550 took: 1.82s  Val. loss: 0.2532\n",
      "Epoch 3, 100% \t Train loss: 0.2551 took: 1.79s  Val. loss: 0.2547\n",
      "Epoch 4, 100% \t Train loss: 0.2550 took: 1.79s  Val. loss: 0.2535\n",
      "Epoch 5, 100% \t Train loss: 0.2550 took: 1.80s  Val. loss: 0.2537\n",
      "Epoch 6, 100% \t Train loss: 0.2549 took: 1.79s  Val. loss: 0.2528\n",
      "Epoch 7, 100% \t Train loss: 0.2548 took: 1.79s  Val. loss: 0.2537\n",
      "Epoch 8, 100% \t Train loss: 0.2545 took: 1.79s  Val. loss: 0.2527\n",
      "Epoch 9, 100% \t Train loss: 0.2540 took: 1.78s  Val. loss: 0.2523\n",
      "Epoch 10, 100% \t Train loss: 0.2526 took: 1.81s  Val. loss: 0.2495\n",
      "Epoch 11, 100% \t Train loss: 0.2485 took: 1.79s  Val. loss: 0.2436\n",
      "Epoch 12, 100% \t Train loss: 0.2405 took: 1.79s  Val. loss: 0.2355\n",
      "Epoch 13, 100% \t Train loss: 0.2326 took: 1.79s  Val. loss: 0.2292\n",
      "Epoch 14, 100% \t Train loss: 0.2265 took: 1.78s  Val. loss: 0.2237\n",
      "Epoch 15, 100% \t Train loss: 0.2214 took: 1.78s  Val. loss: 0.2189\n",
      "Epoch 16, 100% \t Train loss: 0.2163 took: 1.77s  Val. loss: 0.2124\n",
      "Epoch 17, 100% \t Train loss: 0.2119 took: 1.78s  Val. loss: 0.2072\n",
      "Epoch 18, 100% \t Train loss: 0.2068 took: 1.78s  Val. loss: 0.2040\n",
      "Epoch 19, 100% \t Train loss: 0.2023 took: 1.78s  Val. loss: 0.1999\n",
      "Epoch 20, 100% \t Train loss: 0.1974 took: 1.78s  Val. loss: 0.2021\n",
      "Epoch 21, 100% \t Train loss: 0.1949 took: 1.80s  Val. loss: 0.1997\n",
      "Epoch 22, 100% \t Train loss: 0.1938 took: 1.80s  Val. loss: 0.1923\n",
      "Epoch 23, 100% \t Train loss: 0.1911 took: 1.80s  Val. loss: 0.1909\n",
      "Epoch 24, 100% \t Train loss: 0.1899 took: 1.80s  Val. loss: 0.1904\n",
      "Epoch 25, 100% \t Train loss: 0.1897 took: 1.81s  Val. loss: 0.1922\n",
      "Epoch 26, 100% \t Train loss: 0.1888 took: 1.80s  Val. loss: 0.1920\n",
      "Epoch 27, 100% \t Train loss: 0.1874 took: 1.78s  Val. loss: 0.1916\n",
      "Epoch 28, 100% \t Train loss: 0.1867 took: 1.79s  Val. loss: 0.1899\n",
      "Epoch 29, 100% \t Train loss: 0.1869 took: 1.78s  Val. loss: 0.1923\n",
      "Epoch 30, 100% \t Train loss: 0.1855 took: 1.79s  Val. loss: 0.1917\n",
      "Epoch 31, 100% \t Train loss: 0.1846 took: 1.79s  Val. loss: 0.1886\n",
      "Epoch 32, 100% \t Train loss: 0.1849 took: 1.79s  Val. loss: 0.1920\n",
      "Epoch 33, 100% \t Train loss: 0.1840 took: 1.80s  Val. loss: 0.1901\n",
      "Epoch 34, 100% \t Train loss: 0.1830 took: 1.78s  Val. loss: 0.1868\n",
      "Epoch 35, 100% \t Train loss: 0.1827 took: 1.78s  Val. loss: 0.1943\n",
      "Epoch 36, 100% \t Train loss: 0.1825 took: 1.80s  Val. loss: 0.1862\n",
      "Epoch 37, 100% \t Train loss: 0.1817 took: 1.80s  Val. loss: 0.1873\n",
      "Epoch 38, 100% \t Train loss: 0.1814 took: 1.80s  Val. loss: 0.1852\n",
      "Epoch 39, 100% \t Train loss: 0.1805 took: 1.80s  Val. loss: 0.1838\n",
      "Epoch 40, 100% \t Train loss: 0.1816 took: 1.79s  Val. loss: 0.1874\n",
      "Epoch 41, 100% \t Train loss: 0.1804 took: 1.77s  Val. loss: 0.1900\n",
      "Epoch 42, 100% \t Train loss: 0.1794 took: 1.78s  Val. loss: 0.1887\n",
      "Epoch 43, 100% \t Train loss: 0.1796 took: 1.81s  Val. loss: 0.1867\n",
      "Epoch 44, 100% \t Train loss: 0.1803 took: 1.81s  Val. loss: 0.1866\n",
      "Epoch 45, 100% \t Train loss: 0.1785 took: 1.78s  Val. loss: 0.1835\n",
      "Epoch 46, 100% \t Train loss: 0.1780 took: 1.77s  Val. loss: 0.1836\n",
      "Epoch 47, 100% \t Train loss: 0.1781 took: 1.78s  Val. loss: 0.1811\n",
      "Epoch 48, 100% \t Train loss: 0.1774 took: 1.76s  Val. loss: 0.1840\n",
      "Epoch 49, 100% \t Train loss: 0.1772 took: 1.77s  Val. loss: 0.1825\n",
      "Epoch 50, 100% \t Train loss: 0.1767 took: 1.81s  Val. loss: 0.1882\n",
      "Training finished, took 101.79s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.27\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.816763\n",
      "lambda: 0.0010 - V: 0.801292\n",
      "lambda: 0.0005 - V: 0.792707\n",
      "Average V: 0.803587\n",
      "Time elapsed: 269.27 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.21\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.81s  Val. loss: 0.2545\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.79s  Val. loss: 0.2536\n",
      "Epoch 3, 100% \t Train loss: 0.2440 took: 1.81s  Val. loss: 0.2100\n",
      "Epoch 4, 100% \t Train loss: 0.1977 took: 1.80s  Val. loss: 0.1990\n",
      "Epoch 5, 100% \t Train loss: 0.1883 took: 1.80s  Val. loss: 0.1921\n",
      "Epoch 6, 100% \t Train loss: 0.1872 took: 1.80s  Val. loss: 0.1944\n",
      "Epoch 7, 100% \t Train loss: 0.1843 took: 1.80s  Val. loss: 0.1939\n",
      "Epoch 8, 100% \t Train loss: 0.1807 took: 1.82s  Val. loss: 0.1910\n",
      "Epoch 9, 100% \t Train loss: 0.1776 took: 1.81s  Val. loss: 0.1840\n",
      "Epoch 10, 100% \t Train loss: 0.1709 took: 1.81s  Val. loss: 0.1822\n",
      "Epoch 11, 100% \t Train loss: 0.1645 took: 1.83s  Val. loss: 0.1743\n",
      "Epoch 12, 100% \t Train loss: 0.1570 took: 1.84s  Val. loss: 0.1656\n",
      "Epoch 13, 100% \t Train loss: 0.1499 took: 1.82s  Val. loss: 0.1648\n",
      "Epoch 14, 100% \t Train loss: 0.1467 took: 1.81s  Val. loss: 0.1603\n",
      "Epoch 15, 100% \t Train loss: 0.1427 took: 1.81s  Val. loss: 0.1603\n",
      "Epoch 16, 100% \t Train loss: 0.1392 took: 1.81s  Val. loss: 0.1529\n",
      "Epoch 17, 100% \t Train loss: 0.1387 took: 1.83s  Val. loss: 0.1512\n",
      "Epoch 18, 100% \t Train loss: 0.1359 took: 1.80s  Val. loss: 0.1490\n",
      "Epoch 19, 100% \t Train loss: 0.1335 took: 1.82s  Val. loss: 0.1499\n",
      "Epoch 20, 100% \t Train loss: 0.1333 took: 1.80s  Val. loss: 0.1490\n",
      "Epoch 21, 100% \t Train loss: 0.1307 took: 1.81s  Val. loss: 0.1479\n",
      "Epoch 22, 100% \t Train loss: 0.1297 took: 1.82s  Val. loss: 0.1478\n",
      "Epoch 23, 100% \t Train loss: 0.1294 took: 1.84s  Val. loss: 0.1473\n",
      "Epoch 24, 100% \t Train loss: 0.1299 took: 1.81s  Val. loss: 0.1475\n",
      "Epoch 25, 100% \t Train loss: 0.1280 took: 1.81s  Val. loss: 0.1437\n",
      "Epoch 26, 100% \t Train loss: 0.1270 took: 1.80s  Val. loss: 0.1441\n",
      "Epoch 27, 100% \t Train loss: 0.1271 took: 1.80s  Val. loss: 0.1434\n",
      "Epoch 28, 100% \t Train loss: 0.1261 took: 1.81s  Val. loss: 0.1432\n",
      "Epoch 29, 100% \t Train loss: 0.1251 took: 1.82s  Val. loss: 0.1439\n",
      "Epoch 30, 100% \t Train loss: 0.1248 took: 1.83s  Val. loss: 0.1420\n",
      "Epoch 31, 100% \t Train loss: 0.1249 took: 1.84s  Val. loss: 0.1429\n",
      "Epoch 32, 100% \t Train loss: 0.1242 took: 1.93s  Val. loss: 0.1425\n",
      "Epoch 33, 100% \t Train loss: 0.1235 took: 2.16s  Val. loss: 0.1479\n",
      "Epoch 34, 100% \t Train loss: 0.1245 took: 2.21s  Val. loss: 0.1417\n",
      "Epoch 35, 100% \t Train loss: 0.1221 took: 2.22s  Val. loss: 0.1404\n",
      "Epoch 36, 100% \t Train loss: 0.1224 took: 2.22s  Val. loss: 0.1403\n",
      "Epoch 37, 100% \t Train loss: 0.1218 took: 2.23s  Val. loss: 0.1426\n",
      "Epoch 38, 100% \t Train loss: 0.1214 took: 2.23s  Val. loss: 0.1424\n",
      "Epoch 39, 100% \t Train loss: 0.1209 took: 2.23s  Val. loss: 0.1400\n",
      "Epoch 40, 100% \t Train loss: 0.1210 took: 2.24s  Val. loss: 0.1370\n",
      "Epoch 41, 100% \t Train loss: 0.1206 took: 2.27s  Val. loss: 0.1395\n",
      "Epoch 42, 100% \t Train loss: 0.1213 took: 2.27s  Val. loss: 0.1379\n",
      "Epoch 43, 100% \t Train loss: 0.1189 took: 2.27s  Val. loss: 0.1403\n",
      "Epoch 44, 100% \t Train loss: 0.1190 took: 2.27s  Val. loss: 0.1378\n",
      "Epoch 45, 100% \t Train loss: 0.1194 took: 1.52s  Val. loss: 0.1394\n",
      "Epoch 46, 100% \t Train loss: 0.1192 took: 1.53s  Val. loss: 0.1414\n",
      "Epoch 47, 100% \t Train loss: 0.1198 took: 2.29s  Val. loss: 0.1405\n",
      "Epoch 48, 100% \t Train loss: 0.1185 took: 2.31s  Val. loss: 0.1388\n",
      "Epoch 49, 100% \t Train loss: 0.1180 took: 2.32s  Val. loss: 0.1434\n",
      "Epoch 50, 100% \t Train loss: 0.1189 took: 2.32s  Val. loss: 0.1385\n",
      "Training finished, took 110.71s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2577 took: 1.85s  Val. loss: 0.2533\n",
      "Epoch 2, 100% \t Train loss: 0.2570 took: 1.83s  Val. loss: 0.2525\n",
      "Epoch 3, 100% \t Train loss: 0.2530 took: 1.86s  Val. loss: 0.2447\n",
      "Epoch 4, 100% \t Train loss: 0.2308 took: 1.82s  Val. loss: 0.2092\n",
      "Epoch 5, 100% \t Train loss: 0.2026 took: 1.83s  Val. loss: 0.1924\n",
      "Epoch 6, 100% \t Train loss: 0.1963 took: 1.82s  Val. loss: 0.1910\n",
      "Epoch 7, 100% \t Train loss: 0.1934 took: 1.84s  Val. loss: 0.1890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.1917 took: 1.83s  Val. loss: 0.1874\n",
      "Epoch 9, 100% \t Train loss: 0.1890 took: 1.83s  Val. loss: 0.1849\n",
      "Epoch 10, 100% \t Train loss: 0.1879 took: 1.06s  Val. loss: 0.1831\n",
      "Epoch 11, 100% \t Train loss: 0.1864 took: 1.07s  Val. loss: 0.1820\n",
      "Epoch 12, 100% \t Train loss: 0.1858 took: 1.07s  Val. loss: 0.1832\n",
      "Epoch 13, 100% \t Train loss: 0.1857 took: 1.06s  Val. loss: 0.1809\n",
      "Epoch 14, 100% \t Train loss: 0.1840 took: 1.06s  Val. loss: 0.1810\n",
      "Epoch 15, 100% \t Train loss: 0.1836 took: 1.07s  Val. loss: 0.1790\n",
      "Epoch 16, 100% \t Train loss: 0.1833 took: 1.07s  Val. loss: 0.1798\n",
      "Epoch 17, 100% \t Train loss: 0.1828 took: 1.06s  Val. loss: 0.1779\n",
      "Epoch 18, 100% \t Train loss: 0.1814 took: 1.14s  Val. loss: 0.1756\n",
      "Epoch 19, 100% \t Train loss: 0.1808 took: 1.49s  Val. loss: 0.1744\n",
      "Epoch 20, 100% \t Train loss: 0.1811 took: 1.82s  Val. loss: 0.1741\n",
      "Epoch 21, 100% \t Train loss: 0.1815 took: 1.84s  Val. loss: 0.1757\n",
      "Epoch 22, 100% \t Train loss: 0.1804 took: 1.83s  Val. loss: 0.1789\n",
      "Epoch 23, 100% \t Train loss: 0.1802 took: 1.82s  Val. loss: 0.1752\n",
      "Epoch 24, 100% \t Train loss: 0.1808 took: 1.81s  Val. loss: 0.1743\n",
      "Epoch 25, 100% \t Train loss: 0.1794 took: 1.68s  Val. loss: 0.1759\n",
      "Epoch 26, 100% \t Train loss: 0.1790 took: 1.66s  Val. loss: 0.1756\n",
      "Epoch 27, 100% \t Train loss: 0.1792 took: 1.06s  Val. loss: 0.1750\n",
      "Epoch 28, 100% \t Train loss: 0.1786 took: 1.07s  Val. loss: 0.1753\n",
      "Epoch 29, 100% \t Train loss: 0.1776 took: 1.08s  Val. loss: 0.1720\n",
      "Epoch 30, 100% \t Train loss: 0.1784 took: 1.07s  Val. loss: 0.1790\n",
      "Epoch 31, 100% \t Train loss: 0.1789 took: 1.08s  Val. loss: 0.1752\n",
      "Epoch 32, 100% \t Train loss: 0.1768 took: 1.08s  Val. loss: 0.1730\n",
      "Epoch 33, 100% \t Train loss: 0.1766 took: 1.08s  Val. loss: 0.1753\n",
      "Epoch 34, 100% \t Train loss: 0.1770 took: 1.09s  Val. loss: 0.1728\n",
      "Epoch 35, 100% \t Train loss: 0.1759 took: 1.09s  Val. loss: 0.1713\n",
      "Epoch 36, 100% \t Train loss: 0.1765 took: 1.10s  Val. loss: 0.1708\n",
      "Epoch 37, 100% \t Train loss: 0.1748 took: 1.10s  Val. loss: 0.1711\n",
      "Epoch 38, 100% \t Train loss: 0.1746 took: 1.09s  Val. loss: 0.1698\n",
      "Epoch 39, 100% \t Train loss: 0.1733 took: 1.10s  Val. loss: 0.1693\n",
      "Epoch 40, 100% \t Train loss: 0.1712 took: 1.11s  Val. loss: 0.1657\n",
      "Epoch 41, 100% \t Train loss: 0.1689 took: 1.12s  Val. loss: 0.1645\n",
      "Epoch 42, 100% \t Train loss: 0.1663 took: 1.13s  Val. loss: 0.1615\n",
      "Epoch 43, 100% \t Train loss: 0.1630 took: 1.13s  Val. loss: 0.1610\n",
      "Epoch 44, 100% \t Train loss: 0.1609 took: 1.13s  Val. loss: 0.1558\n",
      "Epoch 45, 100% \t Train loss: 0.1576 took: 1.12s  Val. loss: 0.1563\n",
      "Epoch 46, 100% \t Train loss: 0.1555 took: 1.17s  Val. loss: 0.1542\n",
      "Epoch 47, 100% \t Train loss: 0.1530 took: 1.15s  Val. loss: 0.1547\n",
      "Epoch 48, 100% \t Train loss: 0.1512 took: 1.15s  Val. loss: 0.1557\n",
      "Epoch 49, 100% \t Train loss: 0.1502 took: 1.14s  Val. loss: 0.1501\n",
      "Epoch 50, 100% \t Train loss: 0.1478 took: 1.14s  Val. loss: 0.1485\n",
      "Training finished, took 75.76s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2605 took: 1.07s  Val. loss: 0.2598\n",
      "Epoch 2, 100% \t Train loss: 0.2591 took: 1.06s  Val. loss: 0.2583\n",
      "Epoch 3, 100% \t Train loss: 0.2591 took: 1.07s  Val. loss: 0.2590\n",
      "Epoch 4, 100% \t Train loss: 0.2590 took: 1.06s  Val. loss: 0.2589\n",
      "Epoch 5, 100% \t Train loss: 0.2589 took: 1.07s  Val. loss: 0.2585\n",
      "Epoch 6, 100% \t Train loss: 0.2588 took: 1.06s  Val. loss: 0.2579\n",
      "Epoch 7, 100% \t Train loss: 0.2585 took: 1.06s  Val. loss: 0.2585\n",
      "Epoch 8, 100% \t Train loss: 0.2576 took: 1.06s  Val. loss: 0.2570\n",
      "Epoch 9, 100% \t Train loss: 0.2551 took: 1.07s  Val. loss: 0.2541\n",
      "Epoch 10, 100% \t Train loss: 0.2476 took: 1.07s  Val. loss: 0.2422\n",
      "Epoch 11, 100% \t Train loss: 0.2316 took: 1.06s  Val. loss: 0.2287\n",
      "Epoch 12, 100% \t Train loss: 0.2162 took: 1.06s  Val. loss: 0.2164\n",
      "Epoch 13, 100% \t Train loss: 0.2045 took: 1.07s  Val. loss: 0.2096\n",
      "Epoch 14, 100% \t Train loss: 0.1999 took: 1.07s  Val. loss: 0.2066\n",
      "Epoch 15, 100% \t Train loss: 0.1979 took: 1.07s  Val. loss: 0.2054\n",
      "Epoch 16, 100% \t Train loss: 0.1965 took: 1.06s  Val. loss: 0.2037\n",
      "Epoch 17, 100% \t Train loss: 0.1947 took: 1.06s  Val. loss: 0.2030\n",
      "Epoch 18, 100% \t Train loss: 0.1933 took: 1.06s  Val. loss: 0.1993\n",
      "Epoch 19, 100% \t Train loss: 0.1925 took: 1.06s  Val. loss: 0.2002\n",
      "Epoch 20, 100% \t Train loss: 0.1916 took: 1.07s  Val. loss: 0.1990\n",
      "Epoch 21, 100% \t Train loss: 0.1906 took: 1.15s  Val. loss: 0.1960\n",
      "Epoch 22, 100% \t Train loss: 0.1896 took: 1.81s  Val. loss: 0.1956\n",
      "Epoch 23, 100% \t Train loss: 0.1915 took: 1.84s  Val. loss: 0.1992\n",
      "Epoch 24, 100% \t Train loss: 0.1897 took: 1.81s  Val. loss: 0.1962\n",
      "Epoch 25, 100% \t Train loss: 0.1896 took: 1.81s  Val. loss: 0.1961\n",
      "Epoch 26, 100% \t Train loss: 0.1889 took: 1.82s  Val. loss: 0.1976\n",
      "Epoch 27, 100% \t Train loss: 0.1883 took: 1.81s  Val. loss: 0.1941\n",
      "Epoch 28, 100% \t Train loss: 0.1882 took: 1.82s  Val. loss: 0.1960\n",
      "Epoch 29, 100% \t Train loss: 0.1873 took: 1.84s  Val. loss: 0.1925\n",
      "Epoch 30, 100% \t Train loss: 0.1880 took: 1.82s  Val. loss: 0.1974\n",
      "Epoch 31, 100% \t Train loss: 0.1872 took: 1.85s  Val. loss: 0.1972\n",
      "Epoch 32, 100% \t Train loss: 0.1877 took: 1.83s  Val. loss: 0.1966\n",
      "Epoch 33, 100% \t Train loss: 0.1868 took: 1.86s  Val. loss: 0.1932\n",
      "Epoch 34, 100% \t Train loss: 0.1864 took: 1.84s  Val. loss: 0.1926\n",
      "Epoch 35, 100% \t Train loss: 0.1863 took: 1.83s  Val. loss: 0.1942\n",
      "Epoch 36, 100% \t Train loss: 0.1860 took: 1.83s  Val. loss: 0.1937\n",
      "Epoch 37, 100% \t Train loss: 0.1860 took: 1.86s  Val. loss: 0.1924\n",
      "Epoch 38, 100% \t Train loss: 0.1855 took: 1.84s  Val. loss: 0.1947\n",
      "Epoch 39, 100% \t Train loss: 0.1857 took: 1.86s  Val. loss: 0.1912\n",
      "Epoch 40, 100% \t Train loss: 0.1860 took: 1.86s  Val. loss: 0.1937\n",
      "Epoch 41, 100% \t Train loss: 0.1851 took: 1.86s  Val. loss: 0.1964\n",
      "Epoch 42, 100% \t Train loss: 0.1858 took: 1.89s  Val. loss: 0.1905\n",
      "Epoch 43, 100% \t Train loss: 0.1846 took: 1.85s  Val. loss: 0.1963\n",
      "Epoch 44, 100% \t Train loss: 0.1851 took: 1.84s  Val. loss: 0.1965\n",
      "Epoch 45, 100% \t Train loss: 0.1855 took: 1.83s  Val. loss: 0.1927\n",
      "Epoch 46, 100% \t Train loss: 0.1842 took: 1.84s  Val. loss: 0.1919\n",
      "Epoch 47, 100% \t Train loss: 0.1840 took: 1.85s  Val. loss: 0.1945\n",
      "Epoch 48, 100% \t Train loss: 0.1841 took: 1.83s  Val. loss: 0.1931\n",
      "Epoch 49, 100% \t Train loss: 0.1840 took: 1.83s  Val. loss: 0.1913\n",
      "Epoch 50, 100% \t Train loss: 0.1848 took: 1.88s  Val. loss: 0.1915\n",
      "Training finished, took 86.28s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.21\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.842035\n",
      "lambda: 0.0010 - V: 0.821826\n",
      "lambda: 0.0005 - V: 0.790581\n",
      "Average V: 0.818147\n",
      "Time elapsed: 276.11 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.21\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2557 took: 2.53s  Val. loss: 0.2623\n",
      "Epoch 2, 100% \t Train loss: 0.2553 took: 2.52s  Val. loss: 0.2631\n",
      "Epoch 3, 100% \t Train loss: 0.2554 took: 2.53s  Val. loss: 0.2618\n",
      "Epoch 4, 100% \t Train loss: 0.2553 took: 2.52s  Val. loss: 0.2634\n",
      "Epoch 5, 100% \t Train loss: 0.2553 took: 1.55s  Val. loss: 0.2630\n",
      "Epoch 6, 100% \t Train loss: 0.2553 took: 1.55s  Val. loss: 0.2624\n",
      "Epoch 7, 100% \t Train loss: 0.2553 took: 1.55s  Val. loss: 0.2623\n",
      "Epoch 8, 100% \t Train loss: 0.2553 took: 1.55s  Val. loss: 0.2623\n",
      "Epoch 9, 100% \t Train loss: 0.2553 took: 1.55s  Val. loss: 0.2633\n",
      "Epoch 10, 100% \t Train loss: 0.2553 took: 1.56s  Val. loss: 0.2630\n",
      "Epoch 11, 100% \t Train loss: 0.2553 took: 1.55s  Val. loss: 0.2628\n",
      "Epoch 12, 100% \t Train loss: 0.2554 took: 1.55s  Val. loss: 0.2634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 100% \t Train loss: 0.2553 took: 1.58s  Val. loss: 0.2628\n",
      "Epoch 14, 100% \t Train loss: 0.2553 took: 1.56s  Val. loss: 0.2631\n",
      "Epoch 15, 100% \t Train loss: 0.2553 took: 1.56s  Val. loss: 0.2624\n",
      "Epoch 16, 100% \t Train loss: 0.2553 took: 1.58s  Val. loss: 0.2632\n",
      "Epoch 17, 100% \t Train loss: 0.2553 took: 1.59s  Val. loss: 0.2632\n",
      "Epoch 18, 100% \t Train loss: 0.2553 took: 1.59s  Val. loss: 0.2632\n",
      "Epoch 19, 100% \t Train loss: 0.2554 took: 1.59s  Val. loss: 0.2625\n",
      "Epoch 20, 100% \t Train loss: 0.2553 took: 1.59s  Val. loss: 0.2628\n",
      "Epoch 21, 100% \t Train loss: 0.2553 took: 1.58s  Val. loss: 0.2626\n",
      "Epoch 22, 100% \t Train loss: 0.2553 took: 1.63s  Val. loss: 0.2634\n",
      "Epoch 23, 100% \t Train loss: 0.2553 took: 1.64s  Val. loss: 0.2621\n",
      "Epoch 24, 100% \t Train loss: 0.2553 took: 1.74s  Val. loss: 0.2626\n",
      "Epoch 25, 100% \t Train loss: 0.2553 took: 2.08s  Val. loss: 0.2631\n",
      "Epoch 26, 100% \t Train loss: 0.2553 took: 3.41s  Val. loss: 0.2626\n",
      "Epoch 27, 100% \t Train loss: 0.2553 took: 3.63s  Val. loss: 0.2629\n",
      "Epoch 28, 100% \t Train loss: 0.2552 took: 3.53s  Val. loss: 0.2626\n",
      "Epoch 29, 100% \t Train loss: 0.2553 took: 3.45s  Val. loss: 0.2636\n",
      "Epoch 30, 100% \t Train loss: 0.2553 took: 3.54s  Val. loss: 0.2623\n",
      "Epoch 31, 100% \t Train loss: 0.2553 took: 3.36s  Val. loss: 0.2629\n",
      "Epoch 32, 100% \t Train loss: 0.2553 took: 3.66s  Val. loss: 0.2622\n",
      "Epoch 33, 100% \t Train loss: 0.2553 took: 3.47s  Val. loss: 0.2625\n",
      "Epoch 34, 100% \t Train loss: 0.2553 took: 3.62s  Val. loss: 0.2637\n",
      "Epoch 35, 100% \t Train loss: 0.2553 took: 3.92s  Val. loss: 0.2624\n",
      "Epoch 36, 100% \t Train loss: 0.2553 took: 3.17s  Val. loss: 0.2623\n",
      "Epoch 37, 100% \t Train loss: 0.2553 took: 3.46s  Val. loss: 0.2624\n",
      "Epoch 38, 100% \t Train loss: 0.2553 took: 3.89s  Val. loss: 0.2629\n",
      "Epoch 39, 100% \t Train loss: 0.2553 took: 3.61s  Val. loss: 0.2627\n",
      "Epoch 40, 100% \t Train loss: 0.2552 took: 3.59s  Val. loss: 0.2628\n",
      "Epoch 41, 100% \t Train loss: 0.2553 took: 3.47s  Val. loss: 0.2627\n",
      "Epoch 42, 100% \t Train loss: 0.2553 took: 3.36s  Val. loss: 0.2623\n",
      "Epoch 43, 100% \t Train loss: 0.2553 took: 3.36s  Val. loss: 0.2629\n",
      "Epoch 44, 100% \t Train loss: 0.2553 took: 3.40s  Val. loss: 0.2626\n",
      "Epoch 45, 100% \t Train loss: 0.2553 took: 3.41s  Val. loss: 0.2631\n",
      "Epoch 46, 100% \t Train loss: 0.2553 took: 3.42s  Val. loss: 0.2632\n",
      "Epoch 47, 100% \t Train loss: 0.2553 took: 3.29s  Val. loss: 0.2629\n",
      "Epoch 48, 100% \t Train loss: 0.2553 took: 3.28s  Val. loss: 0.2627\n",
      "Epoch 49, 100% \t Train loss: 0.2553 took: 3.22s  Val. loss: 0.2623\n",
      "Epoch 50, 100% \t Train loss: 0.2553 took: 3.26s  Val. loss: 0.2631\n",
      "Training finished, took 145.71s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 1.59s  Val. loss: 0.2563\n",
      "Epoch 2, 100% \t Train loss: 0.2575 took: 1.58s  Val. loss: 0.2563\n",
      "Epoch 3, 100% \t Train loss: 0.2575 took: 1.57s  Val. loss: 0.2569\n",
      "Epoch 4, 100% \t Train loss: 0.2576 took: 1.58s  Val. loss: 0.2557\n",
      "Epoch 5, 100% \t Train loss: 0.2576 took: 1.58s  Val. loss: 0.2554\n",
      "Epoch 6, 100% \t Train loss: 0.2576 took: 1.58s  Val. loss: 0.2548\n",
      "Epoch 7, 100% \t Train loss: 0.2575 took: 1.58s  Val. loss: 0.2550\n",
      "Epoch 8, 100% \t Train loss: 0.2575 took: 1.58s  Val. loss: 0.2554\n",
      "Epoch 9, 100% \t Train loss: 0.2576 took: 1.58s  Val. loss: 0.2553\n",
      "Epoch 10, 100% \t Train loss: 0.2574 took: 1.58s  Val. loss: 0.2556\n",
      "Epoch 11, 100% \t Train loss: 0.2575 took: 2.54s  Val. loss: 0.2561\n",
      "Epoch 12, 100% \t Train loss: 0.2575 took: 2.52s  Val. loss: 0.2553\n",
      "Epoch 13, 100% \t Train loss: 0.2575 took: 2.52s  Val. loss: 0.2556\n",
      "Epoch 14, 100% \t Train loss: 0.2574 took: 2.52s  Val. loss: 0.2574\n",
      "Epoch 15, 100% \t Train loss: 0.2576 took: 2.56s  Val. loss: 0.2561\n",
      "Epoch 16, 100% \t Train loss: 0.2575 took: 1.58s  Val. loss: 0.2560\n",
      "Epoch 17, 100% \t Train loss: 0.2574 took: 1.55s  Val. loss: 0.2568\n",
      "Epoch 18, 100% \t Train loss: 0.2575 took: 2.17s  Val. loss: 0.2553\n",
      "Epoch 19, 100% \t Train loss: 0.2575 took: 2.52s  Val. loss: 0.2546\n",
      "Epoch 20, 100% \t Train loss: 0.2575 took: 2.54s  Val. loss: 0.2559\n",
      "Epoch 21, 100% \t Train loss: 0.2574 took: 2.54s  Val. loss: 0.2559\n",
      "Epoch 22, 100% \t Train loss: 0.2575 took: 2.52s  Val. loss: 0.2558\n",
      "Epoch 23, 100% \t Train loss: 0.2575 took: 2.54s  Val. loss: 0.2554\n",
      "Epoch 24, 100% \t Train loss: 0.2575 took: 2.52s  Val. loss: 0.2564\n",
      "Epoch 25, 100% \t Train loss: 0.2574 took: 2.55s  Val. loss: 0.2554\n",
      "Epoch 26, 100% \t Train loss: 0.2575 took: 2.58s  Val. loss: 0.2566\n",
      "Epoch 27, 100% \t Train loss: 0.2574 took: 2.59s  Val. loss: 0.2557\n",
      "Epoch 28, 100% \t Train loss: 0.2575 took: 2.63s  Val. loss: 0.2550\n",
      "Epoch 29, 100% \t Train loss: 0.2574 took: 2.64s  Val. loss: 0.2549\n",
      "Epoch 30, 100% \t Train loss: 0.2575 took: 2.68s  Val. loss: 0.2558\n",
      "Epoch 31, 100% \t Train loss: 0.2574 took: 2.73s  Val. loss: 0.2551\n",
      "Epoch 32, 100% \t Train loss: 0.2574 took: 1.91s  Val. loss: 0.2553\n",
      "Epoch 33, 100% \t Train loss: 0.2575 took: 2.04s  Val. loss: 0.2563\n",
      "Epoch 34, 100% \t Train loss: 0.2574 took: 1.98s  Val. loss: 0.2550\n",
      "Epoch 35, 100% \t Train loss: 0.2574 took: 1.94s  Val. loss: 0.2550\n",
      "Epoch 36, 100% \t Train loss: 0.2575 took: 2.93s  Val. loss: 0.2549\n",
      "Epoch 37, 100% \t Train loss: 0.2574 took: 3.08s  Val. loss: 0.2555\n",
      "Epoch 38, 100% \t Train loss: 0.2575 took: 2.74s  Val. loss: 0.2556\n",
      "Epoch 39, 100% \t Train loss: 0.2575 took: 3.41s  Val. loss: 0.2556\n",
      "Epoch 40, 100% \t Train loss: 0.2575 took: 3.35s  Val. loss: 0.2549\n",
      "Epoch 41, 100% \t Train loss: 0.2574 took: 3.52s  Val. loss: 0.2566\n",
      "Epoch 42, 100% \t Train loss: 0.2575 took: 3.50s  Val. loss: 0.2557\n",
      "Epoch 43, 100% \t Train loss: 0.2574 took: 3.62s  Val. loss: 0.2556\n",
      "Epoch 44, 100% \t Train loss: 0.2574 took: 2.90s  Val. loss: 0.2557\n",
      "Epoch 45, 100% \t Train loss: 0.2575 took: 4.00s  Val. loss: 0.2555\n",
      "Epoch 46, 100% \t Train loss: 0.2574 took: 4.12s  Val. loss: 0.2562\n",
      "Epoch 47, 100% \t Train loss: 0.2574 took: 4.35s  Val. loss: 0.2558\n",
      "Epoch 48, 100% \t Train loss: 0.2575 took: 4.73s  Val. loss: 0.2565\n",
      "Epoch 49, 100% \t Train loss: 0.2574 took: 4.93s  Val. loss: 0.2553\n",
      "Epoch 50, 100% \t Train loss: 0.2574 took: 5.03s  Val. loss: 0.2553\n",
      "Training finished, took 145.34s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2587 took: 2.55s  Val. loss: 0.2630\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 2.52s  Val. loss: 0.2631\n",
      "Epoch 3, 100% \t Train loss: 0.2584 took: 2.52s  Val. loss: 0.2625\n",
      "Epoch 4, 100% \t Train loss: 0.2585 took: 2.52s  Val. loss: 0.2637\n",
      "Epoch 5, 100% \t Train loss: 0.2584 took: 2.53s  Val. loss: 0.2622\n",
      "Epoch 6, 100% \t Train loss: 0.2584 took: 2.54s  Val. loss: 0.2623\n",
      "Epoch 7, 100% \t Train loss: 0.2584 took: 1.55s  Val. loss: 0.2630\n",
      "Epoch 8, 100% \t Train loss: 0.2584 took: 1.55s  Val. loss: 0.2621\n",
      "Epoch 9, 100% \t Train loss: 0.2584 took: 1.56s  Val. loss: 0.2631\n",
      "Epoch 10, 100% \t Train loss: 0.2583 took: 1.56s  Val. loss: 0.2635\n",
      "Epoch 11, 100% \t Train loss: 0.2580 took: 1.56s  Val. loss: 0.2615\n",
      "Epoch 12, 100% \t Train loss: 0.2566 took: 1.56s  Val. loss: 0.2594\n",
      "Epoch 13, 100% \t Train loss: 0.2498 took: 1.56s  Val. loss: 0.2463\n",
      "Epoch 14, 100% \t Train loss: 0.2316 took: 1.56s  Val. loss: 0.2213\n",
      "Epoch 15, 100% \t Train loss: 0.2148 took: 1.55s  Val. loss: 0.2108\n",
      "Epoch 16, 100% \t Train loss: 0.2054 took: 1.55s  Val. loss: 0.2019\n",
      "Epoch 17, 100% \t Train loss: 0.2014 took: 1.55s  Val. loss: 0.2006\n",
      "Epoch 18, 100% \t Train loss: 0.1984 took: 1.55s  Val. loss: 0.1980\n",
      "Epoch 19, 100% \t Train loss: 0.1967 took: 1.55s  Val. loss: 0.1944\n",
      "Epoch 20, 100% \t Train loss: 0.1953 took: 1.55s  Val. loss: 0.1958\n",
      "Epoch 21, 100% \t Train loss: 0.1942 took: 1.55s  Val. loss: 0.1936\n",
      "Epoch 22, 100% \t Train loss: 0.1931 took: 1.55s  Val. loss: 0.1918\n",
      "Epoch 23, 100% \t Train loss: 0.1927 took: 1.55s  Val. loss: 0.1947\n",
      "Epoch 24, 100% \t Train loss: 0.1911 took: 1.55s  Val. loss: 0.1914\n",
      "Epoch 25, 100% \t Train loss: 0.1915 took: 1.56s  Val. loss: 0.1924\n",
      "Epoch 26, 100% \t Train loss: 0.1910 took: 1.56s  Val. loss: 0.1915\n",
      "Epoch 27, 100% \t Train loss: 0.1906 took: 1.56s  Val. loss: 0.1915\n",
      "Epoch 28, 100% \t Train loss: 0.1891 took: 1.57s  Val. loss: 0.1919\n",
      "Epoch 29, 100% \t Train loss: 0.1892 took: 1.57s  Val. loss: 0.1914\n",
      "Epoch 30, 100% \t Train loss: 0.1882 took: 1.57s  Val. loss: 0.1901\n",
      "Epoch 31, 100% \t Train loss: 0.1879 took: 1.58s  Val. loss: 0.1879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, 100% \t Train loss: 0.1886 took: 1.59s  Val. loss: 0.1882\n",
      "Epoch 33, 100% \t Train loss: 0.1872 took: 1.59s  Val. loss: 0.1900\n",
      "Epoch 34, 100% \t Train loss: 0.1875 took: 1.76s  Val. loss: 0.1880\n",
      "Epoch 35, 100% \t Train loss: 0.1863 took: 2.55s  Val. loss: 0.1944\n",
      "Epoch 36, 100% \t Train loss: 0.1869 took: 2.57s  Val. loss: 0.1906\n",
      "Epoch 37, 100% \t Train loss: 0.1866 took: 2.59s  Val. loss: 0.1870\n",
      "Epoch 38, 100% \t Train loss: 0.1861 took: 2.61s  Val. loss: 0.1902\n",
      "Epoch 39, 100% \t Train loss: 0.1862 took: 2.61s  Val. loss: 0.1866\n",
      "Epoch 40, 100% \t Train loss: 0.1859 took: 2.63s  Val. loss: 0.1958\n",
      "Epoch 41, 100% \t Train loss: 0.1858 took: 2.60s  Val. loss: 0.1929\n",
      "Epoch 42, 100% \t Train loss: 0.1853 took: 2.62s  Val. loss: 0.1879\n",
      "Epoch 43, 100% \t Train loss: 0.1851 took: 2.59s  Val. loss: 0.1872\n",
      "Epoch 44, 100% \t Train loss: 0.1854 took: 2.60s  Val. loss: 0.1884\n",
      "Epoch 45, 100% \t Train loss: 0.1850 took: 2.04s  Val. loss: 0.1890\n",
      "Epoch 46, 100% \t Train loss: 0.1849 took: 2.59s  Val. loss: 0.1863\n",
      "Epoch 47, 100% \t Train loss: 0.1852 took: 2.59s  Val. loss: 0.1883\n",
      "Epoch 48, 100% \t Train loss: 0.1848 took: 2.59s  Val. loss: 0.1878\n",
      "Epoch 49, 100% \t Train loss: 0.1837 took: 2.61s  Val. loss: 0.1886\n",
      "Epoch 50, 100% \t Train loss: 0.1836 took: 2.60s  Val. loss: 0.1899\n",
      "Training finished, took 110.75s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.34\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.21\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.737224\n",
      "lambda: 0.0010 - V: 0.744316\n",
      "lambda: 0.0005 - V: 0.789523\n",
      "Average V: 0.757021\n",
      "Time elapsed: 405.16 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2575 took: 1.83s  Val. loss: 0.2543\n",
      "Epoch 2, 100% \t Train loss: 0.2570 took: 1.79s  Val. loss: 0.2576\n",
      "Epoch 3, 100% \t Train loss: 0.2559 took: 1.81s  Val. loss: 0.2513\n",
      "Epoch 4, 100% \t Train loss: 0.2177 took: 1.80s  Val. loss: 0.1759\n",
      "Epoch 5, 100% \t Train loss: 0.1698 took: 1.81s  Val. loss: 0.1684\n",
      "Epoch 6, 100% \t Train loss: 0.1619 took: 1.80s  Val. loss: 0.1673\n",
      "Epoch 7, 100% \t Train loss: 0.1581 took: 1.82s  Val. loss: 0.1666\n",
      "Epoch 8, 100% \t Train loss: 0.1539 took: 1.80s  Val. loss: 0.1643\n",
      "Epoch 9, 100% \t Train loss: 0.1523 took: 1.81s  Val. loss: 0.1642\n",
      "Epoch 10, 100% \t Train loss: 0.1536 took: 1.80s  Val. loss: 0.1691\n",
      "Epoch 11, 100% \t Train loss: 0.1504 took: 1.80s  Val. loss: 0.1642\n",
      "Epoch 12, 100% \t Train loss: 0.1492 took: 1.80s  Val. loss: 0.1589\n",
      "Epoch 13, 100% \t Train loss: 0.1479 took: 1.81s  Val. loss: 0.1613\n",
      "Epoch 14, 100% \t Train loss: 0.1484 took: 1.81s  Val. loss: 0.1577\n",
      "Epoch 15, 100% \t Train loss: 0.1465 took: 1.81s  Val. loss: 0.1580\n",
      "Epoch 16, 100% \t Train loss: 0.1460 took: 1.81s  Val. loss: 0.1615\n",
      "Epoch 17, 100% \t Train loss: 0.1452 took: 1.81s  Val. loss: 0.1574\n",
      "Epoch 18, 100% \t Train loss: 0.1448 took: 1.82s  Val. loss: 0.1604\n",
      "Epoch 19, 100% \t Train loss: 0.1451 took: 1.82s  Val. loss: 0.1590\n",
      "Epoch 20, 100% \t Train loss: 0.1443 took: 1.84s  Val. loss: 0.1602\n",
      "Epoch 21, 100% \t Train loss: 0.1445 took: 1.80s  Val. loss: 0.1555\n",
      "Epoch 22, 100% \t Train loss: 0.1439 took: 1.82s  Val. loss: 0.1579\n",
      "Epoch 23, 100% \t Train loss: 0.1431 took: 1.81s  Val. loss: 0.1589\n",
      "Epoch 24, 100% \t Train loss: 0.1429 took: 1.81s  Val. loss: 0.1541\n",
      "Epoch 25, 100% \t Train loss: 0.1423 took: 1.82s  Val. loss: 0.1581\n",
      "Epoch 26, 100% \t Train loss: 0.1420 took: 1.82s  Val. loss: 0.1560\n",
      "Epoch 27, 100% \t Train loss: 0.1404 took: 1.82s  Val. loss: 0.1508\n",
      "Epoch 28, 100% \t Train loss: 0.1385 took: 1.82s  Val. loss: 0.1550\n",
      "Epoch 29, 100% \t Train loss: 0.1350 took: 1.83s  Val. loss: 0.1469\n",
      "Epoch 30, 100% \t Train loss: 0.1279 took: 1.82s  Val. loss: 0.1404\n",
      "Epoch 31, 100% \t Train loss: 0.1208 took: 1.84s  Val. loss: 0.1330\n",
      "Epoch 32, 100% \t Train loss: 0.1145 took: 1.86s  Val. loss: 0.1286\n",
      "Epoch 33, 100% \t Train loss: 0.1077 took: 1.95s  Val. loss: 0.1143\n",
      "Epoch 34, 100% \t Train loss: 0.1009 took: 1.98s  Val. loss: 0.1067\n",
      "Epoch 35, 100% \t Train loss: 0.0965 took: 1.99s  Val. loss: 0.1084\n",
      "Epoch 36, 100% \t Train loss: 0.0919 took: 1.98s  Val. loss: 0.0995\n",
      "Epoch 37, 100% \t Train loss: 0.0884 took: 1.98s  Val. loss: 0.0969\n",
      "Epoch 38, 100% \t Train loss: 0.0863 took: 1.97s  Val. loss: 0.0978\n",
      "Epoch 39, 100% \t Train loss: 0.0843 took: 1.98s  Val. loss: 0.0917\n",
      "Epoch 40, 100% \t Train loss: 0.0825 took: 2.01s  Val. loss: 0.0912\n",
      "Epoch 41, 100% \t Train loss: 0.0816 took: 1.98s  Val. loss: 0.0897\n",
      "Epoch 42, 100% \t Train loss: 0.0795 took: 1.96s  Val. loss: 0.0908\n",
      "Epoch 43, 100% \t Train loss: 0.0803 took: 1.96s  Val. loss: 0.0895\n",
      "Epoch 44, 100% \t Train loss: 0.0775 took: 1.96s  Val. loss: 0.0875\n",
      "Epoch 45, 100% \t Train loss: 0.0777 took: 1.97s  Val. loss: 0.0873\n",
      "Epoch 46, 100% \t Train loss: 0.0769 took: 1.96s  Val. loss: 0.0883\n",
      "Epoch 47, 100% \t Train loss: 0.0770 took: 1.94s  Val. loss: 0.0889\n",
      "Epoch 48, 100% \t Train loss: 0.0755 took: 1.97s  Val. loss: 0.0862\n",
      "Epoch 49, 100% \t Train loss: 0.0744 took: 1.94s  Val. loss: 0.0916\n",
      "Epoch 50, 100% \t Train loss: 0.0748 took: 1.95s  Val. loss: 0.0904\n",
      "Training finished, took 106.18s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2613 took: 1.81s  Val. loss: 0.2571\n",
      "Epoch 2, 100% \t Train loss: 0.2585 took: 1.80s  Val. loss: 0.2523\n",
      "Epoch 3, 100% \t Train loss: 0.2321 took: 1.80s  Val. loss: 0.2225\n",
      "Epoch 4, 100% \t Train loss: 0.2038 took: 1.80s  Val. loss: 0.1990\n",
      "Epoch 5, 100% \t Train loss: 0.1833 took: 1.79s  Val. loss: 0.1834\n",
      "Epoch 6, 100% \t Train loss: 0.1765 took: 1.81s  Val. loss: 0.1790\n",
      "Epoch 7, 100% \t Train loss: 0.1747 took: 1.81s  Val. loss: 0.1782\n",
      "Epoch 8, 100% \t Train loss: 0.1735 took: 1.84s  Val. loss: 0.1767\n",
      "Epoch 9, 100% \t Train loss: 0.1712 took: 1.81s  Val. loss: 0.1795\n",
      "Epoch 10, 100% \t Train loss: 0.1674 took: 1.81s  Val. loss: 0.1747\n",
      "Epoch 11, 100% \t Train loss: 0.1677 took: 1.81s  Val. loss: 0.1724\n",
      "Epoch 12, 100% \t Train loss: 0.1658 took: 1.82s  Val. loss: 0.1728\n",
      "Epoch 13, 100% \t Train loss: 0.1649 took: 1.83s  Val. loss: 0.1688\n",
      "Epoch 14, 100% \t Train loss: 0.1623 took: 1.82s  Val. loss: 0.1680\n",
      "Epoch 15, 100% \t Train loss: 0.1632 took: 1.81s  Val. loss: 0.1673\n",
      "Epoch 16, 100% \t Train loss: 0.1609 took: 1.81s  Val. loss: 0.1652\n",
      "Epoch 17, 100% \t Train loss: 0.1617 took: 1.82s  Val. loss: 0.1686\n",
      "Epoch 18, 100% \t Train loss: 0.1633 took: 1.82s  Val. loss: 0.1662\n",
      "Epoch 19, 100% \t Train loss: 0.1591 took: 1.82s  Val. loss: 0.1652\n",
      "Epoch 20, 100% \t Train loss: 0.1595 took: 1.82s  Val. loss: 0.1664\n",
      "Epoch 21, 100% \t Train loss: 0.1593 took: 1.82s  Val. loss: 0.1669\n",
      "Epoch 22, 100% \t Train loss: 0.1610 took: 1.81s  Val. loss: 0.1696\n",
      "Epoch 23, 100% \t Train loss: 0.1573 took: 1.81s  Val. loss: 0.1641\n",
      "Epoch 24, 100% \t Train loss: 0.1564 took: 1.83s  Val. loss: 0.1677\n",
      "Epoch 25, 100% \t Train loss: 0.1561 took: 1.81s  Val. loss: 0.1649\n",
      "Epoch 26, 100% \t Train loss: 0.1541 took: 1.82s  Val. loss: 0.1634\n",
      "Epoch 27, 100% \t Train loss: 0.1539 took: 1.81s  Val. loss: 0.1704\n",
      "Epoch 28, 100% \t Train loss: 0.1546 took: 1.81s  Val. loss: 0.1619\n",
      "Epoch 29, 100% \t Train loss: 0.1530 took: 1.80s  Val. loss: 0.1623\n",
      "Epoch 30, 100% \t Train loss: 0.1529 took: 1.80s  Val. loss: 0.1642\n",
      "Epoch 31, 100% \t Train loss: 0.1514 took: 1.83s  Val. loss: 0.1627\n",
      "Epoch 32, 100% \t Train loss: 0.1513 took: 1.83s  Val. loss: 0.1648\n",
      "Epoch 33, 100% \t Train loss: 0.1518 took: 1.83s  Val. loss: 0.1620\n",
      "Epoch 34, 100% \t Train loss: 0.1502 took: 1.83s  Val. loss: 0.1608\n",
      "Epoch 35, 100% \t Train loss: 0.1503 took: 1.86s  Val. loss: 0.1637\n",
      "Epoch 36, 100% \t Train loss: 0.1506 took: 1.86s  Val. loss: 0.1605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, 100% \t Train loss: 0.1497 took: 1.86s  Val. loss: 0.1613\n",
      "Epoch 38, 100% \t Train loss: 0.1493 took: 1.85s  Val. loss: 0.1631\n",
      "Epoch 39, 100% \t Train loss: 0.1499 took: 1.85s  Val. loss: 0.1633\n",
      "Epoch 40, 100% \t Train loss: 0.1496 took: 1.88s  Val. loss: 0.1625\n",
      "Epoch 41, 100% \t Train loss: 0.1495 took: 1.87s  Val. loss: 0.1642\n",
      "Epoch 42, 100% \t Train loss: 0.1476 took: 1.87s  Val. loss: 0.1616\n",
      "Epoch 43, 100% \t Train loss: 0.1477 took: 1.87s  Val. loss: 0.1643\n",
      "Epoch 44, 100% \t Train loss: 0.1476 took: 1.86s  Val. loss: 0.1631\n",
      "Epoch 45, 100% \t Train loss: 0.1469 took: 1.88s  Val. loss: 0.1604\n",
      "Epoch 46, 100% \t Train loss: 0.1463 took: 1.89s  Val. loss: 0.1607\n",
      "Epoch 47, 100% \t Train loss: 0.1481 took: 1.89s  Val. loss: 0.1613\n",
      "Epoch 48, 100% \t Train loss: 0.1470 took: 1.90s  Val. loss: 0.1630\n",
      "Epoch 49, 100% \t Train loss: 0.1472 took: 1.91s  Val. loss: 0.1617\n",
      "Epoch 50, 100% \t Train loss: 0.1464 took: 1.95s  Val. loss: 0.1599\n",
      "Training finished, took 104.21s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2555 took: 1.83s  Val. loss: 0.2506\n",
      "Epoch 2, 100% \t Train loss: 0.2549 took: 1.81s  Val. loss: 0.2497\n",
      "Epoch 3, 100% \t Train loss: 0.2548 took: 1.81s  Val. loss: 0.2483\n",
      "Epoch 4, 100% \t Train loss: 0.2545 took: 1.82s  Val. loss: 0.2482\n",
      "Epoch 5, 100% \t Train loss: 0.2533 took: 1.85s  Val. loss: 0.2481\n",
      "Epoch 6, 100% \t Train loss: 0.2487 took: 1.81s  Val. loss: 0.2372\n",
      "Epoch 7, 100% \t Train loss: 0.2263 took: 1.81s  Val. loss: 0.2030\n",
      "Epoch 8, 100% \t Train loss: 0.1963 took: 1.82s  Val. loss: 0.1862\n",
      "Epoch 9, 100% \t Train loss: 0.1822 took: 1.82s  Val. loss: 0.1727\n",
      "Epoch 10, 100% \t Train loss: 0.1776 took: 1.81s  Val. loss: 0.1702\n",
      "Epoch 11, 100% \t Train loss: 0.1739 took: 1.80s  Val. loss: 0.1664\n",
      "Epoch 12, 100% \t Train loss: 0.1728 took: 1.81s  Val. loss: 0.1661\n",
      "Epoch 13, 100% \t Train loss: 0.1731 took: 1.81s  Val. loss: 0.1655\n",
      "Epoch 14, 100% \t Train loss: 0.1702 took: 1.82s  Val. loss: 0.1630\n",
      "Epoch 15, 100% \t Train loss: 0.1701 took: 1.82s  Val. loss: 0.1647\n",
      "Epoch 16, 100% \t Train loss: 0.1681 took: 1.82s  Val. loss: 0.1623\n",
      "Epoch 17, 100% \t Train loss: 0.1682 took: 1.82s  Val. loss: 0.1605\n",
      "Epoch 18, 100% \t Train loss: 0.1669 took: 1.82s  Val. loss: 0.1620\n",
      "Epoch 19, 100% \t Train loss: 0.1668 took: 1.83s  Val. loss: 0.1598\n",
      "Epoch 20, 100% \t Train loss: 0.1668 took: 1.83s  Val. loss: 0.1589\n",
      "Epoch 21, 100% \t Train loss: 0.1656 took: 1.83s  Val. loss: 0.1665\n",
      "Epoch 22, 100% \t Train loss: 0.1662 took: 1.82s  Val. loss: 0.1590\n",
      "Epoch 23, 100% \t Train loss: 0.1628 took: 1.82s  Val. loss: 0.1588\n",
      "Epoch 24, 100% \t Train loss: 0.1644 took: 1.84s  Val. loss: 0.1571\n",
      "Epoch 25, 100% \t Train loss: 0.1619 took: 1.82s  Val. loss: 0.1558\n",
      "Epoch 26, 100% \t Train loss: 0.1618 took: 1.83s  Val. loss: 0.1546\n",
      "Epoch 27, 100% \t Train loss: 0.1612 took: 1.84s  Val. loss: 0.1556\n",
      "Epoch 28, 100% \t Train loss: 0.1611 took: 1.83s  Val. loss: 0.1557\n",
      "Epoch 29, 100% \t Train loss: 0.1601 took: 1.84s  Val. loss: 0.1567\n",
      "Epoch 30, 100% \t Train loss: 0.1631 took: 1.83s  Val. loss: 0.1559\n",
      "Epoch 31, 100% \t Train loss: 0.1599 took: 1.86s  Val. loss: 0.1599\n",
      "Epoch 32, 100% \t Train loss: 0.1591 took: 1.84s  Val. loss: 0.1550\n",
      "Epoch 33, 100% \t Train loss: 0.1589 took: 1.84s  Val. loss: 0.1557\n",
      "Epoch 34, 100% \t Train loss: 0.1573 took: 1.85s  Val. loss: 0.1562\n",
      "Epoch 35, 100% \t Train loss: 0.1601 took: 1.83s  Val. loss: 0.1582\n",
      "Epoch 36, 100% \t Train loss: 0.1576 took: 1.84s  Val. loss: 0.1523\n",
      "Epoch 37, 100% \t Train loss: 0.1577 took: 1.85s  Val. loss: 0.1534\n",
      "Epoch 38, 100% \t Train loss: 0.1579 took: 1.85s  Val. loss: 0.1545\n",
      "Epoch 39, 100% \t Train loss: 0.1554 took: 1.84s  Val. loss: 0.1518\n",
      "Epoch 40, 100% \t Train loss: 0.1569 took: 1.85s  Val. loss: 0.1515\n",
      "Epoch 41, 100% \t Train loss: 0.1551 took: 1.87s  Val. loss: 0.1541\n",
      "Epoch 42, 100% \t Train loss: 0.1542 took: 1.86s  Val. loss: 0.1550\n",
      "Epoch 43, 100% \t Train loss: 0.1551 took: 1.86s  Val. loss: 0.1514\n",
      "Epoch 44, 100% \t Train loss: 0.1549 took: 1.88s  Val. loss: 0.1528\n",
      "Epoch 45, 100% \t Train loss: 0.1543 took: 1.85s  Val. loss: 0.1553\n",
      "Epoch 46, 100% \t Train loss: 0.1532 took: 1.87s  Val. loss: 0.1525\n",
      "Epoch 47, 100% \t Train loss: 0.1537 took: 1.86s  Val. loss: 0.1525\n",
      "Epoch 48, 100% \t Train loss: 0.1529 took: 1.84s  Val. loss: 0.1528\n",
      "Epoch 49, 100% \t Train loss: 0.1518 took: 1.84s  Val. loss: 0.1580\n",
      "Epoch 50, 100% \t Train loss: 0.1520 took: 1.85s  Val. loss: 0.1508\n",
      "Training finished, took 104.42s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.859408\n",
      "lambda: 0.0010 - V: 0.828322\n",
      "lambda: 0.0005 - V: 0.829949\n",
      "Average V: 0.839226\n",
      "Time elapsed: 318.16 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2613 took: 1.93s  Val. loss: 0.2529\n",
      "Epoch 2, 100% \t Train loss: 0.2401 took: 1.92s  Val. loss: 0.2079\n",
      "Epoch 3, 100% \t Train loss: 0.1993 took: 1.92s  Val. loss: 0.1978\n",
      "Epoch 4, 100% \t Train loss: 0.1924 took: 1.91s  Val. loss: 0.1955\n",
      "Epoch 5, 100% \t Train loss: 0.1903 took: 1.92s  Val. loss: 0.1969\n",
      "Epoch 6, 100% \t Train loss: 0.1906 took: 1.93s  Val. loss: 0.1931\n",
      "Epoch 7, 100% \t Train loss: 0.1881 took: 1.91s  Val. loss: 0.1955\n",
      "Epoch 8, 100% \t Train loss: 0.1884 took: 1.95s  Val. loss: 0.1917\n",
      "Epoch 9, 100% \t Train loss: 0.1864 took: 1.93s  Val. loss: 0.1936\n",
      "Epoch 10, 100% \t Train loss: 0.1845 took: 1.93s  Val. loss: 0.1917\n",
      "Epoch 11, 100% \t Train loss: 0.1837 took: 1.93s  Val. loss: 0.1916\n",
      "Epoch 12, 100% \t Train loss: 0.1816 took: 1.94s  Val. loss: 0.1878\n",
      "Epoch 13, 100% \t Train loss: 0.1804 took: 1.93s  Val. loss: 0.1857\n",
      "Epoch 14, 100% \t Train loss: 0.1781 took: 1.91s  Val. loss: 0.1837\n",
      "Epoch 15, 100% \t Train loss: 0.1774 took: 1.91s  Val. loss: 0.1805\n",
      "Epoch 16, 100% \t Train loss: 0.1741 took: 1.92s  Val. loss: 0.1776\n",
      "Epoch 17, 100% \t Train loss: 0.1717 took: 1.90s  Val. loss: 0.1783\n",
      "Epoch 18, 100% \t Train loss: 0.1705 took: 1.89s  Val. loss: 0.1727\n",
      "Epoch 19, 100% \t Train loss: 0.1680 took: 1.91s  Val. loss: 0.1722\n",
      "Epoch 20, 100% \t Train loss: 0.1642 took: 1.92s  Val. loss: 0.1680\n",
      "Epoch 21, 100% \t Train loss: 0.1599 took: 1.93s  Val. loss: 0.1605\n",
      "Epoch 22, 100% \t Train loss: 0.1559 took: 1.93s  Val. loss: 0.1590\n",
      "Epoch 23, 100% \t Train loss: 0.1504 took: 1.94s  Val. loss: 0.1495\n",
      "Epoch 24, 100% \t Train loss: 0.1473 took: 1.94s  Val. loss: 0.1469\n",
      "Epoch 25, 100% \t Train loss: 0.1435 took: 1.94s  Val. loss: 0.1459\n",
      "Epoch 26, 100% \t Train loss: 0.1434 took: 1.92s  Val. loss: 0.1412\n",
      "Epoch 27, 100% \t Train loss: 0.1419 took: 1.91s  Val. loss: 0.1451\n",
      "Epoch 28, 100% \t Train loss: 0.1380 took: 1.92s  Val. loss: 0.1399\n",
      "Epoch 29, 100% \t Train loss: 0.1365 took: 1.93s  Val. loss: 0.1397\n",
      "Epoch 30, 100% \t Train loss: 0.1362 took: 1.94s  Val. loss: 0.1378\n",
      "Epoch 31, 100% \t Train loss: 0.1339 took: 1.97s  Val. loss: 0.1385\n",
      "Epoch 32, 100% \t Train loss: 0.1335 took: 2.04s  Val. loss: 0.1410\n",
      "Epoch 33, 100% \t Train loss: 0.1343 took: 2.24s  Val. loss: 0.1349\n",
      "Epoch 34, 100% \t Train loss: 0.1317 took: 2.28s  Val. loss: 0.1333\n",
      "Epoch 35, 100% \t Train loss: 0.1314 took: 2.30s  Val. loss: 0.1327\n",
      "Epoch 36, 100% \t Train loss: 0.1303 took: 2.29s  Val. loss: 0.1344\n",
      "Epoch 37, 100% \t Train loss: 0.1314 took: 2.32s  Val. loss: 0.1352\n",
      "Epoch 38, 100% \t Train loss: 0.1299 took: 2.34s  Val. loss: 0.1320\n",
      "Epoch 39, 100% \t Train loss: 0.1295 took: 2.37s  Val. loss: 0.1332\n",
      "Epoch 40, 100% \t Train loss: 0.1290 took: 2.38s  Val. loss: 0.1292\n",
      "Epoch 41, 100% \t Train loss: 0.1285 took: 2.39s  Val. loss: 0.1288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, 100% \t Train loss: 0.1278 took: 2.35s  Val. loss: 0.1282\n",
      "Epoch 43, 100% \t Train loss: 0.1273 took: 2.36s  Val. loss: 0.1318\n",
      "Epoch 44, 100% \t Train loss: 0.1263 took: 2.36s  Val. loss: 0.1299\n",
      "Epoch 45, 100% \t Train loss: 0.1264 took: 2.35s  Val. loss: 0.1269\n",
      "Epoch 46, 100% \t Train loss: 0.1263 took: 2.37s  Val. loss: 0.1317\n",
      "Epoch 47, 100% \t Train loss: 0.1257 took: 2.36s  Val. loss: 0.1298\n",
      "Epoch 48, 100% \t Train loss: 0.1258 took: 2.36s  Val. loss: 0.1291\n",
      "Epoch 49, 100% \t Train loss: 0.1274 took: 2.34s  Val. loss: 0.1274\n",
      "Epoch 50, 100% \t Train loss: 0.1247 took: 2.38s  Val. loss: 0.1291\n",
      "Training finished, took 117.75s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2569 took: 1.95s  Val. loss: 0.2577\n",
      "Epoch 2, 100% \t Train loss: 0.2550 took: 1.91s  Val. loss: 0.2576\n",
      "Epoch 3, 100% \t Train loss: 0.2535 took: 1.93s  Val. loss: 0.2541\n",
      "Epoch 4, 100% \t Train loss: 0.2407 took: 1.92s  Val. loss: 0.2310\n",
      "Epoch 5, 100% \t Train loss: 0.2189 took: 1.93s  Val. loss: 0.2144\n",
      "Epoch 6, 100% \t Train loss: 0.2065 took: 1.91s  Val. loss: 0.2080\n",
      "Epoch 7, 100% \t Train loss: 0.2021 took: 1.93s  Val. loss: 0.2010\n",
      "Epoch 8, 100% \t Train loss: 0.1984 took: 1.93s  Val. loss: 0.1972\n",
      "Epoch 9, 100% \t Train loss: 0.1975 took: 1.91s  Val. loss: 0.1932\n",
      "Epoch 10, 100% \t Train loss: 0.1941 took: 1.92s  Val. loss: 0.1926\n",
      "Epoch 11, 100% \t Train loss: 0.1932 took: 1.93s  Val. loss: 0.1913\n",
      "Epoch 12, 100% \t Train loss: 0.1911 took: 1.92s  Val. loss: 0.1924\n",
      "Epoch 13, 100% \t Train loss: 0.1918 took: 1.92s  Val. loss: 0.1920\n",
      "Epoch 14, 100% \t Train loss: 0.1905 took: 1.92s  Val. loss: 0.1913\n",
      "Epoch 15, 100% \t Train loss: 0.1885 took: 1.95s  Val. loss: 0.1864\n",
      "Epoch 16, 100% \t Train loss: 0.1886 took: 1.93s  Val. loss: 0.1912\n",
      "Epoch 17, 100% \t Train loss: 0.1887 took: 1.93s  Val. loss: 0.1930\n",
      "Epoch 18, 100% \t Train loss: 0.1884 took: 1.93s  Val. loss: 0.1874\n",
      "Epoch 19, 100% \t Train loss: 0.1858 took: 1.93s  Val. loss: 0.1848\n",
      "Epoch 20, 100% \t Train loss: 0.1853 took: 1.93s  Val. loss: 0.1845\n",
      "Epoch 21, 100% \t Train loss: 0.1839 took: 1.93s  Val. loss: 0.1851\n",
      "Epoch 22, 100% \t Train loss: 0.1834 took: 1.93s  Val. loss: 0.1822\n",
      "Epoch 23, 100% \t Train loss: 0.1826 took: 1.93s  Val. loss: 0.1868\n",
      "Epoch 24, 100% \t Train loss: 0.1812 took: 1.92s  Val. loss: 0.1838\n",
      "Epoch 25, 100% \t Train loss: 0.1797 took: 1.91s  Val. loss: 0.1876\n",
      "Epoch 26, 100% \t Train loss: 0.1810 took: 1.90s  Val. loss: 0.1785\n",
      "Epoch 27, 100% \t Train loss: 0.1789 took: 1.91s  Val. loss: 0.1815\n",
      "Epoch 28, 100% \t Train loss: 0.1773 took: 1.92s  Val. loss: 0.1775\n",
      "Epoch 29, 100% \t Train loss: 0.1775 took: 1.95s  Val. loss: 0.1794\n",
      "Epoch 30, 100% \t Train loss: 0.1772 took: 1.95s  Val. loss: 0.1774\n",
      "Epoch 31, 100% \t Train loss: 0.1752 took: 1.96s  Val. loss: 0.1751\n",
      "Epoch 32, 100% \t Train loss: 0.1736 took: 1.98s  Val. loss: 0.1755\n",
      "Epoch 33, 100% \t Train loss: 0.1744 took: 2.00s  Val. loss: 0.1861\n",
      "Epoch 34, 100% \t Train loss: 0.1745 took: 2.00s  Val. loss: 0.1752\n",
      "Epoch 35, 100% \t Train loss: 0.1713 took: 2.01s  Val. loss: 0.1737\n",
      "Epoch 36, 100% \t Train loss: 0.1707 took: 2.02s  Val. loss: 0.1749\n",
      "Epoch 37, 100% \t Train loss: 0.1707 took: 2.02s  Val. loss: 0.1703\n",
      "Epoch 38, 100% \t Train loss: 0.1689 took: 2.02s  Val. loss: 0.1763\n",
      "Epoch 39, 100% \t Train loss: 0.1690 took: 2.04s  Val. loss: 0.1720\n",
      "Epoch 40, 100% \t Train loss: 0.1671 took: 2.07s  Val. loss: 0.1694\n",
      "Epoch 41, 100% \t Train loss: 0.1676 took: 2.06s  Val. loss: 0.1726\n",
      "Epoch 42, 100% \t Train loss: 0.1664 took: 2.06s  Val. loss: 0.1692\n",
      "Epoch 43, 100% \t Train loss: 0.1660 took: 2.06s  Val. loss: 0.1717\n",
      "Epoch 44, 100% \t Train loss: 0.1642 took: 2.08s  Val. loss: 0.1660\n",
      "Epoch 45, 100% \t Train loss: 0.1622 took: 2.07s  Val. loss: 0.1681\n",
      "Epoch 46, 100% \t Train loss: 0.1620 took: 1.21s  Val. loss: 0.1649\n",
      "Epoch 47, 100% \t Train loss: 0.1613 took: 1.22s  Val. loss: 0.1643\n",
      "Epoch 48, 100% \t Train loss: 0.1613 took: 1.23s  Val. loss: 0.1644\n",
      "Epoch 49, 100% \t Train loss: 0.1598 took: 1.21s  Val. loss: 0.1644\n",
      "Epoch 50, 100% \t Train loss: 0.1608 took: 1.21s  Val. loss: 0.1676\n",
      "Training finished, took 106.49s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2580 took: 1.12s  Val. loss: 0.2554\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 1.12s  Val. loss: 0.2569\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 1.14s  Val. loss: 0.2555\n",
      "Epoch 4, 100% \t Train loss: 0.2575 took: 1.12s  Val. loss: 0.2553\n",
      "Epoch 5, 100% \t Train loss: 0.2575 took: 1.12s  Val. loss: 0.2558\n",
      "Epoch 6, 100% \t Train loss: 0.2574 took: 1.12s  Val. loss: 0.2562\n",
      "Epoch 7, 100% \t Train loss: 0.2572 took: 1.13s  Val. loss: 0.2552\n",
      "Epoch 8, 100% \t Train loss: 0.2566 took: 1.14s  Val. loss: 0.2536\n",
      "Epoch 9, 100% \t Train loss: 0.2545 took: 1.14s  Val. loss: 0.2505\n",
      "Epoch 10, 100% \t Train loss: 0.2461 took: 1.13s  Val. loss: 0.2349\n",
      "Epoch 11, 100% \t Train loss: 0.2354 took: 1.13s  Val. loss: 0.2287\n",
      "Epoch 12, 100% \t Train loss: 0.2302 took: 1.13s  Val. loss: 0.2227\n",
      "Epoch 13, 100% \t Train loss: 0.2255 took: 1.13s  Val. loss: 0.2176\n",
      "Epoch 14, 100% \t Train loss: 0.2170 took: 1.13s  Val. loss: 0.2122\n",
      "Epoch 15, 100% \t Train loss: 0.2081 took: 1.13s  Val. loss: 0.2043\n",
      "Epoch 16, 100% \t Train loss: 0.2020 took: 1.13s  Val. loss: 0.1991\n",
      "Epoch 17, 100% \t Train loss: 0.1979 took: 1.13s  Val. loss: 0.1956\n",
      "Epoch 18, 100% \t Train loss: 0.1957 took: 1.13s  Val. loss: 0.1949\n",
      "Epoch 19, 100% \t Train loss: 0.1954 took: 1.13s  Val. loss: 0.1958\n",
      "Epoch 20, 100% \t Train loss: 0.1946 took: 1.13s  Val. loss: 0.1952\n",
      "Epoch 21, 100% \t Train loss: 0.1933 took: 1.13s  Val. loss: 0.1936\n",
      "Epoch 22, 100% \t Train loss: 0.1932 took: 1.14s  Val. loss: 0.1940\n",
      "Epoch 23, 100% \t Train loss: 0.1924 took: 1.14s  Val. loss: 0.1974\n",
      "Epoch 24, 100% \t Train loss: 0.1933 took: 1.14s  Val. loss: 0.1947\n",
      "Epoch 25, 100% \t Train loss: 0.1916 took: 1.14s  Val. loss: 0.1934\n",
      "Epoch 26, 100% \t Train loss: 0.1909 took: 1.13s  Val. loss: 0.1909\n",
      "Epoch 27, 100% \t Train loss: 0.1909 took: 1.13s  Val. loss: 0.1910\n",
      "Epoch 28, 100% \t Train loss: 0.1902 took: 1.18s  Val. loss: 0.1915\n",
      "Epoch 29, 100% \t Train loss: 0.1894 took: 1.15s  Val. loss: 0.1902\n",
      "Epoch 30, 100% \t Train loss: 0.1902 took: 1.16s  Val. loss: 0.1895\n",
      "Epoch 31, 100% \t Train loss: 0.1892 took: 1.17s  Val. loss: 0.1907\n",
      "Epoch 32, 100% \t Train loss: 0.1890 took: 1.19s  Val. loss: 0.1931\n",
      "Epoch 33, 100% \t Train loss: 0.1889 took: 1.18s  Val. loss: 0.1907\n",
      "Epoch 34, 100% \t Train loss: 0.1881 took: 1.19s  Val. loss: 0.1887\n",
      "Epoch 35, 100% \t Train loss: 0.1882 took: 1.20s  Val. loss: 0.1893\n",
      "Epoch 36, 100% \t Train loss: 0.1869 took: 1.20s  Val. loss: 0.1896\n",
      "Epoch 37, 100% \t Train loss: 0.1871 took: 1.20s  Val. loss: 0.1868\n",
      "Epoch 38, 100% \t Train loss: 0.1860 took: 1.20s  Val. loss: 0.1880\n",
      "Epoch 39, 100% \t Train loss: 0.1860 took: 1.20s  Val. loss: 0.1891\n",
      "Epoch 40, 100% \t Train loss: 0.1857 took: 1.20s  Val. loss: 0.1860\n",
      "Epoch 41, 100% \t Train loss: 0.1849 took: 1.21s  Val. loss: 0.1896\n",
      "Epoch 42, 100% \t Train loss: 0.1853 took: 1.21s  Val. loss: 0.1885\n",
      "Epoch 43, 100% \t Train loss: 0.1842 took: 1.21s  Val. loss: 0.1889\n",
      "Epoch 44, 100% \t Train loss: 0.1844 took: 1.22s  Val. loss: 0.1888\n",
      "Epoch 45, 100% \t Train loss: 0.1834 took: 1.23s  Val. loss: 0.1881\n",
      "Epoch 46, 100% \t Train loss: 0.1827 took: 1.23s  Val. loss: 0.1856\n",
      "Epoch 47, 100% \t Train loss: 0.1826 took: 1.24s  Val. loss: 0.1885\n",
      "Epoch 48, 100% \t Train loss: 0.1818 took: 1.25s  Val. loss: 0.1865\n",
      "Epoch 49, 100% \t Train loss: 0.1816 took: 1.27s  Val. loss: 0.1860\n",
      "Epoch 50, 100% \t Train loss: 0.1814 took: 1.28s  Val. loss: 0.1877\n",
      "Training finished, took 65.41s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.841657\n",
      "lambda: 0.0010 - V: 0.813150\n",
      "lambda: 0.0005 - V: 0.794167\n",
      "Average V: 0.816325\n",
      "Time elapsed: 293.00 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 1.97s  Val. loss: 0.2642\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 1.96s  Val. loss: 0.2634\n",
      "Epoch 3, 100% \t Train loss: 0.2574 took: 1.95s  Val. loss: 0.2594\n",
      "Epoch 4, 100% \t Train loss: 0.2035 took: 1.93s  Val. loss: 0.1997\n",
      "Epoch 5, 100% \t Train loss: 0.1720 took: 1.93s  Val. loss: 0.1933\n",
      "Epoch 6, 100% \t Train loss: 0.1660 took: 1.15s  Val. loss: 0.1891\n",
      "Epoch 7, 100% \t Train loss: 0.1614 took: 1.15s  Val. loss: 0.1858\n",
      "Epoch 8, 100% \t Train loss: 0.1614 took: 1.15s  Val. loss: 0.1840\n",
      "Epoch 9, 100% \t Train loss: 0.1573 took: 1.15s  Val. loss: 0.1789\n",
      "Epoch 10, 100% \t Train loss: 0.1556 took: 1.14s  Val. loss: 0.1778\n",
      "Epoch 11, 100% \t Train loss: 0.1541 took: 1.15s  Val. loss: 0.1871\n",
      "Epoch 12, 100% \t Train loss: 0.1531 took: 1.15s  Val. loss: 0.1792\n",
      "Epoch 13, 100% \t Train loss: 0.1502 took: 1.15s  Val. loss: 0.1729\n",
      "Epoch 14, 100% \t Train loss: 0.1441 took: 1.15s  Val. loss: 0.1638\n",
      "Epoch 15, 100% \t Train loss: 0.1328 took: 1.14s  Val. loss: 0.1492\n",
      "Epoch 16, 100% \t Train loss: 0.1221 took: 1.15s  Val. loss: 0.1365\n",
      "Epoch 17, 100% \t Train loss: 0.1102 took: 1.15s  Val. loss: 0.1241\n",
      "Epoch 18, 100% \t Train loss: 0.1018 took: 1.14s  Val. loss: 0.1147\n",
      "Epoch 19, 100% \t Train loss: 0.0978 took: 1.15s  Val. loss: 0.1116\n",
      "Epoch 20, 100% \t Train loss: 0.0928 took: 1.15s  Val. loss: 0.1096\n",
      "Epoch 21, 100% \t Train loss: 0.0905 took: 1.15s  Val. loss: 0.1034\n",
      "Epoch 22, 100% \t Train loss: 0.0872 took: 1.15s  Val. loss: 0.1024\n",
      "Epoch 23, 100% \t Train loss: 0.0852 took: 1.16s  Val. loss: 0.0989\n",
      "Epoch 24, 100% \t Train loss: 0.0848 took: 1.16s  Val. loss: 0.1027\n",
      "Epoch 25, 100% \t Train loss: 0.0834 took: 1.16s  Val. loss: 0.1012\n",
      "Epoch 26, 100% \t Train loss: 0.0821 took: 1.16s  Val. loss: 0.0968\n",
      "Epoch 27, 100% \t Train loss: 0.0810 took: 1.15s  Val. loss: 0.0937\n",
      "Epoch 28, 100% \t Train loss: 0.0794 took: 1.15s  Val. loss: 0.0969\n",
      "Epoch 29, 100% \t Train loss: 0.0787 took: 1.16s  Val. loss: 0.0955\n",
      "Epoch 30, 100% \t Train loss: 0.0781 took: 1.17s  Val. loss: 0.0947\n",
      "Epoch 31, 100% \t Train loss: 0.0773 took: 1.17s  Val. loss: 0.0967\n",
      "Epoch 32, 100% \t Train loss: 0.0767 took: 1.23s  Val. loss: 0.0972\n",
      "Epoch 33, 100% \t Train loss: 0.0755 took: 2.20s  Val. loss: 0.0916\n",
      "Epoch 34, 100% \t Train loss: 0.0745 took: 2.22s  Val. loss: 0.0974\n",
      "Epoch 35, 100% \t Train loss: 0.0745 took: 2.25s  Val. loss: 0.1004\n",
      "Epoch 36, 100% \t Train loss: 0.0749 took: 2.29s  Val. loss: 0.0960\n",
      "Epoch 37, 100% \t Train loss: 0.0737 took: 2.30s  Val. loss: 0.1001\n",
      "Epoch 38, 100% \t Train loss: 0.0731 took: 2.29s  Val. loss: 0.0917\n",
      "Epoch 39, 100% \t Train loss: 0.0722 took: 2.31s  Val. loss: 0.0971\n",
      "Epoch 40, 100% \t Train loss: 0.0738 took: 2.30s  Val. loss: 0.0917\n",
      "Epoch 41, 100% \t Train loss: 0.0722 took: 2.31s  Val. loss: 0.0943\n",
      "Epoch 42, 100% \t Train loss: 0.0725 took: 2.30s  Val. loss: 0.0978\n",
      "Epoch 43, 100% \t Train loss: 0.0725 took: 2.32s  Val. loss: 0.0931\n",
      "Epoch 44, 100% \t Train loss: 0.0715 took: 2.32s  Val. loss: 0.0917\n",
      "Epoch 45, 100% \t Train loss: 0.0724 took: 2.35s  Val. loss: 0.0932\n",
      "Epoch 46, 100% \t Train loss: 0.0706 took: 2.35s  Val. loss: 0.0958\n",
      "Epoch 47, 100% \t Train loss: 0.0706 took: 2.37s  Val. loss: 0.0945\n",
      "Epoch 48, 100% \t Train loss: 0.0707 took: 2.41s  Val. loss: 0.0921\n",
      "Epoch 49, 100% \t Train loss: 0.0705 took: 2.44s  Val. loss: 0.0899\n",
      "Epoch 50, 100% \t Train loss: 0.0693 took: 2.45s  Val. loss: 0.0937\n",
      "Training finished, took 93.35s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.94s  Val. loss: 0.2579\n",
      "Epoch 2, 100% \t Train loss: 0.2559 took: 1.94s  Val. loss: 0.2501\n",
      "Epoch 3, 100% \t Train loss: 0.2155 took: 1.94s  Val. loss: 0.1822\n",
      "Epoch 4, 100% \t Train loss: 0.1792 took: 1.95s  Val. loss: 0.1822\n",
      "Epoch 5, 100% \t Train loss: 0.1762 took: 1.94s  Val. loss: 0.1718\n",
      "Epoch 6, 100% \t Train loss: 0.1725 took: 1.96s  Val. loss: 0.1686\n",
      "Epoch 7, 100% \t Train loss: 0.1698 took: 1.18s  Val. loss: 0.1659\n",
      "Epoch 8, 100% \t Train loss: 0.1674 took: 1.16s  Val. loss: 0.1728\n",
      "Epoch 9, 100% \t Train loss: 0.1684 took: 1.16s  Val. loss: 0.1706\n",
      "Epoch 10, 100% \t Train loss: 0.1637 took: 1.16s  Val. loss: 0.1580\n",
      "Epoch 11, 100% \t Train loss: 0.1635 took: 1.15s  Val. loss: 0.1594\n",
      "Epoch 12, 100% \t Train loss: 0.1616 took: 1.15s  Val. loss: 0.1622\n",
      "Epoch 13, 100% \t Train loss: 0.1583 took: 1.16s  Val. loss: 0.1555\n",
      "Epoch 14, 100% \t Train loss: 0.1562 took: 1.16s  Val. loss: 0.1557\n",
      "Epoch 15, 100% \t Train loss: 0.1533 took: 1.16s  Val. loss: 0.1509\n",
      "Epoch 16, 100% \t Train loss: 0.1487 took: 1.16s  Val. loss: 0.1478\n",
      "Epoch 17, 100% \t Train loss: 0.1437 took: 1.15s  Val. loss: 0.1428\n",
      "Epoch 18, 100% \t Train loss: 0.1397 took: 1.18s  Val. loss: 0.1374\n",
      "Epoch 19, 100% \t Train loss: 0.1353 took: 1.16s  Val. loss: 0.1321\n",
      "Epoch 20, 100% \t Train loss: 0.1316 took: 1.15s  Val. loss: 0.1304\n",
      "Epoch 21, 100% \t Train loss: 0.1277 took: 1.15s  Val. loss: 0.1236\n",
      "Epoch 22, 100% \t Train loss: 0.1257 took: 1.16s  Val. loss: 0.1210\n",
      "Epoch 23, 100% \t Train loss: 0.1206 took: 1.64s  Val. loss: 0.1198\n",
      "Epoch 24, 100% \t Train loss: 0.1157 took: 1.93s  Val. loss: 0.1152\n",
      "Epoch 25, 100% \t Train loss: 0.1140 took: 1.95s  Val. loss: 0.1128\n",
      "Epoch 26, 100% \t Train loss: 0.1106 took: 1.95s  Val. loss: 0.1149\n",
      "Epoch 27, 100% \t Train loss: 0.1082 took: 1.96s  Val. loss: 0.1082\n",
      "Epoch 28, 100% \t Train loss: 0.1046 took: 1.95s  Val. loss: 0.1042\n",
      "Epoch 29, 100% \t Train loss: 0.1037 took: 1.94s  Val. loss: 0.1075\n",
      "Epoch 30, 100% \t Train loss: 0.1023 took: 1.94s  Val. loss: 0.1047\n",
      "Epoch 31, 100% \t Train loss: 0.1000 took: 1.95s  Val. loss: 0.1075\n",
      "Epoch 32, 100% \t Train loss: 0.0979 took: 1.95s  Val. loss: 0.0977\n",
      "Epoch 33, 100% \t Train loss: 0.0979 took: 1.19s  Val. loss: 0.1014\n",
      "Epoch 34, 100% \t Train loss: 0.0947 took: 1.16s  Val. loss: 0.1045\n",
      "Epoch 35, 100% \t Train loss: 0.0934 took: 1.15s  Val. loss: 0.0991\n",
      "Epoch 36, 100% \t Train loss: 0.0930 took: 1.17s  Val. loss: 0.0972\n",
      "Epoch 37, 100% \t Train loss: 0.0907 took: 1.17s  Val. loss: 0.0960\n",
      "Epoch 38, 100% \t Train loss: 0.0900 took: 1.16s  Val. loss: 0.1002\n",
      "Epoch 39, 100% \t Train loss: 0.0883 took: 1.16s  Val. loss: 0.0949\n",
      "Epoch 40, 100% \t Train loss: 0.0894 took: 1.17s  Val. loss: 0.0942\n",
      "Epoch 41, 100% \t Train loss: 0.0884 took: 1.17s  Val. loss: 0.0927\n",
      "Epoch 42, 100% \t Train loss: 0.0864 took: 1.17s  Val. loss: 0.0945\n",
      "Epoch 43, 100% \t Train loss: 0.0860 took: 1.17s  Val. loss: 0.0930\n",
      "Epoch 44, 100% \t Train loss: 0.0848 took: 1.17s  Val. loss: 0.0918\n",
      "Epoch 45, 100% \t Train loss: 0.0856 took: 1.17s  Val. loss: 0.0902\n",
      "Epoch 46, 100% \t Train loss: 0.0830 took: 1.17s  Val. loss: 0.0907\n",
      "Epoch 47, 100% \t Train loss: 0.0830 took: 1.18s  Val. loss: 0.0909\n",
      "Epoch 48, 100% \t Train loss: 0.0818 took: 1.19s  Val. loss: 0.0885\n",
      "Epoch 49, 100% \t Train loss: 0.0814 took: 1.19s  Val. loss: 0.0935\n",
      "Epoch 50, 100% \t Train loss: 0.0820 took: 1.19s  Val. loss: 0.0947\n",
      "Training finished, took 79.65s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2621 took: 1.94s  Val. loss: 0.2555\n",
      "Epoch 2, 100% \t Train loss: 0.2601 took: 1.95s  Val. loss: 0.2539\n",
      "Epoch 3, 100% \t Train loss: 0.2555 took: 1.94s  Val. loss: 0.2417\n",
      "Epoch 4, 100% \t Train loss: 0.2298 took: 1.16s  Val. loss: 0.2034\n",
      "Epoch 5, 100% \t Train loss: 0.1973 took: 1.15s  Val. loss: 0.1839\n",
      "Epoch 6, 100% \t Train loss: 0.1830 took: 1.15s  Val. loss: 0.1692\n",
      "Epoch 7, 100% \t Train loss: 0.1773 took: 1.15s  Val. loss: 0.1642\n",
      "Epoch 8, 100% \t Train loss: 0.1755 took: 1.38s  Val. loss: 0.1618\n",
      "Epoch 9, 100% \t Train loss: 0.1734 took: 1.94s  Val. loss: 0.1633\n",
      "Epoch 10, 100% \t Train loss: 0.1707 took: 1.15s  Val. loss: 0.1617\n",
      "Epoch 11, 100% \t Train loss: 0.1681 took: 1.15s  Val. loss: 0.1572\n",
      "Epoch 12, 100% \t Train loss: 0.1680 took: 1.15s  Val. loss: 0.1581\n",
      "Epoch 13, 100% \t Train loss: 0.1653 took: 1.35s  Val. loss: 0.1551\n",
      "Epoch 14, 100% \t Train loss: 0.1637 took: 1.95s  Val. loss: 0.1574\n",
      "Epoch 15, 100% \t Train loss: 0.1660 took: 1.94s  Val. loss: 0.1551\n",
      "Epoch 16, 100% \t Train loss: 0.1614 took: 1.92s  Val. loss: 0.1531\n",
      "Epoch 17, 100% \t Train loss: 0.1617 took: 1.96s  Val. loss: 0.1572\n",
      "Epoch 18, 100% \t Train loss: 0.1604 took: 1.96s  Val. loss: 0.1533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1600 took: 1.98s  Val. loss: 0.1593\n",
      "Epoch 20, 100% \t Train loss: 0.1594 took: 1.96s  Val. loss: 0.1533\n",
      "Epoch 21, 100% \t Train loss: 0.1593 took: 1.98s  Val. loss: 0.1507\n",
      "Epoch 22, 100% \t Train loss: 0.1580 took: 1.96s  Val. loss: 0.1532\n",
      "Epoch 23, 100% \t Train loss: 0.1579 took: 1.97s  Val. loss: 0.1517\n",
      "Epoch 24, 100% \t Train loss: 0.1571 took: 1.96s  Val. loss: 0.1504\n",
      "Epoch 25, 100% \t Train loss: 0.1562 took: 1.98s  Val. loss: 0.1510\n",
      "Epoch 26, 100% \t Train loss: 0.1560 took: 1.95s  Val. loss: 0.1509\n",
      "Epoch 27, 100% \t Train loss: 0.1566 took: 1.95s  Val. loss: 0.1495\n",
      "Epoch 28, 100% \t Train loss: 0.1569 took: 1.97s  Val. loss: 0.1540\n",
      "Epoch 29, 100% \t Train loss: 0.1562 took: 1.98s  Val. loss: 0.1500\n",
      "Epoch 30, 100% \t Train loss: 0.1552 took: 1.97s  Val. loss: 0.1495\n",
      "Epoch 31, 100% \t Train loss: 0.1551 took: 1.98s  Val. loss: 0.1495\n",
      "Epoch 32, 100% \t Train loss: 0.1562 took: 1.99s  Val. loss: 0.1512\n",
      "Epoch 33, 100% \t Train loss: 0.1560 took: 1.96s  Val. loss: 0.1506\n",
      "Epoch 34, 100% \t Train loss: 0.1547 took: 1.97s  Val. loss: 0.1482\n",
      "Epoch 35, 100% \t Train loss: 0.1537 took: 1.95s  Val. loss: 0.1482\n",
      "Epoch 36, 100% \t Train loss: 0.1535 took: 1.99s  Val. loss: 0.1494\n",
      "Epoch 37, 100% \t Train loss: 0.1530 took: 1.97s  Val. loss: 0.1477\n",
      "Epoch 38, 100% \t Train loss: 0.1530 took: 1.98s  Val. loss: 0.1494\n",
      "Epoch 39, 100% \t Train loss: 0.1537 took: 1.99s  Val. loss: 0.1487\n",
      "Epoch 40, 100% \t Train loss: 0.1544 took: 1.97s  Val. loss: 0.1477\n",
      "Epoch 41, 100% \t Train loss: 0.1522 took: 1.97s  Val. loss: 0.1496\n",
      "Epoch 42, 100% \t Train loss: 0.1533 took: 1.98s  Val. loss: 0.1488\n",
      "Epoch 43, 100% \t Train loss: 0.1518 took: 1.94s  Val. loss: 0.1459\n",
      "Epoch 44, 100% \t Train loss: 0.1512 took: 1.98s  Val. loss: 0.1483\n",
      "Epoch 45, 100% \t Train loss: 0.1519 took: 1.98s  Val. loss: 0.1482\n",
      "Epoch 46, 100% \t Train loss: 0.1508 took: 1.99s  Val. loss: 0.1479\n",
      "Epoch 47, 100% \t Train loss: 0.1520 took: 1.99s  Val. loss: 0.1465\n",
      "Epoch 48, 100% \t Train loss: 0.1510 took: 1.97s  Val. loss: 0.1491\n",
      "Epoch 49, 100% \t Train loss: 0.1507 took: 2.03s  Val. loss: 0.1483\n",
      "Epoch 50, 100% \t Train loss: 0.1503 took: 2.01s  Val. loss: 0.1488\n",
      "Training finished, took 103.71s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.871459\n",
      "lambda: 0.0010 - V: 0.872007\n",
      "lambda: 0.0005 - V: 0.839994\n",
      "Average V: 0.861153\n",
      "Time elapsed: 280.45 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2603 took: 2.58s  Val. loss: 0.2574\n",
      "Epoch 2, 100% \t Train loss: 0.2594 took: 2.57s  Val. loss: 0.2576\n",
      "Epoch 3, 100% \t Train loss: 0.2591 took: 2.58s  Val. loss: 0.2573\n",
      "Epoch 4, 100% \t Train loss: 0.2590 took: 2.57s  Val. loss: 0.2568\n",
      "Epoch 5, 100% \t Train loss: 0.2590 took: 2.55s  Val. loss: 0.2570\n",
      "Epoch 6, 100% \t Train loss: 0.2592 took: 2.59s  Val. loss: 0.2576\n",
      "Epoch 7, 100% \t Train loss: 0.2589 took: 2.55s  Val. loss: 0.2572\n",
      "Epoch 8, 100% \t Train loss: 0.2590 took: 2.57s  Val. loss: 0.2585\n",
      "Epoch 9, 100% \t Train loss: 0.2590 took: 2.55s  Val. loss: 0.2568\n",
      "Epoch 10, 100% \t Train loss: 0.2589 took: 2.54s  Val. loss: 0.2573\n",
      "Epoch 11, 100% \t Train loss: 0.2588 took: 2.56s  Val. loss: 0.2580\n",
      "Epoch 12, 100% \t Train loss: 0.2590 took: 2.57s  Val. loss: 0.2574\n",
      "Epoch 13, 100% \t Train loss: 0.2589 took: 2.57s  Val. loss: 0.2576\n",
      "Epoch 14, 100% \t Train loss: 0.2589 took: 2.55s  Val. loss: 0.2583\n",
      "Epoch 15, 100% \t Train loss: 0.2590 took: 2.57s  Val. loss: 0.2577\n",
      "Epoch 16, 100% \t Train loss: 0.2589 took: 2.56s  Val. loss: 0.2570\n",
      "Epoch 17, 100% \t Train loss: 0.2587 took: 2.55s  Val. loss: 0.2577\n",
      "Epoch 18, 100% \t Train loss: 0.2589 took: 2.57s  Val. loss: 0.2568\n",
      "Epoch 19, 100% \t Train loss: 0.2589 took: 2.55s  Val. loss: 0.2568\n",
      "Epoch 20, 100% \t Train loss: 0.2588 took: 1.55s  Val. loss: 0.2572\n",
      "Epoch 21, 100% \t Train loss: 0.2589 took: 1.57s  Val. loss: 0.2575\n",
      "Epoch 22, 100% \t Train loss: 0.2588 took: 1.57s  Val. loss: 0.2568\n",
      "Epoch 23, 100% \t Train loss: 0.2588 took: 1.58s  Val. loss: 0.2584\n",
      "Epoch 24, 100% \t Train loss: 0.2589 took: 1.61s  Val. loss: 0.2578\n",
      "Epoch 25, 100% \t Train loss: 0.2588 took: 1.65s  Val. loss: 0.2582\n",
      "Epoch 26, 100% \t Train loss: 0.2588 took: 1.68s  Val. loss: 0.2584\n",
      "Epoch 27, 100% \t Train loss: 0.2588 took: 1.81s  Val. loss: 0.2573\n",
      "Epoch 28, 100% \t Train loss: 0.2588 took: 2.67s  Val. loss: 0.2580\n",
      "Epoch 29, 100% \t Train loss: 0.2588 took: 1.74s  Val. loss: 0.2579\n",
      "Epoch 30, 100% \t Train loss: 0.2588 took: 1.79s  Val. loss: 0.2578\n",
      "Epoch 31, 100% \t Train loss: 0.2588 took: 1.85s  Val. loss: 0.2574\n",
      "Epoch 32, 100% \t Train loss: 0.2589 took: 2.07s  Val. loss: 0.2574\n",
      "Epoch 33, 100% \t Train loss: 0.2588 took: 2.74s  Val. loss: 0.2574\n",
      "Epoch 34, 100% \t Train loss: 0.2587 took: 3.83s  Val. loss: 0.2568\n",
      "Epoch 35, 100% \t Train loss: 0.2588 took: 3.70s  Val. loss: 0.2572\n",
      "Epoch 36, 100% \t Train loss: 0.2588 took: 3.73s  Val. loss: 0.2583\n",
      "Epoch 37, 100% \t Train loss: 0.2588 took: 3.61s  Val. loss: 0.2576\n",
      "Epoch 38, 100% \t Train loss: 0.2589 took: 3.27s  Val. loss: 0.2572\n",
      "Epoch 39, 100% \t Train loss: 0.2588 took: 3.21s  Val. loss: 0.2581\n",
      "Epoch 40, 100% \t Train loss: 0.2587 took: 3.25s  Val. loss: 0.2574\n",
      "Epoch 41, 100% \t Train loss: 0.2588 took: 3.36s  Val. loss: 0.2570\n",
      "Epoch 42, 100% \t Train loss: 0.2588 took: 3.29s  Val. loss: 0.2577\n",
      "Epoch 43, 100% \t Train loss: 0.2588 took: 2.18s  Val. loss: 0.2585\n",
      "Epoch 44, 100% \t Train loss: 0.2588 took: 2.25s  Val. loss: 0.2576\n",
      "Epoch 45, 100% \t Train loss: 0.2588 took: 2.36s  Val. loss: 0.2573\n",
      "Epoch 46, 100% \t Train loss: 0.2588 took: 2.46s  Val. loss: 0.2580\n",
      "Epoch 47, 100% \t Train loss: 0.2588 took: 3.35s  Val. loss: 0.2572\n",
      "Epoch 48, 100% \t Train loss: 0.2588 took: 3.48s  Val. loss: 0.2574\n",
      "Epoch 49, 100% \t Train loss: 0.2588 took: 3.58s  Val. loss: 0.2570\n",
      "Epoch 50, 100% \t Train loss: 0.2587 took: 3.70s  Val. loss: 0.2572\n",
      "Training finished, took 143.17s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2582 took: 2.57s  Val. loss: 0.2614\n",
      "Epoch 2, 100% \t Train loss: 0.2574 took: 2.54s  Val. loss: 0.2621\n",
      "Epoch 3, 100% \t Train loss: 0.2575 took: 2.56s  Val. loss: 0.2614\n",
      "Epoch 4, 100% \t Train loss: 0.2574 took: 2.57s  Val. loss: 0.2607\n",
      "Epoch 5, 100% \t Train loss: 0.2574 took: 2.56s  Val. loss: 0.2616\n",
      "Epoch 6, 100% \t Train loss: 0.2574 took: 2.55s  Val. loss: 0.2624\n",
      "Epoch 7, 100% \t Train loss: 0.2574 took: 2.54s  Val. loss: 0.2610\n",
      "Epoch 8, 100% \t Train loss: 0.2574 took: 2.55s  Val. loss: 0.2626\n",
      "Epoch 9, 100% \t Train loss: 0.2574 took: 2.57s  Val. loss: 0.2619\n",
      "Epoch 10, 100% \t Train loss: 0.2574 took: 2.55s  Val. loss: 0.2614\n",
      "Epoch 11, 100% \t Train loss: 0.2575 took: 2.56s  Val. loss: 0.2629\n",
      "Epoch 12, 100% \t Train loss: 0.2575 took: 2.56s  Val. loss: 0.2615\n",
      "Epoch 13, 100% \t Train loss: 0.2573 took: 2.55s  Val. loss: 0.2620\n",
      "Epoch 14, 100% \t Train loss: 0.2574 took: 2.56s  Val. loss: 0.2620\n",
      "Epoch 15, 100% \t Train loss: 0.2574 took: 2.56s  Val. loss: 0.2608\n",
      "Epoch 16, 100% \t Train loss: 0.2574 took: 2.57s  Val. loss: 0.2617\n",
      "Epoch 17, 100% \t Train loss: 0.2574 took: 2.56s  Val. loss: 0.2615\n",
      "Epoch 18, 100% \t Train loss: 0.2574 took: 2.56s  Val. loss: 0.2622\n",
      "Epoch 19, 100% \t Train loss: 0.2574 took: 2.58s  Val. loss: 0.2614\n",
      "Epoch 20, 100% \t Train loss: 0.2574 took: 2.56s  Val. loss: 0.2617\n",
      "Epoch 21, 100% \t Train loss: 0.2574 took: 2.38s  Val. loss: 0.2617\n",
      "Epoch 22, 100% \t Train loss: 0.2575 took: 1.55s  Val. loss: 0.2627\n",
      "Epoch 23, 100% \t Train loss: 0.2574 took: 1.55s  Val. loss: 0.2627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.2574 took: 1.82s  Val. loss: 0.2619\n",
      "Epoch 25, 100% \t Train loss: 0.2574 took: 2.57s  Val. loss: 0.2620\n",
      "Epoch 26, 100% \t Train loss: 0.2573 took: 2.59s  Val. loss: 0.2623\n",
      "Epoch 27, 100% \t Train loss: 0.2574 took: 2.61s  Val. loss: 0.2617\n",
      "Epoch 28, 100% \t Train loss: 0.2573 took: 2.61s  Val. loss: 0.2627\n",
      "Epoch 29, 100% \t Train loss: 0.2575 took: 2.64s  Val. loss: 0.2624\n",
      "Epoch 30, 100% \t Train loss: 0.2574 took: 2.63s  Val. loss: 0.2613\n",
      "Epoch 31, 100% \t Train loss: 0.2574 took: 2.69s  Val. loss: 0.2619\n",
      "Epoch 32, 100% \t Train loss: 0.2573 took: 2.74s  Val. loss: 0.2620\n",
      "Epoch 33, 100% \t Train loss: 0.2574 took: 2.79s  Val. loss: 0.2622\n",
      "Epoch 34, 100% \t Train loss: 0.2574 took: 2.79s  Val. loss: 0.2612\n",
      "Epoch 35, 100% \t Train loss: 0.2574 took: 2.30s  Val. loss: 0.2614\n",
      "Epoch 36, 100% \t Train loss: 0.2574 took: 1.64s  Val. loss: 0.2620\n",
      "Epoch 37, 100% \t Train loss: 0.2574 took: 1.64s  Val. loss: 0.2624\n",
      "Epoch 38, 100% \t Train loss: 0.2574 took: 1.68s  Val. loss: 0.2617\n",
      "Epoch 39, 100% \t Train loss: 0.2574 took: 1.73s  Val. loss: 0.2615\n",
      "Epoch 40, 100% \t Train loss: 0.2573 took: 1.74s  Val. loss: 0.2615\n",
      "Epoch 41, 100% \t Train loss: 0.2573 took: 1.77s  Val. loss: 0.2615\n",
      "Epoch 42, 100% \t Train loss: 0.2573 took: 2.80s  Val. loss: 0.2609\n",
      "Epoch 43, 100% \t Train loss: 0.2574 took: 2.95s  Val. loss: 0.2627\n",
      "Epoch 44, 100% \t Train loss: 0.2573 took: 2.91s  Val. loss: 0.2607\n",
      "Epoch 45, 100% \t Train loss: 0.2574 took: 3.12s  Val. loss: 0.2627\n",
      "Epoch 46, 100% \t Train loss: 0.2573 took: 3.10s  Val. loss: 0.2618\n",
      "Epoch 47, 100% \t Train loss: 0.2574 took: 3.15s  Val. loss: 0.2609\n",
      "Epoch 48, 100% \t Train loss: 0.2574 took: 3.14s  Val. loss: 0.2608\n",
      "Epoch 49, 100% \t Train loss: 0.2573 took: 3.17s  Val. loss: 0.2618\n",
      "Epoch 50, 100% \t Train loss: 0.2573 took: 3.18s  Val. loss: 0.2616\n",
      "Training finished, took 138.13s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2589 took: 2.56s  Val. loss: 0.2592\n",
      "Epoch 2, 100% \t Train loss: 0.2586 took: 2.55s  Val. loss: 0.2589\n",
      "Epoch 3, 100% \t Train loss: 0.2587 took: 2.54s  Val. loss: 0.2591\n",
      "Epoch 4, 100% \t Train loss: 0.2587 took: 2.57s  Val. loss: 0.2588\n",
      "Epoch 5, 100% \t Train loss: 0.2587 took: 2.56s  Val. loss: 0.2582\n",
      "Epoch 6, 100% \t Train loss: 0.2587 took: 2.56s  Val. loss: 0.2588\n",
      "Epoch 7, 100% \t Train loss: 0.2586 took: 2.54s  Val. loss: 0.2589\n",
      "Epoch 8, 100% \t Train loss: 0.2587 took: 2.54s  Val. loss: 0.2582\n",
      "Epoch 9, 100% \t Train loss: 0.2587 took: 2.57s  Val. loss: 0.2582\n",
      "Epoch 10, 100% \t Train loss: 0.2587 took: 2.56s  Val. loss: 0.2583\n",
      "Epoch 11, 100% \t Train loss: 0.2587 took: 2.59s  Val. loss: 0.2590\n",
      "Epoch 12, 100% \t Train loss: 0.2587 took: 2.55s  Val. loss: 0.2578\n",
      "Epoch 13, 100% \t Train loss: 0.2587 took: 2.56s  Val. loss: 0.2587\n",
      "Epoch 14, 100% \t Train loss: 0.2587 took: 2.58s  Val. loss: 0.2587\n",
      "Epoch 15, 100% \t Train loss: 0.2587 took: 2.57s  Val. loss: 0.2586\n",
      "Epoch 16, 100% \t Train loss: 0.2588 took: 2.57s  Val. loss: 0.2593\n",
      "Epoch 17, 100% \t Train loss: 0.2587 took: 2.54s  Val. loss: 0.2603\n",
      "Epoch 18, 100% \t Train loss: 0.2587 took: 2.56s  Val. loss: 0.2587\n",
      "Epoch 19, 100% \t Train loss: 0.2587 took: 2.58s  Val. loss: 0.2586\n",
      "Epoch 20, 100% \t Train loss: 0.2587 took: 2.56s  Val. loss: 0.2591\n",
      "Epoch 21, 100% \t Train loss: 0.2587 took: 2.55s  Val. loss: 0.2582\n",
      "Epoch 22, 100% \t Train loss: 0.2587 took: 2.56s  Val. loss: 0.2589\n",
      "Epoch 23, 100% \t Train loss: 0.2587 took: 2.57s  Val. loss: 0.2591\n",
      "Epoch 24, 100% \t Train loss: 0.2586 took: 2.58s  Val. loss: 0.2590\n",
      "Epoch 25, 100% \t Train loss: 0.2587 took: 2.58s  Val. loss: 0.2595\n",
      "Epoch 26, 100% \t Train loss: 0.2587 took: 2.58s  Val. loss: 0.2588\n",
      "Epoch 27, 100% \t Train loss: 0.2586 took: 2.57s  Val. loss: 0.2589\n",
      "Epoch 28, 100% \t Train loss: 0.2586 took: 2.59s  Val. loss: 0.2595\n",
      "Epoch 29, 100% \t Train loss: 0.2586 took: 2.59s  Val. loss: 0.2584\n",
      "Epoch 30, 100% \t Train loss: 0.2586 took: 2.64s  Val. loss: 0.2590\n",
      "Epoch 31, 100% \t Train loss: 0.2587 took: 2.61s  Val. loss: 0.2580\n",
      "Epoch 32, 100% \t Train loss: 0.2587 took: 2.63s  Val. loss: 0.2581\n",
      "Epoch 33, 100% \t Train loss: 0.2587 took: 2.66s  Val. loss: 0.2585\n",
      "Epoch 34, 100% \t Train loss: 0.2586 took: 2.67s  Val. loss: 0.2586\n",
      "Epoch 35, 100% \t Train loss: 0.2586 took: 2.68s  Val. loss: 0.2592\n",
      "Epoch 36, 100% \t Train loss: 0.2586 took: 2.67s  Val. loss: 0.2582\n",
      "Epoch 37, 100% \t Train loss: 0.2586 took: 2.66s  Val. loss: 0.2593\n",
      "Epoch 38, 100% \t Train loss: 0.2585 took: 2.66s  Val. loss: 0.2583\n",
      "Epoch 39, 100% \t Train loss: 0.2582 took: 2.66s  Val. loss: 0.2578\n",
      "Epoch 40, 100% \t Train loss: 0.2565 took: 2.66s  Val. loss: 0.2532\n",
      "Epoch 41, 100% \t Train loss: 0.2478 took: 2.65s  Val. loss: 0.2416\n",
      "Epoch 42, 100% \t Train loss: 0.2341 took: 2.65s  Val. loss: 0.2301\n",
      "Epoch 43, 100% \t Train loss: 0.2245 took: 2.66s  Val. loss: 0.2228\n",
      "Epoch 44, 100% \t Train loss: 0.2134 took: 2.74s  Val. loss: 0.2090\n",
      "Epoch 45, 100% \t Train loss: 0.2027 took: 2.68s  Val. loss: 0.2006\n",
      "Epoch 46, 100% \t Train loss: 0.1972 took: 2.65s  Val. loss: 0.1992\n",
      "Epoch 47, 100% \t Train loss: 0.1950 took: 2.65s  Val. loss: 0.1995\n",
      "Epoch 48, 100% \t Train loss: 0.1935 took: 2.65s  Val. loss: 0.1980\n",
      "Epoch 49, 100% \t Train loss: 0.1929 took: 2.67s  Val. loss: 0.2024\n",
      "Epoch 50, 100% \t Train loss: 0.1919 took: 2.70s  Val. loss: 0.1979\n",
      "Training finished, took 143.66s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  8  - prob: 0.36\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.742488\n",
      "lambda: 0.0010 - V: 0.738230\n",
      "lambda: 0.0005 - V: 0.751096\n",
      "Average V: 0.743938\n",
      "Time elapsed: 428.37 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.27\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 2.57s  Val. loss: 0.2566\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 2.58s  Val. loss: 0.2584\n",
      "Epoch 3, 100% \t Train loss: 0.2582 took: 2.57s  Val. loss: 0.2579\n",
      "Epoch 4, 100% \t Train loss: 0.2581 took: 2.56s  Val. loss: 0.2614\n",
      "Epoch 5, 100% \t Train loss: 0.2582 took: 2.59s  Val. loss: 0.2575\n",
      "Epoch 6, 100% \t Train loss: 0.2580 took: 2.59s  Val. loss: 0.2585\n",
      "Epoch 7, 100% \t Train loss: 0.2581 took: 2.56s  Val. loss: 0.2596\n",
      "Epoch 8, 100% \t Train loss: 0.2581 took: 2.56s  Val. loss: 0.2573\n",
      "Epoch 9, 100% \t Train loss: 0.2581 took: 2.58s  Val. loss: 0.2577\n",
      "Epoch 10, 100% \t Train loss: 0.2580 took: 2.56s  Val. loss: 0.2580\n",
      "Epoch 11, 100% \t Train loss: 0.2580 took: 2.56s  Val. loss: 0.2590\n",
      "Epoch 12, 100% \t Train loss: 0.2579 took: 2.55s  Val. loss: 0.2570\n",
      "Epoch 13, 100% \t Train loss: 0.2580 took: 1.58s  Val. loss: 0.2589\n",
      "Epoch 14, 100% \t Train loss: 0.2580 took: 2.47s  Val. loss: 0.2591\n",
      "Epoch 15, 100% \t Train loss: 0.2579 took: 2.58s  Val. loss: 0.2578\n",
      "Epoch 16, 100% \t Train loss: 0.2580 took: 2.59s  Val. loss: 0.2566\n",
      "Epoch 17, 100% \t Train loss: 0.2579 took: 2.59s  Val. loss: 0.2599\n",
      "Epoch 18, 100% \t Train loss: 0.2580 took: 2.60s  Val. loss: 0.2572\n",
      "Epoch 19, 100% \t Train loss: 0.2579 took: 2.60s  Val. loss: 0.2585\n",
      "Epoch 20, 100% \t Train loss: 0.2579 took: 2.64s  Val. loss: 0.2584\n",
      "Epoch 21, 100% \t Train loss: 0.2579 took: 2.62s  Val. loss: 0.2590\n",
      "Epoch 22, 100% \t Train loss: 0.2579 took: 2.57s  Val. loss: 0.2580\n",
      "Epoch 23, 100% \t Train loss: 0.2580 took: 2.63s  Val. loss: 0.2582\n",
      "Epoch 24, 100% \t Train loss: 0.2579 took: 2.68s  Val. loss: 0.2586\n",
      "Epoch 25, 100% \t Train loss: 0.2580 took: 2.61s  Val. loss: 0.2583\n",
      "Epoch 26, 100% \t Train loss: 0.2579 took: 2.61s  Val. loss: 0.2587\n",
      "Epoch 27, 100% \t Train loss: 0.2580 took: 2.65s  Val. loss: 0.2579\n",
      "Epoch 28, 100% \t Train loss: 0.2580 took: 2.63s  Val. loss: 0.2580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.2580 took: 2.63s  Val. loss: 0.2574\n",
      "Epoch 30, 100% \t Train loss: 0.2579 took: 2.67s  Val. loss: 0.2588\n",
      "Epoch 31, 100% \t Train loss: 0.2579 took: 2.89s  Val. loss: 0.2575\n",
      "Epoch 32, 100% \t Train loss: 0.2579 took: 3.57s  Val. loss: 0.2584\n",
      "Epoch 33, 100% \t Train loss: 0.2579 took: 4.15s  Val. loss: 0.2586\n",
      "Epoch 34, 100% \t Train loss: 0.2579 took: 4.50s  Val. loss: 0.2585\n",
      "Epoch 35, 100% \t Train loss: 0.2579 took: 4.61s  Val. loss: 0.2584\n",
      "Epoch 36, 100% \t Train loss: 0.2579 took: 4.71s  Val. loss: 0.2587\n",
      "Epoch 37, 100% \t Train loss: 0.2579 took: 5.05s  Val. loss: 0.2586\n",
      "Epoch 38, 100% \t Train loss: 0.2579 took: 5.25s  Val. loss: 0.2582\n",
      "Epoch 39, 100% \t Train loss: 0.2580 took: 5.01s  Val. loss: 0.2585\n",
      "Epoch 40, 100% \t Train loss: 0.2580 took: 5.00s  Val. loss: 0.2576\n",
      "Epoch 41, 100% \t Train loss: 0.2579 took: 4.76s  Val. loss: 0.2578\n",
      "Epoch 42, 100% \t Train loss: 0.2579 took: 4.72s  Val. loss: 0.2578\n",
      "Epoch 43, 100% \t Train loss: 0.2579 took: 4.54s  Val. loss: 0.2582\n",
      "Epoch 44, 100% \t Train loss: 0.2580 took: 4.55s  Val. loss: 0.2586\n",
      "Epoch 45, 100% \t Train loss: 0.2579 took: 4.59s  Val. loss: 0.2577\n",
      "Epoch 46, 100% \t Train loss: 0.2579 took: 4.50s  Val. loss: 0.2583\n",
      "Epoch 47, 100% \t Train loss: 0.2579 took: 4.44s  Val. loss: 0.2577\n",
      "Epoch 48, 100% \t Train loss: 0.2579 took: 4.60s  Val. loss: 0.2587\n",
      "Epoch 49, 100% \t Train loss: 0.2579 took: 4.35s  Val. loss: 0.2577\n",
      "Epoch 50, 100% \t Train loss: 0.2579 took: 4.18s  Val. loss: 0.2581\n",
      "Training finished, took 184.17s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 2.58s  Val. loss: 0.2562\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 2.53s  Val. loss: 0.2566\n",
      "Epoch 3, 100% \t Train loss: 0.2582 took: 2.36s  Val. loss: 0.2559\n",
      "Epoch 4, 100% \t Train loss: 0.2584 took: 1.57s  Val. loss: 0.2553\n",
      "Epoch 5, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2552\n",
      "Epoch 6, 100% \t Train loss: 0.2584 took: 1.56s  Val. loss: 0.2560\n",
      "Epoch 7, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2558\n",
      "Epoch 8, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2560\n",
      "Epoch 9, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2563\n",
      "Epoch 10, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2556\n",
      "Epoch 11, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2559\n",
      "Epoch 12, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2568\n",
      "Epoch 13, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2554\n",
      "Epoch 14, 100% \t Train loss: 0.2584 took: 1.58s  Val. loss: 0.2564\n",
      "Epoch 15, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2549\n",
      "Epoch 16, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2564\n",
      "Epoch 17, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2559\n",
      "Epoch 18, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2553\n",
      "Epoch 19, 100% \t Train loss: 0.2583 took: 1.61s  Val. loss: 0.2564\n",
      "Epoch 20, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2564\n",
      "Epoch 21, 100% \t Train loss: 0.2583 took: 1.57s  Val. loss: 0.2554\n",
      "Epoch 22, 100% \t Train loss: 0.2582 took: 1.57s  Val. loss: 0.2554\n",
      "Epoch 23, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2562\n",
      "Epoch 24, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2558\n",
      "Epoch 25, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2557\n",
      "Epoch 26, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2552\n",
      "Epoch 27, 100% \t Train loss: 0.2583 took: 1.58s  Val. loss: 0.2566\n",
      "Epoch 28, 100% \t Train loss: 0.2583 took: 1.59s  Val. loss: 0.2562\n",
      "Epoch 29, 100% \t Train loss: 0.2583 took: 1.61s  Val. loss: 0.2561\n",
      "Epoch 30, 100% \t Train loss: 0.2583 took: 1.64s  Val. loss: 0.2556\n",
      "Epoch 31, 100% \t Train loss: 0.2583 took: 1.76s  Val. loss: 0.2560\n",
      "Epoch 32, 100% \t Train loss: 0.2583 took: 1.95s  Val. loss: 0.2557\n",
      "Epoch 33, 100% \t Train loss: 0.2583 took: 2.97s  Val. loss: 0.2557\n",
      "Epoch 34, 100% \t Train loss: 0.2583 took: 3.01s  Val. loss: 0.2565\n",
      "Epoch 35, 100% \t Train loss: 0.2583 took: 3.18s  Val. loss: 0.2566\n",
      "Epoch 36, 100% \t Train loss: 0.2583 took: 3.23s  Val. loss: 0.2561\n",
      "Epoch 37, 100% \t Train loss: 0.2583 took: 3.28s  Val. loss: 0.2567\n",
      "Epoch 38, 100% \t Train loss: 0.2583 took: 4.13s  Val. loss: 0.2555\n",
      "Epoch 39, 100% \t Train loss: 0.2583 took: 4.34s  Val. loss: 0.2562\n",
      "Epoch 40, 100% \t Train loss: 0.2583 took: 4.32s  Val. loss: 0.2560\n",
      "Epoch 41, 100% \t Train loss: 0.2583 took: 4.62s  Val. loss: 0.2559\n",
      "Epoch 42, 100% \t Train loss: 0.2583 took: 4.38s  Val. loss: 0.2562\n",
      "Epoch 43, 100% \t Train loss: 0.2583 took: 4.51s  Val. loss: 0.2556\n",
      "Epoch 44, 100% \t Train loss: 0.2583 took: 4.61s  Val. loss: 0.2561\n",
      "Epoch 45, 100% \t Train loss: 0.2583 took: 4.72s  Val. loss: 0.2563\n",
      "Epoch 46, 100% \t Train loss: 0.2583 took: 4.70s  Val. loss: 0.2562\n",
      "Epoch 47, 100% \t Train loss: 0.2584 took: 4.82s  Val. loss: 0.2557\n",
      "Epoch 48, 100% \t Train loss: 0.2584 took: 4.82s  Val. loss: 0.2559\n",
      "Epoch 49, 100% \t Train loss: 0.2583 took: 4.03s  Val. loss: 0.2559\n",
      "Epoch 50, 100% \t Train loss: 0.2583 took: 3.92s  Val. loss: 0.2560\n",
      "Training finished, took 142.74s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2581 took: 2.55s  Val. loss: 0.2610\n",
      "Epoch 2, 100% \t Train loss: 0.2576 took: 2.55s  Val. loss: 0.2607\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 2.57s  Val. loss: 0.2606\n",
      "Epoch 4, 100% \t Train loss: 0.2576 took: 2.58s  Val. loss: 0.2615\n",
      "Epoch 5, 100% \t Train loss: 0.2576 took: 2.57s  Val. loss: 0.2614\n",
      "Epoch 6, 100% \t Train loss: 0.2576 took: 2.56s  Val. loss: 0.2620\n",
      "Epoch 7, 100% \t Train loss: 0.2577 took: 2.57s  Val. loss: 0.2613\n",
      "Epoch 8, 100% \t Train loss: 0.2576 took: 1.57s  Val. loss: 0.2623\n",
      "Epoch 9, 100% \t Train loss: 0.2577 took: 1.58s  Val. loss: 0.2621\n",
      "Epoch 10, 100% \t Train loss: 0.2576 took: 1.58s  Val. loss: 0.2613\n",
      "Epoch 11, 100% \t Train loss: 0.2576 took: 1.58s  Val. loss: 0.2615\n",
      "Epoch 12, 100% \t Train loss: 0.2576 took: 1.57s  Val. loss: 0.2605\n",
      "Epoch 13, 100% \t Train loss: 0.2577 took: 1.57s  Val. loss: 0.2612\n",
      "Epoch 14, 100% \t Train loss: 0.2576 took: 1.57s  Val. loss: 0.2613\n",
      "Epoch 15, 100% \t Train loss: 0.2576 took: 1.57s  Val. loss: 0.2622\n",
      "Epoch 16, 100% \t Train loss: 0.2577 took: 1.57s  Val. loss: 0.2618\n",
      "Epoch 17, 100% \t Train loss: 0.2576 took: 1.58s  Val. loss: 0.2615\n",
      "Epoch 18, 100% \t Train loss: 0.2577 took: 1.67s  Val. loss: 0.2614\n",
      "Epoch 19, 100% \t Train loss: 0.2576 took: 2.55s  Val. loss: 0.2607\n",
      "Epoch 20, 100% \t Train loss: 0.2576 took: 2.55s  Val. loss: 0.2617\n",
      "Epoch 21, 100% \t Train loss: 0.2577 took: 2.58s  Val. loss: 0.2622\n",
      "Epoch 22, 100% \t Train loss: 0.2577 took: 2.58s  Val. loss: 0.2616\n",
      "Epoch 23, 100% \t Train loss: 0.2576 took: 2.58s  Val. loss: 0.2615\n",
      "Epoch 24, 100% \t Train loss: 0.2576 took: 2.58s  Val. loss: 0.2614\n",
      "Epoch 25, 100% \t Train loss: 0.2576 took: 2.59s  Val. loss: 0.2619\n",
      "Epoch 26, 100% \t Train loss: 0.2576 took: 2.62s  Val. loss: 0.2623\n",
      "Epoch 27, 100% \t Train loss: 0.2577 took: 2.61s  Val. loss: 0.2612\n",
      "Epoch 28, 100% \t Train loss: 0.2576 took: 2.63s  Val. loss: 0.2606\n",
      "Epoch 29, 100% \t Train loss: 0.2576 took: 2.63s  Val. loss: 0.2612\n",
      "Epoch 30, 100% \t Train loss: 0.2576 took: 2.64s  Val. loss: 0.2605\n",
      "Epoch 31, 100% \t Train loss: 0.2576 took: 2.67s  Val. loss: 0.2610\n",
      "Epoch 32, 100% \t Train loss: 0.2576 took: 2.70s  Val. loss: 0.2620\n",
      "Epoch 33, 100% \t Train loss: 0.2576 took: 2.70s  Val. loss: 0.2618\n",
      "Epoch 34, 100% \t Train loss: 0.2576 took: 2.72s  Val. loss: 0.2619\n",
      "Epoch 35, 100% \t Train loss: 0.2576 took: 2.71s  Val. loss: 0.2617\n",
      "Epoch 36, 100% \t Train loss: 0.2576 took: 2.75s  Val. loss: 0.2619\n",
      "Epoch 37, 100% \t Train loss: 0.2576 took: 2.78s  Val. loss: 0.2619\n",
      "Epoch 38, 100% \t Train loss: 0.2576 took: 2.78s  Val. loss: 0.2610\n",
      "Epoch 39, 100% \t Train loss: 0.2576 took: 1.81s  Val. loss: 0.2615\n",
      "Epoch 40, 100% \t Train loss: 0.2576 took: 1.79s  Val. loss: 0.2608\n",
      "Epoch 41, 100% \t Train loss: 0.2576 took: 1.79s  Val. loss: 0.2611\n",
      "Epoch 42, 100% \t Train loss: 0.2576 took: 2.61s  Val. loss: 0.2618\n",
      "Epoch 43, 100% \t Train loss: 0.2576 took: 2.85s  Val. loss: 0.2618\n",
      "Epoch 44, 100% \t Train loss: 0.2576 took: 2.91s  Val. loss: 0.2620\n",
      "Epoch 45, 100% \t Train loss: 0.2576 took: 2.51s  Val. loss: 0.2613\n",
      "Epoch 46, 100% \t Train loss: 0.2576 took: 2.81s  Val. loss: 0.2613\n",
      "Epoch 47, 100% \t Train loss: 0.2576 took: 2.94s  Val. loss: 0.2621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.2576 took: 2.89s  Val. loss: 0.2605\n",
      "Epoch 49, 100% \t Train loss: 0.2576 took: 2.86s  Val. loss: 0.2618\n",
      "Epoch 50, 100% \t Train loss: 0.2576 took: 2.82s  Val. loss: 0.2615\n",
      "Training finished, took 131.18s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.27\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.741763\n",
      "lambda: 0.0010 - V: 0.744046\n",
      "lambda: 0.0005 - V: 0.738553\n",
      "Average V: 0.741454\n",
      "Time elapsed: 461.48 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2583 took: 2.48s  Val. loss: 0.2572\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 2.49s  Val. loss: 0.2573\n",
      "Epoch 3, 100% \t Train loss: 0.2575 took: 2.50s  Val. loss: 0.2577\n",
      "Epoch 4, 100% \t Train loss: 0.2577 took: 1.51s  Val. loss: 0.2571\n",
      "Epoch 5, 100% \t Train loss: 0.2576 took: 1.50s  Val. loss: 0.2584\n",
      "Epoch 6, 100% \t Train loss: 0.2576 took: 1.50s  Val. loss: 0.2572\n",
      "Epoch 7, 100% \t Train loss: 0.2577 took: 1.50s  Val. loss: 0.2573\n",
      "Epoch 8, 100% \t Train loss: 0.2575 took: 1.50s  Val. loss: 0.2576\n",
      "Epoch 9, 100% \t Train loss: 0.2576 took: 1.51s  Val. loss: 0.2578\n",
      "Epoch 10, 100% \t Train loss: 0.2576 took: 1.51s  Val. loss: 0.2573\n",
      "Epoch 11, 100% \t Train loss: 0.2577 took: 1.51s  Val. loss: 0.2575\n",
      "Epoch 12, 100% \t Train loss: 0.2575 took: 1.50s  Val. loss: 0.2578\n",
      "Epoch 13, 100% \t Train loss: 0.2576 took: 1.50s  Val. loss: 0.2577\n",
      "Epoch 14, 100% \t Train loss: 0.2576 took: 1.50s  Val. loss: 0.2579\n",
      "Epoch 15, 100% \t Train loss: 0.2575 took: 1.51s  Val. loss: 0.2573\n",
      "Epoch 16, 100% \t Train loss: 0.2576 took: 1.50s  Val. loss: 0.2563\n",
      "Epoch 17, 100% \t Train loss: 0.2575 took: 1.50s  Val. loss: 0.2572\n",
      "Epoch 18, 100% \t Train loss: 0.2576 took: 2.27s  Val. loss: 0.2569\n",
      "Epoch 19, 100% \t Train loss: 0.2576 took: 2.48s  Val. loss: 0.2580\n",
      "Epoch 20, 100% \t Train loss: 0.2575 took: 2.52s  Val. loss: 0.2569\n",
      "Epoch 21, 100% \t Train loss: 0.2575 took: 2.51s  Val. loss: 0.2574\n",
      "Epoch 22, 100% \t Train loss: 0.2575 took: 2.50s  Val. loss: 0.2577\n",
      "Epoch 23, 100% \t Train loss: 0.2575 took: 2.49s  Val. loss: 0.2579\n",
      "Epoch 24, 100% \t Train loss: 0.2575 took: 2.51s  Val. loss: 0.2578\n",
      "Epoch 25, 100% \t Train loss: 0.2575 took: 2.53s  Val. loss: 0.2574\n",
      "Epoch 26, 100% \t Train loss: 0.2575 took: 2.55s  Val. loss: 0.2569\n",
      "Epoch 27, 100% \t Train loss: 0.2575 took: 2.59s  Val. loss: 0.2577\n",
      "Epoch 28, 100% \t Train loss: 0.2575 took: 2.66s  Val. loss: 0.2571\n",
      "Epoch 29, 100% \t Train loss: 0.2575 took: 2.69s  Val. loss: 0.2578\n",
      "Epoch 30, 100% \t Train loss: 0.2575 took: 2.75s  Val. loss: 0.2568\n",
      "Epoch 31, 100% \t Train loss: 0.2575 took: 2.93s  Val. loss: 0.2574\n",
      "Epoch 32, 100% \t Train loss: 0.2575 took: 3.43s  Val. loss: 0.2573\n",
      "Epoch 33, 100% \t Train loss: 0.2575 took: 3.78s  Val. loss: 0.2574\n",
      "Epoch 34, 100% \t Train loss: 0.2575 took: 3.98s  Val. loss: 0.2569\n",
      "Epoch 35, 100% \t Train loss: 0.2575 took: 3.02s  Val. loss: 0.2573\n",
      "Epoch 36, 100% \t Train loss: 0.2576 took: 3.15s  Val. loss: 0.2564\n",
      "Epoch 37, 100% \t Train loss: 0.2575 took: 3.20s  Val. loss: 0.2567\n",
      "Epoch 38, 100% \t Train loss: 0.2575 took: 3.34s  Val. loss: 0.2571\n",
      "Epoch 39, 100% \t Train loss: 0.2575 took: 3.43s  Val. loss: 0.2578\n",
      "Epoch 40, 100% \t Train loss: 0.2575 took: 3.27s  Val. loss: 0.2579\n",
      "Epoch 41, 100% \t Train loss: 0.2575 took: 3.49s  Val. loss: 0.2571\n",
      "Epoch 42, 100% \t Train loss: 0.2574 took: 3.41s  Val. loss: 0.2573\n",
      "Epoch 43, 100% \t Train loss: 0.2575 took: 3.55s  Val. loss: 0.2574\n",
      "Epoch 44, 100% \t Train loss: 0.2575 took: 4.31s  Val. loss: 0.2570\n",
      "Epoch 45, 100% \t Train loss: 0.2575 took: 4.61s  Val. loss: 0.2569\n",
      "Epoch 46, 100% \t Train loss: 0.2575 took: 4.49s  Val. loss: 0.2575\n",
      "Epoch 47, 100% \t Train loss: 0.2575 took: 4.54s  Val. loss: 0.2569\n",
      "Epoch 48, 100% \t Train loss: 0.2575 took: 4.50s  Val. loss: 0.2578\n",
      "Epoch 49, 100% \t Train loss: 0.2575 took: 4.67s  Val. loss: 0.2577\n",
      "Epoch 50, 100% \t Train loss: 0.2575 took: 4.65s  Val. loss: 0.2571\n",
      "Training finished, took 152.75s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2604 took: 2.46s  Val. loss: 0.2619\n",
      "Epoch 2, 100% \t Train loss: 0.2578 took: 2.48s  Val. loss: 0.2605\n",
      "Epoch 3, 100% \t Train loss: 0.2580 took: 2.49s  Val. loss: 0.2621\n",
      "Epoch 4, 100% \t Train loss: 0.2579 took: 2.49s  Val. loss: 0.2625\n",
      "Epoch 5, 100% \t Train loss: 0.2579 took: 2.48s  Val. loss: 0.2615\n",
      "Epoch 6, 100% \t Train loss: 0.2579 took: 2.48s  Val. loss: 0.2618\n",
      "Epoch 7, 100% \t Train loss: 0.2579 took: 2.53s  Val. loss: 0.2629\n",
      "Epoch 8, 100% \t Train loss: 0.2580 took: 2.50s  Val. loss: 0.2625\n",
      "Epoch 9, 100% \t Train loss: 0.2579 took: 2.48s  Val. loss: 0.2614\n",
      "Epoch 10, 100% \t Train loss: 0.2580 took: 2.49s  Val. loss: 0.2621\n",
      "Epoch 11, 100% \t Train loss: 0.2580 took: 2.48s  Val. loss: 0.2613\n",
      "Epoch 12, 100% \t Train loss: 0.2580 took: 2.48s  Val. loss: 0.2610\n",
      "Epoch 13, 100% \t Train loss: 0.2579 took: 2.50s  Val. loss: 0.2622\n",
      "Epoch 14, 100% \t Train loss: 0.2579 took: 2.48s  Val. loss: 0.2621\n",
      "Epoch 15, 100% \t Train loss: 0.2579 took: 2.49s  Val. loss: 0.2614\n",
      "Epoch 16, 100% \t Train loss: 0.2579 took: 2.49s  Val. loss: 0.2624\n",
      "Epoch 17, 100% \t Train loss: 0.2579 took: 2.50s  Val. loss: 0.2615\n",
      "Epoch 18, 100% \t Train loss: 0.2580 took: 2.47s  Val. loss: 0.2615\n",
      "Epoch 19, 100% \t Train loss: 0.2579 took: 2.49s  Val. loss: 0.2616\n",
      "Epoch 20, 100% \t Train loss: 0.2579 took: 2.48s  Val. loss: 0.2616\n",
      "Epoch 21, 100% \t Train loss: 0.2579 took: 2.48s  Val. loss: 0.2614\n",
      "Epoch 22, 100% \t Train loss: 0.2579 took: 1.81s  Val. loss: 0.2615\n",
      "Epoch 23, 100% \t Train loss: 0.2579 took: 1.50s  Val. loss: 0.2623\n",
      "Epoch 24, 100% \t Train loss: 0.2579 took: 1.50s  Val. loss: 0.2617\n",
      "Epoch 25, 100% \t Train loss: 0.2579 took: 1.50s  Val. loss: 0.2619\n",
      "Epoch 26, 100% \t Train loss: 0.2579 took: 1.53s  Val. loss: 0.2613\n",
      "Epoch 27, 100% \t Train loss: 0.2579 took: 1.56s  Val. loss: 0.2607\n",
      "Epoch 28, 100% \t Train loss: 0.2579 took: 1.60s  Val. loss: 0.2619\n",
      "Epoch 29, 100% \t Train loss: 0.2579 took: 1.63s  Val. loss: 0.2625\n",
      "Epoch 30, 100% \t Train loss: 0.2579 took: 1.65s  Val. loss: 0.2611\n",
      "Epoch 31, 100% \t Train loss: 0.2579 took: 1.73s  Val. loss: 0.2626\n",
      "Epoch 32, 100% \t Train loss: 0.2579 took: 1.79s  Val. loss: 0.2623\n",
      "Epoch 33, 100% \t Train loss: 0.2579 took: 1.81s  Val. loss: 0.2615\n",
      "Epoch 34, 100% \t Train loss: 0.2579 took: 1.80s  Val. loss: 0.2633\n",
      "Epoch 35, 100% \t Train loss: 0.2578 took: 1.81s  Val. loss: 0.2621\n",
      "Epoch 36, 100% \t Train loss: 0.2579 took: 1.83s  Val. loss: 0.2624\n",
      "Epoch 37, 100% \t Train loss: 0.2578 took: 1.85s  Val. loss: 0.2618\n",
      "Epoch 38, 100% \t Train loss: 0.2579 took: 1.86s  Val. loss: 0.2622\n",
      "Epoch 39, 100% \t Train loss: 0.2579 took: 1.86s  Val. loss: 0.2621\n",
      "Epoch 40, 100% \t Train loss: 0.2579 took: 1.88s  Val. loss: 0.2623\n",
      "Epoch 41, 100% \t Train loss: 0.2578 took: 2.97s  Val. loss: 0.2625\n",
      "Epoch 42, 100% \t Train loss: 0.2579 took: 3.29s  Val. loss: 0.2618\n",
      "Epoch 43, 100% \t Train loss: 0.2579 took: 3.65s  Val. loss: 0.2618\n",
      "Epoch 44, 100% \t Train loss: 0.2579 took: 3.61s  Val. loss: 0.2613\n",
      "Epoch 45, 100% \t Train loss: 0.2578 took: 3.30s  Val. loss: 0.2629\n",
      "Epoch 46, 100% \t Train loss: 0.2579 took: 3.43s  Val. loss: 0.2626\n",
      "Epoch 47, 100% \t Train loss: 0.2579 took: 3.36s  Val. loss: 0.2617\n",
      "Epoch 48, 100% \t Train loss: 0.2579 took: 3.39s  Val. loss: 0.2618\n",
      "Epoch 49, 100% \t Train loss: 0.2579 took: 3.45s  Val. loss: 0.2617\n",
      "Epoch 50, 100% \t Train loss: 0.2579 took: 3.44s  Val. loss: 0.2617\n",
      "Training finished, took 130.60s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2621 took: 2.49s  Val. loss: 0.2542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2586 took: 2.50s  Val. loss: 0.2551\n",
      "Epoch 3, 100% \t Train loss: 0.2586 took: 2.47s  Val. loss: 0.2549\n",
      "Epoch 4, 100% \t Train loss: 0.2586 took: 2.50s  Val. loss: 0.2546\n",
      "Epoch 5, 100% \t Train loss: 0.2586 took: 2.49s  Val. loss: 0.2549\n",
      "Epoch 6, 100% \t Train loss: 0.2586 took: 2.50s  Val. loss: 0.2554\n",
      "Epoch 7, 100% \t Train loss: 0.2586 took: 2.49s  Val. loss: 0.2555\n",
      "Epoch 8, 100% \t Train loss: 0.2586 took: 2.51s  Val. loss: 0.2547\n",
      "Epoch 9, 100% \t Train loss: 0.2586 took: 2.49s  Val. loss: 0.2547\n",
      "Epoch 10, 100% \t Train loss: 0.2586 took: 2.53s  Val. loss: 0.2544\n",
      "Epoch 11, 100% \t Train loss: 0.2586 took: 2.51s  Val. loss: 0.2543\n",
      "Epoch 12, 100% \t Train loss: 0.2586 took: 2.52s  Val. loss: 0.2538\n",
      "Epoch 13, 100% \t Train loss: 0.2586 took: 2.54s  Val. loss: 0.2544\n",
      "Epoch 14, 100% \t Train loss: 0.2586 took: 2.50s  Val. loss: 0.2553\n",
      "Epoch 15, 100% \t Train loss: 0.2586 took: 2.48s  Val. loss: 0.2552\n",
      "Epoch 16, 100% \t Train loss: 0.2586 took: 2.49s  Val. loss: 0.2557\n",
      "Epoch 17, 100% \t Train loss: 0.2586 took: 2.48s  Val. loss: 0.2545\n",
      "Epoch 18, 100% \t Train loss: 0.2586 took: 2.50s  Val. loss: 0.2548\n",
      "Epoch 19, 100% \t Train loss: 0.2586 took: 2.49s  Val. loss: 0.2546\n",
      "Epoch 20, 100% \t Train loss: 0.2586 took: 2.48s  Val. loss: 0.2551\n",
      "Epoch 21, 100% \t Train loss: 0.2586 took: 2.50s  Val. loss: 0.2547\n",
      "Epoch 22, 100% \t Train loss: 0.2586 took: 2.52s  Val. loss: 0.2552\n",
      "Epoch 23, 100% \t Train loss: 0.2586 took: 2.53s  Val. loss: 0.2551\n",
      "Epoch 24, 100% \t Train loss: 0.2586 took: 2.54s  Val. loss: 0.2541\n",
      "Epoch 25, 100% \t Train loss: 0.2586 took: 2.54s  Val. loss: 0.2545\n",
      "Epoch 26, 100% \t Train loss: 0.2586 took: 2.51s  Val. loss: 0.2558\n",
      "Epoch 27, 100% \t Train loss: 0.2586 took: 2.59s  Val. loss: 0.2545\n",
      "Epoch 28, 100% \t Train loss: 0.2586 took: 2.54s  Val. loss: 0.2543\n",
      "Epoch 29, 100% \t Train loss: 0.2587 took: 2.54s  Val. loss: 0.2544\n",
      "Epoch 30, 100% \t Train loss: 0.2586 took: 2.50s  Val. loss: 0.2545\n",
      "Epoch 31, 100% \t Train loss: 0.2586 took: 2.50s  Val. loss: 0.2546\n",
      "Epoch 32, 100% \t Train loss: 0.2586 took: 2.55s  Val. loss: 0.2555\n",
      "Epoch 33, 100% \t Train loss: 0.2586 took: 2.56s  Val. loss: 0.2545\n",
      "Epoch 34, 100% \t Train loss: 0.2586 took: 2.55s  Val. loss: 0.2550\n",
      "Epoch 35, 100% \t Train loss: 0.2586 took: 2.57s  Val. loss: 0.2547\n",
      "Epoch 36, 100% \t Train loss: 0.2586 took: 2.58s  Val. loss: 0.2546\n",
      "Epoch 37, 100% \t Train loss: 0.2586 took: 2.57s  Val. loss: 0.2545\n",
      "Epoch 38, 100% \t Train loss: 0.2586 took: 2.58s  Val. loss: 0.2550\n",
      "Epoch 39, 100% \t Train loss: 0.2586 took: 2.56s  Val. loss: 0.2545\n",
      "Epoch 40, 100% \t Train loss: 0.2586 took: 2.60s  Val. loss: 0.2541\n",
      "Epoch 41, 100% \t Train loss: 0.2586 took: 1.97s  Val. loss: 0.2549\n",
      "Epoch 42, 100% \t Train loss: 0.2586 took: 1.67s  Val. loss: 0.2550\n",
      "Epoch 43, 100% \t Train loss: 0.2586 took: 1.68s  Val. loss: 0.2550\n",
      "Epoch 44, 100% \t Train loss: 0.2586 took: 1.70s  Val. loss: 0.2545\n",
      "Epoch 45, 100% \t Train loss: 0.2586 took: 1.71s  Val. loss: 0.2546\n",
      "Epoch 46, 100% \t Train loss: 0.2586 took: 1.71s  Val. loss: 0.2551\n",
      "Epoch 47, 100% \t Train loss: 0.2586 took: 1.68s  Val. loss: 0.2549\n",
      "Epoch 48, 100% \t Train loss: 0.2586 took: 1.70s  Val. loss: 0.2556\n",
      "Epoch 49, 100% \t Train loss: 0.2586 took: 1.72s  Val. loss: 0.2551\n",
      "Epoch 50, 100% \t Train loss: 0.2586 took: 1.72s  Val. loss: 0.2547\n",
      "Training finished, took 130.63s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.742646\n",
      "lambda: 0.0010 - V: 0.738113\n",
      "lambda: 0.0005 - V: 0.745210\n",
      "Average V: 0.741990\n",
      "Time elapsed: 417.36 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.21\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 1.79s  Val. loss: 0.2599\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 1.03s  Val. loss: 0.2597\n",
      "Epoch 3, 100% \t Train loss: 0.2557 took: 1.03s  Val. loss: 0.2478\n",
      "Epoch 4, 100% \t Train loss: 0.1948 took: 1.02s  Val. loss: 0.1894\n",
      "Epoch 5, 100% \t Train loss: 0.1720 took: 1.03s  Val. loss: 0.1838\n",
      "Epoch 6, 100% \t Train loss: 0.1691 took: 1.03s  Val. loss: 0.1846\n",
      "Epoch 7, 100% \t Train loss: 0.1668 took: 1.04s  Val. loss: 0.1847\n",
      "Epoch 8, 100% \t Train loss: 0.1665 took: 1.03s  Val. loss: 0.1848\n",
      "Epoch 9, 100% \t Train loss: 0.1647 took: 1.03s  Val. loss: 0.1847\n",
      "Epoch 10, 100% \t Train loss: 0.1628 took: 1.04s  Val. loss: 0.1801\n",
      "Epoch 11, 100% \t Train loss: 0.1600 took: 1.03s  Val. loss: 0.1828\n",
      "Epoch 12, 100% \t Train loss: 0.1578 took: 1.04s  Val. loss: 0.1791\n",
      "Epoch 13, 100% \t Train loss: 0.1556 took: 1.04s  Val. loss: 0.1769\n",
      "Epoch 14, 100% \t Train loss: 0.1527 took: 1.03s  Val. loss: 0.1772\n",
      "Epoch 15, 100% \t Train loss: 0.1525 took: 1.03s  Val. loss: 0.1755\n",
      "Epoch 16, 100% \t Train loss: 0.1498 took: 1.04s  Val. loss: 0.1785\n",
      "Epoch 17, 100% \t Train loss: 0.1498 took: 1.04s  Val. loss: 0.1758\n",
      "Epoch 18, 100% \t Train loss: 0.1489 took: 1.04s  Val. loss: 0.1752\n",
      "Epoch 19, 100% \t Train loss: 0.1478 took: 1.04s  Val. loss: 0.1728\n",
      "Epoch 20, 100% \t Train loss: 0.1467 took: 1.04s  Val. loss: 0.1774\n",
      "Epoch 21, 100% \t Train loss: 0.1425 took: 1.04s  Val. loss: 0.1709\n",
      "Epoch 22, 100% \t Train loss: 0.1386 took: 1.04s  Val. loss: 0.1672\n",
      "Epoch 23, 100% \t Train loss: 0.1327 took: 1.03s  Val. loss: 0.1639\n",
      "Epoch 24, 100% \t Train loss: 0.1277 took: 1.04s  Val. loss: 0.1610\n",
      "Epoch 25, 100% \t Train loss: 0.1231 took: 1.04s  Val. loss: 0.1527\n",
      "Epoch 26, 100% \t Train loss: 0.1188 took: 1.04s  Val. loss: 0.1562\n",
      "Epoch 27, 100% \t Train loss: 0.1149 took: 1.04s  Val. loss: 0.1420\n",
      "Epoch 28, 100% \t Train loss: 0.1118 took: 1.05s  Val. loss: 0.1470\n",
      "Epoch 29, 100% \t Train loss: 0.1089 took: 1.10s  Val. loss: 0.1403\n",
      "Epoch 30, 100% \t Train loss: 0.1068 took: 1.86s  Val. loss: 0.1370\n",
      "Epoch 31, 100% \t Train loss: 0.1031 took: 1.90s  Val. loss: 0.1368\n",
      "Epoch 32, 100% \t Train loss: 0.0997 took: 1.99s  Val. loss: 0.1277\n",
      "Epoch 33, 100% \t Train loss: 0.0974 took: 2.10s  Val. loss: 0.1254\n",
      "Epoch 34, 100% \t Train loss: 0.0942 took: 2.14s  Val. loss: 0.1232\n",
      "Epoch 35, 100% \t Train loss: 0.0920 took: 2.16s  Val. loss: 0.1197\n",
      "Epoch 36, 100% \t Train loss: 0.0906 took: 2.18s  Val. loss: 0.1197\n",
      "Epoch 37, 100% \t Train loss: 0.0891 took: 2.16s  Val. loss: 0.1141\n",
      "Epoch 38, 100% \t Train loss: 0.0885 took: 2.14s  Val. loss: 0.1144\n",
      "Epoch 39, 100% \t Train loss: 0.0870 took: 2.14s  Val. loss: 0.1133\n",
      "Epoch 40, 100% \t Train loss: 0.0863 took: 2.15s  Val. loss: 0.1136\n",
      "Epoch 41, 100% \t Train loss: 0.0855 took: 2.17s  Val. loss: 0.1128\n",
      "Epoch 42, 100% \t Train loss: 0.0844 took: 2.16s  Val. loss: 0.1088\n",
      "Epoch 43, 100% \t Train loss: 0.0840 took: 1.42s  Val. loss: 0.1090\n",
      "Epoch 44, 100% \t Train loss: 0.0828 took: 1.43s  Val. loss: 0.1094\n",
      "Epoch 45, 100% \t Train loss: 0.0827 took: 1.44s  Val. loss: 0.1122\n",
      "Epoch 46, 100% \t Train loss: 0.0824 took: 1.43s  Val. loss: 0.1121\n",
      "Epoch 47, 100% \t Train loss: 0.0821 took: 1.45s  Val. loss: 0.1145\n",
      "Epoch 48, 100% \t Train loss: 0.0826 took: 2.19s  Val. loss: 0.1033\n",
      "Epoch 49, 100% \t Train loss: 0.0804 took: 2.25s  Val. loss: 0.1079\n",
      "Epoch 50, 100% \t Train loss: 0.0812 took: 2.25s  Val. loss: 0.1054\n",
      "Training finished, took 81.81s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2572 took: 1.79s  Val. loss: 0.2543\n",
      "Epoch 2, 100% \t Train loss: 0.2567 took: 1.76s  Val. loss: 0.2545\n",
      "Epoch 3, 100% \t Train loss: 0.2482 took: 1.79s  Val. loss: 0.2284\n",
      "Epoch 4, 100% \t Train loss: 0.2081 took: 1.77s  Val. loss: 0.2010\n",
      "Epoch 5, 100% \t Train loss: 0.1806 took: 1.77s  Val. loss: 0.1669\n",
      "Epoch 6, 100% \t Train loss: 0.1719 took: 1.81s  Val. loss: 0.1634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, 100% \t Train loss: 0.1687 took: 1.82s  Val. loss: 0.1711\n",
      "Epoch 8, 100% \t Train loss: 0.1664 took: 1.80s  Val. loss: 0.1613\n",
      "Epoch 9, 100% \t Train loss: 0.1630 took: 1.82s  Val. loss: 0.1574\n",
      "Epoch 10, 100% \t Train loss: 0.1631 took: 1.81s  Val. loss: 0.1602\n",
      "Epoch 11, 100% \t Train loss: 0.1616 took: 1.81s  Val. loss: 0.1600\n",
      "Epoch 12, 100% \t Train loss: 0.1619 took: 1.80s  Val. loss: 0.1677\n",
      "Epoch 13, 100% \t Train loss: 0.1611 took: 1.82s  Val. loss: 0.1629\n",
      "Epoch 14, 100% \t Train loss: 0.1573 took: 1.79s  Val. loss: 0.1556\n",
      "Epoch 15, 100% \t Train loss: 0.1574 took: 1.79s  Val. loss: 0.1550\n",
      "Epoch 16, 100% \t Train loss: 0.1572 took: 1.80s  Val. loss: 0.1579\n",
      "Epoch 17, 100% \t Train loss: 0.1561 took: 1.78s  Val. loss: 0.1532\n",
      "Epoch 18, 100% \t Train loss: 0.1535 took: 1.80s  Val. loss: 0.1549\n",
      "Epoch 19, 100% \t Train loss: 0.1538 took: 1.77s  Val. loss: 0.1565\n",
      "Epoch 20, 100% \t Train loss: 0.1534 took: 1.76s  Val. loss: 0.1562\n",
      "Epoch 21, 100% \t Train loss: 0.1538 took: 1.77s  Val. loss: 0.1598\n",
      "Epoch 22, 100% \t Train loss: 0.1515 took: 1.77s  Val. loss: 0.1562\n",
      "Epoch 23, 100% \t Train loss: 0.1505 took: 1.79s  Val. loss: 0.1557\n",
      "Epoch 24, 100% \t Train loss: 0.1511 took: 1.77s  Val. loss: 0.1569\n",
      "Epoch 25, 100% \t Train loss: 0.1491 took: 1.77s  Val. loss: 0.1545\n",
      "Epoch 26, 100% \t Train loss: 0.1481 took: 1.78s  Val. loss: 0.1550\n",
      "Epoch 27, 100% \t Train loss: 0.1485 took: 1.78s  Val. loss: 0.1548\n",
      "Epoch 28, 100% \t Train loss: 0.1477 took: 1.80s  Val. loss: 0.1550\n",
      "Epoch 29, 100% \t Train loss: 0.1468 took: 1.81s  Val. loss: 0.1553\n",
      "Epoch 30, 100% \t Train loss: 0.1463 took: 1.82s  Val. loss: 0.1542\n",
      "Epoch 31, 100% \t Train loss: 0.1452 took: 1.83s  Val. loss: 0.1567\n",
      "Epoch 32, 100% \t Train loss: 0.1453 took: 1.89s  Val. loss: 0.1568\n",
      "Epoch 33, 100% \t Train loss: 0.1441 took: 1.92s  Val. loss: 0.1586\n",
      "Epoch 34, 100% \t Train loss: 0.1435 took: 1.94s  Val. loss: 0.1557\n",
      "Epoch 35, 100% \t Train loss: 0.1424 took: 1.94s  Val. loss: 0.1555\n",
      "Epoch 36, 100% \t Train loss: 0.1425 took: 1.96s  Val. loss: 0.1571\n",
      "Epoch 37, 100% \t Train loss: 0.1409 took: 1.93s  Val. loss: 0.1559\n",
      "Epoch 38, 100% \t Train loss: 0.1404 took: 1.96s  Val. loss: 0.1552\n",
      "Epoch 39, 100% \t Train loss: 0.1402 took: 1.96s  Val. loss: 0.1545\n",
      "Epoch 40, 100% \t Train loss: 0.1391 took: 1.97s  Val. loss: 0.1565\n",
      "Epoch 41, 100% \t Train loss: 0.1387 took: 1.99s  Val. loss: 0.1529\n",
      "Epoch 42, 100% \t Train loss: 0.1383 took: 1.99s  Val. loss: 0.1520\n",
      "Epoch 43, 100% \t Train loss: 0.1371 took: 2.00s  Val. loss: 0.1557\n",
      "Epoch 44, 100% \t Train loss: 0.1371 took: 2.01s  Val. loss: 0.1578\n",
      "Epoch 45, 100% \t Train loss: 0.1375 took: 2.02s  Val. loss: 0.1569\n",
      "Epoch 46, 100% \t Train loss: 0.1359 took: 2.02s  Val. loss: 0.1547\n",
      "Epoch 47, 100% \t Train loss: 0.1347 took: 2.08s  Val. loss: 0.1537\n",
      "Epoch 48, 100% \t Train loss: 0.1342 took: 2.05s  Val. loss: 0.1499\n",
      "Epoch 49, 100% \t Train loss: 0.1341 took: 2.03s  Val. loss: 0.1539\n",
      "Epoch 50, 100% \t Train loss: 0.1329 took: 2.01s  Val. loss: 0.1517\n",
      "Training finished, took 105.95s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 1.79s  Val. loss: 0.2590\n",
      "Epoch 2, 100% \t Train loss: 0.2586 took: 1.79s  Val. loss: 0.2587\n",
      "Epoch 3, 100% \t Train loss: 0.2585 took: 1.78s  Val. loss: 0.2592\n",
      "Epoch 4, 100% \t Train loss: 0.2582 took: 1.78s  Val. loss: 0.2589\n",
      "Epoch 5, 100% \t Train loss: 0.2570 took: 1.78s  Val. loss: 0.2569\n",
      "Epoch 6, 100% \t Train loss: 0.2493 took: 1.79s  Val. loss: 0.2390\n",
      "Epoch 7, 100% \t Train loss: 0.2064 took: 1.78s  Val. loss: 0.1802\n",
      "Epoch 8, 100% \t Train loss: 0.1773 took: 1.77s  Val. loss: 0.1698\n",
      "Epoch 9, 100% \t Train loss: 0.1706 took: 1.78s  Val. loss: 0.1685\n",
      "Epoch 10, 100% \t Train loss: 0.1681 took: 1.78s  Val. loss: 0.1676\n",
      "Epoch 11, 100% \t Train loss: 0.1659 took: 1.81s  Val. loss: 0.1670\n",
      "Epoch 12, 100% \t Train loss: 0.1650 took: 1.81s  Val. loss: 0.1616\n",
      "Epoch 13, 100% \t Train loss: 0.1638 took: 1.79s  Val. loss: 0.1649\n",
      "Epoch 14, 100% \t Train loss: 0.1627 took: 1.82s  Val. loss: 0.1631\n",
      "Epoch 15, 100% \t Train loss: 0.1616 took: 1.81s  Val. loss: 0.1626\n",
      "Epoch 16, 100% \t Train loss: 0.1611 took: 1.82s  Val. loss: 0.1616\n",
      "Epoch 17, 100% \t Train loss: 0.1589 took: 1.79s  Val. loss: 0.1595\n",
      "Epoch 18, 100% \t Train loss: 0.1588 took: 1.81s  Val. loss: 0.1585\n",
      "Epoch 19, 100% \t Train loss: 0.1574 took: 1.77s  Val. loss: 0.1611\n",
      "Epoch 20, 100% \t Train loss: 0.1576 took: 1.77s  Val. loss: 0.1598\n",
      "Epoch 21, 100% \t Train loss: 0.1573 took: 1.78s  Val. loss: 0.1591\n",
      "Epoch 22, 100% \t Train loss: 0.1568 took: 1.78s  Val. loss: 0.1572\n",
      "Epoch 23, 100% \t Train loss: 0.1554 took: 1.77s  Val. loss: 0.1570\n",
      "Epoch 24, 100% \t Train loss: 0.1553 took: 1.79s  Val. loss: 0.1556\n",
      "Epoch 25, 100% \t Train loss: 0.1543 took: 1.80s  Val. loss: 0.1576\n",
      "Epoch 26, 100% \t Train loss: 0.1538 took: 1.79s  Val. loss: 0.1619\n",
      "Epoch 27, 100% \t Train loss: 0.1545 took: 1.80s  Val. loss: 0.1596\n",
      "Epoch 28, 100% \t Train loss: 0.1535 took: 1.80s  Val. loss: 0.1558\n",
      "Epoch 29, 100% \t Train loss: 0.1537 took: 1.82s  Val. loss: 0.1553\n",
      "Epoch 30, 100% \t Train loss: 0.1536 took: 1.83s  Val. loss: 0.1574\n",
      "Epoch 31, 100% \t Train loss: 0.1521 took: 1.84s  Val. loss: 0.1561\n",
      "Epoch 32, 100% \t Train loss: 0.1517 took: 1.85s  Val. loss: 0.1577\n",
      "Epoch 33, 100% \t Train loss: 0.1516 took: 1.86s  Val. loss: 0.1553\n",
      "Epoch 34, 100% \t Train loss: 0.1513 took: 1.87s  Val. loss: 0.1599\n",
      "Epoch 35, 100% \t Train loss: 0.1517 took: 1.89s  Val. loss: 0.1551\n",
      "Epoch 36, 100% \t Train loss: 0.1515 took: 1.86s  Val. loss: 0.1557\n",
      "Epoch 37, 100% \t Train loss: 0.1508 took: 1.88s  Val. loss: 0.1592\n",
      "Epoch 38, 100% \t Train loss: 0.1510 took: 1.89s  Val. loss: 0.1555\n",
      "Epoch 39, 100% \t Train loss: 0.1499 took: 1.90s  Val. loss: 0.1540\n",
      "Epoch 40, 100% \t Train loss: 0.1498 took: 1.90s  Val. loss: 0.1547\n",
      "Epoch 41, 100% \t Train loss: 0.1496 took: 1.90s  Val. loss: 0.1571\n",
      "Epoch 42, 100% \t Train loss: 0.1488 took: 1.94s  Val. loss: 0.1557\n",
      "Epoch 43, 100% \t Train loss: 0.1484 took: 1.92s  Val. loss: 0.1530\n",
      "Epoch 44, 100% \t Train loss: 0.1484 took: 1.93s  Val. loss: 0.1544\n",
      "Epoch 45, 100% \t Train loss: 0.1491 took: 1.91s  Val. loss: 0.1593\n",
      "Epoch 46, 100% \t Train loss: 0.1483 took: 1.88s  Val. loss: 0.1546\n",
      "Epoch 47, 100% \t Train loss: 0.1471 took: 1.88s  Val. loss: 0.1534\n",
      "Epoch 48, 100% \t Train loss: 0.1477 took: 1.86s  Val. loss: 0.1588\n",
      "Epoch 49, 100% \t Train loss: 0.1476 took: 1.85s  Val. loss: 0.1549\n",
      "Epoch 50, 100% \t Train loss: 0.1472 took: 1.84s  Val. loss: 0.1535\n",
      "Training finished, took 104.05s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.21\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.846556\n",
      "lambda: 0.0010 - V: 0.836850\n",
      "lambda: 0.0005 - V: 0.829357\n",
      "Average V: 0.837588\n",
      "Time elapsed: 295.24 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2572 took: 2.44s  Val. loss: 0.2570\n",
      "Epoch 2, 100% \t Train loss: 0.2567 took: 2.44s  Val. loss: 0.2557\n",
      "Epoch 3, 100% \t Train loss: 0.2568 took: 2.45s  Val. loss: 0.2586\n",
      "Epoch 4, 100% \t Train loss: 0.2569 took: 2.43s  Val. loss: 0.2585\n",
      "Epoch 5, 100% \t Train loss: 0.2567 took: 2.46s  Val. loss: 0.2582\n",
      "Epoch 6, 100% \t Train loss: 0.2568 took: 2.45s  Val. loss: 0.2573\n",
      "Epoch 7, 100% \t Train loss: 0.2568 took: 2.46s  Val. loss: 0.2564\n",
      "Epoch 8, 100% \t Train loss: 0.2567 took: 2.44s  Val. loss: 0.2571\n",
      "Epoch 9, 100% \t Train loss: 0.2567 took: 2.44s  Val. loss: 0.2562\n",
      "Epoch 10, 100% \t Train loss: 0.2567 took: 2.49s  Val. loss: 0.2576\n",
      "Epoch 11, 100% \t Train loss: 0.2568 took: 2.46s  Val. loss: 0.2570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, 100% \t Train loss: 0.2567 took: 2.47s  Val. loss: 0.2560\n",
      "Epoch 13, 100% \t Train loss: 0.2567 took: 2.47s  Val. loss: 0.2563\n",
      "Epoch 14, 100% \t Train loss: 0.2568 took: 2.48s  Val. loss: 0.2566\n",
      "Epoch 15, 100% \t Train loss: 0.2568 took: 2.49s  Val. loss: 0.2572\n",
      "Epoch 16, 100% \t Train loss: 0.2567 took: 2.47s  Val. loss: 0.2578\n",
      "Epoch 17, 100% \t Train loss: 0.2567 took: 2.47s  Val. loss: 0.2584\n",
      "Epoch 18, 100% \t Train loss: 0.2567 took: 2.47s  Val. loss: 0.2584\n",
      "Epoch 19, 100% \t Train loss: 0.2567 took: 2.50s  Val. loss: 0.2578\n",
      "Epoch 20, 100% \t Train loss: 0.2567 took: 2.55s  Val. loss: 0.2570\n",
      "Epoch 21, 100% \t Train loss: 0.2567 took: 2.56s  Val. loss: 0.2572\n",
      "Epoch 22, 100% \t Train loss: 0.2567 took: 2.59s  Val. loss: 0.2575\n",
      "Epoch 23, 100% \t Train loss: 0.2568 took: 2.74s  Val. loss: 0.2567\n",
      "Epoch 24, 100% \t Train loss: 0.2567 took: 2.83s  Val. loss: 0.2576\n",
      "Epoch 25, 100% \t Train loss: 0.2567 took: 2.93s  Val. loss: 0.2573\n",
      "Epoch 26, 100% \t Train loss: 0.2568 took: 2.90s  Val. loss: 0.2573\n",
      "Epoch 27, 100% \t Train loss: 0.2567 took: 3.10s  Val. loss: 0.2578\n",
      "Epoch 28, 100% \t Train loss: 0.2567 took: 3.09s  Val. loss: 0.2570\n",
      "Epoch 29, 100% \t Train loss: 0.2567 took: 3.15s  Val. loss: 0.2579\n",
      "Epoch 30, 100% \t Train loss: 0.2567 took: 3.17s  Val. loss: 0.2566\n",
      "Epoch 31, 100% \t Train loss: 0.2567 took: 3.16s  Val. loss: 0.2575\n",
      "Epoch 32, 100% \t Train loss: 0.2567 took: 3.44s  Val. loss: 0.2576\n",
      "Epoch 33, 100% \t Train loss: 0.2567 took: 3.87s  Val. loss: 0.2569\n",
      "Epoch 34, 100% \t Train loss: 0.2567 took: 4.16s  Val. loss: 0.2569\n",
      "Epoch 35, 100% \t Train loss: 0.2567 took: 4.07s  Val. loss: 0.2568\n",
      "Epoch 36, 100% \t Train loss: 0.2567 took: 4.14s  Val. loss: 0.2578\n",
      "Epoch 37, 100% \t Train loss: 0.2567 took: 4.07s  Val. loss: 0.2569\n",
      "Epoch 38, 100% \t Train loss: 0.2567 took: 3.98s  Val. loss: 0.2562\n",
      "Epoch 39, 100% \t Train loss: 0.2567 took: 4.03s  Val. loss: 0.2568\n",
      "Epoch 40, 100% \t Train loss: 0.2567 took: 3.97s  Val. loss: 0.2573\n",
      "Epoch 41, 100% \t Train loss: 0.2567 took: 4.10s  Val. loss: 0.2571\n",
      "Epoch 42, 100% \t Train loss: 0.2567 took: 4.08s  Val. loss: 0.2575\n",
      "Epoch 43, 100% \t Train loss: 0.2567 took: 3.89s  Val. loss: 0.2573\n",
      "Epoch 44, 100% \t Train loss: 0.2567 took: 4.12s  Val. loss: 0.2573\n",
      "Epoch 45, 100% \t Train loss: 0.2567 took: 4.00s  Val. loss: 0.2568\n",
      "Epoch 46, 100% \t Train loss: 0.2567 took: 4.00s  Val. loss: 0.2575\n",
      "Epoch 47, 100% \t Train loss: 0.2567 took: 4.16s  Val. loss: 0.2575\n",
      "Epoch 48, 100% \t Train loss: 0.2567 took: 4.11s  Val. loss: 0.2567\n",
      "Epoch 49, 100% \t Train loss: 0.2566 took: 4.28s  Val. loss: 0.2573\n",
      "Epoch 50, 100% \t Train loss: 0.2567 took: 4.32s  Val. loss: 0.2579\n",
      "Training finished, took 175.96s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 1.53s  Val. loss: 0.2546\n",
      "Epoch 2, 100% \t Train loss: 0.2565 took: 1.49s  Val. loss: 0.2561\n",
      "Epoch 3, 100% \t Train loss: 0.2565 took: 1.49s  Val. loss: 0.2552\n",
      "Epoch 4, 100% \t Train loss: 0.2565 took: 1.73s  Val. loss: 0.2550\n",
      "Epoch 5, 100% \t Train loss: 0.2566 took: 2.46s  Val. loss: 0.2555\n",
      "Epoch 6, 100% \t Train loss: 0.2565 took: 2.47s  Val. loss: 0.2555\n",
      "Epoch 7, 100% \t Train loss: 0.2565 took: 2.49s  Val. loss: 0.2556\n",
      "Epoch 8, 100% \t Train loss: 0.2566 took: 2.46s  Val. loss: 0.2550\n",
      "Epoch 9, 100% \t Train loss: 0.2565 took: 2.48s  Val. loss: 0.2545\n",
      "Epoch 10, 100% \t Train loss: 0.2565 took: 2.46s  Val. loss: 0.2560\n",
      "Epoch 11, 100% \t Train loss: 0.2564 took: 2.45s  Val. loss: 0.2547\n",
      "Epoch 12, 100% \t Train loss: 0.2565 took: 2.46s  Val. loss: 0.2561\n",
      "Epoch 13, 100% \t Train loss: 0.2565 took: 2.46s  Val. loss: 0.2557\n",
      "Epoch 14, 100% \t Train loss: 0.2565 took: 2.46s  Val. loss: 0.2550\n",
      "Epoch 15, 100% \t Train loss: 0.2565 took: 2.46s  Val. loss: 0.2551\n",
      "Epoch 16, 100% \t Train loss: 0.2565 took: 2.47s  Val. loss: 0.2560\n",
      "Epoch 17, 100% \t Train loss: 0.2564 took: 2.46s  Val. loss: 0.2560\n",
      "Epoch 18, 100% \t Train loss: 0.2565 took: 2.47s  Val. loss: 0.2556\n",
      "Epoch 19, 100% \t Train loss: 0.2564 took: 2.47s  Val. loss: 0.2564\n",
      "Epoch 20, 100% \t Train loss: 0.2564 took: 2.47s  Val. loss: 0.2560\n",
      "Epoch 21, 100% \t Train loss: 0.2564 took: 2.47s  Val. loss: 0.2559\n",
      "Epoch 22, 100% \t Train loss: 0.2564 took: 2.46s  Val. loss: 0.2555\n",
      "Epoch 23, 100% \t Train loss: 0.2564 took: 2.49s  Val. loss: 0.2553\n",
      "Epoch 24, 100% \t Train loss: 0.2564 took: 2.55s  Val. loss: 0.2563\n",
      "Epoch 25, 100% \t Train loss: 0.2564 took: 2.51s  Val. loss: 0.2558\n",
      "Epoch 26, 100% \t Train loss: 0.2565 took: 2.54s  Val. loss: 0.2556\n",
      "Epoch 27, 100% \t Train loss: 0.2564 took: 2.64s  Val. loss: 0.2549\n",
      "Epoch 28, 100% \t Train loss: 0.2564 took: 2.66s  Val. loss: 0.2547\n",
      "Epoch 29, 100% \t Train loss: 0.2564 took: 2.72s  Val. loss: 0.2554\n",
      "Epoch 30, 100% \t Train loss: 0.2564 took: 2.79s  Val. loss: 0.2549\n",
      "Epoch 31, 100% \t Train loss: 0.2564 took: 2.83s  Val. loss: 0.2559\n",
      "Epoch 32, 100% \t Train loss: 0.2564 took: 2.90s  Val. loss: 0.2564\n",
      "Epoch 33, 100% \t Train loss: 0.2564 took: 3.10s  Val. loss: 0.2554\n",
      "Epoch 34, 100% \t Train loss: 0.2564 took: 3.03s  Val. loss: 0.2555\n",
      "Epoch 35, 100% \t Train loss: 0.2564 took: 2.94s  Val. loss: 0.2553\n",
      "Epoch 36, 100% \t Train loss: 0.2564 took: 2.94s  Val. loss: 0.2557\n",
      "Epoch 37, 100% \t Train loss: 0.2564 took: 2.95s  Val. loss: 0.2562\n",
      "Epoch 38, 100% \t Train loss: 0.2564 took: 2.99s  Val. loss: 0.2562\n",
      "Epoch 39, 100% \t Train loss: 0.2564 took: 3.10s  Val. loss: 0.2558\n",
      "Epoch 40, 100% \t Train loss: 0.2564 took: 3.11s  Val. loss: 0.2557\n",
      "Epoch 41, 100% \t Train loss: 0.2564 took: 3.24s  Val. loss: 0.2561\n",
      "Epoch 42, 100% \t Train loss: 0.2564 took: 3.53s  Val. loss: 0.2551\n",
      "Epoch 43, 100% \t Train loss: 0.2564 took: 3.67s  Val. loss: 0.2554\n",
      "Epoch 44, 100% \t Train loss: 0.2564 took: 3.95s  Val. loss: 0.2554\n",
      "Epoch 45, 100% \t Train loss: 0.2564 took: 3.71s  Val. loss: 0.2556\n",
      "Epoch 46, 100% \t Train loss: 0.2564 took: 3.99s  Val. loss: 0.2556\n",
      "Epoch 47, 100% \t Train loss: 0.2564 took: 3.76s  Val. loss: 0.2558\n",
      "Epoch 48, 100% \t Train loss: 0.2564 took: 3.54s  Val. loss: 0.2557\n",
      "Epoch 49, 100% \t Train loss: 0.2564 took: 3.55s  Val. loss: 0.2553\n",
      "Epoch 50, 100% \t Train loss: 0.2564 took: 3.42s  Val. loss: 0.2550\n",
      "Training finished, took 151.62s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2566 took: 2.50s  Val. loss: 0.2578\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 2.49s  Val. loss: 0.2575\n",
      "Epoch 3, 100% \t Train loss: 0.2565 took: 2.49s  Val. loss: 0.2582\n",
      "Epoch 4, 100% \t Train loss: 0.2564 took: 2.47s  Val. loss: 0.2589\n",
      "Epoch 5, 100% \t Train loss: 0.2564 took: 2.48s  Val. loss: 0.2581\n",
      "Epoch 6, 100% \t Train loss: 0.2564 took: 2.49s  Val. loss: 0.2582\n",
      "Epoch 7, 100% \t Train loss: 0.2563 took: 2.48s  Val. loss: 0.2576\n",
      "Epoch 8, 100% \t Train loss: 0.2562 took: 2.46s  Val. loss: 0.2569\n",
      "Epoch 9, 100% \t Train loss: 0.2558 took: 2.49s  Val. loss: 0.2576\n",
      "Epoch 10, 100% \t Train loss: 0.2533 took: 2.48s  Val. loss: 0.2507\n",
      "Epoch 11, 100% \t Train loss: 0.2371 took: 2.49s  Val. loss: 0.2239\n",
      "Epoch 12, 100% \t Train loss: 0.1999 took: 2.47s  Val. loss: 0.1955\n",
      "Epoch 13, 100% \t Train loss: 0.1787 took: 2.50s  Val. loss: 0.1806\n",
      "Epoch 14, 100% \t Train loss: 0.1711 took: 2.53s  Val. loss: 0.1752\n",
      "Epoch 15, 100% \t Train loss: 0.1679 took: 2.49s  Val. loss: 0.1713\n",
      "Epoch 16, 100% \t Train loss: 0.1653 took: 2.46s  Val. loss: 0.1710\n",
      "Epoch 17, 100% \t Train loss: 0.1641 took: 2.46s  Val. loss: 0.1709\n",
      "Epoch 18, 100% \t Train loss: 0.1631 took: 2.47s  Val. loss: 0.1735\n",
      "Epoch 19, 100% \t Train loss: 0.1633 took: 2.46s  Val. loss: 0.1684\n",
      "Epoch 20, 100% \t Train loss: 0.1610 took: 2.50s  Val. loss: 0.1673\n",
      "Epoch 21, 100% \t Train loss: 0.1607 took: 2.47s  Val. loss: 0.1664\n",
      "Epoch 22, 100% \t Train loss: 0.1593 took: 2.47s  Val. loss: 0.1654\n",
      "Epoch 23, 100% \t Train loss: 0.1585 took: 2.50s  Val. loss: 0.1649\n",
      "Epoch 24, 100% \t Train loss: 0.1579 took: 2.48s  Val. loss: 0.1637\n",
      "Epoch 25, 100% \t Train loss: 0.1575 took: 2.47s  Val. loss: 0.1614\n",
      "Epoch 26, 100% \t Train loss: 0.1576 took: 2.47s  Val. loss: 0.1630\n",
      "Epoch 27, 100% \t Train loss: 0.1560 took: 1.50s  Val. loss: 0.1633\n",
      "Epoch 28, 100% \t Train loss: 0.1557 took: 1.51s  Val. loss: 0.1623\n",
      "Epoch 29, 100% \t Train loss: 0.1554 took: 1.54s  Val. loss: 0.1609\n",
      "Epoch 30, 100% \t Train loss: 0.1548 took: 1.54s  Val. loss: 0.1616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, 100% \t Train loss: 0.1542 took: 1.58s  Val. loss: 0.1610\n",
      "Epoch 32, 100% \t Train loss: 0.1540 took: 1.59s  Val. loss: 0.1607\n",
      "Epoch 33, 100% \t Train loss: 0.1537 took: 1.61s  Val. loss: 0.1584\n",
      "Epoch 34, 100% \t Train loss: 0.1532 took: 1.63s  Val. loss: 0.1608\n",
      "Epoch 35, 100% \t Train loss: 0.1534 took: 1.65s  Val. loss: 0.1595\n",
      "Epoch 36, 100% \t Train loss: 0.1531 took: 1.68s  Val. loss: 0.1589\n",
      "Epoch 37, 100% \t Train loss: 0.1528 took: 1.69s  Val. loss: 0.1582\n",
      "Epoch 38, 100% \t Train loss: 0.1527 took: 1.70s  Val. loss: 0.1579\n",
      "Epoch 39, 100% \t Train loss: 0.1532 took: 1.73s  Val. loss: 0.1587\n",
      "Epoch 40, 100% \t Train loss: 0.1523 took: 1.77s  Val. loss: 0.1581\n",
      "Epoch 41, 100% \t Train loss: 0.1530 took: 1.87s  Val. loss: 0.1598\n",
      "Epoch 42, 100% \t Train loss: 0.1524 took: 1.99s  Val. loss: 0.1597\n",
      "Epoch 43, 100% \t Train loss: 0.1521 took: 2.04s  Val. loss: 0.1582\n",
      "Epoch 44, 100% \t Train loss: 0.1518 took: 2.10s  Val. loss: 0.1607\n",
      "Epoch 45, 100% \t Train loss: 0.1522 took: 2.11s  Val. loss: 0.1579\n",
      "Epoch 46, 100% \t Train loss: 0.1512 took: 2.10s  Val. loss: 0.1582\n",
      "Epoch 47, 100% \t Train loss: 0.1518 took: 2.08s  Val. loss: 0.1585\n",
      "Epoch 48, 100% \t Train loss: 0.1518 took: 2.09s  Val. loss: 0.1605\n",
      "Epoch 49, 100% \t Train loss: 0.1517 took: 2.07s  Val. loss: 0.1601\n",
      "Epoch 50, 100% \t Train loss: 0.1510 took: 3.00s  Val. loss: 0.1587\n",
      "Training finished, took 120.03s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.36\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.742769\n",
      "lambda: 0.0010 - V: 0.744456\n",
      "lambda: 0.0005 - V: 0.816270\n",
      "Average V: 0.767832\n",
      "Time elapsed: 450.95 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2575 took: 1.91s  Val. loss: 0.2647\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 1.90s  Val. loss: 0.2646\n",
      "Epoch 3, 100% \t Train loss: 0.2563 took: 1.90s  Val. loss: 0.2649\n",
      "Epoch 4, 100% \t Train loss: 0.2561 took: 1.89s  Val. loss: 0.2642\n",
      "Epoch 5, 100% \t Train loss: 0.2467 took: 1.90s  Val. loss: 0.2357\n",
      "Epoch 6, 100% \t Train loss: 0.1971 took: 1.91s  Val. loss: 0.1828\n",
      "Epoch 7, 100% \t Train loss: 0.1742 took: 1.88s  Val. loss: 0.1749\n",
      "Epoch 8, 100% \t Train loss: 0.1691 took: 1.89s  Val. loss: 0.1660\n",
      "Epoch 9, 100% \t Train loss: 0.1643 took: 1.90s  Val. loss: 0.1648\n",
      "Epoch 10, 100% \t Train loss: 0.1619 took: 1.84s  Val. loss: 0.1628\n",
      "Epoch 11, 100% \t Train loss: 0.1591 took: 1.90s  Val. loss: 0.1579\n",
      "Epoch 12, 100% \t Train loss: 0.1577 took: 1.89s  Val. loss: 0.1617\n",
      "Epoch 13, 100% \t Train loss: 0.1576 took: 1.91s  Val. loss: 0.1615\n",
      "Epoch 14, 100% \t Train loss: 0.1562 took: 1.91s  Val. loss: 0.1613\n",
      "Epoch 15, 100% \t Train loss: 0.1558 took: 1.89s  Val. loss: 0.1575\n",
      "Epoch 16, 100% \t Train loss: 0.1522 took: 1.89s  Val. loss: 0.1532\n",
      "Epoch 17, 100% \t Train loss: 0.1450 took: 1.91s  Val. loss: 0.1484\n",
      "Epoch 18, 100% \t Train loss: 0.1301 took: 1.87s  Val. loss: 0.1266\n",
      "Epoch 19, 100% \t Train loss: 0.1184 took: 1.88s  Val. loss: 0.1123\n",
      "Epoch 20, 100% \t Train loss: 0.1081 took: 1.90s  Val. loss: 0.1113\n",
      "Epoch 21, 100% \t Train loss: 0.1017 took: 1.91s  Val. loss: 0.1075\n",
      "Epoch 22, 100% \t Train loss: 0.0981 took: 1.90s  Val. loss: 0.1030\n",
      "Epoch 23, 100% \t Train loss: 0.0953 took: 1.89s  Val. loss: 0.1000\n",
      "Epoch 24, 100% \t Train loss: 0.0934 took: 1.90s  Val. loss: 0.0958\n",
      "Epoch 25, 100% \t Train loss: 0.0909 took: 1.91s  Val. loss: 0.0956\n",
      "Epoch 26, 100% \t Train loss: 0.0894 took: 1.90s  Val. loss: 0.0905\n",
      "Epoch 27, 100% \t Train loss: 0.0879 took: 1.90s  Val. loss: 0.0886\n",
      "Epoch 28, 100% \t Train loss: 0.0860 took: 1.90s  Val. loss: 0.0890\n",
      "Epoch 29, 100% \t Train loss: 0.0847 took: 1.89s  Val. loss: 0.0912\n",
      "Epoch 30, 100% \t Train loss: 0.0839 took: 1.90s  Val. loss: 0.0875\n",
      "Epoch 31, 100% \t Train loss: 0.0826 took: 1.88s  Val. loss: 0.0932\n",
      "Epoch 32, 100% \t Train loss: 0.0826 took: 1.90s  Val. loss: 0.0939\n",
      "Epoch 33, 100% \t Train loss: 0.0812 took: 1.93s  Val. loss: 0.0856\n",
      "Epoch 34, 100% \t Train loss: 0.0805 took: 1.92s  Val. loss: 0.0924\n",
      "Epoch 35, 100% \t Train loss: 0.0798 took: 1.93s  Val. loss: 0.0851\n",
      "Epoch 36, 100% \t Train loss: 0.0796 took: 1.95s  Val. loss: 0.0854\n",
      "Epoch 37, 100% \t Train loss: 0.0796 took: 1.93s  Val. loss: 0.0890\n",
      "Epoch 38, 100% \t Train loss: 0.0785 took: 1.93s  Val. loss: 0.0879\n",
      "Epoch 39, 100% \t Train loss: 0.0791 took: 1.95s  Val. loss: 0.0867\n",
      "Epoch 40, 100% \t Train loss: 0.0783 took: 1.95s  Val. loss: 0.0849\n",
      "Epoch 41, 100% \t Train loss: 0.0768 took: 1.95s  Val. loss: 0.0861\n",
      "Epoch 42, 100% \t Train loss: 0.0769 took: 1.95s  Val. loss: 0.0872\n",
      "Epoch 43, 100% \t Train loss: 0.0769 took: 1.97s  Val. loss: 0.0899\n",
      "Epoch 44, 100% \t Train loss: 0.0776 took: 1.93s  Val. loss: 0.0874\n",
      "Epoch 45, 100% \t Train loss: 0.0762 took: 1.95s  Val. loss: 0.0899\n",
      "Epoch 46, 100% \t Train loss: 0.0753 took: 1.94s  Val. loss: 0.0876\n",
      "Epoch 47, 100% \t Train loss: 0.0755 took: 1.93s  Val. loss: 0.0896\n",
      "Epoch 48, 100% \t Train loss: 0.0765 took: 1.93s  Val. loss: 0.0864\n",
      "Epoch 49, 100% \t Train loss: 0.0740 took: 1.93s  Val. loss: 0.0871\n",
      "Epoch 50, 100% \t Train loss: 0.0744 took: 1.94s  Val. loss: 0.0874\n",
      "Training finished, took 108.29s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2563 took: 1.90s  Val. loss: 0.2596\n",
      "Epoch 2, 100% \t Train loss: 0.2501 took: 1.88s  Val. loss: 0.2361\n",
      "Epoch 3, 100% \t Train loss: 0.1963 took: 1.90s  Val. loss: 0.1788\n",
      "Epoch 4, 100% \t Train loss: 0.1711 took: 1.90s  Val. loss: 0.1727\n",
      "Epoch 5, 100% \t Train loss: 0.1664 took: 1.89s  Val. loss: 0.1633\n",
      "Epoch 6, 100% \t Train loss: 0.1642 took: 1.89s  Val. loss: 0.1675\n",
      "Epoch 7, 100% \t Train loss: 0.1604 took: 1.88s  Val. loss: 0.1627\n",
      "Epoch 8, 100% \t Train loss: 0.1586 took: 1.88s  Val. loss: 0.1662\n",
      "Epoch 9, 100% \t Train loss: 0.1579 took: 1.89s  Val. loss: 0.1575\n",
      "Epoch 10, 100% \t Train loss: 0.1550 took: 1.87s  Val. loss: 0.1591\n",
      "Epoch 11, 100% \t Train loss: 0.1559 took: 1.90s  Val. loss: 0.1565\n",
      "Epoch 12, 100% \t Train loss: 0.1521 took: 1.87s  Val. loss: 0.1587\n",
      "Epoch 13, 100% \t Train loss: 0.1517 took: 1.90s  Val. loss: 0.1576\n",
      "Epoch 14, 100% \t Train loss: 0.1504 took: 1.88s  Val. loss: 0.1592\n",
      "Epoch 15, 100% \t Train loss: 0.1501 took: 1.89s  Val. loss: 0.1576\n",
      "Epoch 16, 100% \t Train loss: 0.1491 took: 1.89s  Val. loss: 0.1540\n",
      "Epoch 17, 100% \t Train loss: 0.1483 took: 1.89s  Val. loss: 0.1562\n",
      "Epoch 18, 100% \t Train loss: 0.1480 took: 1.90s  Val. loss: 0.1583\n",
      "Epoch 19, 100% \t Train loss: 0.1475 took: 1.89s  Val. loss: 0.1540\n",
      "Epoch 20, 100% \t Train loss: 0.1477 took: 1.89s  Val. loss: 0.1524\n",
      "Epoch 21, 100% \t Train loss: 0.1469 took: 1.90s  Val. loss: 0.1549\n",
      "Epoch 22, 100% \t Train loss: 0.1478 took: 1.91s  Val. loss: 0.1536\n",
      "Epoch 23, 100% \t Train loss: 0.1459 took: 1.91s  Val. loss: 0.1520\n",
      "Epoch 24, 100% \t Train loss: 0.1447 took: 1.88s  Val. loss: 0.1543\n",
      "Epoch 25, 100% \t Train loss: 0.1457 took: 1.88s  Val. loss: 0.1560\n",
      "Epoch 26, 100% \t Train loss: 0.1459 took: 1.87s  Val. loss: 0.1527\n",
      "Epoch 27, 100% \t Train loss: 0.1445 took: 1.87s  Val. loss: 0.1550\n",
      "Epoch 28, 100% \t Train loss: 0.1451 took: 1.90s  Val. loss: 0.1530\n",
      "Epoch 29, 100% \t Train loss: 0.1440 took: 1.90s  Val. loss: 0.1514\n",
      "Epoch 30, 100% \t Train loss: 0.1434 took: 1.90s  Val. loss: 0.1530\n",
      "Epoch 31, 100% \t Train loss: 0.1428 took: 1.91s  Val. loss: 0.1521\n",
      "Epoch 32, 100% \t Train loss: 0.1430 took: 1.90s  Val. loss: 0.1548\n",
      "Epoch 33, 100% \t Train loss: 0.1422 took: 1.92s  Val. loss: 0.1504\n",
      "Epoch 34, 100% \t Train loss: 0.1419 took: 1.88s  Val. loss: 0.1531\n",
      "Epoch 35, 100% \t Train loss: 0.1414 took: 1.91s  Val. loss: 0.1509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, 100% \t Train loss: 0.1401 took: 1.90s  Val. loss: 0.1491\n",
      "Epoch 37, 100% \t Train loss: 0.1395 took: 1.91s  Val. loss: 0.1505\n",
      "Epoch 38, 100% \t Train loss: 0.1378 took: 1.91s  Val. loss: 0.1523\n",
      "Epoch 39, 100% \t Train loss: 0.1369 took: 1.93s  Val. loss: 0.1491\n",
      "Epoch 40, 100% \t Train loss: 0.1331 took: 1.90s  Val. loss: 0.1460\n",
      "Epoch 41, 100% \t Train loss: 0.1297 took: 1.91s  Val. loss: 0.1420\n",
      "Epoch 42, 100% \t Train loss: 0.1259 took: 1.94s  Val. loss: 0.1385\n",
      "Epoch 43, 100% \t Train loss: 0.1217 took: 1.92s  Val. loss: 0.1356\n",
      "Epoch 44, 100% \t Train loss: 0.1167 took: 1.92s  Val. loss: 0.1303\n",
      "Epoch 45, 100% \t Train loss: 0.1126 took: 1.92s  Val. loss: 0.1298\n",
      "Epoch 46, 100% \t Train loss: 0.1094 took: 1.91s  Val. loss: 0.1257\n",
      "Epoch 47, 100% \t Train loss: 0.1058 took: 1.94s  Val. loss: 0.1201\n",
      "Epoch 48, 100% \t Train loss: 0.1028 took: 1.93s  Val. loss: 0.1182\n",
      "Epoch 49, 100% \t Train loss: 0.0995 took: 1.93s  Val. loss: 0.1132\n",
      "Epoch 50, 100% \t Train loss: 0.0979 took: 1.94s  Val. loss: 0.1118\n",
      "Training finished, took 107.76s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2600 took: 1.91s  Val. loss: 0.2560\n",
      "Epoch 2, 100% \t Train loss: 0.2595 took: 1.88s  Val. loss: 0.2540\n",
      "Epoch 3, 100% \t Train loss: 0.2591 took: 1.89s  Val. loss: 0.2548\n",
      "Epoch 4, 100% \t Train loss: 0.2565 took: 1.89s  Val. loss: 0.2467\n",
      "Epoch 5, 100% \t Train loss: 0.2375 took: 1.09s  Val. loss: 0.2089\n",
      "Epoch 6, 100% \t Train loss: 0.2006 took: 1.10s  Val. loss: 0.1784\n",
      "Epoch 7, 100% \t Train loss: 0.1806 took: 1.11s  Val. loss: 0.1681\n",
      "Epoch 8, 100% \t Train loss: 0.1741 took: 1.10s  Val. loss: 0.1628\n",
      "Epoch 9, 100% \t Train loss: 0.1713 took: 1.11s  Val. loss: 0.1653\n",
      "Epoch 10, 100% \t Train loss: 0.1694 took: 1.11s  Val. loss: 0.1593\n",
      "Epoch 11, 100% \t Train loss: 0.1667 took: 1.11s  Val. loss: 0.1620\n",
      "Epoch 12, 100% \t Train loss: 0.1695 took: 1.10s  Val. loss: 0.1533\n",
      "Epoch 13, 100% \t Train loss: 0.1643 took: 1.10s  Val. loss: 0.1529\n",
      "Epoch 14, 100% \t Train loss: 0.1621 took: 1.10s  Val. loss: 0.1530\n",
      "Epoch 15, 100% \t Train loss: 0.1635 took: 1.10s  Val. loss: 0.1534\n",
      "Epoch 16, 100% \t Train loss: 0.1597 took: 1.10s  Val. loss: 0.1504\n",
      "Epoch 17, 100% \t Train loss: 0.1582 took: 1.13s  Val. loss: 0.1498\n",
      "Epoch 18, 100% \t Train loss: 0.1593 took: 1.87s  Val. loss: 0.1491\n",
      "Epoch 19, 100% \t Train loss: 0.1573 took: 1.87s  Val. loss: 0.1486\n",
      "Epoch 20, 100% \t Train loss: 0.1565 took: 1.91s  Val. loss: 0.1473\n",
      "Epoch 21, 100% \t Train loss: 0.1573 took: 1.89s  Val. loss: 0.1498\n",
      "Epoch 22, 100% \t Train loss: 0.1569 took: 1.89s  Val. loss: 0.1465\n",
      "Epoch 23, 100% \t Train loss: 0.1555 took: 1.88s  Val. loss: 0.1445\n",
      "Epoch 24, 100% \t Train loss: 0.1553 took: 1.10s  Val. loss: 0.1494\n",
      "Epoch 25, 100% \t Train loss: 0.1560 took: 1.11s  Val. loss: 0.1467\n",
      "Epoch 26, 100% \t Train loss: 0.1558 took: 1.10s  Val. loss: 0.1457\n",
      "Epoch 27, 100% \t Train loss: 0.1536 took: 1.11s  Val. loss: 0.1451\n",
      "Epoch 28, 100% \t Train loss: 0.1537 took: 1.11s  Val. loss: 0.1499\n",
      "Epoch 29, 100% \t Train loss: 0.1546 took: 1.11s  Val. loss: 0.1466\n",
      "Epoch 30, 100% \t Train loss: 0.1522 took: 1.11s  Val. loss: 0.1451\n",
      "Epoch 31, 100% \t Train loss: 0.1528 took: 1.12s  Val. loss: 0.1448\n",
      "Epoch 32, 100% \t Train loss: 0.1521 took: 1.13s  Val. loss: 0.1450\n",
      "Epoch 33, 100% \t Train loss: 0.1509 took: 1.13s  Val. loss: 0.1445\n",
      "Epoch 34, 100% \t Train loss: 0.1499 took: 1.13s  Val. loss: 0.1426\n",
      "Epoch 35, 100% \t Train loss: 0.1498 took: 1.13s  Val. loss: 0.1453\n",
      "Epoch 36, 100% \t Train loss: 0.1494 took: 1.13s  Val. loss: 0.1425\n",
      "Epoch 37, 100% \t Train loss: 0.1475 took: 1.13s  Val. loss: 0.1425\n",
      "Epoch 38, 100% \t Train loss: 0.1471 took: 1.14s  Val. loss: 0.1439\n",
      "Epoch 39, 100% \t Train loss: 0.1453 took: 1.18s  Val. loss: 0.1381\n",
      "Epoch 40, 100% \t Train loss: 0.1445 took: 1.14s  Val. loss: 0.1397\n",
      "Epoch 41, 100% \t Train loss: 0.1432 took: 1.14s  Val. loss: 0.1368\n",
      "Epoch 42, 100% \t Train loss: 0.1420 took: 1.14s  Val. loss: 0.1360\n",
      "Epoch 43, 100% \t Train loss: 0.1394 took: 1.14s  Val. loss: 0.1331\n",
      "Epoch 44, 100% \t Train loss: 0.1385 took: 1.14s  Val. loss: 0.1320\n",
      "Epoch 45, 100% \t Train loss: 0.1371 took: 1.14s  Val. loss: 0.1304\n",
      "Epoch 46, 100% \t Train loss: 0.1349 took: 1.15s  Val. loss: 0.1296\n",
      "Epoch 47, 100% \t Train loss: 0.1328 took: 1.17s  Val. loss: 0.1292\n",
      "Epoch 48, 100% \t Train loss: 0.1320 took: 1.19s  Val. loss: 0.1302\n",
      "Epoch 49, 100% \t Train loss: 0.1312 took: 1.20s  Val. loss: 0.1279\n",
      "Epoch 50, 100% \t Train loss: 0.1284 took: 1.21s  Val. loss: 0.1250\n",
      "Training finished, took 72.44s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.873837\n",
      "lambda: 0.0010 - V: 0.846053\n",
      "lambda: 0.0005 - V: 0.844353\n",
      "Average V: 0.854747\n",
      "Time elapsed: 291.81 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2571 took: 1.50s  Val. loss: 0.2641\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 1.50s  Val. loss: 0.2600\n",
      "Epoch 3, 100% \t Train loss: 0.2565 took: 1.50s  Val. loss: 0.2602\n",
      "Epoch 4, 100% \t Train loss: 0.2565 took: 1.50s  Val. loss: 0.2594\n",
      "Epoch 5, 100% \t Train loss: 0.2564 took: 1.50s  Val. loss: 0.2594\n",
      "Epoch 6, 100% \t Train loss: 0.2564 took: 1.49s  Val. loss: 0.2591\n",
      "Epoch 7, 100% \t Train loss: 0.2566 took: 1.51s  Val. loss: 0.2605\n",
      "Epoch 8, 100% \t Train loss: 0.2565 took: 1.50s  Val. loss: 0.2587\n",
      "Epoch 9, 100% \t Train loss: 0.2564 took: 1.51s  Val. loss: 0.2590\n",
      "Epoch 10, 100% \t Train loss: 0.2565 took: 1.50s  Val. loss: 0.2587\n",
      "Epoch 11, 100% \t Train loss: 0.2565 took: 1.89s  Val. loss: 0.2592\n",
      "Epoch 12, 100% \t Train loss: 0.2564 took: 2.48s  Val. loss: 0.2600\n",
      "Epoch 13, 100% \t Train loss: 0.2564 took: 2.47s  Val. loss: 0.2602\n",
      "Epoch 14, 100% \t Train loss: 0.2564 took: 2.48s  Val. loss: 0.2590\n",
      "Epoch 15, 100% \t Train loss: 0.2563 took: 2.49s  Val. loss: 0.2598\n",
      "Epoch 16, 100% \t Train loss: 0.2564 took: 2.49s  Val. loss: 0.2608\n",
      "Epoch 17, 100% \t Train loss: 0.2564 took: 2.49s  Val. loss: 0.2593\n",
      "Epoch 18, 100% \t Train loss: 0.2564 took: 2.47s  Val. loss: 0.2589\n",
      "Epoch 19, 100% \t Train loss: 0.2565 took: 2.49s  Val. loss: 0.2585\n",
      "Epoch 20, 100% \t Train loss: 0.2564 took: 2.48s  Val. loss: 0.2598\n",
      "Epoch 21, 100% \t Train loss: 0.2564 took: 2.48s  Val. loss: 0.2589\n",
      "Epoch 22, 100% \t Train loss: 0.2563 took: 2.48s  Val. loss: 0.2612\n",
      "Epoch 23, 100% \t Train loss: 0.2564 took: 2.47s  Val. loss: 0.2596\n",
      "Epoch 24, 100% \t Train loss: 0.2563 took: 2.48s  Val. loss: 0.2597\n",
      "Epoch 25, 100% \t Train loss: 0.2563 took: 2.47s  Val. loss: 0.2595\n",
      "Epoch 26, 100% \t Train loss: 0.2564 took: 2.48s  Val. loss: 0.2588\n",
      "Epoch 27, 100% \t Train loss: 0.2564 took: 2.50s  Val. loss: 0.2596\n",
      "Epoch 28, 100% \t Train loss: 0.2563 took: 2.50s  Val. loss: 0.2606\n",
      "Epoch 29, 100% \t Train loss: 0.2563 took: 2.51s  Val. loss: 0.2578\n",
      "Epoch 30, 100% \t Train loss: 0.2564 took: 2.54s  Val. loss: 0.2604\n",
      "Epoch 31, 100% \t Train loss: 0.2563 took: 2.58s  Val. loss: 0.2600\n",
      "Epoch 32, 100% \t Train loss: 0.2563 took: 2.77s  Val. loss: 0.2599\n",
      "Epoch 33, 100% \t Train loss: 0.2564 took: 2.98s  Val. loss: 0.2596\n",
      "Epoch 34, 100% \t Train loss: 0.2563 took: 3.07s  Val. loss: 0.2591\n",
      "Epoch 35, 100% \t Train loss: 0.2563 took: 3.11s  Val. loss: 0.2593\n",
      "Epoch 36, 100% \t Train loss: 0.2563 took: 3.12s  Val. loss: 0.2592\n",
      "Epoch 37, 100% \t Train loss: 0.2563 took: 3.16s  Val. loss: 0.2597\n",
      "Epoch 38, 100% \t Train loss: 0.2563 took: 3.26s  Val. loss: 0.2597\n",
      "Epoch 39, 100% \t Train loss: 0.2563 took: 3.63s  Val. loss: 0.2599\n",
      "Epoch 40, 100% \t Train loss: 0.2563 took: 3.64s  Val. loss: 0.2588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, 100% \t Train loss: 0.2563 took: 3.67s  Val. loss: 0.2593\n",
      "Epoch 42, 100% \t Train loss: 0.2563 took: 3.50s  Val. loss: 0.2587\n",
      "Epoch 43, 100% \t Train loss: 0.2563 took: 3.67s  Val. loss: 0.2597\n",
      "Epoch 44, 100% \t Train loss: 0.2563 took: 2.64s  Val. loss: 0.2604\n",
      "Epoch 45, 100% \t Train loss: 0.2564 took: 2.90s  Val. loss: 0.2594\n",
      "Epoch 46, 100% \t Train loss: 0.2563 took: 3.79s  Val. loss: 0.2591\n",
      "Epoch 47, 100% \t Train loss: 0.2563 took: 3.75s  Val. loss: 0.2586\n",
      "Epoch 48, 100% \t Train loss: 0.2563 took: 3.73s  Val. loss: 0.2592\n",
      "Epoch 49, 100% \t Train loss: 0.2563 took: 3.74s  Val. loss: 0.2601\n",
      "Epoch 50, 100% \t Train loss: 0.2563 took: 3.73s  Val. loss: 0.2597\n",
      "Training finished, took 145.50s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2602 took: 2.47s  Val. loss: 0.2628\n",
      "Epoch 2, 100% \t Train loss: 0.2603 took: 2.48s  Val. loss: 0.2615\n",
      "Epoch 3, 100% \t Train loss: 0.2601 took: 2.48s  Val. loss: 0.2613\n",
      "Epoch 4, 100% \t Train loss: 0.2603 took: 2.46s  Val. loss: 0.2619\n",
      "Epoch 5, 100% \t Train loss: 0.2601 took: 2.48s  Val. loss: 0.2606\n",
      "Epoch 6, 100% \t Train loss: 0.2601 took: 2.46s  Val. loss: 0.2618\n",
      "Epoch 7, 100% \t Train loss: 0.2601 took: 2.45s  Val. loss: 0.2626\n",
      "Epoch 8, 100% \t Train loss: 0.2600 took: 2.46s  Val. loss: 0.2615\n",
      "Epoch 9, 100% \t Train loss: 0.2601 took: 2.46s  Val. loss: 0.2612\n",
      "Epoch 10, 100% \t Train loss: 0.2601 took: 2.46s  Val. loss: 0.2620\n",
      "Epoch 11, 100% \t Train loss: 0.2601 took: 2.45s  Val. loss: 0.2610\n",
      "Epoch 12, 100% \t Train loss: 0.2601 took: 2.45s  Val. loss: 0.2621\n",
      "Epoch 13, 100% \t Train loss: 0.2601 took: 2.46s  Val. loss: 0.2624\n",
      "Epoch 14, 100% \t Train loss: 0.2601 took: 2.47s  Val. loss: 0.2620\n",
      "Epoch 15, 100% \t Train loss: 0.2601 took: 2.46s  Val. loss: 0.2618\n",
      "Epoch 16, 100% \t Train loss: 0.2602 took: 2.46s  Val. loss: 0.2625\n",
      "Epoch 17, 100% \t Train loss: 0.2601 took: 2.46s  Val. loss: 0.2614\n",
      "Epoch 18, 100% \t Train loss: 0.2601 took: 2.47s  Val. loss: 0.2620\n",
      "Epoch 19, 100% \t Train loss: 0.2601 took: 2.48s  Val. loss: 0.2606\n",
      "Epoch 20, 100% \t Train loss: 0.2601 took: 2.48s  Val. loss: 0.2615\n",
      "Epoch 21, 100% \t Train loss: 0.2601 took: 2.48s  Val. loss: 0.2610\n",
      "Epoch 22, 100% \t Train loss: 0.2601 took: 2.38s  Val. loss: 0.2627\n",
      "Epoch 23, 100% \t Train loss: 0.2601 took: 2.46s  Val. loss: 0.2616\n",
      "Epoch 24, 100% \t Train loss: 0.2601 took: 1.50s  Val. loss: 0.2616\n",
      "Epoch 25, 100% \t Train loss: 0.2601 took: 1.50s  Val. loss: 0.2621\n",
      "Epoch 26, 100% \t Train loss: 0.2601 took: 1.50s  Val. loss: 0.2620\n",
      "Epoch 27, 100% \t Train loss: 0.2601 took: 1.52s  Val. loss: 0.2618\n",
      "Epoch 28, 100% \t Train loss: 0.2601 took: 1.54s  Val. loss: 0.2610\n",
      "Epoch 29, 100% \t Train loss: 0.2601 took: 1.56s  Val. loss: 0.2618\n",
      "Epoch 30, 100% \t Train loss: 0.2601 took: 1.56s  Val. loss: 0.2622\n",
      "Epoch 31, 100% \t Train loss: 0.2601 took: 1.58s  Val. loss: 0.2620\n",
      "Epoch 32, 100% \t Train loss: 0.2601 took: 2.25s  Val. loss: 0.2611\n",
      "Epoch 33, 100% \t Train loss: 0.2600 took: 2.60s  Val. loss: 0.2609\n",
      "Epoch 34, 100% \t Train loss: 0.2601 took: 2.63s  Val. loss: 0.2618\n",
      "Epoch 35, 100% \t Train loss: 0.2601 took: 2.69s  Val. loss: 0.2608\n",
      "Epoch 36, 100% \t Train loss: 0.2601 took: 2.72s  Val. loss: 0.2611\n",
      "Epoch 37, 100% \t Train loss: 0.2600 took: 2.72s  Val. loss: 0.2621\n",
      "Epoch 38, 100% \t Train loss: 0.2601 took: 2.73s  Val. loss: 0.2614\n",
      "Epoch 39, 100% \t Train loss: 0.2600 took: 2.72s  Val. loss: 0.2617\n",
      "Epoch 40, 100% \t Train loss: 0.2601 took: 2.69s  Val. loss: 0.2622\n",
      "Epoch 41, 100% \t Train loss: 0.2601 took: 2.69s  Val. loss: 0.2609\n",
      "Epoch 42, 100% \t Train loss: 0.2600 took: 2.70s  Val. loss: 0.2624\n",
      "Epoch 43, 100% \t Train loss: 0.2601 took: 1.71s  Val. loss: 0.2611\n",
      "Epoch 44, 100% \t Train loss: 0.2601 took: 1.61s  Val. loss: 0.2622\n",
      "Epoch 45, 100% \t Train loss: 0.2601 took: 1.63s  Val. loss: 0.2615\n",
      "Epoch 46, 100% \t Train loss: 0.2600 took: 1.56s  Val. loss: 0.2626\n",
      "Epoch 47, 100% \t Train loss: 0.2600 took: 2.62s  Val. loss: 0.2618\n",
      "Epoch 48, 100% \t Train loss: 0.2600 took: 2.59s  Val. loss: 0.2611\n",
      "Epoch 49, 100% \t Train loss: 0.2601 took: 2.57s  Val. loss: 0.2617\n",
      "Epoch 50, 100% \t Train loss: 0.2601 took: 2.64s  Val. loss: 0.2617\n",
      "Training finished, took 127.03s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2595 took: 2.47s  Val. loss: 0.2577\n",
      "Epoch 2, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2569\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2565\n",
      "Epoch 4, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2579\n",
      "Epoch 5, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2572\n",
      "Epoch 6, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2570\n",
      "Epoch 7, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2577\n",
      "Epoch 8, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2567\n",
      "Epoch 9, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2577\n",
      "Epoch 10, 100% \t Train loss: 0.2590 took: 1.50s  Val. loss: 0.2557\n",
      "Epoch 11, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2575\n",
      "Epoch 12, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2579\n",
      "Epoch 13, 100% \t Train loss: 0.2590 took: 1.50s  Val. loss: 0.2570\n",
      "Epoch 14, 100% \t Train loss: 0.2590 took: 1.50s  Val. loss: 0.2568\n",
      "Epoch 15, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2559\n",
      "Epoch 16, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2575\n",
      "Epoch 17, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2572\n",
      "Epoch 18, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2571\n",
      "Epoch 19, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2569\n",
      "Epoch 20, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2562\n",
      "Epoch 21, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2567\n",
      "Epoch 22, 100% \t Train loss: 0.2589 took: 1.51s  Val. loss: 0.2564\n",
      "Epoch 23, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2569\n",
      "Epoch 24, 100% \t Train loss: 0.2589 took: 1.50s  Val. loss: 0.2574\n",
      "Epoch 25, 100% \t Train loss: 0.2589 took: 1.85s  Val. loss: 0.2567\n",
      "Epoch 26, 100% \t Train loss: 0.2589 took: 2.46s  Val. loss: 0.2562\n",
      "Epoch 27, 100% \t Train loss: 0.2589 took: 2.50s  Val. loss: 0.2581\n",
      "Epoch 28, 100% \t Train loss: 0.2589 took: 2.50s  Val. loss: 0.2568\n",
      "Epoch 29, 100% \t Train loss: 0.2589 took: 2.52s  Val. loss: 0.2572\n",
      "Epoch 30, 100% \t Train loss: 0.2589 took: 2.52s  Val. loss: 0.2574\n",
      "Epoch 31, 100% \t Train loss: 0.2589 took: 2.56s  Val. loss: 0.2570\n",
      "Epoch 32, 100% \t Train loss: 0.2589 took: 2.59s  Val. loss: 0.2562\n",
      "Epoch 33, 100% \t Train loss: 0.2589 took: 2.61s  Val. loss: 0.2575\n",
      "Epoch 34, 100% \t Train loss: 0.2589 took: 2.61s  Val. loss: 0.2551\n",
      "Epoch 35, 100% \t Train loss: 0.2589 took: 2.63s  Val. loss: 0.2570\n",
      "Epoch 36, 100% \t Train loss: 0.2589 took: 2.60s  Val. loss: 0.2566\n",
      "Epoch 37, 100% \t Train loss: 0.2589 took: 2.61s  Val. loss: 0.2562\n",
      "Epoch 38, 100% \t Train loss: 0.2589 took: 2.60s  Val. loss: 0.2566\n",
      "Epoch 39, 100% \t Train loss: 0.2589 took: 2.59s  Val. loss: 0.2574\n",
      "Epoch 40, 100% \t Train loss: 0.2589 took: 2.60s  Val. loss: 0.2581\n",
      "Epoch 41, 100% \t Train loss: 0.2589 took: 2.61s  Val. loss: 0.2563\n",
      "Epoch 42, 100% \t Train loss: 0.2589 took: 2.60s  Val. loss: 0.2573\n",
      "Epoch 43, 100% \t Train loss: 0.2589 took: 2.65s  Val. loss: 0.2556\n",
      "Epoch 44, 100% \t Train loss: 0.2589 took: 2.66s  Val. loss: 0.2570\n",
      "Epoch 45, 100% \t Train loss: 0.2589 took: 2.67s  Val. loss: 0.2567\n",
      "Epoch 46, 100% \t Train loss: 0.2589 took: 2.67s  Val. loss: 0.2565\n",
      "Epoch 47, 100% \t Train loss: 0.2589 took: 2.64s  Val. loss: 0.2568\n",
      "Epoch 48, 100% \t Train loss: 0.2589 took: 2.68s  Val. loss: 0.2560\n",
      "Epoch 49, 100% \t Train loss: 0.2589 took: 2.72s  Val. loss: 0.2559\n",
      "Epoch 50, 100% \t Train loss: 0.2589 took: 2.78s  Val. loss: 0.2567\n",
      "Training finished, took 114.86s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.740399\n",
      "lambda: 0.0010 - V: 0.738312\n",
      "lambda: 0.0005 - V: 0.743124\n",
      "Average V: 0.740612\n",
      "Time elapsed: 390.86 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2562 took: 1.89s  Val. loss: 0.2586\n",
      "Epoch 2, 100% \t Train loss: 0.2548 took: 1.90s  Val. loss: 0.2585\n",
      "Epoch 3, 100% \t Train loss: 0.2547 took: 1.90s  Val. loss: 0.2589\n",
      "Epoch 4, 100% \t Train loss: 0.2546 took: 1.89s  Val. loss: 0.2598\n",
      "Epoch 5, 100% \t Train loss: 0.2544 took: 1.89s  Val. loss: 0.2596\n",
      "Epoch 6, 100% \t Train loss: 0.2546 took: 1.90s  Val. loss: 0.2588\n",
      "Epoch 7, 100% \t Train loss: 0.2544 took: 1.89s  Val. loss: 0.2583\n",
      "Epoch 8, 100% \t Train loss: 0.2544 took: 1.90s  Val. loss: 0.2586\n",
      "Epoch 9, 100% \t Train loss: 0.2544 took: 1.88s  Val. loss: 0.2585\n",
      "Epoch 10, 100% \t Train loss: 0.2541 took: 1.88s  Val. loss: 0.2593\n",
      "Epoch 11, 100% \t Train loss: 0.2334 took: 1.88s  Val. loss: 0.2113\n",
      "Epoch 12, 100% \t Train loss: 0.2018 took: 1.90s  Val. loss: 0.2026\n",
      "Epoch 13, 100% \t Train loss: 0.1973 took: 1.88s  Val. loss: 0.2008\n",
      "Epoch 14, 100% \t Train loss: 0.1932 took: 1.87s  Val. loss: 0.1964\n",
      "Epoch 15, 100% \t Train loss: 0.1900 took: 1.90s  Val. loss: 0.1916\n",
      "Epoch 16, 100% \t Train loss: 0.1879 took: 1.88s  Val. loss: 0.1904\n",
      "Epoch 17, 100% \t Train loss: 0.1857 took: 1.87s  Val. loss: 0.1888\n",
      "Epoch 18, 100% \t Train loss: 0.1831 took: 1.87s  Val. loss: 0.1860\n",
      "Epoch 19, 100% \t Train loss: 0.1834 took: 1.89s  Val. loss: 0.1859\n",
      "Epoch 20, 100% \t Train loss: 0.1809 took: 1.88s  Val. loss: 0.1834\n",
      "Epoch 21, 100% \t Train loss: 0.1747 took: 1.87s  Val. loss: 0.1807\n",
      "Epoch 22, 100% \t Train loss: 0.1685 took: 1.88s  Val. loss: 0.1676\n",
      "Epoch 23, 100% \t Train loss: 0.1602 took: 1.08s  Val. loss: 0.1617\n",
      "Epoch 24, 100% \t Train loss: 0.1490 took: 1.08s  Val. loss: 0.1484\n",
      "Epoch 25, 100% \t Train loss: 0.1423 took: 1.08s  Val. loss: 0.1435\n",
      "Epoch 26, 100% \t Train loss: 0.1387 took: 1.08s  Val. loss: 0.1399\n",
      "Epoch 27, 100% \t Train loss: 0.1356 took: 1.08s  Val. loss: 0.1361\n",
      "Epoch 28, 100% \t Train loss: 0.1333 took: 1.08s  Val. loss: 0.1382\n",
      "Epoch 29, 100% \t Train loss: 0.1309 took: 1.08s  Val. loss: 0.1367\n",
      "Epoch 30, 100% \t Train loss: 0.1307 took: 1.09s  Val. loss: 0.1360\n",
      "Epoch 31, 100% \t Train loss: 0.1280 took: 1.10s  Val. loss: 0.1329\n",
      "Epoch 32, 100% \t Train loss: 0.1262 took: 1.12s  Val. loss: 0.1323\n",
      "Epoch 33, 100% \t Train loss: 0.1269 took: 1.16s  Val. loss: 0.1304\n",
      "Epoch 34, 100% \t Train loss: 0.1258 took: 1.22s  Val. loss: 0.1294\n",
      "Epoch 35, 100% \t Train loss: 0.1245 took: 1.23s  Val. loss: 0.1300\n",
      "Epoch 36, 100% \t Train loss: 0.1235 took: 1.22s  Val. loss: 0.1350\n",
      "Epoch 37, 100% \t Train loss: 0.1245 took: 1.22s  Val. loss: 0.1288\n",
      "Epoch 38, 100% \t Train loss: 0.1215 took: 1.22s  Val. loss: 0.1287\n",
      "Epoch 39, 100% \t Train loss: 0.1229 took: 1.22s  Val. loss: 0.1287\n",
      "Epoch 40, 100% \t Train loss: 0.1204 took: 1.22s  Val. loss: 0.1263\n",
      "Epoch 41, 100% \t Train loss: 0.1206 took: 1.23s  Val. loss: 0.1282\n",
      "Epoch 42, 100% \t Train loss: 0.1206 took: 1.25s  Val. loss: 0.1259\n",
      "Epoch 43, 100% \t Train loss: 0.1188 took: 1.29s  Val. loss: 0.1238\n",
      "Epoch 44, 100% \t Train loss: 0.1197 took: 1.26s  Val. loss: 0.1304\n",
      "Epoch 45, 100% \t Train loss: 0.1183 took: 1.26s  Val. loss: 0.1246\n",
      "Epoch 46, 100% \t Train loss: 0.1192 took: 1.27s  Val. loss: 0.1283\n",
      "Epoch 47, 100% \t Train loss: 0.1181 took: 1.28s  Val. loss: 0.1275\n",
      "Epoch 48, 100% \t Train loss: 0.1173 took: 1.28s  Val. loss: 0.1246\n",
      "Epoch 49, 100% \t Train loss: 0.1185 took: 1.28s  Val. loss: 0.1265\n",
      "Epoch 50, 100% \t Train loss: 0.1176 took: 1.29s  Val. loss: 0.1290\n",
      "Training finished, took 85.02s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2549 took: 1.86s  Val. loss: 0.2591\n",
      "Epoch 2, 100% \t Train loss: 0.2407 took: 1.85s  Val. loss: 0.2432\n",
      "Epoch 3, 100% \t Train loss: 0.2153 took: 1.87s  Val. loss: 0.2289\n",
      "Epoch 4, 100% \t Train loss: 0.2023 took: 1.87s  Val. loss: 0.2214\n",
      "Epoch 5, 100% \t Train loss: 0.1975 took: 1.86s  Val. loss: 0.2173\n",
      "Epoch 6, 100% \t Train loss: 0.1969 took: 1.86s  Val. loss: 0.2173\n",
      "Epoch 7, 100% \t Train loss: 0.1946 took: 1.87s  Val. loss: 0.2159\n",
      "Epoch 8, 100% \t Train loss: 0.1938 took: 1.87s  Val. loss: 0.2199\n",
      "Epoch 9, 100% \t Train loss: 0.1937 took: 1.87s  Val. loss: 0.2140\n",
      "Epoch 10, 100% \t Train loss: 0.1931 took: 1.86s  Val. loss: 0.2148\n",
      "Epoch 11, 100% \t Train loss: 0.1908 took: 1.88s  Val. loss: 0.2113\n",
      "Epoch 12, 100% \t Train loss: 0.1921 took: 1.87s  Val. loss: 0.2105\n",
      "Epoch 13, 100% \t Train loss: 0.1901 took: 1.87s  Val. loss: 0.2086\n",
      "Epoch 14, 100% \t Train loss: 0.1893 took: 1.86s  Val. loss: 0.2119\n",
      "Epoch 15, 100% \t Train loss: 0.1885 took: 1.87s  Val. loss: 0.2098\n",
      "Epoch 16, 100% \t Train loss: 0.1888 took: 1.86s  Val. loss: 0.2116\n",
      "Epoch 17, 100% \t Train loss: 0.1881 took: 1.87s  Val. loss: 0.2074\n",
      "Epoch 18, 100% \t Train loss: 0.1877 took: 1.87s  Val. loss: 0.2088\n",
      "Epoch 19, 100% \t Train loss: 0.1874 took: 1.87s  Val. loss: 0.2086\n",
      "Epoch 20, 100% \t Train loss: 0.1863 took: 1.88s  Val. loss: 0.2079\n",
      "Epoch 21, 100% \t Train loss: 0.1888 took: 1.87s  Val. loss: 0.2069\n",
      "Epoch 22, 100% \t Train loss: 0.1861 took: 1.86s  Val. loss: 0.2077\n",
      "Epoch 23, 100% \t Train loss: 0.1872 took: 1.87s  Val. loss: 0.2076\n",
      "Epoch 24, 100% \t Train loss: 0.1858 took: 1.88s  Val. loss: 0.2075\n",
      "Epoch 25, 100% \t Train loss: 0.1848 took: 1.86s  Val. loss: 0.2089\n",
      "Epoch 26, 100% \t Train loss: 0.1849 took: 1.86s  Val. loss: 0.2067\n",
      "Epoch 27, 100% \t Train loss: 0.1841 took: 1.86s  Val. loss: 0.2102\n",
      "Epoch 28, 100% \t Train loss: 0.1841 took: 1.87s  Val. loss: 0.2109\n",
      "Epoch 29, 100% \t Train loss: 0.1843 took: 1.89s  Val. loss: 0.2069\n",
      "Epoch 30, 100% \t Train loss: 0.1837 took: 1.89s  Val. loss: 0.2069\n",
      "Epoch 31, 100% \t Train loss: 0.1837 took: 1.87s  Val. loss: 0.2036\n",
      "Epoch 32, 100% \t Train loss: 0.1828 took: 1.87s  Val. loss: 0.2081\n",
      "Epoch 33, 100% \t Train loss: 0.1829 took: 1.90s  Val. loss: 0.2040\n",
      "Epoch 34, 100% \t Train loss: 0.1829 took: 1.87s  Val. loss: 0.2079\n",
      "Epoch 35, 100% \t Train loss: 0.1829 took: 1.87s  Val. loss: 0.2069\n",
      "Epoch 36, 100% \t Train loss: 0.1825 took: 1.89s  Val. loss: 0.2057\n",
      "Epoch 37, 100% \t Train loss: 0.1828 took: 1.88s  Val. loss: 0.2058\n",
      "Epoch 38, 100% \t Train loss: 0.1823 took: 1.86s  Val. loss: 0.2117\n",
      "Epoch 39, 100% \t Train loss: 0.1823 took: 1.88s  Val. loss: 0.2031\n",
      "Epoch 40, 100% \t Train loss: 0.1815 took: 1.90s  Val. loss: 0.2025\n",
      "Epoch 41, 100% \t Train loss: 0.1813 took: 1.89s  Val. loss: 0.2077\n",
      "Epoch 42, 100% \t Train loss: 0.1806 took: 1.88s  Val. loss: 0.2028\n",
      "Epoch 43, 100% \t Train loss: 0.1813 took: 1.90s  Val. loss: 0.2062\n",
      "Epoch 44, 100% \t Train loss: 0.1804 took: 1.87s  Val. loss: 0.2054\n",
      "Epoch 45, 100% \t Train loss: 0.1801 took: 1.87s  Val. loss: 0.2068\n",
      "Epoch 46, 100% \t Train loss: 0.1800 took: 1.87s  Val. loss: 0.2058\n",
      "Epoch 47, 100% \t Train loss: 0.1799 took: 1.87s  Val. loss: 0.2084\n",
      "Epoch 48, 100% \t Train loss: 0.1800 took: 1.87s  Val. loss: 0.2012\n",
      "Epoch 49, 100% \t Train loss: 0.1794 took: 1.88s  Val. loss: 0.2064\n",
      "Epoch 50, 100% \t Train loss: 0.1793 took: 1.87s  Val. loss: 0.2010\n",
      "Training finished, took 106.22s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2593 took: 1.92s  Val. loss: 0.2641\n",
      "Epoch 2, 100% \t Train loss: 0.2589 took: 1.89s  Val. loss: 0.2642\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 1.88s  Val. loss: 0.2651\n",
      "Epoch 4, 100% \t Train loss: 0.2588 took: 1.89s  Val. loss: 0.2634\n",
      "Epoch 5, 100% \t Train loss: 0.2584 took: 1.89s  Val. loss: 0.2635\n",
      "Epoch 6, 100% \t Train loss: 0.2577 took: 1.88s  Val. loss: 0.2625\n",
      "Epoch 7, 100% \t Train loss: 0.2546 took: 1.87s  Val. loss: 0.2567\n",
      "Epoch 8, 100% \t Train loss: 0.2408 took: 1.87s  Val. loss: 0.2383\n",
      "Epoch 9, 100% \t Train loss: 0.2239 took: 1.89s  Val. loss: 0.2298\n",
      "Epoch 10, 100% \t Train loss: 0.2156 took: 1.89s  Val. loss: 0.2181\n",
      "Epoch 11, 100% \t Train loss: 0.2110 took: 1.87s  Val. loss: 0.2127\n",
      "Epoch 12, 100% \t Train loss: 0.2089 took: 1.87s  Val. loss: 0.2145\n",
      "Epoch 13, 100% \t Train loss: 0.2082 took: 1.89s  Val. loss: 0.2095\n",
      "Epoch 14, 100% \t Train loss: 0.2067 took: 1.88s  Val. loss: 0.2092\n",
      "Epoch 15, 100% \t Train loss: 0.2061 took: 1.87s  Val. loss: 0.2141\n",
      "Epoch 16, 100% \t Train loss: 0.2059 took: 1.87s  Val. loss: 0.2072\n",
      "Epoch 17, 100% \t Train loss: 0.2043 took: 1.90s  Val. loss: 0.2071\n",
      "Epoch 18, 100% \t Train loss: 0.2037 took: 1.88s  Val. loss: 0.2053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.2038 took: 1.89s  Val. loss: 0.2061\n",
      "Epoch 20, 100% \t Train loss: 0.2032 took: 1.87s  Val. loss: 0.2053\n",
      "Epoch 21, 100% \t Train loss: 0.2024 took: 1.88s  Val. loss: 0.2059\n",
      "Epoch 22, 100% \t Train loss: 0.2016 took: 1.88s  Val. loss: 0.2023\n",
      "Epoch 23, 100% \t Train loss: 0.2027 took: 1.87s  Val. loss: 0.2030\n",
      "Epoch 24, 100% \t Train loss: 0.2011 took: 1.87s  Val. loss: 0.2081\n",
      "Epoch 25, 100% \t Train loss: 0.2018 took: 1.87s  Val. loss: 0.2038\n",
      "Epoch 26, 100% \t Train loss: 0.2000 took: 1.88s  Val. loss: 0.2026\n",
      "Epoch 27, 100% \t Train loss: 0.2011 took: 1.86s  Val. loss: 0.2020\n",
      "Epoch 28, 100% \t Train loss: 0.2008 took: 1.89s  Val. loss: 0.1996\n",
      "Epoch 29, 100% \t Train loss: 0.2006 took: 1.89s  Val. loss: 0.2060\n",
      "Epoch 30, 100% \t Train loss: 0.1998 took: 1.90s  Val. loss: 0.2056\n",
      "Epoch 31, 100% \t Train loss: 0.1999 took: 1.91s  Val. loss: 0.1991\n",
      "Epoch 32, 100% \t Train loss: 0.1981 took: 1.91s  Val. loss: 0.1981\n",
      "Epoch 33, 100% \t Train loss: 0.1997 took: 1.89s  Val. loss: 0.1995\n",
      "Epoch 34, 100% \t Train loss: 0.2000 took: 1.93s  Val. loss: 0.1983\n",
      "Epoch 35, 100% \t Train loss: 0.1979 took: 1.90s  Val. loss: 0.1984\n",
      "Epoch 36, 100% \t Train loss: 0.1976 took: 1.92s  Val. loss: 0.1985\n",
      "Epoch 37, 100% \t Train loss: 0.1978 took: 1.93s  Val. loss: 0.2007\n",
      "Epoch 38, 100% \t Train loss: 0.1986 took: 1.89s  Val. loss: 0.1997\n",
      "Epoch 39, 100% \t Train loss: 0.1969 took: 1.90s  Val. loss: 0.1957\n",
      "Epoch 40, 100% \t Train loss: 0.1961 took: 1.90s  Val. loss: 0.1953\n",
      "Epoch 41, 100% \t Train loss: 0.1970 took: 1.90s  Val. loss: 0.1990\n",
      "Epoch 42, 100% \t Train loss: 0.1971 took: 1.91s  Val. loss: 0.1989\n",
      "Epoch 43, 100% \t Train loss: 0.1977 took: 1.90s  Val. loss: 0.1951\n",
      "Epoch 44, 100% \t Train loss: 0.1953 took: 1.91s  Val. loss: 0.1943\n",
      "Epoch 45, 100% \t Train loss: 0.1951 took: 1.93s  Val. loss: 0.1980\n",
      "Epoch 46, 100% \t Train loss: 0.1950 took: 1.90s  Val. loss: 0.1929\n",
      "Epoch 47, 100% \t Train loss: 0.1944 took: 1.90s  Val. loss: 0.1953\n",
      "Epoch 48, 100% \t Train loss: 0.1945 took: 1.90s  Val. loss: 0.1966\n",
      "Epoch 49, 100% \t Train loss: 0.1949 took: 1.90s  Val. loss: 0.1927\n",
      "Epoch 50, 100% \t Train loss: 0.1948 took: 1.90s  Val. loss: 0.1951\n",
      "Training finished, took 107.20s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.31\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.828273\n",
      "lambda: 0.0010 - V: 0.789203\n",
      "lambda: 0.0005 - V: 0.788066\n",
      "Average V: 0.801847\n",
      "Time elapsed: 301.78 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2593 took: 1.92s  Val. loss: 0.2493\n",
      "Epoch 2, 100% \t Train loss: 0.2592 took: 1.90s  Val. loss: 0.2480\n",
      "Epoch 3, 100% \t Train loss: 0.2590 took: 1.91s  Val. loss: 0.2484\n",
      "Epoch 4, 100% \t Train loss: 0.2590 took: 1.92s  Val. loss: 0.2491\n",
      "Epoch 5, 100% \t Train loss: 0.2591 took: 1.88s  Val. loss: 0.2488\n",
      "Epoch 6, 100% \t Train loss: 0.2590 took: 1.93s  Val. loss: 0.2499\n",
      "Epoch 7, 100% \t Train loss: 0.2590 took: 1.91s  Val. loss: 0.2488\n",
      "Epoch 8, 100% \t Train loss: 0.2590 took: 1.91s  Val. loss: 0.2494\n",
      "Epoch 9, 100% \t Train loss: 0.2591 took: 1.91s  Val. loss: 0.2500\n",
      "Epoch 10, 100% \t Train loss: 0.2590 took: 1.90s  Val. loss: 0.2490\n",
      "Epoch 11, 100% \t Train loss: 0.2589 took: 1.89s  Val. loss: 0.2489\n",
      "Epoch 12, 100% \t Train loss: 0.2590 took: 1.90s  Val. loss: 0.2489\n",
      "Epoch 13, 100% \t Train loss: 0.2590 took: 1.90s  Val. loss: 0.2490\n",
      "Epoch 14, 100% \t Train loss: 0.2589 took: 1.87s  Val. loss: 0.2480\n",
      "Epoch 15, 100% \t Train loss: 0.2590 took: 1.89s  Val. loss: 0.2487\n",
      "Epoch 16, 100% \t Train loss: 0.2590 took: 1.89s  Val. loss: 0.2491\n",
      "Epoch 17, 100% \t Train loss: 0.2590 took: 1.89s  Val. loss: 0.2499\n",
      "Epoch 18, 100% \t Train loss: 0.2590 took: 1.88s  Val. loss: 0.2495\n",
      "Epoch 19, 100% \t Train loss: 0.2589 took: 1.91s  Val. loss: 0.2498\n",
      "Epoch 20, 100% \t Train loss: 0.2589 took: 1.88s  Val. loss: 0.2502\n",
      "Epoch 21, 100% \t Train loss: 0.2590 took: 1.89s  Val. loss: 0.2490\n",
      "Epoch 22, 100% \t Train loss: 0.2589 took: 1.89s  Val. loss: 0.2496\n",
      "Epoch 23, 100% \t Train loss: 0.2589 took: 1.89s  Val. loss: 0.2485\n",
      "Epoch 24, 100% \t Train loss: 0.2590 took: 1.89s  Val. loss: 0.2492\n",
      "Epoch 25, 100% \t Train loss: 0.2590 took: 1.87s  Val. loss: 0.2497\n",
      "Epoch 26, 100% \t Train loss: 0.2589 took: 1.87s  Val. loss: 0.2501\n",
      "Epoch 27, 100% \t Train loss: 0.2589 took: 1.88s  Val. loss: 0.2496\n",
      "Epoch 28, 100% \t Train loss: 0.2590 took: 1.88s  Val. loss: 0.2493\n",
      "Epoch 29, 100% \t Train loss: 0.2589 took: 1.90s  Val. loss: 0.2486\n",
      "Epoch 30, 100% \t Train loss: 0.2589 took: 1.92s  Val. loss: 0.2495\n",
      "Epoch 31, 100% \t Train loss: 0.2589 took: 2.05s  Val. loss: 0.2495\n",
      "Epoch 32, 100% \t Train loss: 0.2590 took: 2.52s  Val. loss: 0.2487\n",
      "Epoch 33, 100% \t Train loss: 0.2589 took: 2.85s  Val. loss: 0.2487\n",
      "Epoch 34, 100% \t Train loss: 0.2589 took: 2.86s  Val. loss: 0.2488\n",
      "Epoch 35, 100% \t Train loss: 0.2589 took: 2.93s  Val. loss: 0.2490\n",
      "Epoch 36, 100% \t Train loss: 0.2589 took: 2.95s  Val. loss: 0.2494\n",
      "Epoch 37, 100% \t Train loss: 0.2589 took: 2.96s  Val. loss: 0.2494\n",
      "Epoch 38, 100% \t Train loss: 0.2589 took: 2.91s  Val. loss: 0.2494\n",
      "Epoch 39, 100% \t Train loss: 0.2589 took: 2.94s  Val. loss: 0.2488\n",
      "Epoch 40, 100% \t Train loss: 0.2589 took: 2.99s  Val. loss: 0.2496\n",
      "Epoch 41, 100% \t Train loss: 0.2590 took: 2.94s  Val. loss: 0.2488\n",
      "Epoch 42, 100% \t Train loss: 0.2589 took: 2.94s  Val. loss: 0.2493\n",
      "Epoch 43, 100% \t Train loss: 0.2589 took: 3.01s  Val. loss: 0.2495\n",
      "Epoch 44, 100% \t Train loss: 0.2589 took: 2.94s  Val. loss: 0.2506\n",
      "Epoch 45, 100% \t Train loss: 0.2589 took: 2.21s  Val. loss: 0.2496\n",
      "Epoch 46, 100% \t Train loss: 0.2589 took: 2.21s  Val. loss: 0.2485\n",
      "Epoch 47, 100% \t Train loss: 0.2589 took: 2.99s  Val. loss: 0.2493\n",
      "Epoch 48, 100% \t Train loss: 0.2589 took: 3.03s  Val. loss: 0.2497\n",
      "Epoch 49, 100% \t Train loss: 0.2589 took: 3.01s  Val. loss: 0.2495\n",
      "Epoch 50, 100% \t Train loss: 0.2589 took: 3.07s  Val. loss: 0.2486\n",
      "Training finished, took 128.69s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2606 took: 1.92s  Val. loss: 0.2547\n",
      "Epoch 2, 100% \t Train loss: 0.2594 took: 1.91s  Val. loss: 0.2528\n",
      "Epoch 3, 100% \t Train loss: 0.2468 took: 1.89s  Val. loss: 0.2194\n",
      "Epoch 4, 100% \t Train loss: 0.1956 took: 1.90s  Val. loss: 0.1739\n",
      "Epoch 5, 100% \t Train loss: 0.1823 took: 1.90s  Val. loss: 0.1728\n",
      "Epoch 6, 100% \t Train loss: 0.1770 took: 1.87s  Val. loss: 0.1655\n",
      "Epoch 7, 100% \t Train loss: 0.1732 took: 1.90s  Val. loss: 0.1635\n",
      "Epoch 8, 100% \t Train loss: 0.1710 took: 1.89s  Val. loss: 0.1584\n",
      "Epoch 9, 100% \t Train loss: 0.1671 took: 1.89s  Val. loss: 0.1585\n",
      "Epoch 10, 100% \t Train loss: 0.1677 took: 1.88s  Val. loss: 0.1585\n",
      "Epoch 11, 100% \t Train loss: 0.1669 took: 1.90s  Val. loss: 0.1606\n",
      "Epoch 12, 100% \t Train loss: 0.1653 took: 1.88s  Val. loss: 0.1584\n",
      "Epoch 13, 100% \t Train loss: 0.1637 took: 1.89s  Val. loss: 0.1540\n",
      "Epoch 14, 100% \t Train loss: 0.1627 took: 1.91s  Val. loss: 0.1567\n",
      "Epoch 15, 100% \t Train loss: 0.1633 took: 1.89s  Val. loss: 0.1526\n",
      "Epoch 16, 100% \t Train loss: 0.1621 took: 1.88s  Val. loss: 0.1544\n",
      "Epoch 17, 100% \t Train loss: 0.1610 took: 1.22s  Val. loss: 0.1565\n",
      "Epoch 18, 100% \t Train loss: 0.1613 took: 1.11s  Val. loss: 0.1506\n",
      "Epoch 19, 100% \t Train loss: 0.1609 took: 1.11s  Val. loss: 0.1518\n",
      "Epoch 20, 100% \t Train loss: 0.1601 took: 1.10s  Val. loss: 0.1520\n",
      "Epoch 21, 100% \t Train loss: 0.1618 took: 1.10s  Val. loss: 0.1538\n",
      "Epoch 22, 100% \t Train loss: 0.1610 took: 1.11s  Val. loss: 0.1510\n",
      "Epoch 23, 100% \t Train loss: 0.1596 took: 1.11s  Val. loss: 0.1526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1586 took: 1.11s  Val. loss: 0.1535\n",
      "Epoch 25, 100% \t Train loss: 0.1583 took: 1.11s  Val. loss: 0.1563\n",
      "Epoch 26, 100% \t Train loss: 0.1592 took: 1.11s  Val. loss: 0.1523\n",
      "Epoch 27, 100% \t Train loss: 0.1580 took: 1.11s  Val. loss: 0.1514\n",
      "Epoch 28, 100% \t Train loss: 0.1581 took: 1.11s  Val. loss: 0.1486\n",
      "Epoch 29, 100% \t Train loss: 0.1575 took: 1.12s  Val. loss: 0.1489\n",
      "Epoch 30, 100% \t Train loss: 0.1572 took: 1.13s  Val. loss: 0.1509\n",
      "Epoch 31, 100% \t Train loss: 0.1567 took: 1.13s  Val. loss: 0.1534\n",
      "Epoch 32, 100% \t Train loss: 0.1582 took: 1.14s  Val. loss: 0.1520\n",
      "Epoch 33, 100% \t Train loss: 0.1571 took: 1.14s  Val. loss: 0.1521\n",
      "Epoch 34, 100% \t Train loss: 0.1560 took: 1.14s  Val. loss: 0.1500\n",
      "Epoch 35, 100% \t Train loss: 0.1557 took: 1.15s  Val. loss: 0.1489\n",
      "Epoch 36, 100% \t Train loss: 0.1557 took: 1.15s  Val. loss: 0.1545\n",
      "Epoch 37, 100% \t Train loss: 0.1556 took: 1.15s  Val. loss: 0.1483\n",
      "Epoch 38, 100% \t Train loss: 0.1549 took: 1.15s  Val. loss: 0.1504\n",
      "Epoch 39, 100% \t Train loss: 0.1554 took: 1.16s  Val. loss: 0.1495\n",
      "Epoch 40, 100% \t Train loss: 0.1557 took: 1.15s  Val. loss: 0.1501\n",
      "Epoch 41, 100% \t Train loss: 0.1544 took: 1.16s  Val. loss: 0.1489\n",
      "Epoch 42, 100% \t Train loss: 0.1549 took: 1.16s  Val. loss: 0.1528\n",
      "Epoch 43, 100% \t Train loss: 0.1541 took: 1.16s  Val. loss: 0.1489\n",
      "Epoch 44, 100% \t Train loss: 0.1533 took: 1.16s  Val. loss: 0.1481\n",
      "Epoch 45, 100% \t Train loss: 0.1538 took: 1.17s  Val. loss: 0.1494\n",
      "Epoch 46, 100% \t Train loss: 0.1539 took: 1.17s  Val. loss: 0.1491\n",
      "Epoch 47, 100% \t Train loss: 0.1526 took: 1.18s  Val. loss: 0.1484\n",
      "Epoch 48, 100% \t Train loss: 0.1532 took: 1.19s  Val. loss: 0.1506\n",
      "Epoch 49, 100% \t Train loss: 0.1539 took: 1.18s  Val. loss: 0.1489\n",
      "Epoch 50, 100% \t Train loss: 0.1523 took: 1.20s  Val. loss: 0.1505\n",
      "Training finished, took 78.25s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2598 took: 1.93s  Val. loss: 0.2621\n",
      "Epoch 2, 100% \t Train loss: 0.2588 took: 1.89s  Val. loss: 0.2623\n",
      "Epoch 3, 100% \t Train loss: 0.2586 took: 1.88s  Val. loss: 0.2620\n",
      "Epoch 4, 100% \t Train loss: 0.2583 took: 1.89s  Val. loss: 0.2620\n",
      "Epoch 5, 100% \t Train loss: 0.2574 took: 1.54s  Val. loss: 0.2601\n",
      "Epoch 6, 100% \t Train loss: 0.2546 took: 1.88s  Val. loss: 0.2556\n",
      "Epoch 7, 100% \t Train loss: 0.2460 took: 1.90s  Val. loss: 0.2428\n",
      "Epoch 8, 100% \t Train loss: 0.2264 took: 1.78s  Val. loss: 0.2210\n",
      "Epoch 9, 100% \t Train loss: 0.2030 took: 1.10s  Val. loss: 0.2052\n",
      "Epoch 10, 100% \t Train loss: 0.1873 took: 1.10s  Val. loss: 0.1984\n",
      "Epoch 11, 100% \t Train loss: 0.1799 took: 1.10s  Val. loss: 0.1846\n",
      "Epoch 12, 100% \t Train loss: 0.1769 took: 1.11s  Val. loss: 0.1838\n",
      "Epoch 13, 100% \t Train loss: 0.1760 took: 1.89s  Val. loss: 0.1816\n",
      "Epoch 14, 100% \t Train loss: 0.1757 took: 1.88s  Val. loss: 0.1798\n",
      "Epoch 15, 100% \t Train loss: 0.1746 took: 1.89s  Val. loss: 0.1811\n",
      "Epoch 16, 100% \t Train loss: 0.1735 took: 1.88s  Val. loss: 0.1789\n",
      "Epoch 17, 100% \t Train loss: 0.1733 took: 1.92s  Val. loss: 0.1798\n",
      "Epoch 18, 100% \t Train loss: 0.1731 took: 1.90s  Val. loss: 0.1781\n",
      "Epoch 19, 100% \t Train loss: 0.1722 took: 1.89s  Val. loss: 0.1784\n",
      "Epoch 20, 100% \t Train loss: 0.1730 took: 1.89s  Val. loss: 0.1783\n",
      "Epoch 21, 100% \t Train loss: 0.1716 took: 1.89s  Val. loss: 0.1788\n",
      "Epoch 22, 100% \t Train loss: 0.1717 took: 1.88s  Val. loss: 0.1767\n",
      "Epoch 23, 100% \t Train loss: 0.1709 took: 1.89s  Val. loss: 0.1780\n",
      "Epoch 24, 100% \t Train loss: 0.1713 took: 1.89s  Val. loss: 0.1781\n",
      "Epoch 25, 100% \t Train loss: 0.1707 took: 1.35s  Val. loss: 0.1763\n",
      "Epoch 26, 100% \t Train loss: 0.1701 took: 1.12s  Val. loss: 0.1775\n",
      "Epoch 27, 100% \t Train loss: 0.1695 took: 1.14s  Val. loss: 0.1755\n",
      "Epoch 28, 100% \t Train loss: 0.1699 took: 1.14s  Val. loss: 0.1761\n",
      "Epoch 29, 100% \t Train loss: 0.1691 took: 1.15s  Val. loss: 0.1732\n",
      "Epoch 30, 100% \t Train loss: 0.1691 took: 1.15s  Val. loss: 0.1771\n",
      "Epoch 31, 100% \t Train loss: 0.1688 took: 1.17s  Val. loss: 0.1758\n",
      "Epoch 32, 100% \t Train loss: 0.1684 took: 1.17s  Val. loss: 0.1756\n",
      "Epoch 33, 100% \t Train loss: 0.1680 took: 1.19s  Val. loss: 0.1760\n",
      "Epoch 34, 100% \t Train loss: 0.1684 took: 1.19s  Val. loss: 0.1745\n",
      "Epoch 35, 100% \t Train loss: 0.1681 took: 1.20s  Val. loss: 0.1746\n",
      "Epoch 36, 100% \t Train loss: 0.1678 took: 1.21s  Val. loss: 0.1740\n",
      "Epoch 37, 100% \t Train loss: 0.1673 took: 1.21s  Val. loss: 0.1769\n",
      "Epoch 38, 100% \t Train loss: 0.1673 took: 1.21s  Val. loss: 0.1773\n",
      "Epoch 39, 100% \t Train loss: 0.1670 took: 1.22s  Val. loss: 0.1729\n",
      "Epoch 40, 100% \t Train loss: 0.1671 took: 1.22s  Val. loss: 0.1732\n",
      "Epoch 41, 100% \t Train loss: 0.1669 took: 1.25s  Val. loss: 0.1714\n",
      "Epoch 42, 100% \t Train loss: 0.1664 took: 1.26s  Val. loss: 0.1757\n",
      "Epoch 43, 100% \t Train loss: 0.1666 took: 1.27s  Val. loss: 0.1721\n",
      "Epoch 44, 100% \t Train loss: 0.1663 took: 1.27s  Val. loss: 0.1712\n",
      "Epoch 45, 100% \t Train loss: 0.1663 took: 1.53s  Val. loss: 0.1748\n",
      "Epoch 46, 100% \t Train loss: 0.1657 took: 2.05s  Val. loss: 0.1712\n",
      "Epoch 47, 100% \t Train loss: 0.1662 took: 2.06s  Val. loss: 0.1724\n",
      "Epoch 48, 100% \t Train loss: 0.1651 took: 2.01s  Val. loss: 0.1717\n",
      "Epoch 49, 100% \t Train loss: 0.1653 took: 2.07s  Val. loss: 0.1732\n",
      "Epoch 50, 100% \t Train loss: 0.1654 took: 2.09s  Val. loss: 0.1724\n",
      "Training finished, took 87.97s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.750781\n",
      "lambda: 0.0010 - V: 0.841000\n",
      "lambda: 0.0005 - V: 0.810388\n",
      "Average V: 0.800723\n",
      "Time elapsed: 298.32 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2604 took: 2.56s  Val. loss: 0.2593\n",
      "Epoch 2, 100% \t Train loss: 0.2592 took: 2.55s  Val. loss: 0.2596\n",
      "Epoch 3, 100% \t Train loss: 0.2590 took: 2.55s  Val. loss: 0.2580\n",
      "Epoch 4, 100% \t Train loss: 0.2589 took: 2.54s  Val. loss: 0.2592\n",
      "Epoch 5, 100% \t Train loss: 0.2591 took: 2.53s  Val. loss: 0.2584\n",
      "Epoch 6, 100% \t Train loss: 0.2589 took: 2.56s  Val. loss: 0.2596\n",
      "Epoch 7, 100% \t Train loss: 0.2590 took: 2.55s  Val. loss: 0.2587\n",
      "Epoch 8, 100% \t Train loss: 0.2590 took: 2.53s  Val. loss: 0.2585\n",
      "Epoch 9, 100% \t Train loss: 0.2590 took: 2.54s  Val. loss: 0.2580\n",
      "Epoch 10, 100% \t Train loss: 0.2591 took: 2.56s  Val. loss: 0.2585\n",
      "Epoch 11, 100% \t Train loss: 0.2590 took: 2.56s  Val. loss: 0.2584\n",
      "Epoch 12, 100% \t Train loss: 0.2589 took: 2.56s  Val. loss: 0.2578\n",
      "Epoch 13, 100% \t Train loss: 0.2589 took: 2.54s  Val. loss: 0.2588\n",
      "Epoch 14, 100% \t Train loss: 0.2588 took: 2.53s  Val. loss: 0.2583\n",
      "Epoch 15, 100% \t Train loss: 0.2590 took: 2.57s  Val. loss: 0.2584\n",
      "Epoch 16, 100% \t Train loss: 0.2589 took: 2.57s  Val. loss: 0.2587\n",
      "Epoch 17, 100% \t Train loss: 0.2590 took: 2.56s  Val. loss: 0.2583\n",
      "Epoch 18, 100% \t Train loss: 0.2589 took: 2.58s  Val. loss: 0.2584\n",
      "Epoch 19, 100% \t Train loss: 0.2590 took: 2.61s  Val. loss: 0.2585\n",
      "Epoch 20, 100% \t Train loss: 0.2590 took: 2.63s  Val. loss: 0.2583\n",
      "Epoch 21, 100% \t Train loss: 0.2588 took: 2.58s  Val. loss: 0.2574\n",
      "Epoch 22, 100% \t Train loss: 0.2588 took: 2.58s  Val. loss: 0.2576\n",
      "Epoch 23, 100% \t Train loss: 0.2588 took: 2.66s  Val. loss: 0.2588\n",
      "Epoch 24, 100% \t Train loss: 0.2588 took: 2.59s  Val. loss: 0.2590\n",
      "Epoch 25, 100% \t Train loss: 0.2589 took: 2.63s  Val. loss: 0.2583\n",
      "Epoch 26, 100% \t Train loss: 0.2588 took: 2.72s  Val. loss: 0.2574\n",
      "Epoch 27, 100% \t Train loss: 0.2588 took: 2.79s  Val. loss: 0.2589\n",
      "Epoch 28, 100% \t Train loss: 0.2589 took: 2.71s  Val. loss: 0.2583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.2590 took: 2.59s  Val. loss: 0.2586\n",
      "Epoch 30, 100% \t Train loss: 0.2589 took: 2.64s  Val. loss: 0.2583\n",
      "Epoch 31, 100% \t Train loss: 0.2589 took: 3.04s  Val. loss: 0.2585\n",
      "Epoch 32, 100% \t Train loss: 0.2588 took: 3.81s  Val. loss: 0.2583\n",
      "Epoch 33, 100% \t Train loss: 0.2589 took: 4.12s  Val. loss: 0.2579\n",
      "Epoch 34, 100% \t Train loss: 0.2590 took: 4.31s  Val. loss: 0.2594\n",
      "Epoch 35, 100% \t Train loss: 0.2588 took: 4.12s  Val. loss: 0.2581\n",
      "Epoch 36, 100% \t Train loss: 0.2589 took: 4.14s  Val. loss: 0.2585\n",
      "Epoch 37, 100% \t Train loss: 0.2588 took: 4.18s  Val. loss: 0.2575\n",
      "Epoch 38, 100% \t Train loss: 0.2589 took: 4.16s  Val. loss: 0.2582\n",
      "Epoch 39, 100% \t Train loss: 0.2588 took: 3.88s  Val. loss: 0.2580\n",
      "Epoch 40, 100% \t Train loss: 0.2588 took: 4.21s  Val. loss: 0.2582\n",
      "Epoch 41, 100% \t Train loss: 0.2588 took: 4.19s  Val. loss: 0.2582\n",
      "Epoch 42, 100% \t Train loss: 0.2588 took: 4.29s  Val. loss: 0.2577\n",
      "Epoch 43, 100% \t Train loss: 0.2588 took: 3.24s  Val. loss: 0.2579\n",
      "Epoch 44, 100% \t Train loss: 0.2588 took: 3.11s  Val. loss: 0.2578\n",
      "Epoch 45, 100% \t Train loss: 0.2588 took: 3.23s  Val. loss: 0.2589\n",
      "Epoch 46, 100% \t Train loss: 0.2588 took: 3.10s  Val. loss: 0.2582\n",
      "Epoch 47, 100% \t Train loss: 0.2588 took: 3.25s  Val. loss: 0.2583\n",
      "Epoch 48, 100% \t Train loss: 0.2588 took: 3.79s  Val. loss: 0.2580\n",
      "Epoch 49, 100% \t Train loss: 0.2588 took: 4.39s  Val. loss: 0.2573\n",
      "Epoch 50, 100% \t Train loss: 0.2588 took: 3.24s  Val. loss: 0.2576\n",
      "Training finished, took 171.40s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2615 took: 2.57s  Val. loss: 0.2573\n",
      "Epoch 2, 100% \t Train loss: 0.2609 took: 2.57s  Val. loss: 0.2577\n",
      "Epoch 3, 100% \t Train loss: 0.2607 took: 2.17s  Val. loss: 0.2565\n",
      "Epoch 4, 100% \t Train loss: 0.2606 took: 1.56s  Val. loss: 0.2559\n",
      "Epoch 5, 100% \t Train loss: 0.2605 took: 1.56s  Val. loss: 0.2561\n",
      "Epoch 6, 100% \t Train loss: 0.2606 took: 1.55s  Val. loss: 0.2581\n",
      "Epoch 7, 100% \t Train loss: 0.2604 took: 1.55s  Val. loss: 0.2565\n",
      "Epoch 8, 100% \t Train loss: 0.2606 took: 1.55s  Val. loss: 0.2571\n",
      "Epoch 9, 100% \t Train loss: 0.2605 took: 1.56s  Val. loss: 0.2568\n",
      "Epoch 10, 100% \t Train loss: 0.2604 took: 1.55s  Val. loss: 0.2571\n",
      "Epoch 11, 100% \t Train loss: 0.2576 took: 1.55s  Val. loss: 0.2469\n",
      "Epoch 12, 100% \t Train loss: 0.2277 took: 1.55s  Val. loss: 0.2118\n",
      "Epoch 13, 100% \t Train loss: 0.2045 took: 1.60s  Val. loss: 0.1988\n",
      "Epoch 14, 100% \t Train loss: 0.2009 took: 1.55s  Val. loss: 0.1985\n",
      "Epoch 15, 100% \t Train loss: 0.1988 took: 1.55s  Val. loss: 0.1978\n",
      "Epoch 16, 100% \t Train loss: 0.1977 took: 1.55s  Val. loss: 0.1981\n",
      "Epoch 17, 100% \t Train loss: 0.1962 took: 1.56s  Val. loss: 0.1950\n",
      "Epoch 18, 100% \t Train loss: 0.1956 took: 1.55s  Val. loss: 0.1956\n",
      "Epoch 19, 100% \t Train loss: 0.1939 took: 1.55s  Val. loss: 0.1940\n",
      "Epoch 20, 100% \t Train loss: 0.1934 took: 1.55s  Val. loss: 0.1945\n",
      "Epoch 21, 100% \t Train loss: 0.1929 took: 1.56s  Val. loss: 0.1945\n",
      "Epoch 22, 100% \t Train loss: 0.1931 took: 1.56s  Val. loss: 0.1934\n",
      "Epoch 23, 100% \t Train loss: 0.1918 took: 1.56s  Val. loss: 0.1918\n",
      "Epoch 24, 100% \t Train loss: 0.1917 took: 1.56s  Val. loss: 0.1945\n",
      "Epoch 25, 100% \t Train loss: 0.1911 took: 1.56s  Val. loss: 0.1955\n",
      "Epoch 26, 100% \t Train loss: 0.1910 took: 1.56s  Val. loss: 0.1924\n",
      "Epoch 27, 100% \t Train loss: 0.1910 took: 1.58s  Val. loss: 0.1925\n",
      "Epoch 28, 100% \t Train loss: 0.1899 took: 1.59s  Val. loss: 0.1914\n",
      "Epoch 29, 100% \t Train loss: 0.1901 took: 1.63s  Val. loss: 0.1939\n",
      "Epoch 30, 100% \t Train loss: 0.1899 took: 2.03s  Val. loss: 0.1900\n",
      "Epoch 31, 100% \t Train loss: 0.1894 took: 2.78s  Val. loss: 0.1905\n",
      "Epoch 32, 100% \t Train loss: 0.1903 took: 2.91s  Val. loss: 0.1902\n",
      "Epoch 33, 100% \t Train loss: 0.1896 took: 2.96s  Val. loss: 0.1896\n",
      "Epoch 34, 100% \t Train loss: 0.1888 took: 3.00s  Val. loss: 0.1912\n",
      "Epoch 35, 100% \t Train loss: 0.1885 took: 2.99s  Val. loss: 0.1911\n",
      "Epoch 36, 100% \t Train loss: 0.1888 took: 2.99s  Val. loss: 0.1893\n",
      "Epoch 37, 100% \t Train loss: 0.1893 took: 2.85s  Val. loss: 0.1955\n",
      "Epoch 38, 100% \t Train loss: 0.1892 took: 2.85s  Val. loss: 0.1913\n",
      "Epoch 39, 100% \t Train loss: 0.1881 took: 2.89s  Val. loss: 0.1905\n",
      "Epoch 40, 100% \t Train loss: 0.1882 took: 2.96s  Val. loss: 0.1984\n",
      "Epoch 41, 100% \t Train loss: 0.1894 took: 2.99s  Val. loss: 0.1907\n",
      "Epoch 42, 100% \t Train loss: 0.1893 took: 3.02s  Val. loss: 0.1901\n",
      "Epoch 43, 100% \t Train loss: 0.1886 took: 3.06s  Val. loss: 0.1902\n",
      "Epoch 44, 100% \t Train loss: 0.1880 took: 3.12s  Val. loss: 0.1910\n",
      "Epoch 45, 100% \t Train loss: 0.1879 took: 3.17s  Val. loss: 0.1903\n",
      "Epoch 46, 100% \t Train loss: 0.1873 took: 3.20s  Val. loss: 0.1893\n",
      "Epoch 47, 100% \t Train loss: 0.1870 took: 3.31s  Val. loss: 0.1920\n",
      "Epoch 48, 100% \t Train loss: 0.1869 took: 3.37s  Val. loss: 0.1898\n",
      "Epoch 49, 100% \t Train loss: 0.1867 took: 3.40s  Val. loss: 0.1897\n",
      "Epoch 50, 100% \t Train loss: 0.1872 took: 3.42s  Val. loss: 0.1874\n",
      "Training finished, took 122.53s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2581 took: 2.58s  Val. loss: 0.2615\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 2.05s  Val. loss: 0.2610\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 1.55s  Val. loss: 0.2603\n",
      "Epoch 4, 100% \t Train loss: 0.2578 took: 1.54s  Val. loss: 0.2602\n",
      "Epoch 5, 100% \t Train loss: 0.2577 took: 1.55s  Val. loss: 0.2609\n",
      "Epoch 6, 100% \t Train loss: 0.2577 took: 1.55s  Val. loss: 0.2604\n",
      "Epoch 7, 100% \t Train loss: 0.2576 took: 1.55s  Val. loss: 0.2602\n",
      "Epoch 8, 100% \t Train loss: 0.2575 took: 1.55s  Val. loss: 0.2610\n",
      "Epoch 9, 100% \t Train loss: 0.2572 took: 1.54s  Val. loss: 0.2595\n",
      "Epoch 10, 100% \t Train loss: 0.2551 took: 1.54s  Val. loss: 0.2547\n",
      "Epoch 11, 100% \t Train loss: 0.2426 took: 2.20s  Val. loss: 0.2303\n",
      "Epoch 12, 100% \t Train loss: 0.2224 took: 2.57s  Val. loss: 0.2086\n",
      "Epoch 13, 100% \t Train loss: 0.2090 took: 2.55s  Val. loss: 0.1960\n",
      "Epoch 14, 100% \t Train loss: 0.2018 took: 2.56s  Val. loss: 0.1919\n",
      "Epoch 15, 100% \t Train loss: 0.2000 took: 2.57s  Val. loss: 0.1926\n",
      "Epoch 16, 100% \t Train loss: 0.1971 took: 2.57s  Val. loss: 0.1903\n",
      "Epoch 17, 100% \t Train loss: 0.1956 took: 2.55s  Val. loss: 0.1878\n",
      "Epoch 18, 100% \t Train loss: 0.1945 took: 2.55s  Val. loss: 0.1874\n",
      "Epoch 19, 100% \t Train loss: 0.1932 took: 2.55s  Val. loss: 0.1848\n",
      "Epoch 20, 100% \t Train loss: 0.1932 took: 2.55s  Val. loss: 0.1860\n",
      "Epoch 21, 100% \t Train loss: 0.1913 took: 2.31s  Val. loss: 0.1848\n",
      "Epoch 22, 100% \t Train loss: 0.1903 took: 1.81s  Val. loss: 0.1836\n",
      "Epoch 23, 100% \t Train loss: 0.1890 took: 2.55s  Val. loss: 0.1829\n",
      "Epoch 24, 100% \t Train loss: 0.1899 took: 2.54s  Val. loss: 0.1826\n",
      "Epoch 25, 100% \t Train loss: 0.1877 took: 2.54s  Val. loss: 0.1815\n",
      "Epoch 26, 100% \t Train loss: 0.1874 took: 2.59s  Val. loss: 0.1820\n",
      "Epoch 27, 100% \t Train loss: 0.1864 took: 2.58s  Val. loss: 0.1831\n",
      "Epoch 28, 100% \t Train loss: 0.1875 took: 2.58s  Val. loss: 0.1809\n",
      "Epoch 29, 100% \t Train loss: 0.1864 took: 2.62s  Val. loss: 0.1803\n",
      "Epoch 30, 100% \t Train loss: 0.1853 took: 2.63s  Val. loss: 0.1789\n",
      "Epoch 31, 100% \t Train loss: 0.1855 took: 2.67s  Val. loss: 0.1843\n",
      "Epoch 32, 100% \t Train loss: 0.1847 took: 2.69s  Val. loss: 0.1804\n",
      "Epoch 33, 100% \t Train loss: 0.1842 took: 2.69s  Val. loss: 0.1802\n",
      "Epoch 34, 100% \t Train loss: 0.1839 took: 2.70s  Val. loss: 0.1808\n",
      "Epoch 35, 100% \t Train loss: 0.1837 took: 2.71s  Val. loss: 0.1798\n",
      "Epoch 36, 100% \t Train loss: 0.1831 took: 2.73s  Val. loss: 0.1795\n",
      "Epoch 37, 100% \t Train loss: 0.1831 took: 2.74s  Val. loss: 0.1816\n",
      "Epoch 38, 100% \t Train loss: 0.1828 took: 2.77s  Val. loss: 0.1803\n",
      "Epoch 39, 100% \t Train loss: 0.1823 took: 2.85s  Val. loss: 0.1780\n",
      "Epoch 40, 100% \t Train loss: 0.1817 took: 2.92s  Val. loss: 0.1796\n",
      "Epoch 41, 100% \t Train loss: 0.1820 took: 2.94s  Val. loss: 0.1845\n",
      "Epoch 42, 100% \t Train loss: 0.1821 took: 2.96s  Val. loss: 0.1790\n",
      "Epoch 43, 100% \t Train loss: 0.1816 took: 2.91s  Val. loss: 0.1821\n",
      "Epoch 44, 100% \t Train loss: 0.1812 took: 2.93s  Val. loss: 0.1785\n",
      "Epoch 45, 100% \t Train loss: 0.1809 took: 2.95s  Val. loss: 0.1788\n",
      "Epoch 46, 100% \t Train loss: 0.1814 took: 2.93s  Val. loss: 0.1798\n",
      "Epoch 47, 100% \t Train loss: 0.1806 took: 2.97s  Val. loss: 0.1785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1801 took: 2.94s  Val. loss: 0.1778\n",
      "Epoch 49, 100% \t Train loss: 0.1802 took: 2.89s  Val. loss: 0.1765\n",
      "Epoch 50, 100% \t Train loss: 0.1802 took: 2.78s  Val. loss: 0.1787\n",
      "Training finished, took 136.20s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  6  - prob: 0.34\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.741665\n",
      "lambda: 0.0010 - V: 0.793032\n",
      "lambda: 0.0005 - V: 0.800508\n",
      "Average V: 0.778402\n",
      "Time elapsed: 433.58 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2613 took: 1.96s  Val. loss: 0.2623\n",
      "Epoch 2, 100% \t Train loss: 0.2556 took: 1.93s  Val. loss: 0.2247\n",
      "Epoch 3, 100% \t Train loss: 0.2054 took: 1.93s  Val. loss: 0.1806\n",
      "Epoch 4, 100% \t Train loss: 0.1786 took: 1.94s  Val. loss: 0.1757\n",
      "Epoch 5, 100% \t Train loss: 0.1747 took: 1.95s  Val. loss: 0.1786\n",
      "Epoch 6, 100% \t Train loss: 0.1720 took: 1.95s  Val. loss: 0.1711\n",
      "Epoch 7, 100% \t Train loss: 0.1689 took: 1.90s  Val. loss: 0.1675\n",
      "Epoch 8, 100% \t Train loss: 0.1658 took: 1.93s  Val. loss: 0.1633\n",
      "Epoch 9, 100% \t Train loss: 0.1606 took: 1.92s  Val. loss: 0.1690\n",
      "Epoch 10, 100% \t Train loss: 0.1578 took: 1.91s  Val. loss: 0.1598\n",
      "Epoch 11, 100% \t Train loss: 0.1543 took: 1.91s  Val. loss: 0.1634\n",
      "Epoch 12, 100% \t Train loss: 0.1513 took: 1.92s  Val. loss: 0.1593\n",
      "Epoch 13, 100% \t Train loss: 0.1466 took: 1.92s  Val. loss: 0.1525\n",
      "Epoch 14, 100% \t Train loss: 0.1420 took: 1.90s  Val. loss: 0.1565\n",
      "Epoch 15, 100% \t Train loss: 0.1388 took: 1.91s  Val. loss: 0.1451\n",
      "Epoch 16, 100% \t Train loss: 0.1354 took: 1.92s  Val. loss: 0.1468\n",
      "Epoch 17, 100% \t Train loss: 0.1313 took: 1.90s  Val. loss: 0.1456\n",
      "Epoch 18, 100% \t Train loss: 0.1290 took: 1.92s  Val. loss: 0.1416\n",
      "Epoch 19, 100% \t Train loss: 0.1276 took: 1.94s  Val. loss: 0.1448\n",
      "Epoch 20, 100% \t Train loss: 0.1241 took: 1.92s  Val. loss: 0.1386\n",
      "Epoch 21, 100% \t Train loss: 0.1222 took: 1.92s  Val. loss: 0.1382\n",
      "Epoch 22, 100% \t Train loss: 0.1172 took: 1.92s  Val. loss: 0.1359\n",
      "Epoch 23, 100% \t Train loss: 0.1164 took: 1.92s  Val. loss: 0.1280\n",
      "Epoch 24, 100% \t Train loss: 0.1128 took: 1.92s  Val. loss: 0.1319\n",
      "Epoch 25, 100% \t Train loss: 0.1128 took: 1.93s  Val. loss: 0.1413\n",
      "Epoch 26, 100% \t Train loss: 0.1121 took: 1.93s  Val. loss: 0.1289\n",
      "Epoch 27, 100% \t Train loss: 0.1099 took: 1.93s  Val. loss: 0.1281\n",
      "Epoch 28, 100% \t Train loss: 0.1090 took: 1.93s  Val. loss: 0.1252\n",
      "Epoch 29, 100% \t Train loss: 0.1068 took: 1.93s  Val. loss: 0.1278\n",
      "Epoch 30, 100% \t Train loss: 0.1065 took: 1.97s  Val. loss: 0.1284\n",
      "Epoch 31, 100% \t Train loss: 0.1054 took: 2.00s  Val. loss: 0.1293\n",
      "Epoch 32, 100% \t Train loss: 0.1046 took: 2.18s  Val. loss: 0.1175\n",
      "Epoch 33, 100% \t Train loss: 0.1045 took: 2.40s  Val. loss: 0.1187\n",
      "Epoch 34, 100% \t Train loss: 0.1021 took: 2.38s  Val. loss: 0.1222\n",
      "Epoch 35, 100% \t Train loss: 0.1028 took: 2.33s  Val. loss: 0.1251\n",
      "Epoch 36, 100% \t Train loss: 0.1021 took: 2.34s  Val. loss: 0.1215\n",
      "Epoch 37, 100% \t Train loss: 0.1016 took: 2.37s  Val. loss: 0.1247\n",
      "Epoch 38, 100% \t Train loss: 0.1009 took: 2.36s  Val. loss: 0.1201\n",
      "Epoch 39, 100% \t Train loss: 0.1003 took: 2.36s  Val. loss: 0.1217\n",
      "Epoch 40, 100% \t Train loss: 0.1016 took: 2.35s  Val. loss: 0.1213\n",
      "Epoch 41, 100% \t Train loss: 0.0985 took: 2.34s  Val. loss: 0.1196\n",
      "Epoch 42, 100% \t Train loss: 0.0976 took: 2.35s  Val. loss: 0.1192\n",
      "Epoch 43, 100% \t Train loss: 0.0996 took: 2.35s  Val. loss: 0.1175\n",
      "Epoch 44, 100% \t Train loss: 0.0970 took: 2.37s  Val. loss: 0.1193\n",
      "Epoch 45, 100% \t Train loss: 0.0983 took: 2.33s  Val. loss: 0.1175\n",
      "Epoch 46, 100% \t Train loss: 0.0982 took: 2.36s  Val. loss: 0.1225\n",
      "Epoch 47, 100% \t Train loss: 0.0975 took: 2.36s  Val. loss: 0.1178\n",
      "Epoch 48, 100% \t Train loss: 0.0970 took: 2.36s  Val. loss: 0.1178\n",
      "Epoch 49, 100% \t Train loss: 0.0948 took: 2.36s  Val. loss: 0.1156\n",
      "Epoch 50, 100% \t Train loss: 0.0939 took: 2.36s  Val. loss: 0.1155\n",
      "Training finished, took 118.25s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2606 took: 1.93s  Val. loss: 0.2612\n",
      "Epoch 2, 100% \t Train loss: 0.2601 took: 1.90s  Val. loss: 0.2602\n",
      "Epoch 3, 100% \t Train loss: 0.2601 took: 1.90s  Val. loss: 0.2593\n",
      "Epoch 4, 100% \t Train loss: 0.2604 took: 1.91s  Val. loss: 0.2598\n",
      "Epoch 5, 100% \t Train loss: 0.2602 took: 1.91s  Val. loss: 0.2599\n",
      "Epoch 6, 100% \t Train loss: 0.2601 took: 1.91s  Val. loss: 0.2601\n",
      "Epoch 7, 100% \t Train loss: 0.2601 took: 1.90s  Val. loss: 0.2605\n",
      "Epoch 8, 100% \t Train loss: 0.2600 took: 1.93s  Val. loss: 0.2593\n",
      "Epoch 9, 100% \t Train loss: 0.2599 took: 1.93s  Val. loss: 0.2602\n",
      "Epoch 10, 100% \t Train loss: 0.2590 took: 1.93s  Val. loss: 0.2575\n",
      "Epoch 11, 100% \t Train loss: 0.2435 took: 1.92s  Val. loss: 0.2274\n",
      "Epoch 12, 100% \t Train loss: 0.2123 took: 1.92s  Val. loss: 0.2071\n",
      "Epoch 13, 100% \t Train loss: 0.1919 took: 1.92s  Val. loss: 0.1987\n",
      "Epoch 14, 100% \t Train loss: 0.1895 took: 1.93s  Val. loss: 0.2005\n",
      "Epoch 15, 100% \t Train loss: 0.1819 took: 1.91s  Val. loss: 0.1951\n",
      "Epoch 16, 100% \t Train loss: 0.1797 took: 1.91s  Val. loss: 0.1901\n",
      "Epoch 17, 100% \t Train loss: 0.1792 took: 1.92s  Val. loss: 0.1837\n",
      "Epoch 18, 100% \t Train loss: 0.1768 took: 1.97s  Val. loss: 0.1824\n",
      "Epoch 19, 100% \t Train loss: 0.1734 took: 1.91s  Val. loss: 0.1831\n",
      "Epoch 20, 100% \t Train loss: 0.1732 took: 1.89s  Val. loss: 0.1811\n",
      "Epoch 21, 100% \t Train loss: 0.1697 took: 1.11s  Val. loss: 0.1800\n",
      "Epoch 22, 100% \t Train loss: 0.1680 took: 1.11s  Val. loss: 0.1901\n",
      "Epoch 23, 100% \t Train loss: 0.1697 took: 1.11s  Val. loss: 0.1828\n",
      "Epoch 24, 100% \t Train loss: 0.1683 took: 1.12s  Val. loss: 0.1740\n",
      "Epoch 25, 100% \t Train loss: 0.1656 took: 1.11s  Val. loss: 0.1748\n",
      "Epoch 26, 100% \t Train loss: 0.1642 took: 1.12s  Val. loss: 0.1713\n",
      "Epoch 27, 100% \t Train loss: 0.1621 took: 1.11s  Val. loss: 0.1773\n",
      "Epoch 28, 100% \t Train loss: 0.1590 took: 1.12s  Val. loss: 0.1656\n",
      "Epoch 29, 100% \t Train loss: 0.1543 took: 1.14s  Val. loss: 0.1659\n",
      "Epoch 30, 100% \t Train loss: 0.1501 took: 1.14s  Val. loss: 0.1552\n",
      "Epoch 31, 100% \t Train loss: 0.1431 took: 1.14s  Val. loss: 0.1496\n",
      "Epoch 32, 100% \t Train loss: 0.1370 took: 1.18s  Val. loss: 0.1497\n",
      "Epoch 33, 100% \t Train loss: 0.1333 took: 1.20s  Val. loss: 0.1428\n",
      "Epoch 34, 100% \t Train loss: 0.1289 took: 1.20s  Val. loss: 0.1437\n",
      "Epoch 35, 100% \t Train loss: 0.1268 took: 1.22s  Val. loss: 0.1395\n",
      "Epoch 36, 100% \t Train loss: 0.1213 took: 1.22s  Val. loss: 0.1321\n",
      "Epoch 37, 100% \t Train loss: 0.1192 took: 1.22s  Val. loss: 0.1277\n",
      "Epoch 38, 100% \t Train loss: 0.1204 took: 1.22s  Val. loss: 0.1333\n",
      "Epoch 39, 100% \t Train loss: 0.1153 took: 1.21s  Val. loss: 0.1291\n",
      "Epoch 40, 100% \t Train loss: 0.1154 took: 1.21s  Val. loss: 0.1363\n",
      "Epoch 41, 100% \t Train loss: 0.1142 took: 1.20s  Val. loss: 0.1256\n",
      "Epoch 42, 100% \t Train loss: 0.1092 took: 1.21s  Val. loss: 0.1209\n",
      "Epoch 43, 100% \t Train loss: 0.1091 took: 1.20s  Val. loss: 0.1237\n",
      "Epoch 44, 100% \t Train loss: 0.1077 took: 1.21s  Val. loss: 0.1265\n",
      "Epoch 45, 100% \t Train loss: 0.1057 took: 1.22s  Val. loss: 0.1242\n",
      "Epoch 46, 100% \t Train loss: 0.1053 took: 1.22s  Val. loss: 0.1134\n",
      "Epoch 47, 100% \t Train loss: 0.1023 took: 1.30s  Val. loss: 0.1125\n",
      "Epoch 48, 100% \t Train loss: 0.1023 took: 1.22s  Val. loss: 0.1169\n",
      "Epoch 49, 100% \t Train loss: 0.1002 took: 1.22s  Val. loss: 0.1128\n",
      "Epoch 50, 100% \t Train loss: 0.0995 took: 1.22s  Val. loss: 0.1101\n",
      "Training finished, took 83.37s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2590 took: 1.12s  Val. loss: 0.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2582 took: 1.11s  Val. loss: 0.2554\n",
      "Epoch 3, 100% \t Train loss: 0.2582 took: 1.12s  Val. loss: 0.2548\n",
      "Epoch 4, 100% \t Train loss: 0.2579 took: 1.11s  Val. loss: 0.2547\n",
      "Epoch 5, 100% \t Train loss: 0.2570 took: 1.11s  Val. loss: 0.2531\n",
      "Epoch 6, 100% \t Train loss: 0.2515 took: 1.11s  Val. loss: 0.2400\n",
      "Epoch 7, 100% \t Train loss: 0.2335 took: 1.31s  Val. loss: 0.2207\n",
      "Epoch 8, 100% \t Train loss: 0.2180 took: 1.93s  Val. loss: 0.2064\n",
      "Epoch 9, 100% \t Train loss: 0.2011 took: 1.11s  Val. loss: 0.1907\n",
      "Epoch 10, 100% \t Train loss: 0.1870 took: 1.11s  Val. loss: 0.1801\n",
      "Epoch 11, 100% \t Train loss: 0.1806 took: 1.11s  Val. loss: 0.1797\n",
      "Epoch 12, 100% \t Train loss: 0.1794 took: 1.11s  Val. loss: 0.1806\n",
      "Epoch 13, 100% \t Train loss: 0.1792 took: 1.12s  Val. loss: 0.1763\n",
      "Epoch 14, 100% \t Train loss: 0.1769 took: 1.11s  Val. loss: 0.1800\n",
      "Epoch 15, 100% \t Train loss: 0.1748 took: 1.12s  Val. loss: 0.1788\n",
      "Epoch 16, 100% \t Train loss: 0.1752 took: 1.12s  Val. loss: 0.1745\n",
      "Epoch 17, 100% \t Train loss: 0.1748 took: 1.12s  Val. loss: 0.1746\n",
      "Epoch 18, 100% \t Train loss: 0.1769 took: 1.13s  Val. loss: 0.1756\n",
      "Epoch 19, 100% \t Train loss: 0.1729 took: 1.13s  Val. loss: 0.1723\n",
      "Epoch 20, 100% \t Train loss: 0.1722 took: 1.13s  Val. loss: 0.1726\n",
      "Epoch 21, 100% \t Train loss: 0.1736 took: 1.13s  Val. loss: 0.1725\n",
      "Epoch 22, 100% \t Train loss: 0.1713 took: 1.12s  Val. loss: 0.1690\n",
      "Epoch 23, 100% \t Train loss: 0.1700 took: 1.12s  Val. loss: 0.1686\n",
      "Epoch 24, 100% \t Train loss: 0.1715 took: 1.12s  Val. loss: 0.1724\n",
      "Epoch 25, 100% \t Train loss: 0.1702 took: 1.12s  Val. loss: 0.1665\n",
      "Epoch 26, 100% \t Train loss: 0.1689 took: 1.12s  Val. loss: 0.1673\n",
      "Epoch 27, 100% \t Train loss: 0.1659 took: 1.12s  Val. loss: 0.1653\n",
      "Epoch 28, 100% \t Train loss: 0.1701 took: 1.12s  Val. loss: 0.1676\n",
      "Epoch 29, 100% \t Train loss: 0.1674 took: 1.13s  Val. loss: 0.1686\n",
      "Epoch 30, 100% \t Train loss: 0.1670 took: 1.15s  Val. loss: 0.1697\n",
      "Epoch 31, 100% \t Train loss: 0.1687 took: 1.15s  Val. loss: 0.1668\n",
      "Epoch 32, 100% \t Train loss: 0.1660 took: 1.16s  Val. loss: 0.1636\n",
      "Epoch 33, 100% \t Train loss: 0.1662 took: 1.96s  Val. loss: 0.1636\n",
      "Epoch 34, 100% \t Train loss: 0.1638 took: 1.97s  Val. loss: 0.1637\n",
      "Epoch 35, 100% \t Train loss: 0.1640 took: 1.99s  Val. loss: 0.1655\n",
      "Epoch 36, 100% \t Train loss: 0.1640 took: 2.01s  Val. loss: 0.1621\n",
      "Epoch 37, 100% \t Train loss: 0.1645 took: 2.01s  Val. loss: 0.1670\n",
      "Epoch 38, 100% \t Train loss: 0.1659 took: 2.02s  Val. loss: 0.1641\n",
      "Epoch 39, 100% \t Train loss: 0.1631 took: 2.02s  Val. loss: 0.1633\n",
      "Epoch 40, 100% \t Train loss: 0.1627 took: 2.02s  Val. loss: 0.1617\n",
      "Epoch 41, 100% \t Train loss: 0.1625 took: 2.05s  Val. loss: 0.1642\n",
      "Epoch 42, 100% \t Train loss: 0.1617 took: 2.05s  Val. loss: 0.1617\n",
      "Epoch 43, 100% \t Train loss: 0.1625 took: 2.05s  Val. loss: 0.1617\n",
      "Epoch 44, 100% \t Train loss: 0.1622 took: 2.06s  Val. loss: 0.1614\n",
      "Epoch 45, 100% \t Train loss: 0.1609 took: 1.27s  Val. loss: 0.1624\n",
      "Epoch 46, 100% \t Train loss: 0.1618 took: 1.26s  Val. loss: 0.1627\n",
      "Epoch 47, 100% \t Train loss: 0.1622 took: 1.26s  Val. loss: 0.1622\n",
      "Epoch 48, 100% \t Train loss: 0.1609 took: 1.25s  Val. loss: 0.1604\n",
      "Epoch 49, 100% \t Train loss: 0.1604 took: 1.51s  Val. loss: 0.1599\n",
      "Epoch 50, 100% \t Train loss: 0.1604 took: 2.07s  Val. loss: 0.1606\n",
      "Training finished, took 78.63s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.858694\n",
      "lambda: 0.0010 - V: 0.822909\n",
      "lambda: 0.0005 - V: 0.819554\n",
      "Average V: 0.833719\n",
      "Time elapsed: 283.62 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 1.74s  Val. loss: 0.2599\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 1.74s  Val. loss: 0.2569\n",
      "Epoch 3, 100% \t Train loss: 0.2309 took: 1.76s  Val. loss: 0.1952\n",
      "Epoch 4, 100% \t Train loss: 0.1993 took: 1.75s  Val. loss: 0.1885\n",
      "Epoch 5, 100% \t Train loss: 0.1958 took: 1.75s  Val. loss: 0.1837\n",
      "Epoch 6, 100% \t Train loss: 0.1940 took: 1.74s  Val. loss: 0.1804\n",
      "Epoch 7, 100% \t Train loss: 0.1916 took: 1.76s  Val. loss: 0.1788\n",
      "Epoch 8, 100% \t Train loss: 0.1915 took: 1.76s  Val. loss: 0.1790\n",
      "Epoch 9, 100% \t Train loss: 0.1886 took: 1.74s  Val. loss: 0.1856\n",
      "Epoch 10, 100% \t Train loss: 0.1875 took: 1.74s  Val. loss: 0.1783\n",
      "Epoch 11, 100% \t Train loss: 0.1867 took: 1.74s  Val. loss: 0.1784\n",
      "Epoch 12, 100% \t Train loss: 0.1847 took: 1.73s  Val. loss: 0.1779\n",
      "Epoch 13, 100% \t Train loss: 0.1823 took: 1.74s  Val. loss: 0.1797\n",
      "Epoch 14, 100% \t Train loss: 0.1808 took: 1.73s  Val. loss: 0.1748\n",
      "Epoch 15, 100% \t Train loss: 0.1769 took: 1.74s  Val. loss: 0.1782\n",
      "Epoch 16, 100% \t Train loss: 0.1736 took: 1.73s  Val. loss: 0.1730\n",
      "Epoch 17, 100% \t Train loss: 0.1699 took: 1.74s  Val. loss: 0.1661\n",
      "Epoch 18, 100% \t Train loss: 0.1658 took: 1.74s  Val. loss: 0.1658\n",
      "Epoch 19, 100% \t Train loss: 0.1617 took: 1.76s  Val. loss: 0.1610\n",
      "Epoch 20, 100% \t Train loss: 0.1569 took: 1.74s  Val. loss: 0.1586\n",
      "Epoch 21, 100% \t Train loss: 0.1541 took: 1.74s  Val. loss: 0.1603\n",
      "Epoch 22, 100% \t Train loss: 0.1515 took: 1.75s  Val. loss: 0.1548\n",
      "Epoch 23, 100% \t Train loss: 0.1500 took: 1.76s  Val. loss: 0.1542\n",
      "Epoch 24, 100% \t Train loss: 0.1470 took: 1.75s  Val. loss: 0.1536\n",
      "Epoch 25, 100% \t Train loss: 0.1452 took: 1.75s  Val. loss: 0.1456\n",
      "Epoch 26, 100% \t Train loss: 0.1425 took: 1.76s  Val. loss: 0.1422\n",
      "Epoch 27, 100% \t Train loss: 0.1411 took: 1.76s  Val. loss: 0.1408\n",
      "Epoch 28, 100% \t Train loss: 0.1392 took: 1.75s  Val. loss: 0.1444\n",
      "Epoch 29, 100% \t Train loss: 0.1385 took: 1.75s  Val. loss: 0.1378\n",
      "Epoch 30, 100% \t Train loss: 0.1388 took: 1.77s  Val. loss: 0.1391\n",
      "Epoch 31, 100% \t Train loss: 0.1362 took: 1.78s  Val. loss: 0.1498\n",
      "Epoch 32, 100% \t Train loss: 0.1376 took: 1.82s  Val. loss: 0.1359\n",
      "Epoch 33, 100% \t Train loss: 0.1347 took: 1.88s  Val. loss: 0.1384\n",
      "Epoch 34, 100% \t Train loss: 0.1354 took: 1.91s  Val. loss: 0.1358\n",
      "Epoch 35, 100% \t Train loss: 0.1333 took: 1.92s  Val. loss: 0.1327\n",
      "Epoch 36, 100% \t Train loss: 0.1330 took: 1.91s  Val. loss: 0.1344\n",
      "Epoch 37, 100% \t Train loss: 0.1313 took: 1.15s  Val. loss: 0.1338\n",
      "Epoch 38, 100% \t Train loss: 0.1319 took: 1.15s  Val. loss: 0.1314\n",
      "Epoch 39, 100% \t Train loss: 0.1316 took: 1.14s  Val. loss: 0.1341\n",
      "Epoch 40, 100% \t Train loss: 0.1312 took: 1.17s  Val. loss: 0.1346\n",
      "Epoch 41, 100% \t Train loss: 0.1305 took: 1.18s  Val. loss: 0.1352\n",
      "Epoch 42, 100% \t Train loss: 0.1293 took: 1.19s  Val. loss: 0.1302\n",
      "Epoch 43, 100% \t Train loss: 0.1289 took: 1.18s  Val. loss: 0.1338\n",
      "Epoch 44, 100% \t Train loss: 0.1295 took: 1.14s  Val. loss: 0.1336\n",
      "Epoch 45, 100% \t Train loss: 0.1292 took: 1.09s  Val. loss: 0.1302\n",
      "Epoch 46, 100% \t Train loss: 0.1281 took: 1.08s  Val. loss: 0.1335\n",
      "Epoch 47, 100% \t Train loss: 0.1285 took: 1.09s  Val. loss: 0.1288\n",
      "Epoch 48, 100% \t Train loss: 0.1281 took: 1.08s  Val. loss: 0.1328\n",
      "Epoch 49, 100% \t Train loss: 0.1263 took: 1.09s  Val. loss: 0.1285\n",
      "Epoch 50, 100% \t Train loss: 0.1276 took: 1.08s  Val. loss: 0.1290\n",
      "Training finished, took 90.79s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2606 took: 1.01s  Val. loss: 0.2623\n",
      "Epoch 2, 100% \t Train loss: 0.2601 took: 1.00s  Val. loss: 0.2625\n",
      "Epoch 3, 100% \t Train loss: 0.2598 took: 1.00s  Val. loss: 0.2637\n",
      "Epoch 4, 100% \t Train loss: 0.2590 took: 1.00s  Val. loss: 0.2623\n",
      "Epoch 5, 100% \t Train loss: 0.2512 took: 1.00s  Val. loss: 0.2418\n",
      "Epoch 6, 100% \t Train loss: 0.2194 took: 1.00s  Val. loss: 0.2185\n",
      "Epoch 7, 100% \t Train loss: 0.2040 took: 1.00s  Val. loss: 0.2061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.2019 took: 1.00s  Val. loss: 0.2083\n",
      "Epoch 9, 100% \t Train loss: 0.1995 took: 1.00s  Val. loss: 0.2045\n",
      "Epoch 10, 100% \t Train loss: 0.1984 took: 1.00s  Val. loss: 0.2010\n",
      "Epoch 11, 100% \t Train loss: 0.1981 took: 1.00s  Val. loss: 0.2030\n",
      "Epoch 12, 100% \t Train loss: 0.1956 took: 1.00s  Val. loss: 0.2023\n",
      "Epoch 13, 100% \t Train loss: 0.1959 took: 1.00s  Val. loss: 0.2020\n",
      "Epoch 14, 100% \t Train loss: 0.1949 took: 0.99s  Val. loss: 0.2016\n",
      "Epoch 15, 100% \t Train loss: 0.1951 took: 1.02s  Val. loss: 0.2081\n",
      "Epoch 16, 100% \t Train loss: 0.1936 took: 1.72s  Val. loss: 0.2026\n",
      "Epoch 17, 100% \t Train loss: 0.1924 took: 1.74s  Val. loss: 0.2029\n",
      "Epoch 18, 100% \t Train loss: 0.1910 took: 1.73s  Val. loss: 0.1969\n",
      "Epoch 19, 100% \t Train loss: 0.1906 took: 1.73s  Val. loss: 0.1986\n",
      "Epoch 20, 100% \t Train loss: 0.1898 took: 1.76s  Val. loss: 0.2092\n",
      "Epoch 21, 100% \t Train loss: 0.1894 took: 1.73s  Val. loss: 0.2036\n",
      "Epoch 22, 100% \t Train loss: 0.1898 took: 1.74s  Val. loss: 0.1999\n",
      "Epoch 23, 100% \t Train loss: 0.1895 took: 1.73s  Val. loss: 0.1988\n",
      "Epoch 24, 100% \t Train loss: 0.1881 took: 1.73s  Val. loss: 0.1970\n",
      "Epoch 25, 100% \t Train loss: 0.1872 took: 1.73s  Val. loss: 0.1978\n",
      "Epoch 26, 100% \t Train loss: 0.1879 took: 1.76s  Val. loss: 0.1991\n",
      "Epoch 27, 100% \t Train loss: 0.1865 took: 1.75s  Val. loss: 0.1987\n",
      "Epoch 28, 100% \t Train loss: 0.1866 took: 1.75s  Val. loss: 0.1928\n",
      "Epoch 29, 100% \t Train loss: 0.1885 took: 1.74s  Val. loss: 0.2004\n",
      "Epoch 30, 100% \t Train loss: 0.1850 took: 1.74s  Val. loss: 0.1948\n",
      "Epoch 31, 100% \t Train loss: 0.1845 took: 1.75s  Val. loss: 0.1942\n",
      "Epoch 32, 100% \t Train loss: 0.1836 took: 1.74s  Val. loss: 0.1953\n",
      "Epoch 33, 100% \t Train loss: 0.1839 took: 1.74s  Val. loss: 0.1985\n",
      "Epoch 34, 100% \t Train loss: 0.1842 took: 1.75s  Val. loss: 0.1933\n",
      "Epoch 35, 100% \t Train loss: 0.1828 took: 1.74s  Val. loss: 0.1958\n",
      "Epoch 36, 100% \t Train loss: 0.1825 took: 1.74s  Val. loss: 0.1932\n",
      "Epoch 37, 100% \t Train loss: 0.1823 took: 1.73s  Val. loss: 0.1916\n",
      "Epoch 38, 100% \t Train loss: 0.1815 took: 1.73s  Val. loss: 0.1910\n",
      "Epoch 39, 100% \t Train loss: 0.1816 took: 1.75s  Val. loss: 0.1888\n",
      "Epoch 40, 100% \t Train loss: 0.1797 took: 1.75s  Val. loss: 0.1960\n",
      "Epoch 41, 100% \t Train loss: 0.1782 took: 1.73s  Val. loss: 0.1944\n",
      "Epoch 42, 100% \t Train loss: 0.1775 took: 1.74s  Val. loss: 0.1864\n",
      "Epoch 43, 100% \t Train loss: 0.1773 took: 1.74s  Val. loss: 0.1839\n",
      "Epoch 44, 100% \t Train loss: 0.1747 took: 1.75s  Val. loss: 0.1821\n",
      "Epoch 45, 100% \t Train loss: 0.1738 took: 1.72s  Val. loss: 0.1839\n",
      "Epoch 46, 100% \t Train loss: 0.1717 took: 1.75s  Val. loss: 0.1825\n",
      "Epoch 47, 100% \t Train loss: 0.1710 took: 1.75s  Val. loss: 0.1887\n",
      "Epoch 48, 100% \t Train loss: 0.1712 took: 1.75s  Val. loss: 0.1829\n",
      "Epoch 49, 100% \t Train loss: 0.1697 took: 1.75s  Val. loss: 0.1828\n",
      "Epoch 50, 100% \t Train loss: 0.1664 took: 1.00s  Val. loss: 0.1769\n",
      "Training finished, took 85.77s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2538 took: 1.01s  Val. loss: 0.2500\n",
      "Epoch 2, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2513\n",
      "Epoch 3, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2502\n",
      "Epoch 4, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2511\n",
      "Epoch 5, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2511\n",
      "Epoch 6, 100% \t Train loss: 0.2532 took: 1.00s  Val. loss: 0.2504\n",
      "Epoch 7, 100% \t Train loss: 0.2530 took: 1.00s  Val. loss: 0.2507\n",
      "Epoch 8, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2508\n",
      "Epoch 9, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2503\n",
      "Epoch 10, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2505\n",
      "Epoch 11, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2512\n",
      "Epoch 12, 100% \t Train loss: 0.2530 took: 1.00s  Val. loss: 0.2508\n",
      "Epoch 13, 100% \t Train loss: 0.2531 took: 1.00s  Val. loss: 0.2512\n",
      "Epoch 14, 100% \t Train loss: 0.2530 took: 1.00s  Val. loss: 0.2510\n",
      "Epoch 15, 100% \t Train loss: 0.2529 took: 1.00s  Val. loss: 0.2512\n",
      "Epoch 16, 100% \t Train loss: 0.2527 took: 1.00s  Val. loss: 0.2509\n",
      "Epoch 17, 100% \t Train loss: 0.2525 took: 1.00s  Val. loss: 0.2506\n",
      "Epoch 18, 100% \t Train loss: 0.2519 took: 1.00s  Val. loss: 0.2493\n",
      "Epoch 19, 100% \t Train loss: 0.2505 took: 1.00s  Val. loss: 0.2477\n",
      "Epoch 20, 100% \t Train loss: 0.2465 took: 1.00s  Val. loss: 0.2421\n",
      "Epoch 21, 100% \t Train loss: 0.2401 took: 1.00s  Val. loss: 0.2359\n",
      "Epoch 22, 100% \t Train loss: 0.2336 took: 1.06s  Val. loss: 0.2302\n",
      "Epoch 23, 100% \t Train loss: 0.2280 took: 1.00s  Val. loss: 0.2249\n",
      "Epoch 24, 100% \t Train loss: 0.2208 took: 1.00s  Val. loss: 0.2157\n",
      "Epoch 25, 100% \t Train loss: 0.2139 took: 1.00s  Val. loss: 0.2074\n",
      "Epoch 26, 100% \t Train loss: 0.2066 took: 1.00s  Val. loss: 0.2041\n",
      "Epoch 27, 100% \t Train loss: 0.2029 took: 1.00s  Val. loss: 0.1985\n",
      "Epoch 28, 100% \t Train loss: 0.1986 took: 1.00s  Val. loss: 0.1947\n",
      "Epoch 29, 100% \t Train loss: 0.1975 took: 1.00s  Val. loss: 0.1933\n",
      "Epoch 30, 100% \t Train loss: 0.1957 took: 1.01s  Val. loss: 0.1928\n",
      "Epoch 31, 100% \t Train loss: 0.1943 took: 1.02s  Val. loss: 0.1919\n",
      "Epoch 32, 100% \t Train loss: 0.1938 took: 1.71s  Val. loss: 0.1887\n",
      "Epoch 33, 100% \t Train loss: 0.1934 took: 1.77s  Val. loss: 0.1878\n",
      "Epoch 34, 100% \t Train loss: 0.1929 took: 1.78s  Val. loss: 0.1933\n",
      "Epoch 35, 100% \t Train loss: 0.1928 took: 1.81s  Val. loss: 0.1929\n",
      "Epoch 36, 100% \t Train loss: 0.1920 took: 1.86s  Val. loss: 0.1947\n",
      "Epoch 37, 100% \t Train loss: 0.1917 took: 1.83s  Val. loss: 0.1900\n",
      "Epoch 38, 100% \t Train loss: 0.1925 took: 1.79s  Val. loss: 0.1867\n",
      "Epoch 39, 100% \t Train loss: 0.1898 took: 1.79s  Val. loss: 0.1872\n",
      "Epoch 40, 100% \t Train loss: 0.1901 took: 1.79s  Val. loss: 0.1889\n",
      "Epoch 41, 100% \t Train loss: 0.1901 took: 1.79s  Val. loss: 0.1884\n",
      "Epoch 42, 100% \t Train loss: 0.1894 took: 1.81s  Val. loss: 0.1847\n",
      "Epoch 43, 100% \t Train loss: 0.1898 took: 1.63s  Val. loss: 0.1880\n",
      "Epoch 44, 100% \t Train loss: 0.1892 took: 1.72s  Val. loss: 0.1854\n",
      "Epoch 45, 100% \t Train loss: 0.1891 took: 1.66s  Val. loss: 0.1890\n",
      "Epoch 46, 100% \t Train loss: 0.1884 took: 1.74s  Val. loss: 0.1842\n",
      "Epoch 47, 100% \t Train loss: 0.1890 took: 1.67s  Val. loss: 0.1904\n",
      "Epoch 48, 100% \t Train loss: 0.1878 took: 1.61s  Val. loss: 0.1849\n",
      "Epoch 49, 100% \t Train loss: 0.1875 took: 1.70s  Val. loss: 0.1871\n",
      "Epoch 50, 100% \t Train loss: 0.1878 took: 1.94s  Val. loss: 0.1868\n",
      "Training finished, took 73.39s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.843012\n",
      "lambda: 0.0010 - V: 0.797538\n",
      "lambda: 0.0005 - V: 0.782576\n",
      "Average V: 0.807709\n",
      "Time elapsed: 253.32 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2613 took: 2.05s  Val. loss: 0.2631\n",
      "Epoch 2, 100% \t Train loss: 0.2595 took: 1.98s  Val. loss: 0.2630\n",
      "Epoch 3, 100% \t Train loss: 0.2591 took: 1.87s  Val. loss: 0.2631\n",
      "Epoch 4, 100% \t Train loss: 0.2593 took: 1.96s  Val. loss: 0.2635\n",
      "Epoch 5, 100% \t Train loss: 0.2568 took: 1.95s  Val. loss: 0.2469\n",
      "Epoch 6, 100% \t Train loss: 0.2128 took: 1.86s  Val. loss: 0.1964\n",
      "Epoch 7, 100% \t Train loss: 0.1839 took: 1.87s  Val. loss: 0.1737\n",
      "Epoch 8, 100% \t Train loss: 0.1757 took: 1.88s  Val. loss: 0.1745\n",
      "Epoch 9, 100% \t Train loss: 0.1705 took: 1.88s  Val. loss: 0.1690\n",
      "Epoch 10, 100% \t Train loss: 0.1693 took: 1.88s  Val. loss: 0.1647\n",
      "Epoch 11, 100% \t Train loss: 0.1670 took: 1.89s  Val. loss: 0.1644\n",
      "Epoch 12, 100% \t Train loss: 0.1651 took: 1.89s  Val. loss: 0.1633\n",
      "Epoch 13, 100% \t Train loss: 0.1641 took: 1.88s  Val. loss: 0.1589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.1637 took: 1.88s  Val. loss: 0.1658\n",
      "Epoch 15, 100% \t Train loss: 0.1648 took: 1.88s  Val. loss: 0.1623\n",
      "Epoch 16, 100% \t Train loss: 0.1628 took: 1.90s  Val. loss: 0.1597\n",
      "Epoch 17, 100% \t Train loss: 0.1607 took: 1.90s  Val. loss: 0.1639\n",
      "Epoch 18, 100% \t Train loss: 0.1615 took: 1.92s  Val. loss: 0.1624\n",
      "Epoch 19, 100% \t Train loss: 0.1603 took: 1.88s  Val. loss: 0.1603\n",
      "Epoch 20, 100% \t Train loss: 0.1593 took: 1.89s  Val. loss: 0.1592\n",
      "Epoch 21, 100% \t Train loss: 0.1593 took: 1.90s  Val. loss: 0.1612\n",
      "Epoch 22, 100% \t Train loss: 0.1581 took: 1.89s  Val. loss: 0.1635\n",
      "Epoch 23, 100% \t Train loss: 0.1579 took: 1.89s  Val. loss: 0.1630\n",
      "Epoch 24, 100% \t Train loss: 0.1578 took: 1.88s  Val. loss: 0.1624\n",
      "Epoch 25, 100% \t Train loss: 0.1569 took: 1.90s  Val. loss: 0.1612\n",
      "Epoch 26, 100% \t Train loss: 0.1559 took: 1.88s  Val. loss: 0.1642\n",
      "Epoch 27, 100% \t Train loss: 0.1558 took: 1.90s  Val. loss: 0.1635\n",
      "Epoch 28, 100% \t Train loss: 0.1556 took: 1.92s  Val. loss: 0.1592\n",
      "Epoch 29, 100% \t Train loss: 0.1541 took: 1.90s  Val. loss: 0.1623\n",
      "Epoch 30, 100% \t Train loss: 0.1540 took: 1.14s  Val. loss: 0.1608\n",
      "Epoch 31, 100% \t Train loss: 0.1517 took: 1.12s  Val. loss: 0.1602\n",
      "Epoch 32, 100% \t Train loss: 0.1500 took: 1.15s  Val. loss: 0.1566\n",
      "Epoch 33, 100% \t Train loss: 0.1468 took: 1.88s  Val. loss: 0.1568\n",
      "Epoch 34, 100% \t Train loss: 0.1438 took: 1.28s  Val. loss: 0.1541\n",
      "Epoch 35, 100% \t Train loss: 0.1390 took: 1.32s  Val. loss: 0.1483\n",
      "Epoch 36, 100% \t Train loss: 0.1352 took: 1.28s  Val. loss: 0.1519\n",
      "Epoch 37, 100% \t Train loss: 0.1318 took: 1.28s  Val. loss: 0.1422\n",
      "Epoch 38, 100% \t Train loss: 0.1278 took: 1.30s  Val. loss: 0.1400\n",
      "Epoch 39, 100% \t Train loss: 0.1241 took: 1.31s  Val. loss: 0.1329\n",
      "Epoch 40, 100% \t Train loss: 0.1225 took: 2.11s  Val. loss: 0.1385\n",
      "Epoch 41, 100% \t Train loss: 0.1169 took: 2.13s  Val. loss: 0.1379\n",
      "Epoch 42, 100% \t Train loss: 0.1167 took: 2.16s  Val. loss: 0.1347\n",
      "Epoch 43, 100% \t Train loss: 0.1114 took: 2.16s  Val. loss: 0.1301\n",
      "Epoch 44, 100% \t Train loss: 0.1099 took: 2.17s  Val. loss: 0.1306\n",
      "Epoch 45, 100% \t Train loss: 0.1079 took: 2.18s  Val. loss: 0.1240\n",
      "Epoch 46, 100% \t Train loss: 0.1065 took: 2.23s  Val. loss: 0.1312\n",
      "Epoch 47, 100% \t Train loss: 0.1042 took: 2.23s  Val. loss: 0.1237\n",
      "Epoch 48, 100% \t Train loss: 0.1019 took: 2.23s  Val. loss: 0.1279\n",
      "Epoch 49, 100% \t Train loss: 0.1011 took: 2.24s  Val. loss: 0.1259\n",
      "Epoch 50, 100% \t Train loss: 0.0989 took: 2.24s  Val. loss: 0.1226\n",
      "Training finished, took 104.56s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2595 took: 1.91s  Val. loss: 0.2587\n",
      "Epoch 2, 100% \t Train loss: 0.2594 took: 1.87s  Val. loss: 0.2596\n",
      "Epoch 3, 100% \t Train loss: 0.2588 took: 1.88s  Val. loss: 0.2593\n",
      "Epoch 4, 100% \t Train loss: 0.2572 took: 1.87s  Val. loss: 0.2522\n",
      "Epoch 5, 100% \t Train loss: 0.2307 took: 1.87s  Val. loss: 0.2136\n",
      "Epoch 6, 100% \t Train loss: 0.1918 took: 1.87s  Val. loss: 0.2036\n",
      "Epoch 7, 100% \t Train loss: 0.1780 took: 1.17s  Val. loss: 0.1880\n",
      "Epoch 8, 100% \t Train loss: 0.1744 took: 1.09s  Val. loss: 0.1859\n",
      "Epoch 9, 100% \t Train loss: 0.1737 took: 1.09s  Val. loss: 0.1889\n",
      "Epoch 10, 100% \t Train loss: 0.1681 took: 1.08s  Val. loss: 0.1840\n",
      "Epoch 11, 100% \t Train loss: 0.1654 took: 1.08s  Val. loss: 0.1854\n",
      "Epoch 12, 100% \t Train loss: 0.1640 took: 1.08s  Val. loss: 0.1792\n",
      "Epoch 13, 100% \t Train loss: 0.1626 took: 1.09s  Val. loss: 0.1856\n",
      "Epoch 14, 100% \t Train loss: 0.1620 took: 1.08s  Val. loss: 0.1766\n",
      "Epoch 15, 100% \t Train loss: 0.1600 took: 1.09s  Val. loss: 0.1772\n",
      "Epoch 16, 100% \t Train loss: 0.1580 took: 1.10s  Val. loss: 0.1799\n",
      "Epoch 17, 100% \t Train loss: 0.1576 took: 1.09s  Val. loss: 0.1758\n",
      "Epoch 18, 100% \t Train loss: 0.1575 took: 1.09s  Val. loss: 0.1758\n",
      "Epoch 19, 100% \t Train loss: 0.1564 took: 1.08s  Val. loss: 0.1804\n",
      "Epoch 20, 100% \t Train loss: 0.1569 took: 1.08s  Val. loss: 0.1782\n",
      "Epoch 21, 100% \t Train loss: 0.1557 took: 1.08s  Val. loss: 0.1765\n",
      "Epoch 22, 100% \t Train loss: 0.1536 took: 1.09s  Val. loss: 0.1758\n",
      "Epoch 23, 100% \t Train loss: 0.1527 took: 1.09s  Val. loss: 0.1722\n",
      "Epoch 24, 100% \t Train loss: 0.1520 took: 1.09s  Val. loss: 0.1835\n",
      "Epoch 25, 100% \t Train loss: 0.1516 took: 1.09s  Val. loss: 0.1740\n",
      "Epoch 26, 100% \t Train loss: 0.1507 took: 1.08s  Val. loss: 0.1906\n",
      "Epoch 27, 100% \t Train loss: 0.1500 took: 1.09s  Val. loss: 0.1738\n",
      "Epoch 28, 100% \t Train loss: 0.1488 took: 1.09s  Val. loss: 0.1739\n",
      "Epoch 29, 100% \t Train loss: 0.1506 took: 1.09s  Val. loss: 0.1754\n",
      "Epoch 30, 100% \t Train loss: 0.1480 took: 1.08s  Val. loss: 0.1745\n",
      "Epoch 31, 100% \t Train loss: 0.1478 took: 1.09s  Val. loss: 0.1756\n",
      "Epoch 32, 100% \t Train loss: 0.1473 took: 1.09s  Val. loss: 0.1764\n",
      "Epoch 33, 100% \t Train loss: 0.1468 took: 1.08s  Val. loss: 0.1746\n",
      "Epoch 34, 100% \t Train loss: 0.1464 took: 1.08s  Val. loss: 0.1781\n",
      "Epoch 35, 100% \t Train loss: 0.1452 took: 1.08s  Val. loss: 0.1746\n",
      "Epoch 36, 100% \t Train loss: 0.1445 took: 1.08s  Val. loss: 0.1741\n",
      "Epoch 37, 100% \t Train loss: 0.1437 took: 1.57s  Val. loss: 0.1740\n",
      "Epoch 38, 100% \t Train loss: 0.1447 took: 1.86s  Val. loss: 0.1762\n",
      "Epoch 39, 100% \t Train loss: 0.1413 took: 1.89s  Val. loss: 0.1712\n",
      "Epoch 40, 100% \t Train loss: 0.1413 took: 1.88s  Val. loss: 0.1730\n",
      "Epoch 41, 100% \t Train loss: 0.1394 took: 1.87s  Val. loss: 0.1709\n",
      "Epoch 42, 100% \t Train loss: 0.1385 took: 1.87s  Val. loss: 0.1720\n",
      "Epoch 43, 100% \t Train loss: 0.1383 took: 1.87s  Val. loss: 0.1695\n",
      "Epoch 44, 100% \t Train loss: 0.1368 took: 1.90s  Val. loss: 0.1701\n",
      "Epoch 45, 100% \t Train loss: 0.1363 took: 1.89s  Val. loss: 0.1655\n",
      "Epoch 46, 100% \t Train loss: 0.1342 took: 1.88s  Val. loss: 0.1718\n",
      "Epoch 47, 100% \t Train loss: 0.1337 took: 1.89s  Val. loss: 0.1679\n",
      "Epoch 48, 100% \t Train loss: 0.1315 took: 1.88s  Val. loss: 0.1636\n",
      "Epoch 49, 100% \t Train loss: 0.1299 took: 1.89s  Val. loss: 0.1638\n",
      "Epoch 50, 100% \t Train loss: 0.1270 took: 1.87s  Val. loss: 0.1572\n",
      "Training finished, took 78.98s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2608 took: 1.90s  Val. loss: 0.2540\n",
      "Epoch 2, 100% \t Train loss: 0.2600 took: 1.90s  Val. loss: 0.2527\n",
      "Epoch 3, 100% \t Train loss: 0.2599 took: 1.90s  Val. loss: 0.2528\n",
      "Epoch 4, 100% \t Train loss: 0.2594 took: 1.90s  Val. loss: 0.2516\n",
      "Epoch 5, 100% \t Train loss: 0.2584 took: 1.89s  Val. loss: 0.2487\n",
      "Epoch 6, 100% \t Train loss: 0.2531 took: 1.88s  Val. loss: 0.2339\n",
      "Epoch 7, 100% \t Train loss: 0.2423 took: 1.89s  Val. loss: 0.2225\n",
      "Epoch 8, 100% \t Train loss: 0.2302 took: 1.87s  Val. loss: 0.2118\n",
      "Epoch 9, 100% \t Train loss: 0.2179 took: 1.86s  Val. loss: 0.2011\n",
      "Epoch 10, 100% \t Train loss: 0.2091 took: 1.87s  Val. loss: 0.1968\n",
      "Epoch 11, 100% \t Train loss: 0.2025 took: 1.86s  Val. loss: 0.1944\n",
      "Epoch 12, 100% \t Train loss: 0.1986 took: 1.88s  Val. loss: 0.1867\n",
      "Epoch 13, 100% \t Train loss: 0.1941 took: 1.87s  Val. loss: 0.1856\n",
      "Epoch 14, 100% \t Train loss: 0.1950 took: 1.88s  Val. loss: 0.1799\n",
      "Epoch 15, 100% \t Train loss: 0.1885 took: 1.89s  Val. loss: 0.1822\n",
      "Epoch 16, 100% \t Train loss: 0.1906 took: 1.87s  Val. loss: 0.1807\n",
      "Epoch 17, 100% \t Train loss: 0.1859 took: 1.89s  Val. loss: 0.1755\n",
      "Epoch 18, 100% \t Train loss: 0.1859 took: 1.89s  Val. loss: 0.1762\n",
      "Epoch 19, 100% \t Train loss: 0.1826 took: 1.86s  Val. loss: 0.1741\n",
      "Epoch 20, 100% \t Train loss: 0.1822 took: 1.87s  Val. loss: 0.1716\n",
      "Epoch 21, 100% \t Train loss: 0.1782 took: 1.87s  Val. loss: 0.1672\n",
      "Epoch 22, 100% \t Train loss: 0.1777 took: 1.87s  Val. loss: 0.1672\n",
      "Epoch 23, 100% \t Train loss: 0.1780 took: 1.85s  Val. loss: 0.1647\n",
      "Epoch 24, 100% \t Train loss: 0.1770 took: 1.86s  Val. loss: 0.1646\n",
      "Epoch 25, 100% \t Train loss: 0.1725 took: 1.87s  Val. loss: 0.1682\n",
      "Epoch 26, 100% \t Train loss: 0.1767 took: 1.88s  Val. loss: 0.1738\n",
      "Epoch 27, 100% \t Train loss: 0.1710 took: 1.87s  Val. loss: 0.1642\n",
      "Epoch 28, 100% \t Train loss: 0.1696 took: 1.87s  Val. loss: 0.1610\n",
      "Epoch 29, 100% \t Train loss: 0.1706 took: 1.87s  Val. loss: 0.1626\n",
      "Epoch 30, 100% \t Train loss: 0.1672 took: 1.89s  Val. loss: 0.1643\n",
      "Epoch 31, 100% \t Train loss: 0.1662 took: 1.88s  Val. loss: 0.1644\n",
      "Epoch 32, 100% \t Train loss: 0.1658 took: 1.88s  Val. loss: 0.1602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, 100% \t Train loss: 0.1630 took: 1.87s  Val. loss: 0.1596\n",
      "Epoch 34, 100% \t Train loss: 0.1643 took: 1.88s  Val. loss: 0.1577\n",
      "Epoch 35, 100% \t Train loss: 0.1604 took: 1.93s  Val. loss: 0.1579\n",
      "Epoch 36, 100% \t Train loss: 0.1589 took: 1.91s  Val. loss: 0.1565\n",
      "Epoch 37, 100% \t Train loss: 0.1590 took: 1.88s  Val. loss: 0.1586\n",
      "Epoch 38, 100% \t Train loss: 0.1576 took: 1.88s  Val. loss: 0.1614\n",
      "Epoch 39, 100% \t Train loss: 0.1538 took: 1.89s  Val. loss: 0.1558\n",
      "Epoch 40, 100% \t Train loss: 0.1525 took: 1.90s  Val. loss: 0.1524\n",
      "Epoch 41, 100% \t Train loss: 0.1536 took: 1.88s  Val. loss: 0.1556\n",
      "Epoch 42, 100% \t Train loss: 0.1490 took: 1.89s  Val. loss: 0.1595\n",
      "Epoch 43, 100% \t Train loss: 0.1476 took: 1.89s  Val. loss: 0.1539\n",
      "Epoch 44, 100% \t Train loss: 0.1460 took: 1.88s  Val. loss: 0.1500\n",
      "Epoch 45, 100% \t Train loss: 0.1449 took: 1.88s  Val. loss: 0.1520\n",
      "Epoch 46, 100% \t Train loss: 0.1424 took: 1.88s  Val. loss: 0.1462\n",
      "Epoch 47, 100% \t Train loss: 0.1405 took: 1.90s  Val. loss: 0.1454\n",
      "Epoch 48, 100% \t Train loss: 0.1389 took: 1.89s  Val. loss: 0.1520\n",
      "Epoch 49, 100% \t Train loss: 0.1387 took: 1.89s  Val. loss: 0.1407\n",
      "Epoch 50, 100% \t Train loss: 0.1336 took: 1.90s  Val. loss: 0.1430\n",
      "Training finished, took 106.78s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.836210\n",
      "lambda: 0.0010 - V: 0.816432\n",
      "lambda: 0.0005 - V: 0.822529\n",
      "Average V: 0.825057\n",
      "Time elapsed: 293.72 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2608 took: 1.93s  Val. loss: 0.2607\n",
      "Epoch 2, 100% \t Train loss: 0.2586 took: 1.17s  Val. loss: 0.2591\n",
      "Epoch 3, 100% \t Train loss: 0.2123 took: 1.17s  Val. loss: 0.1769\n",
      "Epoch 4, 100% \t Train loss: 0.1717 took: 1.17s  Val. loss: 0.1693\n",
      "Epoch 5, 100% \t Train loss: 0.1670 took: 1.18s  Val. loss: 0.1697\n",
      "Epoch 6, 100% \t Train loss: 0.1645 took: 1.18s  Val. loss: 0.1677\n",
      "Epoch 7, 100% \t Train loss: 0.1630 took: 1.18s  Val. loss: 0.1677\n",
      "Epoch 8, 100% \t Train loss: 0.1591 took: 1.17s  Val. loss: 0.1627\n",
      "Epoch 9, 100% \t Train loss: 0.1553 took: 1.17s  Val. loss: 0.1615\n",
      "Epoch 10, 100% \t Train loss: 0.1523 took: 1.18s  Val. loss: 0.1617\n",
      "Epoch 11, 100% \t Train loss: 0.1500 took: 1.18s  Val. loss: 0.1626\n",
      "Epoch 12, 100% \t Train loss: 0.1485 took: 1.17s  Val. loss: 0.1629\n",
      "Epoch 13, 100% \t Train loss: 0.1483 took: 1.17s  Val. loss: 0.1625\n",
      "Epoch 14, 100% \t Train loss: 0.1463 took: 1.22s  Val. loss: 0.1630\n",
      "Epoch 15, 100% \t Train loss: 0.1463 took: 1.17s  Val. loss: 0.1623\n",
      "Epoch 16, 100% \t Train loss: 0.1463 took: 1.17s  Val. loss: 0.1616\n",
      "Epoch 17, 100% \t Train loss: 0.1452 took: 1.17s  Val. loss: 0.1603\n",
      "Epoch 18, 100% \t Train loss: 0.1443 took: 1.16s  Val. loss: 0.1607\n",
      "Epoch 19, 100% \t Train loss: 0.1441 took: 1.17s  Val. loss: 0.1648\n",
      "Epoch 20, 100% \t Train loss: 0.1431 took: 1.17s  Val. loss: 0.1602\n",
      "Epoch 21, 100% \t Train loss: 0.1426 took: 1.17s  Val. loss: 0.1595\n",
      "Epoch 22, 100% \t Train loss: 0.1411 took: 1.18s  Val. loss: 0.1573\n",
      "Epoch 23, 100% \t Train loss: 0.1375 took: 1.18s  Val. loss: 0.1530\n",
      "Epoch 24, 100% \t Train loss: 0.1311 took: 1.17s  Val. loss: 0.1472\n",
      "Epoch 25, 100% \t Train loss: 0.1208 took: 1.17s  Val. loss: 0.1356\n",
      "Epoch 26, 100% \t Train loss: 0.1117 took: 1.17s  Val. loss: 0.1300\n",
      "Epoch 27, 100% \t Train loss: 0.1048 took: 1.18s  Val. loss: 0.1258\n",
      "Epoch 28, 100% \t Train loss: 0.0998 took: 1.21s  Val. loss: 0.1168\n",
      "Epoch 29, 100% \t Train loss: 0.0929 took: 1.24s  Val. loss: 0.1138\n",
      "Epoch 30, 100% \t Train loss: 0.0890 took: 1.25s  Val. loss: 0.1096\n",
      "Epoch 31, 100% \t Train loss: 0.0848 took: 1.27s  Val. loss: 0.1021\n",
      "Epoch 32, 100% \t Train loss: 0.0826 took: 1.70s  Val. loss: 0.1088\n",
      "Epoch 33, 100% \t Train loss: 0.0795 took: 2.34s  Val. loss: 0.1008\n",
      "Epoch 34, 100% \t Train loss: 0.0782 took: 2.40s  Val. loss: 0.0986\n",
      "Epoch 35, 100% \t Train loss: 0.0764 took: 2.39s  Val. loss: 0.0996\n",
      "Epoch 36, 100% \t Train loss: 0.0748 took: 2.42s  Val. loss: 0.1007\n",
      "Epoch 37, 100% \t Train loss: 0.0734 took: 2.40s  Val. loss: 0.0979\n",
      "Epoch 38, 100% \t Train loss: 0.0727 took: 2.42s  Val. loss: 0.0996\n",
      "Epoch 39, 100% \t Train loss: 0.0717 took: 2.43s  Val. loss: 0.0990\n",
      "Epoch 40, 100% \t Train loss: 0.0712 took: 2.09s  Val. loss: 0.0932\n",
      "Epoch 41, 100% \t Train loss: 0.0695 took: 2.46s  Val. loss: 0.0951\n",
      "Epoch 42, 100% \t Train loss: 0.0691 took: 2.50s  Val. loss: 0.0977\n",
      "Epoch 43, 100% \t Train loss: 0.0683 took: 2.48s  Val. loss: 0.0978\n",
      "Epoch 44, 100% \t Train loss: 0.0689 took: 2.50s  Val. loss: 0.0988\n",
      "Epoch 45, 100% \t Train loss: 0.0683 took: 2.52s  Val. loss: 0.1010\n",
      "Epoch 46, 100% \t Train loss: 0.0669 took: 1.72s  Val. loss: 0.0993\n",
      "Epoch 47, 100% \t Train loss: 0.0664 took: 1.73s  Val. loss: 0.0944\n",
      "Epoch 48, 100% \t Train loss: 0.0656 took: 1.72s  Val. loss: 0.0962\n",
      "Epoch 49, 100% \t Train loss: 0.0653 took: 1.73s  Val. loss: 0.0972\n",
      "Epoch 50, 100% \t Train loss: 0.0646 took: 2.56s  Val. loss: 0.0999\n",
      "Training finished, took 89.97s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 1.98s  Val. loss: 0.2600\n",
      "Epoch 2, 100% \t Train loss: 0.2563 took: 1.97s  Val. loss: 0.2628\n",
      "Epoch 3, 100% \t Train loss: 0.2562 took: 1.97s  Val. loss: 0.2618\n",
      "Epoch 4, 100% \t Train loss: 0.2560 took: 1.98s  Val. loss: 0.2608\n",
      "Epoch 5, 100% \t Train loss: 0.2514 took: 1.96s  Val. loss: 0.2442\n",
      "Epoch 6, 100% \t Train loss: 0.2250 took: 1.95s  Val. loss: 0.2103\n",
      "Epoch 7, 100% \t Train loss: 0.1966 took: 1.95s  Val. loss: 0.1860\n",
      "Epoch 8, 100% \t Train loss: 0.1871 took: 1.95s  Val. loss: 0.1872\n",
      "Epoch 9, 100% \t Train loss: 0.1819 took: 1.94s  Val. loss: 0.1856\n",
      "Epoch 10, 100% \t Train loss: 0.1803 took: 1.94s  Val. loss: 0.1777\n",
      "Epoch 11, 100% \t Train loss: 0.1762 took: 1.94s  Val. loss: 0.1817\n",
      "Epoch 12, 100% \t Train loss: 0.1750 took: 1.98s  Val. loss: 0.1822\n",
      "Epoch 13, 100% \t Train loss: 0.1744 took: 1.95s  Val. loss: 0.1800\n",
      "Epoch 14, 100% \t Train loss: 0.1736 took: 1.96s  Val. loss: 0.1724\n",
      "Epoch 15, 100% \t Train loss: 0.1713 took: 1.96s  Val. loss: 0.1757\n",
      "Epoch 16, 100% \t Train loss: 0.1707 took: 1.96s  Val. loss: 0.1722\n",
      "Epoch 17, 100% \t Train loss: 0.1687 took: 1.95s  Val. loss: 0.1725\n",
      "Epoch 18, 100% \t Train loss: 0.1668 took: 1.95s  Val. loss: 0.1669\n",
      "Epoch 19, 100% \t Train loss: 0.1641 took: 1.95s  Val. loss: 0.1651\n",
      "Epoch 20, 100% \t Train loss: 0.1627 took: 1.97s  Val. loss: 0.1635\n",
      "Epoch 21, 100% \t Train loss: 0.1596 took: 1.98s  Val. loss: 0.1671\n",
      "Epoch 22, 100% \t Train loss: 0.1600 took: 1.95s  Val. loss: 0.1601\n",
      "Epoch 23, 100% \t Train loss: 0.1577 took: 1.96s  Val. loss: 0.1581\n",
      "Epoch 24, 100% \t Train loss: 0.1563 took: 1.95s  Val. loss: 0.1610\n",
      "Epoch 25, 100% \t Train loss: 0.1553 took: 1.96s  Val. loss: 0.1582\n",
      "Epoch 26, 100% \t Train loss: 0.1521 took: 1.96s  Val. loss: 0.1536\n",
      "Epoch 27, 100% \t Train loss: 0.1507 took: 1.96s  Val. loss: 0.1509\n",
      "Epoch 28, 100% \t Train loss: 0.1478 took: 1.97s  Val. loss: 0.1553\n",
      "Epoch 29, 100% \t Train loss: 0.1463 took: 2.00s  Val. loss: 0.1505\n",
      "Epoch 30, 100% \t Train loss: 0.1450 took: 2.05s  Val. loss: 0.1516\n",
      "Epoch 31, 100% \t Train loss: 0.1439 took: 2.09s  Val. loss: 0.1478\n",
      "Epoch 32, 100% \t Train loss: 0.1424 took: 2.17s  Val. loss: 0.1459\n",
      "Epoch 33, 100% \t Train loss: 0.1413 took: 2.19s  Val. loss: 0.1432\n",
      "Epoch 34, 100% \t Train loss: 0.1402 took: 2.21s  Val. loss: 0.1469\n",
      "Epoch 35, 100% \t Train loss: 0.1383 took: 2.23s  Val. loss: 0.1454\n",
      "Epoch 36, 100% \t Train loss: 0.1373 took: 2.24s  Val. loss: 0.1405\n",
      "Epoch 37, 100% \t Train loss: 0.1345 took: 2.24s  Val. loss: 0.1408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, 100% \t Train loss: 0.1358 took: 2.23s  Val. loss: 0.1375\n",
      "Epoch 39, 100% \t Train loss: 0.1341 took: 2.23s  Val. loss: 0.1418\n",
      "Epoch 40, 100% \t Train loss: 0.1301 took: 2.25s  Val. loss: 0.1383\n",
      "Epoch 41, 100% \t Train loss: 0.1280 took: 2.25s  Val. loss: 0.1351\n",
      "Epoch 42, 100% \t Train loss: 0.1255 took: 2.25s  Val. loss: 0.1324\n",
      "Epoch 43, 100% \t Train loss: 0.1261 took: 2.26s  Val. loss: 0.1306\n",
      "Epoch 44, 100% \t Train loss: 0.1214 took: 2.25s  Val. loss: 0.1438\n",
      "Epoch 45, 100% \t Train loss: 0.1222 took: 2.26s  Val. loss: 0.1292\n",
      "Epoch 46, 100% \t Train loss: 0.1178 took: 2.26s  Val. loss: 0.1279\n",
      "Epoch 47, 100% \t Train loss: 0.1201 took: 2.27s  Val. loss: 0.1345\n",
      "Epoch 48, 100% \t Train loss: 0.1131 took: 2.28s  Val. loss: 0.1226\n",
      "Epoch 49, 100% \t Train loss: 0.1133 took: 2.28s  Val. loss: 0.1218\n",
      "Epoch 50, 100% \t Train loss: 0.1099 took: 2.28s  Val. loss: 0.1216\n",
      "Training finished, took 116.68s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2576 took: 1.94s  Val. loss: 0.2525\n",
      "Epoch 2, 100% \t Train loss: 0.2569 took: 1.94s  Val. loss: 0.2526\n",
      "Epoch 3, 100% \t Train loss: 0.2556 took: 1.93s  Val. loss: 0.2510\n",
      "Epoch 4, 100% \t Train loss: 0.2405 took: 1.94s  Val. loss: 0.2185\n",
      "Epoch 5, 100% \t Train loss: 0.2025 took: 1.98s  Val. loss: 0.1903\n",
      "Epoch 6, 100% \t Train loss: 0.1827 took: 1.99s  Val. loss: 0.1791\n",
      "Epoch 7, 100% \t Train loss: 0.1792 took: 1.96s  Val. loss: 0.1781\n",
      "Epoch 8, 100% \t Train loss: 0.1723 took: 1.97s  Val. loss: 0.1885\n",
      "Epoch 9, 100% \t Train loss: 0.1694 took: 1.95s  Val. loss: 0.1708\n",
      "Epoch 10, 100% \t Train loss: 0.1685 took: 1.96s  Val. loss: 0.1733\n",
      "Epoch 11, 100% \t Train loss: 0.1668 took: 1.98s  Val. loss: 0.1737\n",
      "Epoch 12, 100% \t Train loss: 0.1657 took: 1.98s  Val. loss: 0.1699\n",
      "Epoch 13, 100% \t Train loss: 0.1647 took: 1.97s  Val. loss: 0.1705\n",
      "Epoch 14, 100% \t Train loss: 0.1635 took: 1.95s  Val. loss: 0.1694\n",
      "Epoch 15, 100% \t Train loss: 0.1634 took: 1.95s  Val. loss: 0.1720\n",
      "Epoch 16, 100% \t Train loss: 0.1613 took: 1.96s  Val. loss: 0.1694\n",
      "Epoch 17, 100% \t Train loss: 0.1603 took: 1.94s  Val. loss: 0.1685\n",
      "Epoch 18, 100% \t Train loss: 0.1601 took: 1.94s  Val. loss: 0.1736\n",
      "Epoch 19, 100% \t Train loss: 0.1584 took: 1.95s  Val. loss: 0.1742\n",
      "Epoch 20, 100% \t Train loss: 0.1559 took: 1.94s  Val. loss: 0.1685\n",
      "Epoch 21, 100% \t Train loss: 0.1542 took: 1.93s  Val. loss: 0.1660\n",
      "Epoch 22, 100% \t Train loss: 0.1535 took: 1.94s  Val. loss: 0.1621\n",
      "Epoch 23, 100% \t Train loss: 0.1535 took: 1.95s  Val. loss: 0.1748\n",
      "Epoch 24, 100% \t Train loss: 0.1529 took: 1.99s  Val. loss: 0.1623\n",
      "Epoch 25, 100% \t Train loss: 0.1473 took: 1.98s  Val. loss: 0.1560\n",
      "Epoch 26, 100% \t Train loss: 0.1453 took: 1.96s  Val. loss: 0.1579\n",
      "Epoch 27, 100% \t Train loss: 0.1407 took: 1.99s  Val. loss: 0.1532\n",
      "Epoch 28, 100% \t Train loss: 0.1379 took: 1.97s  Val. loss: 0.1512\n",
      "Epoch 29, 100% \t Train loss: 0.1321 took: 1.98s  Val. loss: 0.1473\n",
      "Epoch 30, 100% \t Train loss: 0.1309 took: 2.01s  Val. loss: 0.1407\n",
      "Epoch 31, 100% \t Train loss: 0.1248 took: 2.00s  Val. loss: 0.1357\n",
      "Epoch 32, 100% \t Train loss: 0.1212 took: 2.03s  Val. loss: 0.1304\n",
      "Epoch 33, 100% \t Train loss: 0.1168 took: 2.03s  Val. loss: 0.1259\n",
      "Epoch 34, 100% \t Train loss: 0.1139 took: 2.05s  Val. loss: 0.1247\n",
      "Epoch 35, 100% \t Train loss: 0.1095 took: 2.02s  Val. loss: 0.1161\n",
      "Epoch 36, 100% \t Train loss: 0.1058 took: 2.04s  Val. loss: 0.1169\n",
      "Epoch 37, 100% \t Train loss: 0.1053 took: 2.03s  Val. loss: 0.1137\n",
      "Epoch 38, 100% \t Train loss: 0.1023 took: 2.04s  Val. loss: 0.1141\n",
      "Epoch 39, 100% \t Train loss: 0.1000 took: 2.04s  Val. loss: 0.1083\n",
      "Epoch 40, 100% \t Train loss: 0.0973 took: 2.06s  Val. loss: 0.1093\n",
      "Epoch 41, 100% \t Train loss: 0.0962 took: 2.08s  Val. loss: 0.1077\n",
      "Epoch 42, 100% \t Train loss: 0.0939 took: 2.08s  Val. loss: 0.1050\n",
      "Epoch 43, 100% \t Train loss: 0.0913 took: 2.08s  Val. loss: 0.1021\n",
      "Epoch 44, 100% \t Train loss: 0.0899 took: 2.09s  Val. loss: 0.1017\n",
      "Epoch 45, 100% \t Train loss: 0.0899 took: 2.13s  Val. loss: 0.1035\n",
      "Epoch 46, 100% \t Train loss: 0.0918 took: 2.09s  Val. loss: 0.0991\n",
      "Epoch 47, 100% \t Train loss: 0.0880 took: 2.11s  Val. loss: 0.0975\n",
      "Epoch 48, 100% \t Train loss: 0.0853 took: 2.10s  Val. loss: 0.0950\n",
      "Epoch 49, 100% \t Train loss: 0.0837 took: 2.11s  Val. loss: 0.0991\n",
      "Epoch 50, 100% \t Train loss: 0.0840 took: 2.10s  Val. loss: 0.1017\n",
      "Training finished, took 112.93s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.863918\n",
      "lambda: 0.0010 - V: 0.834754\n",
      "lambda: 0.0005 - V: 0.849138\n",
      "Average V: 0.849270\n",
      "Time elapsed: 322.97 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2604 took: 1.84s  Val. loss: 0.2542\n",
      "Epoch 2, 100% \t Train loss: 0.2597 took: 1.83s  Val. loss: 0.2543\n",
      "Epoch 3, 100% \t Train loss: 0.2597 took: 1.83s  Val. loss: 0.2531\n",
      "Epoch 4, 100% \t Train loss: 0.2596 took: 1.82s  Val. loss: 0.2542\n",
      "Epoch 5, 100% \t Train loss: 0.2537 took: 1.80s  Val. loss: 0.2272\n",
      "Epoch 6, 100% \t Train loss: 0.1901 took: 1.81s  Val. loss: 0.1864\n",
      "Epoch 7, 100% \t Train loss: 0.1702 took: 1.81s  Val. loss: 0.1712\n",
      "Epoch 8, 100% \t Train loss: 0.1614 took: 1.81s  Val. loss: 0.1711\n",
      "Epoch 9, 100% \t Train loss: 0.1527 took: 1.84s  Val. loss: 0.1562\n",
      "Epoch 10, 100% \t Train loss: 0.1463 took: 1.82s  Val. loss: 0.1470\n",
      "Epoch 11, 100% \t Train loss: 0.1347 took: 1.81s  Val. loss: 0.1345\n",
      "Epoch 12, 100% \t Train loss: 0.1245 took: 1.80s  Val. loss: 0.1320\n",
      "Epoch 13, 100% \t Train loss: 0.1159 took: 1.05s  Val. loss: 0.1178\n",
      "Epoch 14, 100% \t Train loss: 0.1077 took: 1.54s  Val. loss: 0.1117\n",
      "Epoch 15, 100% \t Train loss: 0.1014 took: 1.04s  Val. loss: 0.1168\n",
      "Epoch 16, 100% \t Train loss: 0.0978 took: 1.04s  Val. loss: 0.1040\n",
      "Epoch 17, 100% \t Train loss: 0.0949 took: 1.04s  Val. loss: 0.1030\n",
      "Epoch 18, 100% \t Train loss: 0.0903 took: 1.04s  Val. loss: 0.1063\n",
      "Epoch 19, 100% \t Train loss: 0.0910 took: 1.03s  Val. loss: 0.0978\n",
      "Epoch 20, 100% \t Train loss: 0.0863 took: 1.04s  Val. loss: 0.0944\n",
      "Epoch 21, 100% \t Train loss: 0.0876 took: 1.04s  Val. loss: 0.0910\n",
      "Epoch 22, 100% \t Train loss: 0.0826 took: 1.04s  Val. loss: 0.0922\n",
      "Epoch 23, 100% \t Train loss: 0.0832 took: 1.04s  Val. loss: 0.0968\n",
      "Epoch 24, 100% \t Train loss: 0.0828 took: 1.04s  Val. loss: 0.0942\n",
      "Epoch 25, 100% \t Train loss: 0.0816 took: 1.03s  Val. loss: 0.0958\n",
      "Epoch 26, 100% \t Train loss: 0.0809 took: 1.03s  Val. loss: 0.0932\n",
      "Epoch 27, 100% \t Train loss: 0.0788 took: 1.04s  Val. loss: 0.0936\n",
      "Epoch 28, 100% \t Train loss: 0.0803 took: 1.03s  Val. loss: 0.1016\n",
      "Epoch 29, 100% \t Train loss: 0.0792 took: 1.04s  Val. loss: 0.0902\n",
      "Epoch 30, 100% \t Train loss: 0.0755 took: 1.04s  Val. loss: 0.0909\n",
      "Epoch 31, 100% \t Train loss: 0.0762 took: 1.04s  Val. loss: 0.0882\n",
      "Epoch 32, 100% \t Train loss: 0.0769 took: 1.05s  Val. loss: 0.0862\n",
      "Epoch 33, 100% \t Train loss: 0.0764 took: 1.10s  Val. loss: 0.0938\n",
      "Epoch 34, 100% \t Train loss: 0.0754 took: 1.10s  Val. loss: 0.0906\n",
      "Epoch 35, 100% \t Train loss: 0.0756 took: 1.11s  Val. loss: 0.0893\n",
      "Epoch 36, 100% \t Train loss: 0.0745 took: 1.11s  Val. loss: 0.0916\n",
      "Epoch 37, 100% \t Train loss: 0.0749 took: 1.11s  Val. loss: 0.0934\n",
      "Epoch 38, 100% \t Train loss: 0.0733 took: 1.11s  Val. loss: 0.0925\n",
      "Epoch 39, 100% \t Train loss: 0.0742 took: 1.11s  Val. loss: 0.0905\n",
      "Epoch 40, 100% \t Train loss: 0.0753 took: 1.16s  Val. loss: 0.0930\n",
      "Epoch 41, 100% \t Train loss: 0.0728 took: 1.11s  Val. loss: 0.0945\n",
      "Epoch 42, 100% \t Train loss: 0.0724 took: 1.10s  Val. loss: 0.0904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, 100% \t Train loss: 0.0731 took: 1.11s  Val. loss: 0.0896\n",
      "Epoch 44, 100% \t Train loss: 0.0728 took: 1.11s  Val. loss: 0.0892\n",
      "Epoch 45, 100% \t Train loss: 0.0734 took: 1.71s  Val. loss: 0.0932\n",
      "Epoch 46, 100% \t Train loss: 0.0726 took: 1.87s  Val. loss: 0.0884\n",
      "Epoch 47, 100% \t Train loss: 0.0726 took: 1.87s  Val. loss: 0.0896\n",
      "Epoch 48, 100% \t Train loss: 0.0714 took: 1.88s  Val. loss: 0.0987\n",
      "Epoch 49, 100% \t Train loss: 0.0717 took: 1.87s  Val. loss: 0.0916\n",
      "Epoch 50, 100% \t Train loss: 0.0708 took: 1.86s  Val. loss: 0.0904\n",
      "Training finished, took 76.52s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 1.82s  Val. loss: 0.2560\n",
      "Epoch 2, 100% \t Train loss: 0.2592 took: 1.04s  Val. loss: 0.2542\n",
      "Epoch 3, 100% \t Train loss: 0.2593 took: 1.04s  Val. loss: 0.2562\n",
      "Epoch 4, 100% \t Train loss: 0.2591 took: 1.04s  Val. loss: 0.2572\n",
      "Epoch 5, 100% \t Train loss: 0.2590 took: 1.04s  Val. loss: 0.2563\n",
      "Epoch 6, 100% \t Train loss: 0.2588 took: 1.04s  Val. loss: 0.2580\n",
      "Epoch 7, 100% \t Train loss: 0.2583 took: 1.03s  Val. loss: 0.2553\n",
      "Epoch 8, 100% \t Train loss: 0.2515 took: 1.04s  Val. loss: 0.2347\n",
      "Epoch 9, 100% \t Train loss: 0.2160 took: 1.04s  Val. loss: 0.1977\n",
      "Epoch 10, 100% \t Train loss: 0.1969 took: 1.03s  Val. loss: 0.1926\n",
      "Epoch 11, 100% \t Train loss: 0.1860 took: 1.03s  Val. loss: 0.2037\n",
      "Epoch 12, 100% \t Train loss: 0.1819 took: 1.03s  Val. loss: 0.2052\n",
      "Epoch 13, 100% \t Train loss: 0.1844 took: 1.04s  Val. loss: 0.1876\n",
      "Epoch 14, 100% \t Train loss: 0.1819 took: 1.04s  Val. loss: 0.1876\n",
      "Epoch 15, 100% \t Train loss: 0.1760 took: 1.04s  Val. loss: 0.1881\n",
      "Epoch 16, 100% \t Train loss: 0.1765 took: 1.04s  Val. loss: 0.1836\n",
      "Epoch 17, 100% \t Train loss: 0.1714 took: 1.03s  Val. loss: 0.1850\n",
      "Epoch 18, 100% \t Train loss: 0.1700 took: 1.03s  Val. loss: 0.1804\n",
      "Epoch 19, 100% \t Train loss: 0.1700 took: 1.03s  Val. loss: 0.1805\n",
      "Epoch 20, 100% \t Train loss: 0.1694 took: 1.04s  Val. loss: 0.1797\n",
      "Epoch 21, 100% \t Train loss: 0.1680 took: 1.05s  Val. loss: 0.1865\n",
      "Epoch 22, 100% \t Train loss: 0.1669 took: 1.71s  Val. loss: 0.1758\n",
      "Epoch 23, 100% \t Train loss: 0.1631 took: 1.80s  Val. loss: 0.1785\n",
      "Epoch 24, 100% \t Train loss: 0.1639 took: 1.81s  Val. loss: 0.1766\n",
      "Epoch 25, 100% \t Train loss: 0.1623 took: 1.82s  Val. loss: 0.1783\n",
      "Epoch 26, 100% \t Train loss: 0.1608 took: 1.80s  Val. loss: 0.1727\n",
      "Epoch 27, 100% \t Train loss: 0.1597 took: 1.82s  Val. loss: 0.1725\n",
      "Epoch 28, 100% \t Train loss: 0.1553 took: 1.81s  Val. loss: 0.1689\n",
      "Epoch 29, 100% \t Train loss: 0.1544 took: 1.81s  Val. loss: 0.1704\n",
      "Epoch 30, 100% \t Train loss: 0.1523 took: 1.84s  Val. loss: 0.1739\n",
      "Epoch 31, 100% \t Train loss: 0.1495 took: 1.84s  Val. loss: 0.1659\n",
      "Epoch 32, 100% \t Train loss: 0.1466 took: 1.86s  Val. loss: 0.1651\n",
      "Epoch 33, 100% \t Train loss: 0.1433 took: 1.84s  Val. loss: 0.1593\n",
      "Epoch 34, 100% \t Train loss: 0.1406 took: 1.86s  Val. loss: 0.1611\n",
      "Epoch 35, 100% \t Train loss: 0.1373 took: 1.86s  Val. loss: 0.1551\n",
      "Epoch 36, 100% \t Train loss: 0.1375 took: 1.39s  Val. loss: 0.1520\n",
      "Epoch 37, 100% \t Train loss: 0.1326 took: 1.07s  Val. loss: 0.1528\n",
      "Epoch 38, 100% \t Train loss: 0.1304 took: 1.07s  Val. loss: 0.1531\n",
      "Epoch 39, 100% \t Train loss: 0.1276 took: 1.07s  Val. loss: 0.1477\n",
      "Epoch 40, 100% \t Train loss: 0.1286 took: 1.07s  Val. loss: 0.1452\n",
      "Epoch 41, 100% \t Train loss: 0.1251 took: 1.85s  Val. loss: 0.1386\n",
      "Epoch 42, 100% \t Train loss: 0.1206 took: 1.84s  Val. loss: 0.1432\n",
      "Epoch 43, 100% \t Train loss: 0.1171 took: 1.85s  Val. loss: 0.1371\n",
      "Epoch 44, 100% \t Train loss: 0.1169 took: 1.84s  Val. loss: 0.1343\n",
      "Epoch 45, 100% \t Train loss: 0.1152 took: 1.82s  Val. loss: 0.1345\n",
      "Epoch 46, 100% \t Train loss: 0.1124 took: 1.81s  Val. loss: 0.1343\n",
      "Epoch 47, 100% \t Train loss: 0.1122 took: 1.83s  Val. loss: 0.1311\n",
      "Epoch 48, 100% \t Train loss: 0.1068 took: 1.85s  Val. loss: 0.1342\n",
      "Epoch 49, 100% \t Train loss: 0.1073 took: 1.85s  Val. loss: 0.1287\n",
      "Epoch 50, 100% \t Train loss: 0.1047 took: 1.81s  Val. loss: 0.1232\n",
      "Training finished, took 81.55s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2620 took: 1.83s  Val. loss: 0.2598\n",
      "Epoch 2, 100% \t Train loss: 0.2594 took: 1.82s  Val. loss: 0.2596\n",
      "Epoch 3, 100% \t Train loss: 0.2595 took: 1.83s  Val. loss: 0.2603\n",
      "Epoch 4, 100% \t Train loss: 0.2595 took: 1.81s  Val. loss: 0.2604\n",
      "Epoch 5, 100% \t Train loss: 0.2595 took: 1.83s  Val. loss: 0.2602\n",
      "Epoch 6, 100% \t Train loss: 0.2594 took: 1.82s  Val. loss: 0.2602\n",
      "Epoch 7, 100% \t Train loss: 0.2594 took: 1.82s  Val. loss: 0.2593\n",
      "Epoch 8, 100% \t Train loss: 0.2593 took: 1.81s  Val. loss: 0.2597\n",
      "Epoch 9, 100% \t Train loss: 0.2590 took: 1.85s  Val. loss: 0.2590\n",
      "Epoch 10, 100% \t Train loss: 0.2585 took: 1.82s  Val. loss: 0.2589\n",
      "Epoch 11, 100% \t Train loss: 0.2556 took: 1.82s  Val. loss: 0.2532\n",
      "Epoch 12, 100% \t Train loss: 0.2370 took: 1.83s  Val. loss: 0.2161\n",
      "Epoch 13, 100% \t Train loss: 0.2094 took: 1.82s  Val. loss: 0.1937\n",
      "Epoch 14, 100% \t Train loss: 0.1983 took: 1.81s  Val. loss: 0.1951\n",
      "Epoch 15, 100% \t Train loss: 0.1961 took: 1.82s  Val. loss: 0.1799\n",
      "Epoch 16, 100% \t Train loss: 0.1919 took: 1.80s  Val. loss: 0.1781\n",
      "Epoch 17, 100% \t Train loss: 0.1881 took: 1.81s  Val. loss: 0.1806\n",
      "Epoch 18, 100% \t Train loss: 0.1854 took: 1.81s  Val. loss: 0.1744\n",
      "Epoch 19, 100% \t Train loss: 0.1856 took: 1.82s  Val. loss: 0.1753\n",
      "Epoch 20, 100% \t Train loss: 0.1849 took: 1.04s  Val. loss: 0.1744\n",
      "Epoch 21, 100% \t Train loss: 0.1825 took: 1.04s  Val. loss: 0.1773\n",
      "Epoch 22, 100% \t Train loss: 0.1817 took: 1.03s  Val. loss: 0.1733\n",
      "Epoch 23, 100% \t Train loss: 0.1811 took: 1.03s  Val. loss: 0.1691\n",
      "Epoch 24, 100% \t Train loss: 0.1792 took: 1.05s  Val. loss: 0.1749\n",
      "Epoch 25, 100% \t Train loss: 0.1808 took: 1.04s  Val. loss: 0.1776\n",
      "Epoch 26, 100% \t Train loss: 0.1803 took: 1.05s  Val. loss: 0.1722\n",
      "Epoch 27, 100% \t Train loss: 0.1774 took: 1.05s  Val. loss: 0.1754\n",
      "Epoch 28, 100% \t Train loss: 0.1786 took: 1.05s  Val. loss: 0.1768\n",
      "Epoch 29, 100% \t Train loss: 0.1783 took: 1.05s  Val. loss: 0.1697\n",
      "Epoch 30, 100% \t Train loss: 0.1762 took: 1.05s  Val. loss: 0.1691\n",
      "Epoch 31, 100% \t Train loss: 0.1756 took: 1.06s  Val. loss: 0.1689\n",
      "Epoch 32, 100% \t Train loss: 0.1751 took: 1.06s  Val. loss: 0.1728\n",
      "Epoch 33, 100% \t Train loss: 0.1757 took: 1.07s  Val. loss: 0.1707\n",
      "Epoch 34, 100% \t Train loss: 0.1747 took: 1.06s  Val. loss: 0.1677\n",
      "Epoch 35, 100% \t Train loss: 0.1738 took: 1.06s  Val. loss: 0.1714\n",
      "Epoch 36, 100% \t Train loss: 0.1754 took: 1.07s  Val. loss: 0.1684\n",
      "Epoch 37, 100% \t Train loss: 0.1734 took: 1.07s  Val. loss: 0.1681\n",
      "Epoch 38, 100% \t Train loss: 0.1738 took: 1.07s  Val. loss: 0.1658\n",
      "Epoch 39, 100% \t Train loss: 0.1722 took: 1.08s  Val. loss: 0.1696\n",
      "Epoch 40, 100% \t Train loss: 0.1725 took: 1.07s  Val. loss: 0.1735\n",
      "Epoch 41, 100% \t Train loss: 0.1734 took: 1.09s  Val. loss: 0.1669\n",
      "Epoch 42, 100% \t Train loss: 0.1720 took: 1.09s  Val. loss: 0.1667\n",
      "Epoch 43, 100% \t Train loss: 0.1717 took: 1.09s  Val. loss: 0.1691\n",
      "Epoch 44, 100% \t Train loss: 0.1717 took: 1.09s  Val. loss: 0.1661\n",
      "Epoch 45, 100% \t Train loss: 0.1702 took: 1.09s  Val. loss: 0.1680\n",
      "Epoch 46, 100% \t Train loss: 0.1704 took: 1.10s  Val. loss: 0.1646\n",
      "Epoch 47, 100% \t Train loss: 0.1687 took: 1.10s  Val. loss: 0.1647\n",
      "Epoch 48, 100% \t Train loss: 0.1675 took: 1.11s  Val. loss: 0.1651\n",
      "Epoch 49, 100% \t Train loss: 0.1678 took: 1.12s  Val. loss: 0.1679\n",
      "Epoch 50, 100% \t Train loss: 0.1674 took: 1.11s  Val. loss: 0.1689\n",
      "Training finished, took 76.65s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.31\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.880851\n",
      "lambda: 0.0010 - V: 0.820995\n",
      "lambda: 0.0005 - V: 0.807630\n",
      "Average V: 0.836492\n",
      "Time elapsed: 238.20 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2603 took: 1.96s  Val. loss: 0.2639\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 1.98s  Val. loss: 0.2627\n",
      "Epoch 3, 100% \t Train loss: 0.2583 took: 1.98s  Val. loss: 0.2628\n",
      "Epoch 4, 100% \t Train loss: 0.2531 took: 1.96s  Val. loss: 0.2268\n",
      "Epoch 5, 100% \t Train loss: 0.1867 took: 1.96s  Val. loss: 0.1743\n",
      "Epoch 6, 100% \t Train loss: 0.1691 took: 1.95s  Val. loss: 0.1708\n",
      "Epoch 7, 100% \t Train loss: 0.1645 took: 1.96s  Val. loss: 0.1722\n",
      "Epoch 8, 100% \t Train loss: 0.1645 took: 1.97s  Val. loss: 0.1835\n",
      "Epoch 9, 100% \t Train loss: 0.1628 took: 1.96s  Val. loss: 0.1679\n",
      "Epoch 10, 100% \t Train loss: 0.1601 took: 1.97s  Val. loss: 0.1683\n",
      "Epoch 11, 100% \t Train loss: 0.1565 took: 1.95s  Val. loss: 0.1669\n",
      "Epoch 12, 100% \t Train loss: 0.1532 took: 1.97s  Val. loss: 0.1631\n",
      "Epoch 13, 100% \t Train loss: 0.1514 took: 1.97s  Val. loss: 0.1666\n",
      "Epoch 14, 100% \t Train loss: 0.1496 took: 1.98s  Val. loss: 0.1624\n",
      "Epoch 15, 100% \t Train loss: 0.1499 took: 1.96s  Val. loss: 0.1679\n",
      "Epoch 16, 100% \t Train loss: 0.1476 took: 1.96s  Val. loss: 0.1606\n",
      "Epoch 17, 100% \t Train loss: 0.1477 took: 1.96s  Val. loss: 0.1610\n",
      "Epoch 18, 100% \t Train loss: 0.1475 took: 1.94s  Val. loss: 0.1589\n",
      "Epoch 19, 100% \t Train loss: 0.1458 took: 1.96s  Val. loss: 0.1601\n",
      "Epoch 20, 100% \t Train loss: 0.1448 took: 1.97s  Val. loss: 0.1617\n",
      "Epoch 21, 100% \t Train loss: 0.1428 took: 1.95s  Val. loss: 0.1631\n",
      "Epoch 22, 100% \t Train loss: 0.1409 took: 1.97s  Val. loss: 0.1563\n",
      "Epoch 23, 100% \t Train loss: 0.1392 took: 1.95s  Val. loss: 0.1586\n",
      "Epoch 24, 100% \t Train loss: 0.1374 took: 1.94s  Val. loss: 0.1533\n",
      "Epoch 25, 100% \t Train loss: 0.1325 took: 1.94s  Val. loss: 0.1543\n",
      "Epoch 26, 100% \t Train loss: 0.1303 took: 1.96s  Val. loss: 0.1478\n",
      "Epoch 27, 100% \t Train loss: 0.1245 took: 1.97s  Val. loss: 0.1454\n",
      "Epoch 28, 100% \t Train loss: 0.1217 took: 1.99s  Val. loss: 0.1405\n",
      "Epoch 29, 100% \t Train loss: 0.1151 took: 1.97s  Val. loss: 0.1416\n",
      "Epoch 30, 100% \t Train loss: 0.1121 took: 1.97s  Val. loss: 0.1340\n",
      "Epoch 31, 100% \t Train loss: 0.1080 took: 1.98s  Val. loss: 0.1371\n",
      "Epoch 32, 100% \t Train loss: 0.1038 took: 2.00s  Val. loss: 0.1296\n",
      "Epoch 33, 100% \t Train loss: 0.1007 took: 2.05s  Val. loss: 0.1284\n",
      "Epoch 34, 100% \t Train loss: 0.0989 took: 2.06s  Val. loss: 0.1222\n",
      "Epoch 35, 100% \t Train loss: 0.0952 took: 2.06s  Val. loss: 0.1275\n",
      "Epoch 36, 100% \t Train loss: 0.0964 took: 2.07s  Val. loss: 0.1220\n",
      "Epoch 37, 100% \t Train loss: 0.0915 took: 2.06s  Val. loss: 0.1201\n",
      "Epoch 38, 100% \t Train loss: 0.0885 took: 2.08s  Val. loss: 0.1170\n",
      "Epoch 39, 100% \t Train loss: 0.0872 took: 2.06s  Val. loss: 0.1170\n",
      "Epoch 40, 100% \t Train loss: 0.0881 took: 2.07s  Val. loss: 0.1134\n",
      "Epoch 41, 100% \t Train loss: 0.0852 took: 2.08s  Val. loss: 0.1114\n",
      "Epoch 42, 100% \t Train loss: 0.0846 took: 2.09s  Val. loss: 0.1100\n",
      "Epoch 43, 100% \t Train loss: 0.0821 took: 2.11s  Val. loss: 0.1071\n",
      "Epoch 44, 100% \t Train loss: 0.0803 took: 2.07s  Val. loss: 0.1042\n",
      "Epoch 45, 100% \t Train loss: 0.0806 took: 2.04s  Val. loss: 0.1049\n",
      "Epoch 46, 100% \t Train loss: 0.0787 took: 2.06s  Val. loss: 0.1037\n",
      "Epoch 47, 100% \t Train loss: 0.0777 took: 2.08s  Val. loss: 0.1048\n",
      "Epoch 48, 100% \t Train loss: 0.0768 took: 1.26s  Val. loss: 0.1033\n",
      "Epoch 49, 100% \t Train loss: 0.0763 took: 1.26s  Val. loss: 0.1026\n",
      "Epoch 50, 100% \t Train loss: 0.0745 took: 1.27s  Val. loss: 0.1039\n",
      "Training finished, took 110.38s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 1.16s  Val. loss: 0.2615\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 1.15s  Val. loss: 0.2594\n",
      "Epoch 3, 100% \t Train loss: 0.2568 took: 1.15s  Val. loss: 0.2589\n",
      "Epoch 4, 100% \t Train loss: 0.2443 took: 1.15s  Val. loss: 0.2249\n",
      "Epoch 5, 100% \t Train loss: 0.2139 took: 1.14s  Val. loss: 0.2173\n",
      "Epoch 6, 100% \t Train loss: 0.2009 took: 1.15s  Val. loss: 0.1943\n",
      "Epoch 7, 100% \t Train loss: 0.1812 took: 1.16s  Val. loss: 0.1752\n",
      "Epoch 8, 100% \t Train loss: 0.1754 took: 1.15s  Val. loss: 0.1712\n",
      "Epoch 9, 100% \t Train loss: 0.1705 took: 1.15s  Val. loss: 0.1693\n",
      "Epoch 10, 100% \t Train loss: 0.1684 took: 1.15s  Val. loss: 0.1696\n",
      "Epoch 11, 100% \t Train loss: 0.1655 took: 1.15s  Val. loss: 0.1674\n",
      "Epoch 12, 100% \t Train loss: 0.1643 took: 1.15s  Val. loss: 0.1638\n",
      "Epoch 13, 100% \t Train loss: 0.1615 took: 1.15s  Val. loss: 0.1627\n",
      "Epoch 14, 100% \t Train loss: 0.1598 took: 1.14s  Val. loss: 0.1633\n",
      "Epoch 15, 100% \t Train loss: 0.1602 took: 1.14s  Val. loss: 0.1640\n",
      "Epoch 16, 100% \t Train loss: 0.1592 took: 1.15s  Val. loss: 0.1635\n",
      "Epoch 17, 100% \t Train loss: 0.1585 took: 1.15s  Val. loss: 0.1740\n",
      "Epoch 18, 100% \t Train loss: 0.1583 took: 1.15s  Val. loss: 0.1633\n",
      "Epoch 19, 100% \t Train loss: 0.1583 took: 1.15s  Val. loss: 0.1640\n",
      "Epoch 20, 100% \t Train loss: 0.1563 took: 1.15s  Val. loss: 0.1684\n",
      "Epoch 21, 100% \t Train loss: 0.1570 took: 1.15s  Val. loss: 0.1644\n",
      "Epoch 22, 100% \t Train loss: 0.1554 took: 1.15s  Val. loss: 0.1591\n",
      "Epoch 23, 100% \t Train loss: 0.1557 took: 1.79s  Val. loss: 0.1616\n",
      "Epoch 24, 100% \t Train loss: 0.1545 took: 1.96s  Val. loss: 0.1615\n",
      "Epoch 25, 100% \t Train loss: 0.1531 took: 1.95s  Val. loss: 0.1621\n",
      "Epoch 26, 100% \t Train loss: 0.1536 took: 1.95s  Val. loss: 0.1589\n",
      "Epoch 27, 100% \t Train loss: 0.1522 took: 1.96s  Val. loss: 0.1610\n",
      "Epoch 28, 100% \t Train loss: 0.1517 took: 1.95s  Val. loss: 0.1630\n",
      "Epoch 29, 100% \t Train loss: 0.1507 took: 1.95s  Val. loss: 0.1605\n",
      "Epoch 30, 100% \t Train loss: 0.1509 took: 1.95s  Val. loss: 0.1616\n",
      "Epoch 31, 100% \t Train loss: 0.1521 took: 1.96s  Val. loss: 0.1640\n",
      "Epoch 32, 100% \t Train loss: 0.1512 took: 1.96s  Val. loss: 0.1634\n",
      "Epoch 33, 100% \t Train loss: 0.1508 took: 1.97s  Val. loss: 0.1611\n",
      "Epoch 34, 100% \t Train loss: 0.1494 took: 1.97s  Val. loss: 0.1602\n",
      "Epoch 35, 100% \t Train loss: 0.1493 took: 1.97s  Val. loss: 0.1589\n",
      "Epoch 36, 100% \t Train loss: 0.1503 took: 1.96s  Val. loss: 0.1619\n",
      "Epoch 37, 100% \t Train loss: 0.1483 took: 1.96s  Val. loss: 0.1613\n",
      "Epoch 38, 100% \t Train loss: 0.1485 took: 1.96s  Val. loss: 0.1616\n",
      "Epoch 39, 100% \t Train loss: 0.1481 took: 1.96s  Val. loss: 0.1600\n",
      "Epoch 40, 100% \t Train loss: 0.1476 took: 1.96s  Val. loss: 0.1619\n",
      "Epoch 41, 100% \t Train loss: 0.1479 took: 1.99s  Val. loss: 0.1586\n",
      "Epoch 42, 100% \t Train loss: 0.1481 took: 1.98s  Val. loss: 0.1604\n",
      "Epoch 43, 100% \t Train loss: 0.1469 took: 1.97s  Val. loss: 0.1597\n",
      "Epoch 44, 100% \t Train loss: 0.1463 took: 1.96s  Val. loss: 0.1593\n",
      "Epoch 45, 100% \t Train loss: 0.1460 took: 1.99s  Val. loss: 0.1600\n",
      "Epoch 46, 100% \t Train loss: 0.1460 took: 1.97s  Val. loss: 0.1606\n",
      "Epoch 47, 100% \t Train loss: 0.1452 took: 1.98s  Val. loss: 0.1613\n",
      "Epoch 48, 100% \t Train loss: 0.1453 took: 1.99s  Val. loss: 0.1598\n",
      "Epoch 49, 100% \t Train loss: 0.1448 took: 1.97s  Val. loss: 0.1601\n",
      "Epoch 50, 100% \t Train loss: 0.1446 took: 1.96s  Val. loss: 0.1599\n",
      "Training finished, took 90.53s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2622 took: 1.97s  Val. loss: 0.2593\n",
      "Epoch 2, 100% \t Train loss: 0.2618 took: 1.97s  Val. loss: 0.2611\n",
      "Epoch 3, 100% \t Train loss: 0.2619 took: 1.98s  Val. loss: 0.2595\n",
      "Epoch 4, 100% \t Train loss: 0.2617 took: 1.97s  Val. loss: 0.2598\n",
      "Epoch 5, 100% \t Train loss: 0.2617 took: 1.96s  Val. loss: 0.2600\n",
      "Epoch 6, 100% \t Train loss: 0.2615 took: 1.99s  Val. loss: 0.2586\n",
      "Epoch 7, 100% \t Train loss: 0.2607 took: 1.96s  Val. loss: 0.2572\n",
      "Epoch 8, 100% \t Train loss: 0.2535 took: 1.96s  Val. loss: 0.2397\n",
      "Epoch 9, 100% \t Train loss: 0.2244 took: 1.96s  Val. loss: 0.2115\n",
      "Epoch 10, 100% \t Train loss: 0.2032 took: 1.96s  Val. loss: 0.1981\n",
      "Epoch 11, 100% \t Train loss: 0.1898 took: 1.45s  Val. loss: 0.1837\n",
      "Epoch 12, 100% \t Train loss: 0.1846 took: 1.16s  Val. loss: 0.1805\n",
      "Epoch 13, 100% \t Train loss: 0.1795 took: 1.15s  Val. loss: 0.1844\n",
      "Epoch 14, 100% \t Train loss: 0.1771 took: 1.15s  Val. loss: 0.1810\n",
      "Epoch 15, 100% \t Train loss: 0.1753 took: 1.15s  Val. loss: 0.1780\n",
      "Epoch 16, 100% \t Train loss: 0.1770 took: 1.15s  Val. loss: 0.1757\n",
      "Epoch 17, 100% \t Train loss: 0.1721 took: 1.16s  Val. loss: 0.1753\n",
      "Epoch 18, 100% \t Train loss: 0.1737 took: 1.16s  Val. loss: 0.1725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1715 took: 1.16s  Val. loss: 0.1728\n",
      "Epoch 20, 100% \t Train loss: 0.1686 took: 1.16s  Val. loss: 0.1689\n",
      "Epoch 21, 100% \t Train loss: 0.1675 took: 1.16s  Val. loss: 0.1768\n",
      "Epoch 22, 100% \t Train loss: 0.1685 took: 1.16s  Val. loss: 0.1764\n",
      "Epoch 23, 100% \t Train loss: 0.1672 took: 1.17s  Val. loss: 0.1700\n",
      "Epoch 24, 100% \t Train loss: 0.1663 took: 1.16s  Val. loss: 0.1713\n",
      "Epoch 25, 100% \t Train loss: 0.1633 took: 1.16s  Val. loss: 0.1670\n",
      "Epoch 26, 100% \t Train loss: 0.1635 took: 1.17s  Val. loss: 0.1675\n",
      "Epoch 27, 100% \t Train loss: 0.1620 took: 1.16s  Val. loss: 0.1699\n",
      "Epoch 28, 100% \t Train loss: 0.1629 took: 1.16s  Val. loss: 0.1634\n",
      "Epoch 29, 100% \t Train loss: 0.1605 took: 1.16s  Val. loss: 0.1640\n",
      "Epoch 30, 100% \t Train loss: 0.1581 took: 1.16s  Val. loss: 0.1642\n",
      "Epoch 31, 100% \t Train loss: 0.1573 took: 1.16s  Val. loss: 0.1650\n",
      "Epoch 32, 100% \t Train loss: 0.1577 took: 1.15s  Val. loss: 0.1623\n",
      "Epoch 33, 100% \t Train loss: 0.1588 took: 1.16s  Val. loss: 0.1736\n",
      "Epoch 34, 100% \t Train loss: 0.1572 took: 1.16s  Val. loss: 0.1639\n",
      "Epoch 35, 100% \t Train loss: 0.1544 took: 1.16s  Val. loss: 0.1613\n",
      "Epoch 36, 100% \t Train loss: 0.1547 took: 1.16s  Val. loss: 0.1618\n",
      "Epoch 37, 100% \t Train loss: 0.1533 took: 1.51s  Val. loss: 0.1633\n",
      "Epoch 38, 100% \t Train loss: 0.1521 took: 1.99s  Val. loss: 0.1585\n",
      "Epoch 39, 100% \t Train loss: 0.1531 took: 1.96s  Val. loss: 0.1667\n",
      "Epoch 40, 100% \t Train loss: 0.1526 took: 1.97s  Val. loss: 0.1632\n",
      "Epoch 41, 100% \t Train loss: 0.1490 took: 1.98s  Val. loss: 0.1590\n",
      "Epoch 42, 100% \t Train loss: 0.1503 took: 1.98s  Val. loss: 0.1571\n",
      "Epoch 43, 100% \t Train loss: 0.1475 took: 1.98s  Val. loss: 0.1528\n",
      "Epoch 44, 100% \t Train loss: 0.1461 took: 1.97s  Val. loss: 0.1534\n",
      "Epoch 45, 100% \t Train loss: 0.1448 took: 1.98s  Val. loss: 0.1574\n",
      "Epoch 46, 100% \t Train loss: 0.1450 took: 1.17s  Val. loss: 0.1523\n",
      "Epoch 47, 100% \t Train loss: 0.1402 took: 1.16s  Val. loss: 0.1513\n",
      "Epoch 48, 100% \t Train loss: 0.1398 took: 1.14s  Val. loss: 0.1528\n",
      "Epoch 49, 100% \t Train loss: 0.1393 took: 1.15s  Val. loss: 0.1493\n",
      "Epoch 50, 100% \t Train loss: 0.1355 took: 1.16s  Val. loss: 0.1456\n",
      "Training finished, took 82.58s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.850643\n",
      "lambda: 0.0010 - V: 0.828330\n",
      "lambda: 0.0005 - V: 0.818024\n",
      "Average V: 0.832332\n",
      "Time elapsed: 287.04 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2578 took: 1.05s  Val. loss: 0.2505\n",
      "Epoch 2, 100% \t Train loss: 0.2565 took: 1.03s  Val. loss: 0.2512\n",
      "Epoch 3, 100% \t Train loss: 0.2402 took: 1.03s  Val. loss: 0.1933\n",
      "Epoch 4, 100% \t Train loss: 0.1971 took: 1.03s  Val. loss: 0.1874\n",
      "Epoch 5, 100% \t Train loss: 0.1925 took: 1.03s  Val. loss: 0.1882\n",
      "Epoch 6, 100% \t Train loss: 0.1893 took: 1.03s  Val. loss: 0.1874\n",
      "Epoch 7, 100% \t Train loss: 0.1877 took: 1.03s  Val. loss: 0.1850\n",
      "Epoch 8, 100% \t Train loss: 0.1854 took: 1.03s  Val. loss: 0.1818\n",
      "Epoch 9, 100% \t Train loss: 0.1840 took: 1.02s  Val. loss: 0.1818\n",
      "Epoch 10, 100% \t Train loss: 0.1814 took: 1.03s  Val. loss: 0.1820\n",
      "Epoch 11, 100% \t Train loss: 0.1801 took: 1.03s  Val. loss: 0.1783\n",
      "Epoch 12, 100% \t Train loss: 0.1770 took: 1.02s  Val. loss: 0.1790\n",
      "Epoch 13, 100% \t Train loss: 0.1675 took: 1.08s  Val. loss: 0.1523\n",
      "Epoch 14, 100% \t Train loss: 0.1500 took: 1.03s  Val. loss: 0.1391\n",
      "Epoch 15, 100% \t Train loss: 0.1380 took: 1.03s  Val. loss: 0.1377\n",
      "Epoch 16, 100% \t Train loss: 0.1348 took: 1.03s  Val. loss: 0.1328\n",
      "Epoch 17, 100% \t Train loss: 0.1308 took: 1.60s  Val. loss: 0.1286\n",
      "Epoch 18, 100% \t Train loss: 0.1284 took: 1.78s  Val. loss: 0.1266\n",
      "Epoch 19, 100% \t Train loss: 0.1264 took: 1.77s  Val. loss: 0.1283\n",
      "Epoch 20, 100% \t Train loss: 0.1262 took: 1.78s  Val. loss: 0.1226\n",
      "Epoch 21, 100% \t Train loss: 0.1242 took: 1.79s  Val. loss: 0.1252\n",
      "Epoch 22, 100% \t Train loss: 0.1231 took: 1.79s  Val. loss: 0.1214\n",
      "Epoch 23, 100% \t Train loss: 0.1222 took: 1.80s  Val. loss: 0.1197\n",
      "Epoch 24, 100% \t Train loss: 0.1218 took: 1.78s  Val. loss: 0.1220\n",
      "Epoch 25, 100% \t Train loss: 0.1214 took: 1.77s  Val. loss: 0.1207\n",
      "Epoch 26, 100% \t Train loss: 0.1209 took: 1.76s  Val. loss: 0.1211\n",
      "Epoch 27, 100% \t Train loss: 0.1200 took: 1.04s  Val. loss: 0.1217\n",
      "Epoch 28, 100% \t Train loss: 0.1197 took: 1.44s  Val. loss: 0.1198\n",
      "Epoch 29, 100% \t Train loss: 0.1190 took: 1.74s  Val. loss: 0.1226\n",
      "Epoch 30, 100% \t Train loss: 0.1198 took: 1.49s  Val. loss: 0.1201\n",
      "Epoch 31, 100% \t Train loss: 0.1185 took: 1.03s  Val. loss: 0.1195\n",
      "Epoch 32, 100% \t Train loss: 0.1192 took: 1.06s  Val. loss: 0.1181\n",
      "Epoch 33, 100% \t Train loss: 0.1178 took: 1.15s  Val. loss: 0.1183\n",
      "Epoch 34, 100% \t Train loss: 0.1175 took: 1.16s  Val. loss: 0.1188\n",
      "Epoch 35, 100% \t Train loss: 0.1169 took: 1.16s  Val. loss: 0.1176\n",
      "Epoch 36, 100% \t Train loss: 0.1168 took: 1.16s  Val. loss: 0.1192\n",
      "Epoch 37, 100% \t Train loss: 0.1171 took: 1.16s  Val. loss: 0.1200\n",
      "Epoch 38, 100% \t Train loss: 0.1170 took: 1.17s  Val. loss: 0.1197\n",
      "Epoch 39, 100% \t Train loss: 0.1165 took: 1.18s  Val. loss: 0.1203\n",
      "Epoch 40, 100% \t Train loss: 0.1162 took: 1.19s  Val. loss: 0.1196\n",
      "Epoch 41, 100% \t Train loss: 0.1162 took: 1.21s  Val. loss: 0.1203\n",
      "Epoch 42, 100% \t Train loss: 0.1158 took: 1.22s  Val. loss: 0.1177\n",
      "Epoch 43, 100% \t Train loss: 0.1153 took: 1.21s  Val. loss: 0.1187\n",
      "Epoch 44, 100% \t Train loss: 0.1160 took: 1.22s  Val. loss: 0.1176\n",
      "Epoch 45, 100% \t Train loss: 0.1146 took: 1.26s  Val. loss: 0.1177\n",
      "Epoch 46, 100% \t Train loss: 0.1152 took: 1.24s  Val. loss: 0.1207\n",
      "Epoch 47, 100% \t Train loss: 0.1145 took: 1.24s  Val. loss: 0.1202\n",
      "Epoch 48, 100% \t Train loss: 0.1145 took: 1.22s  Val. loss: 0.1171\n",
      "Epoch 49, 100% \t Train loss: 0.1144 took: 1.25s  Val. loss: 0.1211\n",
      "Epoch 50, 100% \t Train loss: 0.1142 took: 1.98s  Val. loss: 0.1202\n",
      "Training finished, took 73.25s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2615 took: 1.79s  Val. loss: 0.2554\n",
      "Epoch 2, 100% \t Train loss: 0.2608 took: 1.79s  Val. loss: 0.2546\n",
      "Epoch 3, 100% \t Train loss: 0.2599 took: 1.79s  Val. loss: 0.2520\n",
      "Epoch 4, 100% \t Train loss: 0.2495 took: 1.79s  Val. loss: 0.2337\n",
      "Epoch 5, 100% \t Train loss: 0.2249 took: 1.78s  Val. loss: 0.2094\n",
      "Epoch 6, 100% \t Train loss: 0.2105 took: 1.79s  Val. loss: 0.1965\n",
      "Epoch 7, 100% \t Train loss: 0.2070 took: 1.80s  Val. loss: 0.1927\n",
      "Epoch 8, 100% \t Train loss: 0.2057 took: 1.78s  Val. loss: 0.1904\n",
      "Epoch 9, 100% \t Train loss: 0.2045 took: 1.81s  Val. loss: 0.1924\n",
      "Epoch 10, 100% \t Train loss: 0.2032 took: 1.42s  Val. loss: 0.1902\n",
      "Epoch 11, 100% \t Train loss: 0.2026 took: 1.03s  Val. loss: 0.1903\n",
      "Epoch 12, 100% \t Train loss: 0.2012 took: 1.04s  Val. loss: 0.1883\n",
      "Epoch 13, 100% \t Train loss: 0.2011 took: 1.03s  Val. loss: 0.1918\n",
      "Epoch 14, 100% \t Train loss: 0.1998 took: 1.02s  Val. loss: 0.1880\n",
      "Epoch 15, 100% \t Train loss: 0.1983 took: 1.03s  Val. loss: 0.1895\n",
      "Epoch 16, 100% \t Train loss: 0.1980 took: 1.40s  Val. loss: 0.1848\n",
      "Epoch 17, 100% \t Train loss: 0.1982 took: 1.77s  Val. loss: 0.1856\n",
      "Epoch 18, 100% \t Train loss: 0.1981 took: 1.77s  Val. loss: 0.1865\n",
      "Epoch 19, 100% \t Train loss: 0.1959 took: 1.77s  Val. loss: 0.1875\n",
      "Epoch 20, 100% \t Train loss: 0.1953 took: 1.78s  Val. loss: 0.1846\n",
      "Epoch 21, 100% \t Train loss: 0.1946 took: 1.78s  Val. loss: 0.1839\n",
      "Epoch 22, 100% \t Train loss: 0.1946 took: 1.78s  Val. loss: 0.1970\n",
      "Epoch 23, 100% \t Train loss: 0.1952 took: 1.76s  Val. loss: 0.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1926 took: 1.77s  Val. loss: 0.1838\n",
      "Epoch 25, 100% \t Train loss: 0.1930 took: 1.79s  Val. loss: 0.1839\n",
      "Epoch 26, 100% \t Train loss: 0.1916 took: 1.79s  Val. loss: 0.1823\n",
      "Epoch 27, 100% \t Train loss: 0.1906 took: 1.79s  Val. loss: 0.1802\n",
      "Epoch 28, 100% \t Train loss: 0.1885 took: 1.79s  Val. loss: 0.1791\n",
      "Epoch 29, 100% \t Train loss: 0.1893 took: 1.81s  Val. loss: 0.1835\n",
      "Epoch 30, 100% \t Train loss: 0.1871 took: 1.84s  Val. loss: 0.1828\n",
      "Epoch 31, 100% \t Train loss: 0.1868 took: 1.85s  Val. loss: 0.1825\n",
      "Epoch 32, 100% \t Train loss: 0.1850 took: 1.85s  Val. loss: 0.1811\n",
      "Epoch 33, 100% \t Train loss: 0.1835 took: 1.88s  Val. loss: 0.1732\n",
      "Epoch 34, 100% \t Train loss: 0.1820 took: 1.87s  Val. loss: 0.1743\n",
      "Epoch 35, 100% \t Train loss: 0.1810 took: 1.88s  Val. loss: 0.1735\n",
      "Epoch 36, 100% \t Train loss: 0.1787 took: 1.88s  Val. loss: 0.1714\n",
      "Epoch 37, 100% \t Train loss: 0.1770 took: 1.87s  Val. loss: 0.1786\n",
      "Epoch 38, 100% \t Train loss: 0.1764 took: 1.86s  Val. loss: 0.1652\n",
      "Epoch 39, 100% \t Train loss: 0.1725 took: 1.83s  Val. loss: 0.1647\n",
      "Epoch 40, 100% \t Train loss: 0.1707 took: 1.87s  Val. loss: 0.1642\n",
      "Epoch 41, 100% \t Train loss: 0.1697 took: 1.86s  Val. loss: 0.1607\n",
      "Epoch 42, 100% \t Train loss: 0.1668 took: 1.86s  Val. loss: 0.1600\n",
      "Epoch 43, 100% \t Train loss: 0.1666 took: 1.86s  Val. loss: 0.1565\n",
      "Epoch 44, 100% \t Train loss: 0.1650 took: 1.88s  Val. loss: 0.1557\n",
      "Epoch 45, 100% \t Train loss: 0.1619 took: 1.89s  Val. loss: 0.1574\n",
      "Epoch 46, 100% \t Train loss: 0.1596 took: 1.88s  Val. loss: 0.1541\n",
      "Epoch 47, 100% \t Train loss: 0.1577 took: 1.89s  Val. loss: 0.1492\n",
      "Epoch 48, 100% \t Train loss: 0.1554 took: 1.92s  Val. loss: 0.1518\n",
      "Epoch 49, 100% \t Train loss: 0.1541 took: 1.91s  Val. loss: 0.1476\n",
      "Epoch 50, 100% \t Train loss: 0.1525 took: 1.92s  Val. loss: 0.1536\n",
      "Training finished, took 98.67s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2583 took: 1.77s  Val. loss: 0.2653\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.77s  Val. loss: 0.2644\n",
      "Epoch 3, 100% \t Train loss: 0.2575 took: 1.76s  Val. loss: 0.2650\n",
      "Epoch 4, 100% \t Train loss: 0.2569 took: 1.78s  Val. loss: 0.2629\n",
      "Epoch 5, 100% \t Train loss: 0.2528 took: 1.80s  Val. loss: 0.2526\n",
      "Epoch 6, 100% \t Train loss: 0.2350 took: 1.77s  Val. loss: 0.2253\n",
      "Epoch 7, 100% \t Train loss: 0.2119 took: 1.77s  Val. loss: 0.2053\n",
      "Epoch 8, 100% \t Train loss: 0.2031 took: 1.77s  Val. loss: 0.2027\n",
      "Epoch 9, 100% \t Train loss: 0.2015 took: 1.79s  Val. loss: 0.2001\n",
      "Epoch 10, 100% \t Train loss: 0.1992 took: 1.78s  Val. loss: 0.1986\n",
      "Epoch 11, 100% \t Train loss: 0.1985 took: 1.78s  Val. loss: 0.1980\n",
      "Epoch 12, 100% \t Train loss: 0.1968 took: 1.71s  Val. loss: 0.1988\n",
      "Epoch 13, 100% \t Train loss: 0.1972 took: 1.78s  Val. loss: 0.2025\n",
      "Epoch 14, 100% \t Train loss: 0.1975 took: 1.80s  Val. loss: 0.1962\n",
      "Epoch 15, 100% \t Train loss: 0.1946 took: 1.80s  Val. loss: 0.1967\n",
      "Epoch 16, 100% \t Train loss: 0.1947 took: 1.77s  Val. loss: 0.1969\n",
      "Epoch 17, 100% \t Train loss: 0.1945 took: 1.78s  Val. loss: 0.1946\n",
      "Epoch 18, 100% \t Train loss: 0.1928 took: 1.79s  Val. loss: 0.1963\n",
      "Epoch 19, 100% \t Train loss: 0.1944 took: 1.78s  Val. loss: 0.1984\n",
      "Epoch 20, 100% \t Train loss: 0.1938 took: 1.80s  Val. loss: 0.1952\n",
      "Epoch 21, 100% \t Train loss: 0.1920 took: 1.79s  Val. loss: 0.1969\n",
      "Epoch 22, 100% \t Train loss: 0.1919 took: 1.79s  Val. loss: 0.1947\n",
      "Epoch 23, 100% \t Train loss: 0.1910 took: 1.79s  Val. loss: 0.1951\n",
      "Epoch 24, 100% \t Train loss: 0.1914 took: 1.77s  Val. loss: 0.1962\n",
      "Epoch 25, 100% \t Train loss: 0.1896 took: 1.78s  Val. loss: 0.1962\n",
      "Epoch 26, 100% \t Train loss: 0.1903 took: 1.78s  Val. loss: 0.1942\n",
      "Epoch 27, 100% \t Train loss: 0.1889 took: 1.78s  Val. loss: 0.1932\n",
      "Epoch 28, 100% \t Train loss: 0.1892 took: 1.78s  Val. loss: 0.1935\n",
      "Epoch 29, 100% \t Train loss: 0.1882 took: 1.79s  Val. loss: 0.1936\n",
      "Epoch 30, 100% \t Train loss: 0.1877 took: 1.79s  Val. loss: 0.1903\n",
      "Epoch 31, 100% \t Train loss: 0.1878 took: 1.81s  Val. loss: 0.1933\n",
      "Epoch 32, 100% \t Train loss: 0.1889 took: 1.81s  Val. loss: 0.1936\n",
      "Epoch 33, 100% \t Train loss: 0.1880 took: 1.81s  Val. loss: 0.1915\n",
      "Epoch 34, 100% \t Train loss: 0.1863 took: 1.82s  Val. loss: 0.1951\n",
      "Epoch 35, 100% \t Train loss: 0.1866 took: 1.81s  Val. loss: 0.1897\n",
      "Epoch 36, 100% \t Train loss: 0.1860 took: 1.83s  Val. loss: 0.1908\n",
      "Epoch 37, 100% \t Train loss: 0.1862 took: 1.81s  Val. loss: 0.1911\n",
      "Epoch 38, 100% \t Train loss: 0.1855 took: 1.06s  Val. loss: 0.1914\n",
      "Epoch 39, 100% \t Train loss: 0.1850 took: 1.06s  Val. loss: 0.1902\n",
      "Epoch 40, 100% \t Train loss: 0.1848 took: 1.06s  Val. loss: 0.1901\n",
      "Epoch 41, 100% \t Train loss: 0.1845 took: 1.06s  Val. loss: 0.1906\n",
      "Epoch 42, 100% \t Train loss: 0.1841 took: 1.06s  Val. loss: 0.1949\n",
      "Epoch 43, 100% \t Train loss: 0.1839 took: 1.11s  Val. loss: 0.1886\n",
      "Epoch 44, 100% \t Train loss: 0.1837 took: 1.07s  Val. loss: 0.1967\n",
      "Epoch 45, 100% \t Train loss: 0.1836 took: 1.07s  Val. loss: 0.1877\n",
      "Epoch 46, 100% \t Train loss: 0.1832 took: 1.07s  Val. loss: 0.1897\n",
      "Epoch 47, 100% \t Train loss: 0.1833 took: 1.08s  Val. loss: 0.1874\n",
      "Epoch 48, 100% \t Train loss: 0.1832 took: 1.08s  Val. loss: 0.1910\n",
      "Epoch 49, 100% \t Train loss: 0.1839 took: 1.07s  Val. loss: 0.1893\n",
      "Epoch 50, 100% \t Train loss: 0.1828 took: 1.09s  Val. loss: 0.1932\n",
      "Training finished, took 91.03s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.859786\n",
      "lambda: 0.0010 - V: 0.816770\n",
      "lambda: 0.0005 - V: 0.798291\n",
      "Average V: 0.824949\n",
      "Time elapsed: 266.34 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2569 took: 2.36s  Val. loss: 0.2600\n",
      "Epoch 2, 100% \t Train loss: 0.2566 took: 2.37s  Val. loss: 0.2593\n",
      "Epoch 3, 100% \t Train loss: 0.2565 took: 2.37s  Val. loss: 0.2597\n",
      "Epoch 4, 100% \t Train loss: 0.2567 took: 2.36s  Val. loss: 0.2599\n",
      "Epoch 5, 100% \t Train loss: 0.2565 took: 2.37s  Val. loss: 0.2599\n",
      "Epoch 6, 100% \t Train loss: 0.2566 took: 2.36s  Val. loss: 0.2590\n",
      "Epoch 7, 100% \t Train loss: 0.2565 took: 2.37s  Val. loss: 0.2595\n",
      "Epoch 8, 100% \t Train loss: 0.2565 took: 2.35s  Val. loss: 0.2596\n",
      "Epoch 9, 100% \t Train loss: 0.2565 took: 2.36s  Val. loss: 0.2591\n",
      "Epoch 10, 100% \t Train loss: 0.2564 took: 2.36s  Val. loss: 0.2592\n",
      "Epoch 11, 100% \t Train loss: 0.2564 took: 2.36s  Val. loss: 0.2594\n",
      "Epoch 12, 100% \t Train loss: 0.2565 took: 2.37s  Val. loss: 0.2589\n",
      "Epoch 13, 100% \t Train loss: 0.2565 took: 1.40s  Val. loss: 0.2590\n",
      "Epoch 14, 100% \t Train loss: 0.2565 took: 1.40s  Val. loss: 0.2597\n",
      "Epoch 15, 100% \t Train loss: 0.2565 took: 1.41s  Val. loss: 0.2589\n",
      "Epoch 16, 100% \t Train loss: 0.2564 took: 1.41s  Val. loss: 0.2589\n",
      "Epoch 17, 100% \t Train loss: 0.2564 took: 1.41s  Val. loss: 0.2597\n",
      "Epoch 18, 100% \t Train loss: 0.2565 took: 1.41s  Val. loss: 0.2588\n",
      "Epoch 19, 100% \t Train loss: 0.2565 took: 1.41s  Val. loss: 0.2588\n",
      "Epoch 20, 100% \t Train loss: 0.2564 took: 1.41s  Val. loss: 0.2595\n",
      "Epoch 21, 100% \t Train loss: 0.2564 took: 1.42s  Val. loss: 0.2592\n",
      "Epoch 22, 100% \t Train loss: 0.2565 took: 1.42s  Val. loss: 0.2590\n",
      "Epoch 23, 100% \t Train loss: 0.2564 took: 1.42s  Val. loss: 0.2590\n",
      "Epoch 24, 100% \t Train loss: 0.2564 took: 1.42s  Val. loss: 0.2589\n",
      "Epoch 25, 100% \t Train loss: 0.2564 took: 1.43s  Val. loss: 0.2595\n",
      "Epoch 26, 100% \t Train loss: 0.2564 took: 1.53s  Val. loss: 0.2598\n",
      "Epoch 27, 100% \t Train loss: 0.2565 took: 1.47s  Val. loss: 0.2600\n",
      "Epoch 28, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.2564 took: 1.49s  Val. loss: 0.2586\n",
      "Epoch 30, 100% \t Train loss: 0.2564 took: 1.55s  Val. loss: 0.2599\n",
      "Epoch 31, 100% \t Train loss: 0.2564 took: 1.59s  Val. loss: 0.2602\n",
      "Epoch 32, 100% \t Train loss: 0.2565 took: 1.75s  Val. loss: 0.2594\n",
      "Epoch 33, 100% \t Train loss: 0.2564 took: 1.82s  Val. loss: 0.2595\n",
      "Epoch 34, 100% \t Train loss: 0.2565 took: 1.85s  Val. loss: 0.2580\n",
      "Epoch 35, 100% \t Train loss: 0.2564 took: 2.81s  Val. loss: 0.2595\n",
      "Epoch 36, 100% \t Train loss: 0.2564 took: 2.97s  Val. loss: 0.2604\n",
      "Epoch 37, 100% \t Train loss: 0.2564 took: 2.93s  Val. loss: 0.2592\n",
      "Epoch 38, 100% \t Train loss: 0.2563 took: 3.10s  Val. loss: 0.2601\n",
      "Epoch 39, 100% \t Train loss: 0.2564 took: 3.02s  Val. loss: 0.2594\n",
      "Epoch 40, 100% \t Train loss: 0.2564 took: 3.08s  Val. loss: 0.2597\n",
      "Epoch 41, 100% \t Train loss: 0.2564 took: 3.13s  Val. loss: 0.2595\n",
      "Epoch 42, 100% \t Train loss: 0.2564 took: 3.07s  Val. loss: 0.2589\n",
      "Epoch 43, 100% \t Train loss: 0.2564 took: 3.14s  Val. loss: 0.2597\n",
      "Epoch 44, 100% \t Train loss: 0.2564 took: 3.03s  Val. loss: 0.2592\n",
      "Epoch 45, 100% \t Train loss: 0.2564 took: 3.19s  Val. loss: 0.2598\n",
      "Epoch 46, 100% \t Train loss: 0.2564 took: 3.21s  Val. loss: 0.2593\n",
      "Epoch 47, 100% \t Train loss: 0.2564 took: 3.17s  Val. loss: 0.2595\n",
      "Epoch 48, 100% \t Train loss: 0.2564 took: 3.28s  Val. loss: 0.2589\n",
      "Epoch 49, 100% \t Train loss: 0.2564 took: 3.35s  Val. loss: 0.2595\n",
      "Epoch 50, 100% \t Train loss: 0.2564 took: 3.20s  Val. loss: 0.2594\n",
      "Training finished, took 122.87s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2604 took: 2.39s  Val. loss: 0.2545\n",
      "Epoch 2, 100% \t Train loss: 0.2598 took: 2.40s  Val. loss: 0.2556\n",
      "Epoch 3, 100% \t Train loss: 0.2599 took: 2.38s  Val. loss: 0.2540\n",
      "Epoch 4, 100% \t Train loss: 0.2599 took: 2.37s  Val. loss: 0.2554\n",
      "Epoch 5, 100% \t Train loss: 0.2599 took: 2.39s  Val. loss: 0.2561\n",
      "Epoch 6, 100% \t Train loss: 0.2598 took: 2.38s  Val. loss: 0.2556\n",
      "Epoch 7, 100% \t Train loss: 0.2600 took: 2.37s  Val. loss: 0.2551\n",
      "Epoch 8, 100% \t Train loss: 0.2599 took: 2.38s  Val. loss: 0.2556\n",
      "Epoch 9, 100% \t Train loss: 0.2599 took: 2.38s  Val. loss: 0.2561\n",
      "Epoch 10, 100% \t Train loss: 0.2599 took: 2.37s  Val. loss: 0.2559\n",
      "Epoch 11, 100% \t Train loss: 0.2598 took: 2.38s  Val. loss: 0.2562\n",
      "Epoch 12, 100% \t Train loss: 0.2599 took: 2.37s  Val. loss: 0.2556\n",
      "Epoch 13, 100% \t Train loss: 0.2598 took: 2.37s  Val. loss: 0.2552\n",
      "Epoch 14, 100% \t Train loss: 0.2599 took: 2.37s  Val. loss: 0.2557\n",
      "Epoch 15, 100% \t Train loss: 0.2599 took: 2.36s  Val. loss: 0.2553\n",
      "Epoch 16, 100% \t Train loss: 0.2599 took: 2.35s  Val. loss: 0.2554\n",
      "Epoch 17, 100% \t Train loss: 0.2598 took: 2.36s  Val. loss: 0.2552\n",
      "Epoch 18, 100% \t Train loss: 0.2598 took: 2.36s  Val. loss: 0.2552\n",
      "Epoch 19, 100% \t Train loss: 0.2599 took: 2.37s  Val. loss: 0.2559\n",
      "Epoch 20, 100% \t Train loss: 0.2599 took: 2.37s  Val. loss: 0.2556\n",
      "Epoch 21, 100% \t Train loss: 0.2598 took: 2.38s  Val. loss: 0.2553\n",
      "Epoch 22, 100% \t Train loss: 0.2599 took: 2.38s  Val. loss: 0.2553\n",
      "Epoch 23, 100% \t Train loss: 0.2599 took: 2.36s  Val. loss: 0.2562\n",
      "Epoch 24, 100% \t Train loss: 0.2599 took: 2.36s  Val. loss: 0.2550\n",
      "Epoch 25, 100% \t Train loss: 0.2598 took: 2.39s  Val. loss: 0.2561\n",
      "Epoch 26, 100% \t Train loss: 0.2599 took: 2.39s  Val. loss: 0.2551\n",
      "Epoch 27, 100% \t Train loss: 0.2599 took: 2.38s  Val. loss: 0.2553\n",
      "Epoch 28, 100% \t Train loss: 0.2599 took: 2.43s  Val. loss: 0.2552\n",
      "Epoch 29, 100% \t Train loss: 0.2599 took: 2.41s  Val. loss: 0.2553\n",
      "Epoch 30, 100% \t Train loss: 0.2598 took: 2.41s  Val. loss: 0.2550\n",
      "Epoch 31, 100% \t Train loss: 0.2599 took: 2.43s  Val. loss: 0.2549\n",
      "Epoch 32, 100% \t Train loss: 0.2599 took: 2.48s  Val. loss: 0.2552\n",
      "Epoch 33, 100% \t Train loss: 0.2599 took: 2.51s  Val. loss: 0.2551\n",
      "Epoch 34, 100% \t Train loss: 0.2599 took: 2.48s  Val. loss: 0.2552\n",
      "Epoch 35, 100% \t Train loss: 0.2598 took: 2.47s  Val. loss: 0.2556\n",
      "Epoch 36, 100% \t Train loss: 0.2599 took: 2.46s  Val. loss: 0.2560\n",
      "Epoch 37, 100% \t Train loss: 0.2599 took: 2.49s  Val. loss: 0.2550\n",
      "Epoch 38, 100% \t Train loss: 0.2598 took: 2.47s  Val. loss: 0.2550\n",
      "Epoch 39, 100% \t Train loss: 0.2599 took: 2.46s  Val. loss: 0.2555\n",
      "Epoch 40, 100% \t Train loss: 0.2599 took: 2.53s  Val. loss: 0.2555\n",
      "Epoch 41, 100% \t Train loss: 0.2599 took: 2.46s  Val. loss: 0.2563\n",
      "Epoch 42, 100% \t Train loss: 0.2598 took: 2.51s  Val. loss: 0.2556\n",
      "Epoch 43, 100% \t Train loss: 0.2599 took: 2.52s  Val. loss: 0.2546\n",
      "Epoch 44, 100% \t Train loss: 0.2599 took: 2.56s  Val. loss: 0.2564\n",
      "Epoch 45, 100% \t Train loss: 0.2599 took: 2.58s  Val. loss: 0.2556\n",
      "Epoch 46, 100% \t Train loss: 0.2598 took: 2.62s  Val. loss: 0.2558\n",
      "Epoch 47, 100% \t Train loss: 0.2599 took: 2.65s  Val. loss: 0.2558\n",
      "Epoch 48, 100% \t Train loss: 0.2598 took: 2.70s  Val. loss: 0.2550\n",
      "Epoch 49, 100% \t Train loss: 0.2599 took: 2.69s  Val. loss: 0.2555\n",
      "Epoch 50, 100% \t Train loss: 0.2598 took: 2.76s  Val. loss: 0.2555\n",
      "Training finished, took 135.41s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2586 took: 2.41s  Val. loss: 0.2660\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 2.40s  Val. loss: 0.2668\n",
      "Epoch 3, 100% \t Train loss: 0.2577 took: 2.38s  Val. loss: 0.2661\n",
      "Epoch 4, 100% \t Train loss: 0.2577 took: 2.40s  Val. loss: 0.2667\n",
      "Epoch 5, 100% \t Train loss: 0.2578 took: 2.37s  Val. loss: 0.2667\n",
      "Epoch 6, 100% \t Train loss: 0.2577 took: 2.40s  Val. loss: 0.2672\n",
      "Epoch 7, 100% \t Train loss: 0.2578 took: 2.36s  Val. loss: 0.2658\n",
      "Epoch 8, 100% \t Train loss: 0.2577 took: 2.38s  Val. loss: 0.2659\n",
      "Epoch 9, 100% \t Train loss: 0.2577 took: 2.40s  Val. loss: 0.2664\n",
      "Epoch 10, 100% \t Train loss: 0.2577 took: 2.37s  Val. loss: 0.2667\n",
      "Epoch 11, 100% \t Train loss: 0.2578 took: 2.37s  Val. loss: 0.2661\n",
      "Epoch 12, 100% \t Train loss: 0.2577 took: 2.38s  Val. loss: 0.2665\n",
      "Epoch 13, 100% \t Train loss: 0.2578 took: 2.38s  Val. loss: 0.2658\n",
      "Epoch 14, 100% \t Train loss: 0.2578 took: 2.37s  Val. loss: 0.2659\n",
      "Epoch 15, 100% \t Train loss: 0.2577 took: 2.39s  Val. loss: 0.2665\n",
      "Epoch 16, 100% \t Train loss: 0.2577 took: 2.38s  Val. loss: 0.2666\n",
      "Epoch 17, 100% \t Train loss: 0.2578 took: 2.38s  Val. loss: 0.2663\n",
      "Epoch 18, 100% \t Train loss: 0.2577 took: 2.40s  Val. loss: 0.2659\n",
      "Epoch 19, 100% \t Train loss: 0.2578 took: 2.38s  Val. loss: 0.2663\n",
      "Epoch 20, 100% \t Train loss: 0.2577 took: 2.39s  Val. loss: 0.2658\n",
      "Epoch 21, 100% \t Train loss: 0.2577 took: 2.40s  Val. loss: 0.2651\n",
      "Epoch 22, 100% \t Train loss: 0.2577 took: 2.39s  Val. loss: 0.2664\n",
      "Epoch 23, 100% \t Train loss: 0.2577 took: 2.39s  Val. loss: 0.2660\n",
      "Epoch 24, 100% \t Train loss: 0.2577 took: 2.39s  Val. loss: 0.2666\n",
      "Epoch 25, 100% \t Train loss: 0.2577 took: 2.39s  Val. loss: 0.2659\n",
      "Epoch 26, 100% \t Train loss: 0.2578 took: 1.44s  Val. loss: 0.2654\n",
      "Epoch 27, 100% \t Train loss: 0.2577 took: 1.44s  Val. loss: 0.2666\n",
      "Epoch 28, 100% \t Train loss: 0.2577 took: 1.45s  Val. loss: 0.2653\n",
      "Epoch 29, 100% \t Train loss: 0.2577 took: 1.45s  Val. loss: 0.2668\n",
      "Epoch 30, 100% \t Train loss: 0.2578 took: 1.47s  Val. loss: 0.2663\n",
      "Epoch 31, 100% \t Train loss: 0.2577 took: 1.48s  Val. loss: 0.2662\n",
      "Epoch 32, 100% \t Train loss: 0.2577 took: 1.46s  Val. loss: 0.2668\n",
      "Epoch 33, 100% \t Train loss: 0.2577 took: 1.46s  Val. loss: 0.2667\n",
      "Epoch 34, 100% \t Train loss: 0.2577 took: 1.47s  Val. loss: 0.2663\n",
      "Epoch 35, 100% \t Train loss: 0.2577 took: 1.47s  Val. loss: 0.2672\n",
      "Epoch 36, 100% \t Train loss: 0.2578 took: 1.48s  Val. loss: 0.2657\n",
      "Epoch 37, 100% \t Train loss: 0.2577 took: 1.49s  Val. loss: 0.2661\n",
      "Epoch 38, 100% \t Train loss: 0.2577 took: 1.50s  Val. loss: 0.2662\n",
      "Epoch 39, 100% \t Train loss: 0.2577 took: 1.50s  Val. loss: 0.2650\n",
      "Epoch 40, 100% \t Train loss: 0.2577 took: 1.50s  Val. loss: 0.2665\n",
      "Epoch 41, 100% \t Train loss: 0.2577 took: 1.54s  Val. loss: 0.2655\n",
      "Epoch 42, 100% \t Train loss: 0.2577 took: 1.51s  Val. loss: 0.2664\n",
      "Epoch 43, 100% \t Train loss: 0.2577 took: 1.50s  Val. loss: 0.2659\n",
      "Epoch 44, 100% \t Train loss: 0.2578 took: 1.50s  Val. loss: 0.2665\n",
      "Epoch 45, 100% \t Train loss: 0.2577 took: 1.50s  Val. loss: 0.2656\n",
      "Epoch 46, 100% \t Train loss: 0.2578 took: 1.50s  Val. loss: 0.2661\n",
      "Epoch 47, 100% \t Train loss: 0.2577 took: 1.52s  Val. loss: 0.2666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.2577 took: 1.52s  Val. loss: 0.2657\n",
      "Epoch 49, 100% \t Train loss: 0.2578 took: 1.53s  Val. loss: 0.2662\n",
      "Epoch 50, 100% \t Train loss: 0.2577 took: 1.51s  Val. loss: 0.2654\n",
      "Training finished, took 107.21s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.740619\n",
      "lambda: 0.0010 - V: 0.744554\n",
      "lambda: 0.0005 - V: 0.733820\n",
      "Average V: 0.739665\n",
      "Time elapsed: 368.87 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2587 took: 1.68s  Val. loss: 0.2579\n",
      "Epoch 2, 100% \t Train loss: 0.2537 took: 1.67s  Val. loss: 0.2343\n",
      "Epoch 3, 100% \t Train loss: 0.1899 took: 1.68s  Val. loss: 0.1870\n",
      "Epoch 4, 100% \t Train loss: 0.1697 took: 1.69s  Val. loss: 0.1769\n",
      "Epoch 5, 100% \t Train loss: 0.1636 took: 1.67s  Val. loss: 0.1700\n",
      "Epoch 6, 100% \t Train loss: 0.1603 took: 1.68s  Val. loss: 0.1684\n",
      "Epoch 7, 100% \t Train loss: 0.1579 took: 1.69s  Val. loss: 0.1697\n",
      "Epoch 8, 100% \t Train loss: 0.1571 took: 1.69s  Val. loss: 0.1688\n",
      "Epoch 9, 100% \t Train loss: 0.1562 took: 1.70s  Val. loss: 0.1722\n",
      "Epoch 10, 100% \t Train loss: 0.1568 took: 1.68s  Val. loss: 0.1675\n",
      "Epoch 11, 100% \t Train loss: 0.1547 took: 1.68s  Val. loss: 0.1676\n",
      "Epoch 12, 100% \t Train loss: 0.1535 took: 1.68s  Val. loss: 0.1694\n",
      "Epoch 13, 100% \t Train loss: 0.1529 took: 1.68s  Val. loss: 0.1691\n",
      "Epoch 14, 100% \t Train loss: 0.1527 took: 1.70s  Val. loss: 0.1669\n",
      "Epoch 15, 100% \t Train loss: 0.1543 took: 1.68s  Val. loss: 0.1705\n",
      "Epoch 16, 100% \t Train loss: 0.1520 took: 1.69s  Val. loss: 0.1648\n",
      "Epoch 17, 100% \t Train loss: 0.1519 took: 1.70s  Val. loss: 0.1669\n",
      "Epoch 18, 100% \t Train loss: 0.1521 took: 1.69s  Val. loss: 0.1645\n",
      "Epoch 19, 100% \t Train loss: 0.1517 took: 1.68s  Val. loss: 0.1653\n",
      "Epoch 20, 100% \t Train loss: 0.1509 took: 1.67s  Val. loss: 0.1646\n",
      "Epoch 21, 100% \t Train loss: 0.1498 took: 1.68s  Val. loss: 0.1671\n",
      "Epoch 22, 100% \t Train loss: 0.1497 took: 1.69s  Val. loss: 0.1655\n",
      "Epoch 23, 100% \t Train loss: 0.1504 took: 1.69s  Val. loss: 0.1657\n",
      "Epoch 24, 100% \t Train loss: 0.1499 took: 0.98s  Val. loss: 0.1625\n",
      "Epoch 25, 100% \t Train loss: 0.1485 took: 0.96s  Val. loss: 0.1653\n",
      "Epoch 26, 100% \t Train loss: 0.1481 took: 0.96s  Val. loss: 0.1672\n",
      "Epoch 27, 100% \t Train loss: 0.1477 took: 0.96s  Val. loss: 0.1649\n",
      "Epoch 28, 100% \t Train loss: 0.1464 took: 0.96s  Val. loss: 0.1635\n",
      "Epoch 29, 100% \t Train loss: 0.1452 took: 0.96s  Val. loss: 0.1627\n",
      "Epoch 30, 100% \t Train loss: 0.1432 took: 0.97s  Val. loss: 0.1611\n",
      "Epoch 31, 100% \t Train loss: 0.1420 took: 0.98s  Val. loss: 0.1634\n",
      "Epoch 32, 100% \t Train loss: 0.1404 took: 0.97s  Val. loss: 0.1572\n",
      "Epoch 33, 100% \t Train loss: 0.1391 took: 0.97s  Val. loss: 0.1579\n",
      "Epoch 34, 100% \t Train loss: 0.1376 took: 0.97s  Val. loss: 0.1580\n",
      "Epoch 35, 100% \t Train loss: 0.1348 took: 0.96s  Val. loss: 0.1516\n",
      "Epoch 36, 100% \t Train loss: 0.1336 took: 0.97s  Val. loss: 0.1522\n",
      "Epoch 37, 100% \t Train loss: 0.1302 took: 1.57s  Val. loss: 0.1463\n",
      "Epoch 38, 100% \t Train loss: 0.1267 took: 1.71s  Val. loss: 0.1456\n",
      "Epoch 39, 100% \t Train loss: 0.1219 took: 1.71s  Val. loss: 0.1407\n",
      "Epoch 40, 100% \t Train loss: 0.1192 took: 1.70s  Val. loss: 0.1323\n",
      "Epoch 41, 100% \t Train loss: 0.1143 took: 1.70s  Val. loss: 0.1291\n",
      "Epoch 42, 100% \t Train loss: 0.1115 took: 1.70s  Val. loss: 0.1277\n",
      "Epoch 43, 100% \t Train loss: 0.1092 took: 1.71s  Val. loss: 0.1237\n",
      "Epoch 44, 100% \t Train loss: 0.1087 took: 1.72s  Val. loss: 0.1333\n",
      "Epoch 45, 100% \t Train loss: 0.1061 took: 1.68s  Val. loss: 0.1260\n",
      "Epoch 46, 100% \t Train loss: 0.1050 took: 1.69s  Val. loss: 0.1217\n",
      "Epoch 47, 100% \t Train loss: 0.1033 took: 1.71s  Val. loss: 0.1200\n",
      "Epoch 48, 100% \t Train loss: 0.1021 took: 1.68s  Val. loss: 0.1206\n",
      "Epoch 49, 100% \t Train loss: 0.1000 took: 1.67s  Val. loss: 0.1141\n",
      "Epoch 50, 100% \t Train loss: 0.0987 took: 1.67s  Val. loss: 0.1142\n",
      "Training finished, took 85.61s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2565 took: 1.69s  Val. loss: 0.2583\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 1.69s  Val. loss: 0.2583\n",
      "Epoch 3, 100% \t Train loss: 0.2562 took: 1.67s  Val. loss: 0.2583\n",
      "Epoch 4, 100% \t Train loss: 0.2560 took: 1.68s  Val. loss: 0.2576\n",
      "Epoch 5, 100% \t Train loss: 0.2551 took: 1.69s  Val. loss: 0.2570\n",
      "Epoch 6, 100% \t Train loss: 0.2508 took: 1.68s  Val. loss: 0.2470\n",
      "Epoch 7, 100% \t Train loss: 0.2272 took: 1.67s  Val. loss: 0.2109\n",
      "Epoch 8, 100% \t Train loss: 0.1999 took: 1.67s  Val. loss: 0.1917\n",
      "Epoch 9, 100% \t Train loss: 0.1841 took: 1.03s  Val. loss: 0.1811\n",
      "Epoch 10, 100% \t Train loss: 0.1766 took: 0.96s  Val. loss: 0.1740\n",
      "Epoch 11, 100% \t Train loss: 0.1739 took: 0.96s  Val. loss: 0.1758\n",
      "Epoch 12, 100% \t Train loss: 0.1742 took: 0.96s  Val. loss: 0.1681\n",
      "Epoch 13, 100% \t Train loss: 0.1722 took: 0.96s  Val. loss: 0.1671\n",
      "Epoch 14, 100% \t Train loss: 0.1707 took: 0.96s  Val. loss: 0.1658\n",
      "Epoch 15, 100% \t Train loss: 0.1704 took: 0.96s  Val. loss: 0.1678\n",
      "Epoch 16, 100% \t Train loss: 0.1693 took: 0.96s  Val. loss: 0.1642\n",
      "Epoch 17, 100% \t Train loss: 0.1695 took: 0.96s  Val. loss: 0.1630\n",
      "Epoch 18, 100% \t Train loss: 0.1668 took: 0.97s  Val. loss: 0.1620\n",
      "Epoch 19, 100% \t Train loss: 0.1673 took: 0.96s  Val. loss: 0.1628\n",
      "Epoch 20, 100% \t Train loss: 0.1677 took: 0.96s  Val. loss: 0.1633\n",
      "Epoch 21, 100% \t Train loss: 0.1662 took: 0.96s  Val. loss: 0.1617\n",
      "Epoch 22, 100% \t Train loss: 0.1644 took: 0.96s  Val. loss: 0.1643\n",
      "Epoch 23, 100% \t Train loss: 0.1635 took: 0.96s  Val. loss: 0.1591\n",
      "Epoch 24, 100% \t Train loss: 0.1624 took: 1.50s  Val. loss: 0.1594\n",
      "Epoch 25, 100% \t Train loss: 0.1635 took: 1.69s  Val. loss: 0.1611\n",
      "Epoch 26, 100% \t Train loss: 0.1611 took: 1.69s  Val. loss: 0.1601\n",
      "Epoch 27, 100% \t Train loss: 0.1604 took: 1.68s  Val. loss: 0.1590\n",
      "Epoch 28, 100% \t Train loss: 0.1611 took: 1.70s  Val. loss: 0.1608\n",
      "Epoch 29, 100% \t Train loss: 0.1595 took: 1.71s  Val. loss: 0.1591\n",
      "Epoch 30, 100% \t Train loss: 0.1596 took: 1.70s  Val. loss: 0.1628\n",
      "Epoch 31, 100% \t Train loss: 0.1612 took: 1.69s  Val. loss: 0.1582\n",
      "Epoch 32, 100% \t Train loss: 0.1574 took: 1.73s  Val. loss: 0.1568\n",
      "Epoch 33, 100% \t Train loss: 0.1569 took: 1.72s  Val. loss: 0.1582\n",
      "Epoch 34, 100% \t Train loss: 0.1575 took: 1.71s  Val. loss: 0.1597\n",
      "Epoch 35, 100% \t Train loss: 0.1572 took: 1.71s  Val. loss: 0.1586\n",
      "Epoch 36, 100% \t Train loss: 0.1596 took: 1.72s  Val. loss: 0.1603\n",
      "Epoch 37, 100% \t Train loss: 0.1568 took: 1.72s  Val. loss: 0.1588\n",
      "Epoch 38, 100% \t Train loss: 0.1560 took: 1.71s  Val. loss: 0.1594\n",
      "Epoch 39, 100% \t Train loss: 0.1564 took: 1.72s  Val. loss: 0.1616\n",
      "Epoch 40, 100% \t Train loss: 0.1563 took: 1.72s  Val. loss: 0.1613\n",
      "Epoch 41, 100% \t Train loss: 0.1576 took: 1.74s  Val. loss: 0.1583\n",
      "Epoch 42, 100% \t Train loss: 0.1558 took: 1.73s  Val. loss: 0.1615\n",
      "Epoch 43, 100% \t Train loss: 0.1562 took: 1.73s  Val. loss: 0.1576\n",
      "Epoch 44, 100% \t Train loss: 0.1551 took: 1.74s  Val. loss: 0.1596\n",
      "Epoch 45, 100% \t Train loss: 0.1552 took: 1.75s  Val. loss: 0.1587\n",
      "Epoch 46, 100% \t Train loss: 0.1565 took: 1.75s  Val. loss: 0.1594\n",
      "Epoch 47, 100% \t Train loss: 0.1552 took: 1.78s  Val. loss: 0.1566\n",
      "Epoch 48, 100% \t Train loss: 0.1544 took: 1.75s  Val. loss: 0.1585\n",
      "Epoch 49, 100% \t Train loss: 0.1539 took: 1.76s  Val. loss: 0.1585\n",
      "Epoch 50, 100% \t Train loss: 0.1554 took: 1.74s  Val. loss: 0.1661\n",
      "Training finished, took 84.64s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 1.70s  Val. loss: 0.2596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2574 took: 1.69s  Val. loss: 0.2604\n",
      "Epoch 3, 100% \t Train loss: 0.2573 took: 1.68s  Val. loss: 0.2596\n",
      "Epoch 4, 100% \t Train loss: 0.2574 took: 1.69s  Val. loss: 0.2600\n",
      "Epoch 5, 100% \t Train loss: 0.2574 took: 1.68s  Val. loss: 0.2611\n",
      "Epoch 6, 100% \t Train loss: 0.2574 took: 1.69s  Val. loss: 0.2605\n",
      "Epoch 7, 100% \t Train loss: 0.2573 took: 1.69s  Val. loss: 0.2596\n",
      "Epoch 8, 100% \t Train loss: 0.2573 took: 1.68s  Val. loss: 0.2605\n",
      "Epoch 9, 100% \t Train loss: 0.2574 took: 1.70s  Val. loss: 0.2597\n",
      "Epoch 10, 100% \t Train loss: 0.2574 took: 1.72s  Val. loss: 0.2598\n",
      "Epoch 11, 100% \t Train loss: 0.2573 took: 1.72s  Val. loss: 0.2598\n",
      "Epoch 12, 100% \t Train loss: 0.2574 took: 1.70s  Val. loss: 0.2608\n",
      "Epoch 13, 100% \t Train loss: 0.2573 took: 1.71s  Val. loss: 0.2600\n",
      "Epoch 14, 100% \t Train loss: 0.2574 took: 1.69s  Val. loss: 0.2600\n",
      "Epoch 15, 100% \t Train loss: 0.2573 took: 1.69s  Val. loss: 0.2602\n",
      "Epoch 16, 100% \t Train loss: 0.2573 took: 1.71s  Val. loss: 0.2603\n",
      "Epoch 17, 100% \t Train loss: 0.2572 took: 1.70s  Val. loss: 0.2606\n",
      "Epoch 18, 100% \t Train loss: 0.2573 took: 1.71s  Val. loss: 0.2598\n",
      "Epoch 19, 100% \t Train loss: 0.2572 took: 1.69s  Val. loss: 0.2607\n",
      "Epoch 20, 100% \t Train loss: 0.2572 took: 1.71s  Val. loss: 0.2601\n",
      "Epoch 21, 100% \t Train loss: 0.2572 took: 1.71s  Val. loss: 0.2598\n",
      "Epoch 22, 100% \t Train loss: 0.2571 took: 1.69s  Val. loss: 0.2605\n",
      "Epoch 23, 100% \t Train loss: 0.2569 took: 1.70s  Val. loss: 0.2600\n",
      "Epoch 24, 100% \t Train loss: 0.2567 took: 1.71s  Val. loss: 0.2597\n",
      "Epoch 25, 100% \t Train loss: 0.2559 took: 1.69s  Val. loss: 0.2587\n",
      "Epoch 26, 100% \t Train loss: 0.2539 took: 1.69s  Val. loss: 0.2568\n",
      "Epoch 27, 100% \t Train loss: 0.2490 took: 1.69s  Val. loss: 0.2512\n",
      "Epoch 28, 100% \t Train loss: 0.2386 took: 1.69s  Val. loss: 0.2477\n",
      "Epoch 29, 100% \t Train loss: 0.2315 took: 1.68s  Val. loss: 0.2368\n",
      "Epoch 30, 100% \t Train loss: 0.2255 took: 1.69s  Val. loss: 0.2311\n",
      "Epoch 31, 100% \t Train loss: 0.2234 took: 1.71s  Val. loss: 0.2311\n",
      "Epoch 32, 100% \t Train loss: 0.2219 took: 1.70s  Val. loss: 0.2306\n",
      "Epoch 33, 100% \t Train loss: 0.2182 took: 1.72s  Val. loss: 0.2252\n",
      "Epoch 34, 100% \t Train loss: 0.2153 took: 1.72s  Val. loss: 0.2221\n",
      "Epoch 35, 100% \t Train loss: 0.2113 took: 1.73s  Val. loss: 0.2170\n",
      "Epoch 36, 100% \t Train loss: 0.2085 took: 1.72s  Val. loss: 0.2137\n",
      "Epoch 37, 100% \t Train loss: 0.2037 took: 1.71s  Val. loss: 0.2089\n",
      "Epoch 38, 100% \t Train loss: 0.2016 took: 1.71s  Val. loss: 0.2077\n",
      "Epoch 39, 100% \t Train loss: 0.1998 took: 1.71s  Val. loss: 0.2060\n",
      "Epoch 40, 100% \t Train loss: 0.1986 took: 1.70s  Val. loss: 0.2010\n",
      "Epoch 41, 100% \t Train loss: 0.1974 took: 1.69s  Val. loss: 0.2005\n",
      "Epoch 42, 100% \t Train loss: 0.1983 took: 1.73s  Val. loss: 0.2033\n",
      "Epoch 43, 100% \t Train loss: 0.1972 took: 1.70s  Val. loss: 0.2003\n",
      "Epoch 44, 100% \t Train loss: 0.1954 took: 1.70s  Val. loss: 0.1988\n",
      "Epoch 45, 100% \t Train loss: 0.1940 took: 1.70s  Val. loss: 0.1975\n",
      "Epoch 46, 100% \t Train loss: 0.1948 took: 1.70s  Val. loss: 0.1980\n",
      "Epoch 47, 100% \t Train loss: 0.1929 took: 1.70s  Val. loss: 0.1956\n",
      "Epoch 48, 100% \t Train loss: 0.1924 took: 1.73s  Val. loss: 0.2035\n",
      "Epoch 49, 100% \t Train loss: 0.1931 took: 1.71s  Val. loss: 0.1980\n",
      "Epoch 50, 100% \t Train loss: 0.1921 took: 1.72s  Val. loss: 0.2080\n",
      "Training finished, took 97.56s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.841536\n",
      "lambda: 0.0010 - V: 0.825013\n",
      "lambda: 0.0005 - V: 0.762150\n",
      "Average V: 0.809566\n",
      "Time elapsed: 271.35 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.80s  Val. loss: 0.2519\n",
      "Epoch 2, 100% \t Train loss: 0.2235 took: 1.81s  Val. loss: 0.2099\n",
      "Epoch 3, 100% \t Train loss: 0.2023 took: 1.79s  Val. loss: 0.2080\n",
      "Epoch 4, 100% \t Train loss: 0.1974 took: 1.81s  Val. loss: 0.2011\n",
      "Epoch 5, 100% \t Train loss: 0.1945 took: 1.81s  Val. loss: 0.1997\n",
      "Epoch 6, 100% \t Train loss: 0.1909 took: 1.79s  Val. loss: 0.1974\n",
      "Epoch 7, 100% \t Train loss: 0.1903 took: 1.78s  Val. loss: 0.1944\n",
      "Epoch 8, 100% \t Train loss: 0.1893 took: 1.77s  Val. loss: 0.1928\n",
      "Epoch 9, 100% \t Train loss: 0.1883 took: 1.80s  Val. loss: 0.1953\n",
      "Epoch 10, 100% \t Train loss: 0.1875 took: 1.78s  Val. loss: 0.1927\n",
      "Epoch 11, 100% \t Train loss: 0.1863 took: 1.78s  Val. loss: 0.1943\n",
      "Epoch 12, 100% \t Train loss: 0.1867 took: 1.77s  Val. loss: 0.1971\n",
      "Epoch 13, 100% \t Train loss: 0.1840 took: 1.77s  Val. loss: 0.1901\n",
      "Epoch 14, 100% \t Train loss: 0.1829 took: 1.79s  Val. loss: 0.1868\n",
      "Epoch 15, 100% \t Train loss: 0.1775 took: 1.78s  Val. loss: 0.1861\n",
      "Epoch 16, 100% \t Train loss: 0.1687 took: 1.78s  Val. loss: 0.1701\n",
      "Epoch 17, 100% \t Train loss: 0.1610 took: 1.77s  Val. loss: 0.1675\n",
      "Epoch 18, 100% \t Train loss: 0.1572 took: 1.80s  Val. loss: 0.1597\n",
      "Epoch 19, 100% \t Train loss: 0.1516 took: 1.80s  Val. loss: 0.1564\n",
      "Epoch 20, 100% \t Train loss: 0.1489 took: 1.80s  Val. loss: 0.1520\n",
      "Epoch 21, 100% \t Train loss: 0.1468 took: 1.79s  Val. loss: 0.1541\n",
      "Epoch 22, 100% \t Train loss: 0.1436 took: 1.78s  Val. loss: 0.1497\n",
      "Epoch 23, 100% \t Train loss: 0.1415 took: 1.79s  Val. loss: 0.1464\n",
      "Epoch 24, 100% \t Train loss: 0.1407 took: 1.80s  Val. loss: 0.1456\n",
      "Epoch 25, 100% \t Train loss: 0.1391 took: 1.79s  Val. loss: 0.1463\n",
      "Epoch 26, 100% \t Train loss: 0.1387 took: 1.79s  Val. loss: 0.1420\n",
      "Epoch 27, 100% \t Train loss: 0.1377 took: 1.79s  Val. loss: 0.1427\n",
      "Epoch 28, 100% \t Train loss: 0.1361 took: 1.79s  Val. loss: 0.1430\n",
      "Epoch 29, 100% \t Train loss: 0.1360 took: 1.07s  Val. loss: 0.1415\n",
      "Epoch 30, 100% \t Train loss: 0.1351 took: 1.05s  Val. loss: 0.1406\n",
      "Epoch 31, 100% \t Train loss: 0.1347 took: 1.08s  Val. loss: 0.1435\n",
      "Epoch 32, 100% \t Train loss: 0.1335 took: 1.23s  Val. loss: 0.1384\n",
      "Epoch 33, 100% \t Train loss: 0.1334 took: 1.30s  Val. loss: 0.1377\n",
      "Epoch 34, 100% \t Train loss: 0.1328 took: 1.30s  Val. loss: 0.1386\n",
      "Epoch 35, 100% \t Train loss: 0.1313 took: 1.30s  Val. loss: 0.1373\n",
      "Epoch 36, 100% \t Train loss: 0.1313 took: 2.03s  Val. loss: 0.1391\n",
      "Epoch 37, 100% \t Train loss: 0.1307 took: 2.06s  Val. loss: 0.1384\n",
      "Epoch 38, 100% \t Train loss: 0.1304 took: 2.10s  Val. loss: 0.1404\n",
      "Epoch 39, 100% \t Train loss: 0.1299 took: 2.06s  Val. loss: 0.1371\n",
      "Epoch 40, 100% \t Train loss: 0.1300 took: 2.06s  Val. loss: 0.1373\n",
      "Epoch 41, 100% \t Train loss: 0.1291 took: 2.05s  Val. loss: 0.1375\n",
      "Epoch 42, 100% \t Train loss: 0.1296 took: 2.07s  Val. loss: 0.1405\n",
      "Epoch 43, 100% \t Train loss: 0.1288 took: 2.06s  Val. loss: 0.1361\n",
      "Epoch 44, 100% \t Train loss: 0.1278 took: 2.06s  Val. loss: 0.1341\n",
      "Epoch 45, 100% \t Train loss: 0.1276 took: 2.05s  Val. loss: 0.1366\n",
      "Epoch 46, 100% \t Train loss: 0.1279 took: 2.04s  Val. loss: 0.1352\n",
      "Epoch 47, 100% \t Train loss: 0.1268 took: 2.07s  Val. loss: 0.1336\n",
      "Epoch 48, 100% \t Train loss: 0.1269 took: 2.04s  Val. loss: 0.1391\n",
      "Epoch 49, 100% \t Train loss: 0.1267 took: 2.04s  Val. loss: 0.1342\n",
      "Epoch 50, 100% \t Train loss: 0.1266 took: 2.06s  Val. loss: 0.1360\n",
      "Training finished, took 101.86s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2576 took: 1.81s  Val. loss: 0.2601\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 1.78s  Val. loss: 0.2578\n",
      "Epoch 3, 100% \t Train loss: 0.2467 took: 1.78s  Val. loss: 0.2363\n",
      "Epoch 4, 100% \t Train loss: 0.2078 took: 1.78s  Val. loss: 0.2084\n",
      "Epoch 5, 100% \t Train loss: 0.1937 took: 1.79s  Val. loss: 0.2084\n",
      "Epoch 6, 100% \t Train loss: 0.1899 took: 1.80s  Val. loss: 0.2125\n",
      "Epoch 7, 100% \t Train loss: 0.1878 took: 1.79s  Val. loss: 0.2071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.1853 took: 1.80s  Val. loss: 0.2055\n",
      "Epoch 9, 100% \t Train loss: 0.1839 took: 1.79s  Val. loss: 0.2074\n",
      "Epoch 10, 100% \t Train loss: 0.1819 took: 1.79s  Val. loss: 0.2052\n",
      "Epoch 11, 100% \t Train loss: 0.1815 took: 1.81s  Val. loss: 0.2096\n",
      "Epoch 12, 100% \t Train loss: 0.1805 took: 1.81s  Val. loss: 0.2057\n",
      "Epoch 13, 100% \t Train loss: 0.1797 took: 1.83s  Val. loss: 0.2065\n",
      "Epoch 14, 100% \t Train loss: 0.1787 took: 1.80s  Val. loss: 0.2048\n",
      "Epoch 15, 100% \t Train loss: 0.1774 took: 1.84s  Val. loss: 0.2080\n",
      "Epoch 16, 100% \t Train loss: 0.1769 took: 1.79s  Val. loss: 0.2029\n",
      "Epoch 17, 100% \t Train loss: 0.1764 took: 1.78s  Val. loss: 0.2063\n",
      "Epoch 18, 100% \t Train loss: 0.1765 took: 1.81s  Val. loss: 0.2052\n",
      "Epoch 19, 100% \t Train loss: 0.1750 took: 1.80s  Val. loss: 0.2027\n",
      "Epoch 20, 100% \t Train loss: 0.1745 took: 1.80s  Val. loss: 0.2028\n",
      "Epoch 21, 100% \t Train loss: 0.1729 took: 1.79s  Val. loss: 0.2051\n",
      "Epoch 22, 100% \t Train loss: 0.1707 took: 1.81s  Val. loss: 0.1999\n",
      "Epoch 23, 100% \t Train loss: 0.1682 took: 1.80s  Val. loss: 0.1950\n",
      "Epoch 24, 100% \t Train loss: 0.1650 took: 1.79s  Val. loss: 0.1938\n",
      "Epoch 25, 100% \t Train loss: 0.1598 took: 1.69s  Val. loss: 0.1883\n",
      "Epoch 26, 100% \t Train loss: 0.1553 took: 1.06s  Val. loss: 0.1866\n",
      "Epoch 27, 100% \t Train loss: 0.1524 took: 1.06s  Val. loss: 0.1794\n",
      "Epoch 28, 100% \t Train loss: 0.1490 took: 1.07s  Val. loss: 0.1742\n",
      "Epoch 29, 100% \t Train loss: 0.1456 took: 1.07s  Val. loss: 0.1768\n",
      "Epoch 30, 100% \t Train loss: 0.1428 took: 1.08s  Val. loss: 0.1706\n",
      "Epoch 31, 100% \t Train loss: 0.1412 took: 1.09s  Val. loss: 0.1682\n",
      "Epoch 32, 100% \t Train loss: 0.1386 took: 1.10s  Val. loss: 0.1640\n",
      "Epoch 33, 100% \t Train loss: 0.1382 took: 1.11s  Val. loss: 0.1616\n",
      "Epoch 34, 100% \t Train loss: 0.1344 took: 1.11s  Val. loss: 0.1599\n",
      "Epoch 35, 100% \t Train loss: 0.1328 took: 1.12s  Val. loss: 0.1585\n",
      "Epoch 36, 100% \t Train loss: 0.1320 took: 1.12s  Val. loss: 0.1563\n",
      "Epoch 37, 100% \t Train loss: 0.1301 took: 1.12s  Val. loss: 0.1582\n",
      "Epoch 38, 100% \t Train loss: 0.1299 took: 1.13s  Val. loss: 0.1574\n",
      "Epoch 39, 100% \t Train loss: 0.1292 took: 1.14s  Val. loss: 0.1583\n",
      "Epoch 40, 100% \t Train loss: 0.1272 took: 1.14s  Val. loss: 0.1517\n",
      "Epoch 41, 100% \t Train loss: 0.1262 took: 1.15s  Val. loss: 0.1506\n",
      "Epoch 42, 100% \t Train loss: 0.1259 took: 1.16s  Val. loss: 0.1505\n",
      "Epoch 43, 100% \t Train loss: 0.1246 took: 1.11s  Val. loss: 0.1482\n",
      "Epoch 44, 100% \t Train loss: 0.1249 took: 1.09s  Val. loss: 0.1494\n",
      "Epoch 45, 100% \t Train loss: 0.1234 took: 1.08s  Val. loss: 0.1465\n",
      "Epoch 46, 100% \t Train loss: 0.1229 took: 1.08s  Val. loss: 0.1446\n",
      "Epoch 47, 100% \t Train loss: 0.1226 took: 1.36s  Val. loss: 0.1477\n",
      "Epoch 48, 100% \t Train loss: 0.1222 took: 1.83s  Val. loss: 0.1489\n",
      "Epoch 49, 100% \t Train loss: 0.1217 took: 1.83s  Val. loss: 0.1488\n",
      "Epoch 50, 100% \t Train loss: 0.1205 took: 1.85s  Val. loss: 0.1483\n",
      "Training finished, took 85.10s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2585 took: 1.83s  Val. loss: 0.2701\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.81s  Val. loss: 0.2696\n",
      "Epoch 3, 100% \t Train loss: 0.2581 took: 1.82s  Val. loss: 0.2687\n",
      "Epoch 4, 100% \t Train loss: 0.2574 took: 1.81s  Val. loss: 0.2684\n",
      "Epoch 5, 100% \t Train loss: 0.2552 took: 1.80s  Val. loss: 0.2638\n",
      "Epoch 6, 100% \t Train loss: 0.2491 took: 1.79s  Val. loss: 0.2519\n",
      "Epoch 7, 100% \t Train loss: 0.2323 took: 1.80s  Val. loss: 0.2261\n",
      "Epoch 8, 100% \t Train loss: 0.2121 took: 1.04s  Val. loss: 0.2085\n",
      "Epoch 9, 100% \t Train loss: 0.2043 took: 1.04s  Val. loss: 0.2079\n",
      "Epoch 10, 100% \t Train loss: 0.2028 took: 1.27s  Val. loss: 0.2044\n",
      "Epoch 11, 100% \t Train loss: 0.2008 took: 1.80s  Val. loss: 0.2017\n",
      "Epoch 12, 100% \t Train loss: 0.1999 took: 1.81s  Val. loss: 0.1989\n",
      "Epoch 13, 100% \t Train loss: 0.1982 took: 1.80s  Val. loss: 0.1992\n",
      "Epoch 14, 100% \t Train loss: 0.1973 took: 1.80s  Val. loss: 0.1969\n",
      "Epoch 15, 100% \t Train loss: 0.1958 took: 1.81s  Val. loss: 0.1923\n",
      "Epoch 16, 100% \t Train loss: 0.1945 took: 1.81s  Val. loss: 0.1950\n",
      "Epoch 17, 100% \t Train loss: 0.1939 took: 1.80s  Val. loss: 0.1907\n",
      "Epoch 18, 100% \t Train loss: 0.1932 took: 1.81s  Val. loss: 0.1914\n",
      "Epoch 19, 100% \t Train loss: 0.1919 took: 1.80s  Val. loss: 0.1885\n",
      "Epoch 20, 100% \t Train loss: 0.1914 took: 1.81s  Val. loss: 0.1941\n",
      "Epoch 21, 100% \t Train loss: 0.1913 took: 1.82s  Val. loss: 0.1879\n",
      "Epoch 22, 100% \t Train loss: 0.1900 took: 1.80s  Val. loss: 0.1910\n",
      "Epoch 23, 100% \t Train loss: 0.1909 took: 1.80s  Val. loss: 0.1879\n",
      "Epoch 24, 100% \t Train loss: 0.1894 took: 1.84s  Val. loss: 0.1931\n",
      "Epoch 25, 100% \t Train loss: 0.1896 took: 1.80s  Val. loss: 0.1881\n",
      "Epoch 26, 100% \t Train loss: 0.1900 took: 1.79s  Val. loss: 0.1872\n",
      "Epoch 27, 100% \t Train loss: 0.1883 took: 1.79s  Val. loss: 0.1864\n",
      "Epoch 28, 100% \t Train loss: 0.1889 took: 1.80s  Val. loss: 0.1851\n",
      "Epoch 29, 100% \t Train loss: 0.1884 took: 1.80s  Val. loss: 0.1855\n",
      "Epoch 30, 100% \t Train loss: 0.1883 took: 1.81s  Val. loss: 0.1882\n",
      "Epoch 31, 100% \t Train loss: 0.1887 took: 1.05s  Val. loss: 0.1867\n",
      "Epoch 32, 100% \t Train loss: 0.1878 took: 1.06s  Val. loss: 0.1857\n",
      "Epoch 33, 100% \t Train loss: 0.1882 took: 1.06s  Val. loss: 0.1859\n",
      "Epoch 34, 100% \t Train loss: 0.1871 took: 1.06s  Val. loss: 0.1850\n",
      "Epoch 35, 100% \t Train loss: 0.1880 took: 1.06s  Val. loss: 0.1877\n",
      "Epoch 36, 100% \t Train loss: 0.1873 took: 1.07s  Val. loss: 0.1887\n",
      "Epoch 37, 100% \t Train loss: 0.1868 took: 1.06s  Val. loss: 0.1865\n",
      "Epoch 38, 100% \t Train loss: 0.1869 took: 1.06s  Val. loss: 0.1864\n",
      "Epoch 39, 100% \t Train loss: 0.1872 took: 1.06s  Val. loss: 0.1919\n",
      "Epoch 40, 100% \t Train loss: 0.1874 took: 1.06s  Val. loss: 0.1837\n",
      "Epoch 41, 100% \t Train loss: 0.1859 took: 1.06s  Val. loss: 0.1853\n",
      "Epoch 42, 100% \t Train loss: 0.1860 took: 1.06s  Val. loss: 0.1855\n",
      "Epoch 43, 100% \t Train loss: 0.1854 took: 1.06s  Val. loss: 0.1866\n",
      "Epoch 44, 100% \t Train loss: 0.1856 took: 1.06s  Val. loss: 0.1838\n",
      "Epoch 45, 100% \t Train loss: 0.1856 took: 1.06s  Val. loss: 0.1871\n",
      "Epoch 46, 100% \t Train loss: 0.1859 took: 1.69s  Val. loss: 0.1858\n",
      "Epoch 47, 100% \t Train loss: 0.1847 took: 1.78s  Val. loss: 0.1836\n",
      "Epoch 48, 100% \t Train loss: 0.1842 took: 1.82s  Val. loss: 0.1823\n",
      "Epoch 49, 100% \t Train loss: 0.1852 took: 1.79s  Val. loss: 0.1829\n",
      "Epoch 50, 100% \t Train loss: 0.1840 took: 1.79s  Val. loss: 0.1856\n",
      "Training finished, took 87.60s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.839891\n",
      "lambda: 0.0010 - V: 0.815787\n",
      "lambda: 0.0005 - V: 0.800294\n",
      "Average V: 0.818657\n",
      "Time elapsed: 277.90 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2572 took: 1.83s  Val. loss: 0.2567\n",
      "Epoch 2, 100% \t Train loss: 0.2543 took: 1.83s  Val. loss: 0.2413\n",
      "Epoch 3, 100% \t Train loss: 0.2110 took: 1.84s  Val. loss: 0.2071\n",
      "Epoch 4, 100% \t Train loss: 0.1972 took: 1.83s  Val. loss: 0.2016\n",
      "Epoch 5, 100% \t Train loss: 0.1926 took: 1.83s  Val. loss: 0.1978\n",
      "Epoch 6, 100% \t Train loss: 0.1903 took: 1.81s  Val. loss: 0.1946\n",
      "Epoch 7, 100% \t Train loss: 0.1896 took: 1.81s  Val. loss: 0.1940\n",
      "Epoch 8, 100% \t Train loss: 0.1864 took: 1.82s  Val. loss: 0.1927\n",
      "Epoch 9, 100% \t Train loss: 0.1850 took: 1.82s  Val. loss: 0.1929\n",
      "Epoch 10, 100% \t Train loss: 0.1825 took: 1.83s  Val. loss: 0.1892\n",
      "Epoch 11, 100% \t Train loss: 0.1804 took: 1.84s  Val. loss: 0.1878\n",
      "Epoch 12, 100% \t Train loss: 0.1783 took: 1.82s  Val. loss: 0.1856\n",
      "Epoch 13, 100% \t Train loss: 0.1755 took: 1.81s  Val. loss: 0.1811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.1736 took: 1.82s  Val. loss: 0.1816\n",
      "Epoch 15, 100% \t Train loss: 0.1718 took: 1.83s  Val. loss: 0.1751\n",
      "Epoch 16, 100% \t Train loss: 0.1669 took: 1.82s  Val. loss: 0.1688\n",
      "Epoch 17, 100% \t Train loss: 0.1587 took: 1.84s  Val. loss: 0.1587\n",
      "Epoch 18, 100% \t Train loss: 0.1543 took: 1.83s  Val. loss: 0.1585\n",
      "Epoch 19, 100% \t Train loss: 0.1527 took: 1.82s  Val. loss: 0.1494\n",
      "Epoch 20, 100% \t Train loss: 0.1450 took: 1.81s  Val. loss: 0.1447\n",
      "Epoch 21, 100% \t Train loss: 0.1420 took: 1.04s  Val. loss: 0.1437\n",
      "Epoch 22, 100% \t Train loss: 0.1392 took: 1.05s  Val. loss: 0.1440\n",
      "Epoch 23, 100% \t Train loss: 0.1367 took: 1.04s  Val. loss: 0.1366\n",
      "Epoch 24, 100% \t Train loss: 0.1342 took: 1.04s  Val. loss: 0.1366\n",
      "Epoch 25, 100% \t Train loss: 0.1329 took: 1.05s  Val. loss: 0.1375\n",
      "Epoch 26, 100% \t Train loss: 0.1324 took: 1.05s  Val. loss: 0.1340\n",
      "Epoch 27, 100% \t Train loss: 0.1324 took: 1.05s  Val. loss: 0.1419\n",
      "Epoch 28, 100% \t Train loss: 0.1314 took: 1.05s  Val. loss: 0.1302\n",
      "Epoch 29, 100% \t Train loss: 0.1297 took: 1.05s  Val. loss: 0.1333\n",
      "Epoch 30, 100% \t Train loss: 0.1303 took: 1.06s  Val. loss: 0.1308\n",
      "Epoch 31, 100% \t Train loss: 0.1279 took: 1.07s  Val. loss: 0.1380\n",
      "Epoch 32, 100% \t Train loss: 0.1281 took: 1.10s  Val. loss: 0.1357\n",
      "Epoch 33, 100% \t Train loss: 0.1272 took: 1.20s  Val. loss: 0.1274\n",
      "Epoch 34, 100% \t Train loss: 0.1271 took: 1.23s  Val. loss: 0.1310\n",
      "Epoch 35, 100% \t Train loss: 0.1270 took: 1.23s  Val. loss: 0.1334\n",
      "Epoch 36, 100% \t Train loss: 0.1274 took: 1.24s  Val. loss: 0.1309\n",
      "Epoch 37, 100% \t Train loss: 0.1255 took: 1.24s  Val. loss: 0.1261\n",
      "Epoch 38, 100% \t Train loss: 0.1235 took: 1.24s  Val. loss: 0.1284\n",
      "Epoch 39, 100% \t Train loss: 0.1241 took: 1.25s  Val. loss: 0.1273\n",
      "Epoch 40, 100% \t Train loss: 0.1233 took: 1.25s  Val. loss: 0.1284\n",
      "Epoch 41, 100% \t Train loss: 0.1241 took: 1.24s  Val. loss: 0.1310\n",
      "Epoch 42, 100% \t Train loss: 0.1229 took: 1.24s  Val. loss: 0.1271\n",
      "Epoch 43, 100% \t Train loss: 0.1234 took: 1.24s  Val. loss: 0.1284\n",
      "Epoch 44, 100% \t Train loss: 0.1227 took: 1.24s  Val. loss: 0.1270\n",
      "Epoch 45, 100% \t Train loss: 0.1224 took: 1.23s  Val. loss: 0.1285\n",
      "Epoch 46, 100% \t Train loss: 0.1210 took: 1.23s  Val. loss: 0.1271\n",
      "Epoch 47, 100% \t Train loss: 0.1204 took: 1.23s  Val. loss: 0.1260\n",
      "Epoch 48, 100% \t Train loss: 0.1224 took: 1.23s  Val. loss: 0.1272\n",
      "Epoch 49, 100% \t Train loss: 0.1220 took: 1.24s  Val. loss: 0.1295\n",
      "Epoch 50, 100% \t Train loss: 0.1209 took: 1.23s  Val. loss: 0.1265\n",
      "Training finished, took 81.12s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2582 took: 1.05s  Val. loss: 0.2575\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 1.05s  Val. loss: 0.2567\n",
      "Epoch 3, 100% \t Train loss: 0.2572 took: 1.05s  Val. loss: 0.2569\n",
      "Epoch 4, 100% \t Train loss: 0.2569 took: 1.05s  Val. loss: 0.2551\n",
      "Epoch 5, 100% \t Train loss: 0.2520 took: 1.05s  Val. loss: 0.2407\n",
      "Epoch 6, 100% \t Train loss: 0.2160 took: 1.06s  Val. loss: 0.2047\n",
      "Epoch 7, 100% \t Train loss: 0.2040 took: 1.06s  Val. loss: 0.2082\n",
      "Epoch 8, 100% \t Train loss: 0.1997 took: 1.05s  Val. loss: 0.1983\n",
      "Epoch 9, 100% \t Train loss: 0.1969 took: 1.06s  Val. loss: 0.1975\n",
      "Epoch 10, 100% \t Train loss: 0.1947 took: 1.06s  Val. loss: 0.1978\n",
      "Epoch 11, 100% \t Train loss: 0.1945 took: 1.06s  Val. loss: 0.2011\n",
      "Epoch 12, 100% \t Train loss: 0.1948 took: 1.05s  Val. loss: 0.1968\n",
      "Epoch 13, 100% \t Train loss: 0.1958 took: 1.06s  Val. loss: 0.1981\n",
      "Epoch 14, 100% \t Train loss: 0.1970 took: 1.06s  Val. loss: 0.1990\n",
      "Epoch 15, 100% \t Train loss: 0.1931 took: 1.06s  Val. loss: 0.1969\n",
      "Epoch 16, 100% \t Train loss: 0.1922 took: 1.05s  Val. loss: 0.1949\n",
      "Epoch 17, 100% \t Train loss: 0.1916 took: 1.06s  Val. loss: 0.1958\n",
      "Epoch 18, 100% \t Train loss: 0.1911 took: 1.06s  Val. loss: 0.1973\n",
      "Epoch 19, 100% \t Train loss: 0.1908 took: 1.06s  Val. loss: 0.1960\n",
      "Epoch 20, 100% \t Train loss: 0.1904 took: 1.06s  Val. loss: 0.1942\n",
      "Epoch 21, 100% \t Train loss: 0.1908 took: 1.06s  Val. loss: 0.1950\n",
      "Epoch 22, 100% \t Train loss: 0.1907 took: 1.06s  Val. loss: 0.1940\n",
      "Epoch 23, 100% \t Train loss: 0.1887 took: 1.05s  Val. loss: 0.1939\n",
      "Epoch 24, 100% \t Train loss: 0.1884 took: 1.05s  Val. loss: 0.1944\n",
      "Epoch 25, 100% \t Train loss: 0.1896 took: 1.05s  Val. loss: 0.2071\n",
      "Epoch 26, 100% \t Train loss: 0.1920 took: 1.05s  Val. loss: 0.1956\n",
      "Epoch 27, 100% \t Train loss: 0.1878 took: 1.05s  Val. loss: 0.1943\n",
      "Epoch 28, 100% \t Train loss: 0.1864 took: 1.05s  Val. loss: 0.1916\n",
      "Epoch 29, 100% \t Train loss: 0.1861 took: 1.57s  Val. loss: 0.1910\n",
      "Epoch 30, 100% \t Train loss: 0.1855 took: 1.82s  Val. loss: 0.1917\n",
      "Epoch 31, 100% \t Train loss: 0.1826 took: 1.84s  Val. loss: 0.1904\n",
      "Epoch 32, 100% \t Train loss: 0.1829 took: 1.85s  Val. loss: 0.1962\n",
      "Epoch 33, 100% \t Train loss: 0.1828 took: 1.84s  Val. loss: 0.1881\n",
      "Epoch 34, 100% \t Train loss: 0.1800 took: 1.85s  Val. loss: 0.1876\n",
      "Epoch 35, 100% \t Train loss: 0.1792 took: 1.06s  Val. loss: 0.1847\n",
      "Epoch 36, 100% \t Train loss: 0.1776 took: 1.06s  Val. loss: 0.1811\n",
      "Epoch 37, 100% \t Train loss: 0.1757 took: 1.06s  Val. loss: 0.1818\n",
      "Epoch 38, 100% \t Train loss: 0.1742 took: 1.07s  Val. loss: 0.1795\n",
      "Epoch 39, 100% \t Train loss: 0.1724 took: 1.06s  Val. loss: 0.1806\n",
      "Epoch 40, 100% \t Train loss: 0.1712 took: 1.07s  Val. loss: 0.1748\n",
      "Epoch 41, 100% \t Train loss: 0.1693 took: 1.07s  Val. loss: 0.1792\n",
      "Epoch 42, 100% \t Train loss: 0.1687 took: 1.08s  Val. loss: 0.1761\n",
      "Epoch 43, 100% \t Train loss: 0.1676 took: 1.08s  Val. loss: 0.1716\n",
      "Epoch 44, 100% \t Train loss: 0.1658 took: 1.08s  Val. loss: 0.1710\n",
      "Epoch 45, 100% \t Train loss: 0.1639 took: 1.08s  Val. loss: 0.1724\n",
      "Epoch 46, 100% \t Train loss: 0.1627 took: 1.08s  Val. loss: 0.1695\n",
      "Epoch 47, 100% \t Train loss: 0.1621 took: 1.08s  Val. loss: 0.1667\n",
      "Epoch 48, 100% \t Train loss: 0.1599 took: 1.10s  Val. loss: 0.1712\n",
      "Epoch 49, 100% \t Train loss: 0.1584 took: 1.10s  Val. loss: 0.1721\n",
      "Epoch 50, 100% \t Train loss: 0.1595 took: 1.10s  Val. loss: 0.1681\n",
      "Training finished, took 64.93s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2590 took: 1.07s  Val. loss: 0.2570\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.06s  Val. loss: 0.2569\n",
      "Epoch 3, 100% \t Train loss: 0.2579 took: 1.05s  Val. loss: 0.2571\n",
      "Epoch 4, 100% \t Train loss: 0.2579 took: 1.06s  Val. loss: 0.2573\n",
      "Epoch 5, 100% \t Train loss: 0.2579 took: 1.06s  Val. loss: 0.2566\n",
      "Epoch 6, 100% \t Train loss: 0.2578 took: 1.05s  Val. loss: 0.2578\n",
      "Epoch 7, 100% \t Train loss: 0.2576 took: 1.11s  Val. loss: 0.2573\n",
      "Epoch 8, 100% \t Train loss: 0.2572 took: 1.05s  Val. loss: 0.2553\n",
      "Epoch 9, 100% \t Train loss: 0.2562 took: 1.05s  Val. loss: 0.2530\n",
      "Epoch 10, 100% \t Train loss: 0.2524 took: 1.05s  Val. loss: 0.2448\n",
      "Epoch 11, 100% \t Train loss: 0.2330 took: 1.05s  Val. loss: 0.2123\n",
      "Epoch 12, 100% \t Train loss: 0.2116 took: 1.05s  Val. loss: 0.2015\n",
      "Epoch 13, 100% \t Train loss: 0.2055 took: 1.06s  Val. loss: 0.1975\n",
      "Epoch 14, 100% \t Train loss: 0.2026 took: 1.06s  Val. loss: 0.1993\n",
      "Epoch 15, 100% \t Train loss: 0.2014 took: 1.05s  Val. loss: 0.1942\n",
      "Epoch 16, 100% \t Train loss: 0.2020 took: 1.05s  Val. loss: 0.1952\n",
      "Epoch 17, 100% \t Train loss: 0.2003 took: 1.05s  Val. loss: 0.1958\n",
      "Epoch 18, 100% \t Train loss: 0.2009 took: 1.57s  Val. loss: 0.1981\n",
      "Epoch 19, 100% \t Train loss: 0.1978 took: 1.84s  Val. loss: 0.1924\n",
      "Epoch 20, 100% \t Train loss: 0.1974 took: 1.83s  Val. loss: 0.1946\n",
      "Epoch 21, 100% \t Train loss: 0.1977 took: 1.82s  Val. loss: 0.1940\n",
      "Epoch 22, 100% \t Train loss: 0.1972 took: 1.81s  Val. loss: 0.1948\n",
      "Epoch 23, 100% \t Train loss: 0.1964 took: 1.82s  Val. loss: 0.1918\n",
      "Epoch 24, 100% \t Train loss: 0.1941 took: 1.82s  Val. loss: 0.1933\n",
      "Epoch 25, 100% \t Train loss: 0.1949 took: 1.82s  Val. loss: 0.1924\n",
      "Epoch 26, 100% \t Train loss: 0.1935 took: 1.83s  Val. loss: 0.1925\n",
      "Epoch 27, 100% \t Train loss: 0.1938 took: 1.83s  Val. loss: 0.1913\n",
      "Epoch 28, 100% \t Train loss: 0.1930 took: 1.83s  Val. loss: 0.1922\n",
      "Epoch 29, 100% \t Train loss: 0.1924 took: 1.84s  Val. loss: 0.1893\n",
      "Epoch 30, 100% \t Train loss: 0.1911 took: 1.86s  Val. loss: 0.1912\n",
      "Epoch 31, 100% \t Train loss: 0.1918 took: 1.85s  Val. loss: 0.1888\n",
      "Epoch 32, 100% \t Train loss: 0.1918 took: 1.86s  Val. loss: 0.1879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, 100% \t Train loss: 0.1909 took: 1.87s  Val. loss: 0.1889\n",
      "Epoch 34, 100% \t Train loss: 0.1904 took: 1.86s  Val. loss: 0.1881\n",
      "Epoch 35, 100% \t Train loss: 0.1905 took: 1.89s  Val. loss: 0.1884\n",
      "Epoch 36, 100% \t Train loss: 0.1899 took: 1.88s  Val. loss: 0.1902\n",
      "Epoch 37, 100% \t Train loss: 0.1892 took: 1.29s  Val. loss: 0.1889\n",
      "Epoch 38, 100% \t Train loss: 0.1892 took: 1.09s  Val. loss: 0.1888\n",
      "Epoch 39, 100% \t Train loss: 0.1885 took: 1.09s  Val. loss: 0.1861\n",
      "Epoch 40, 100% \t Train loss: 0.1894 took: 1.10s  Val. loss: 0.1859\n",
      "Epoch 41, 100% \t Train loss: 0.1881 took: 1.11s  Val. loss: 0.1874\n",
      "Epoch 42, 100% \t Train loss: 0.1876 took: 1.11s  Val. loss: 0.1868\n",
      "Epoch 43, 100% \t Train loss: 0.1879 took: 1.11s  Val. loss: 0.1900\n",
      "Epoch 44, 100% \t Train loss: 0.1887 took: 1.11s  Val. loss: 0.1861\n",
      "Epoch 45, 100% \t Train loss: 0.1874 took: 1.11s  Val. loss: 0.1852\n",
      "Epoch 46, 100% \t Train loss: 0.1869 took: 1.10s  Val. loss: 0.1855\n",
      "Epoch 47, 100% \t Train loss: 0.1865 took: 1.10s  Val. loss: 0.1838\n",
      "Epoch 48, 100% \t Train loss: 0.1860 took: 1.11s  Val. loss: 0.1854\n",
      "Epoch 49, 100% \t Train loss: 0.1859 took: 1.85s  Val. loss: 0.1859\n",
      "Epoch 50, 100% \t Train loss: 0.1854 took: 1.86s  Val. loss: 0.1860\n",
      "Training finished, took 79.26s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.845747\n",
      "lambda: 0.0010 - V: 0.804900\n",
      "lambda: 0.0005 - V: 0.795986\n",
      "Average V: 0.815544\n",
      "Time elapsed: 228.81 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2651 took: 1.80s  Val. loss: 0.2615\n",
      "Epoch 2, 100% \t Train loss: 0.2619 took: 1.79s  Val. loss: 0.2612\n",
      "Epoch 3, 100% \t Train loss: 0.2593 took: 1.79s  Val. loss: 0.2485\n",
      "Epoch 4, 100% \t Train loss: 0.2234 took: 1.78s  Val. loss: 0.2028\n",
      "Epoch 5, 100% \t Train loss: 0.2020 took: 1.79s  Val. loss: 0.2003\n",
      "Epoch 6, 100% \t Train loss: 0.1969 took: 1.79s  Val. loss: 0.1927\n",
      "Epoch 7, 100% \t Train loss: 0.1921 took: 1.80s  Val. loss: 0.1916\n",
      "Epoch 8, 100% \t Train loss: 0.1904 took: 1.79s  Val. loss: 0.1884\n",
      "Epoch 9, 100% \t Train loss: 0.1881 took: 1.80s  Val. loss: 0.1903\n",
      "Epoch 10, 100% \t Train loss: 0.1854 took: 1.78s  Val. loss: 0.1888\n",
      "Epoch 11, 100% \t Train loss: 0.1849 took: 1.78s  Val. loss: 0.1874\n",
      "Epoch 12, 100% \t Train loss: 0.1840 took: 1.78s  Val. loss: 0.1847\n",
      "Epoch 13, 100% \t Train loss: 0.1838 took: 1.78s  Val. loss: 0.1904\n",
      "Epoch 14, 100% \t Train loss: 0.1811 took: 1.78s  Val. loss: 0.1820\n",
      "Epoch 15, 100% \t Train loss: 0.1789 took: 1.77s  Val. loss: 0.1847\n",
      "Epoch 16, 100% \t Train loss: 0.1709 took: 1.78s  Val. loss: 0.1755\n",
      "Epoch 17, 100% \t Train loss: 0.1631 took: 1.80s  Val. loss: 0.1763\n",
      "Epoch 18, 100% \t Train loss: 0.1566 took: 1.80s  Val. loss: 0.1602\n",
      "Epoch 19, 100% \t Train loss: 0.1492 took: 1.79s  Val. loss: 0.1540\n",
      "Epoch 20, 100% \t Train loss: 0.1444 took: 1.81s  Val. loss: 0.1495\n",
      "Epoch 21, 100% \t Train loss: 0.1405 took: 1.80s  Val. loss: 0.1457\n",
      "Epoch 22, 100% \t Train loss: 0.1376 took: 1.80s  Val. loss: 0.1467\n",
      "Epoch 23, 100% \t Train loss: 0.1359 took: 1.81s  Val. loss: 0.1426\n",
      "Epoch 24, 100% \t Train loss: 0.1319 took: 1.80s  Val. loss: 0.1402\n",
      "Epoch 25, 100% \t Train loss: 0.1323 took: 1.78s  Val. loss: 0.1365\n",
      "Epoch 26, 100% \t Train loss: 0.1287 took: 1.81s  Val. loss: 0.1357\n",
      "Epoch 27, 100% \t Train loss: 0.1287 took: 1.80s  Val. loss: 0.1336\n",
      "Epoch 28, 100% \t Train loss: 0.1268 took: 1.79s  Val. loss: 0.1379\n",
      "Epoch 29, 100% \t Train loss: 0.1263 took: 1.81s  Val. loss: 0.1326\n",
      "Epoch 30, 100% \t Train loss: 0.1246 took: 1.84s  Val. loss: 0.1358\n",
      "Epoch 31, 100% \t Train loss: 0.1238 took: 1.86s  Val. loss: 0.1355\n",
      "Epoch 32, 100% \t Train loss: 0.1240 took: 1.89s  Val. loss: 0.1342\n",
      "Epoch 33, 100% \t Train loss: 0.1223 took: 2.00s  Val. loss: 0.1314\n",
      "Epoch 34, 100% \t Train loss: 0.1222 took: 1.98s  Val. loss: 0.1354\n",
      "Epoch 35, 100% \t Train loss: 0.1220 took: 1.98s  Val. loss: 0.1317\n",
      "Epoch 36, 100% \t Train loss: 0.1219 took: 1.99s  Val. loss: 0.1342\n",
      "Epoch 37, 100% \t Train loss: 0.1210 took: 1.98s  Val. loss: 0.1333\n",
      "Epoch 38, 100% \t Train loss: 0.1205 took: 1.96s  Val. loss: 0.1317\n",
      "Epoch 39, 100% \t Train loss: 0.1203 took: 1.98s  Val. loss: 0.1348\n",
      "Epoch 40, 100% \t Train loss: 0.1194 took: 1.99s  Val. loss: 0.1318\n",
      "Epoch 41, 100% \t Train loss: 0.1205 took: 1.99s  Val. loss: 0.1333\n",
      "Epoch 42, 100% \t Train loss: 0.1184 took: 1.99s  Val. loss: 0.1295\n",
      "Epoch 43, 100% \t Train loss: 0.1190 took: 1.98s  Val. loss: 0.1294\n",
      "Epoch 44, 100% \t Train loss: 0.1186 took: 2.01s  Val. loss: 0.1285\n",
      "Epoch 45, 100% \t Train loss: 0.1185 took: 2.01s  Val. loss: 0.1325\n",
      "Epoch 46, 100% \t Train loss: 0.1194 took: 2.01s  Val. loss: 0.1343\n",
      "Epoch 47, 100% \t Train loss: 0.1185 took: 1.23s  Val. loss: 0.1304\n",
      "Epoch 48, 100% \t Train loss: 0.1174 took: 1.24s  Val. loss: 0.1315\n",
      "Epoch 49, 100% \t Train loss: 0.1176 took: 1.24s  Val. loss: 0.1314\n",
      "Epoch 50, 100% \t Train loss: 0.1167 took: 1.25s  Val. loss: 0.1312\n",
      "Training finished, took 102.81s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2609 took: 1.03s  Val. loss: 0.2599\n",
      "Epoch 2, 100% \t Train loss: 0.2599 took: 1.10s  Val. loss: 0.2596\n",
      "Epoch 3, 100% \t Train loss: 0.2593 took: 1.02s  Val. loss: 0.2575\n",
      "Epoch 4, 100% \t Train loss: 0.2560 took: 1.02s  Val. loss: 0.2481\n",
      "Epoch 5, 100% \t Train loss: 0.2321 took: 1.03s  Val. loss: 0.2199\n",
      "Epoch 6, 100% \t Train loss: 0.2115 took: 1.02s  Val. loss: 0.2029\n",
      "Epoch 7, 100% \t Train loss: 0.2018 took: 1.03s  Val. loss: 0.1983\n",
      "Epoch 8, 100% \t Train loss: 0.1989 took: 1.03s  Val. loss: 0.1977\n",
      "Epoch 9, 100% \t Train loss: 0.1968 took: 1.04s  Val. loss: 0.1943\n",
      "Epoch 10, 100% \t Train loss: 0.1967 took: 1.03s  Val. loss: 0.1999\n",
      "Epoch 11, 100% \t Train loss: 0.1948 took: 1.03s  Val. loss: 0.1953\n",
      "Epoch 12, 100% \t Train loss: 0.1934 took: 1.03s  Val. loss: 0.1927\n",
      "Epoch 13, 100% \t Train loss: 0.1944 took: 1.03s  Val. loss: 0.1919\n",
      "Epoch 14, 100% \t Train loss: 0.1928 took: 1.02s  Val. loss: 0.1905\n",
      "Epoch 15, 100% \t Train loss: 0.1912 took: 1.80s  Val. loss: 0.1889\n",
      "Epoch 16, 100% \t Train loss: 0.1908 took: 1.80s  Val. loss: 0.1883\n",
      "Epoch 17, 100% \t Train loss: 0.1911 took: 1.79s  Val. loss: 0.1911\n",
      "Epoch 18, 100% \t Train loss: 0.1881 took: 1.78s  Val. loss: 0.1887\n",
      "Epoch 19, 100% \t Train loss: 0.1896 took: 1.78s  Val. loss: 0.1867\n",
      "Epoch 20, 100% \t Train loss: 0.1868 took: 1.80s  Val. loss: 0.1873\n",
      "Epoch 21, 100% \t Train loss: 0.1878 took: 1.81s  Val. loss: 0.1925\n",
      "Epoch 22, 100% \t Train loss: 0.1871 took: 1.03s  Val. loss: 0.1836\n",
      "Epoch 23, 100% \t Train loss: 0.1853 took: 1.02s  Val. loss: 0.1867\n",
      "Epoch 24, 100% \t Train loss: 0.1850 took: 1.02s  Val. loss: 0.1915\n",
      "Epoch 25, 100% \t Train loss: 0.1836 took: 1.02s  Val. loss: 0.1887\n",
      "Epoch 26, 100% \t Train loss: 0.1827 took: 1.02s  Val. loss: 0.1890\n",
      "Epoch 27, 100% \t Train loss: 0.1827 took: 1.02s  Val. loss: 0.1826\n",
      "Epoch 28, 100% \t Train loss: 0.1801 took: 1.01s  Val. loss: 0.1859\n",
      "Epoch 29, 100% \t Train loss: 0.1770 took: 1.03s  Val. loss: 0.1773\n",
      "Epoch 30, 100% \t Train loss: 0.1753 took: 1.03s  Val. loss: 0.1751\n",
      "Epoch 31, 100% \t Train loss: 0.1745 took: 1.05s  Val. loss: 0.1785\n",
      "Epoch 32, 100% \t Train loss: 0.1723 took: 1.05s  Val. loss: 0.1733\n",
      "Epoch 33, 100% \t Train loss: 0.1669 took: 1.05s  Val. loss: 0.1699\n",
      "Epoch 34, 100% \t Train loss: 0.1654 took: 1.05s  Val. loss: 0.1708\n",
      "Epoch 35, 100% \t Train loss: 0.1636 took: 1.05s  Val. loss: 0.1663\n",
      "Epoch 36, 100% \t Train loss: 0.1607 took: 1.05s  Val. loss: 0.1629\n",
      "Epoch 37, 100% \t Train loss: 0.1604 took: 1.05s  Val. loss: 0.1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, 100% \t Train loss: 0.1584 took: 1.06s  Val. loss: 0.1671\n",
      "Epoch 39, 100% \t Train loss: 0.1565 took: 1.05s  Val. loss: 0.1594\n",
      "Epoch 40, 100% \t Train loss: 0.1544 took: 1.04s  Val. loss: 0.1607\n",
      "Epoch 41, 100% \t Train loss: 0.1528 took: 1.04s  Val. loss: 0.1533\n",
      "Epoch 42, 100% \t Train loss: 0.1513 took: 1.05s  Val. loss: 0.1550\n",
      "Epoch 43, 100% \t Train loss: 0.1492 took: 1.06s  Val. loss: 0.1541\n",
      "Epoch 44, 100% \t Train loss: 0.1479 took: 1.06s  Val. loss: 0.1521\n",
      "Epoch 45, 100% \t Train loss: 0.1464 took: 1.05s  Val. loss: 0.1511\n",
      "Epoch 46, 100% \t Train loss: 0.1453 took: 1.05s  Val. loss: 0.1476\n",
      "Epoch 47, 100% \t Train loss: 0.1441 took: 1.06s  Val. loss: 0.1551\n",
      "Epoch 48, 100% \t Train loss: 0.1433 took: 1.05s  Val. loss: 0.1432\n",
      "Epoch 49, 100% \t Train loss: 0.1423 took: 1.05s  Val. loss: 0.1436\n",
      "Epoch 50, 100% \t Train loss: 0.1404 took: 1.11s  Val. loss: 0.1462\n",
      "Training finished, took 64.63s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2576 took: 1.81s  Val. loss: 0.2559\n",
      "Epoch 2, 100% \t Train loss: 0.2572 took: 1.80s  Val. loss: 0.2572\n",
      "Epoch 3, 100% \t Train loss: 0.2570 took: 1.79s  Val. loss: 0.2562\n",
      "Epoch 4, 100% \t Train loss: 0.2563 took: 1.82s  Val. loss: 0.2567\n",
      "Epoch 5, 100% \t Train loss: 0.2551 took: 1.79s  Val. loss: 0.2536\n",
      "Epoch 6, 100% \t Train loss: 0.2494 took: 1.82s  Val. loss: 0.2434\n",
      "Epoch 7, 100% \t Train loss: 0.2380 took: 1.80s  Val. loss: 0.2315\n",
      "Epoch 8, 100% \t Train loss: 0.2223 took: 1.80s  Val. loss: 0.2237\n",
      "Epoch 9, 100% \t Train loss: 0.2131 took: 1.81s  Val. loss: 0.2208\n",
      "Epoch 10, 100% \t Train loss: 0.2102 took: 1.80s  Val. loss: 0.2157\n",
      "Epoch 11, 100% \t Train loss: 0.2084 took: 1.02s  Val. loss: 0.2130\n",
      "Epoch 12, 100% \t Train loss: 0.2055 took: 1.03s  Val. loss: 0.2177\n",
      "Epoch 13, 100% \t Train loss: 0.2076 took: 1.03s  Val. loss: 0.2120\n",
      "Epoch 14, 100% \t Train loss: 0.2045 took: 1.03s  Val. loss: 0.2121\n",
      "Epoch 15, 100% \t Train loss: 0.2034 took: 1.03s  Val. loss: 0.2140\n",
      "Epoch 16, 100% \t Train loss: 0.2027 took: 1.04s  Val. loss: 0.2097\n",
      "Epoch 17, 100% \t Train loss: 0.2024 took: 1.03s  Val. loss: 0.2140\n",
      "Epoch 18, 100% \t Train loss: 0.2015 took: 1.03s  Val. loss: 0.2052\n",
      "Epoch 19, 100% \t Train loss: 0.2004 took: 1.03s  Val. loss: 0.2085\n",
      "Epoch 20, 100% \t Train loss: 0.1995 took: 1.03s  Val. loss: 0.2091\n",
      "Epoch 21, 100% \t Train loss: 0.2000 took: 1.03s  Val. loss: 0.2043\n",
      "Epoch 22, 100% \t Train loss: 0.1974 took: 1.03s  Val. loss: 0.2029\n",
      "Epoch 23, 100% \t Train loss: 0.1975 took: 1.03s  Val. loss: 0.2039\n",
      "Epoch 24, 100% \t Train loss: 0.1966 took: 1.03s  Val. loss: 0.2036\n",
      "Epoch 25, 100% \t Train loss: 0.1984 took: 1.03s  Val. loss: 0.2037\n",
      "Epoch 26, 100% \t Train loss: 0.1960 took: 1.03s  Val. loss: 0.1989\n",
      "Epoch 27, 100% \t Train loss: 0.1939 took: 1.03s  Val. loss: 0.1983\n",
      "Epoch 28, 100% \t Train loss: 0.1940 took: 1.02s  Val. loss: 0.1996\n",
      "Epoch 29, 100% \t Train loss: 0.1929 took: 1.03s  Val. loss: 0.1956\n",
      "Epoch 30, 100% \t Train loss: 0.1939 took: 1.03s  Val. loss: 0.2102\n",
      "Epoch 31, 100% \t Train loss: 0.1925 took: 1.03s  Val. loss: 0.1986\n",
      "Epoch 32, 100% \t Train loss: 0.1926 took: 1.04s  Val. loss: 0.1999\n",
      "Epoch 33, 100% \t Train loss: 0.1916 took: 1.04s  Val. loss: 0.1981\n",
      "Epoch 34, 100% \t Train loss: 0.1895 took: 1.04s  Val. loss: 0.2052\n",
      "Epoch 35, 100% \t Train loss: 0.1905 took: 1.04s  Val. loss: 0.2016\n",
      "Epoch 36, 100% \t Train loss: 0.1883 took: 1.06s  Val. loss: 0.1959\n",
      "Epoch 37, 100% \t Train loss: 0.1876 took: 1.05s  Val. loss: 0.1942\n",
      "Epoch 38, 100% \t Train loss: 0.1888 took: 1.05s  Val. loss: 0.1940\n",
      "Epoch 39, 100% \t Train loss: 0.1864 took: 1.05s  Val. loss: 0.1940\n",
      "Epoch 40, 100% \t Train loss: 0.1867 took: 1.05s  Val. loss: 0.1931\n",
      "Epoch 41, 100% \t Train loss: 0.1862 took: 1.05s  Val. loss: 0.1969\n",
      "Epoch 42, 100% \t Train loss: 0.1857 took: 1.05s  Val. loss: 0.1991\n",
      "Epoch 43, 100% \t Train loss: 0.1866 took: 1.06s  Val. loss: 0.1944\n",
      "Epoch 44, 100% \t Train loss: 0.1838 took: 1.05s  Val. loss: 0.1945\n",
      "Epoch 45, 100% \t Train loss: 0.1843 took: 1.05s  Val. loss: 0.1956\n",
      "Epoch 46, 100% \t Train loss: 0.1842 took: 1.05s  Val. loss: 0.1918\n",
      "Epoch 47, 100% \t Train loss: 0.1845 took: 1.06s  Val. loss: 0.1946\n",
      "Epoch 48, 100% \t Train loss: 0.1833 took: 1.06s  Val. loss: 0.1900\n",
      "Epoch 49, 100% \t Train loss: 0.1835 took: 1.05s  Val. loss: 0.1904\n",
      "Epoch 50, 100% \t Train loss: 0.1833 took: 1.05s  Val. loss: 0.1929\n",
      "Training finished, took 67.34s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.31\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.841918\n",
      "lambda: 0.0010 - V: 0.816754\n",
      "lambda: 0.0005 - V: 0.790676\n",
      "Average V: 0.816449\n",
      "Time elapsed: 238.50 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2605 took: 1.08s  Val. loss: 0.2518\n",
      "Epoch 2, 100% \t Train loss: 0.2212 took: 1.08s  Val. loss: 0.1995\n",
      "Epoch 3, 100% \t Train loss: 0.1992 took: 1.08s  Val. loss: 0.1934\n",
      "Epoch 4, 100% \t Train loss: 0.1937 took: 1.08s  Val. loss: 0.1886\n",
      "Epoch 5, 100% \t Train loss: 0.1908 took: 1.07s  Val. loss: 0.1916\n",
      "Epoch 6, 100% \t Train loss: 0.1888 took: 1.07s  Val. loss: 0.1907\n",
      "Epoch 7, 100% \t Train loss: 0.1857 took: 1.07s  Val. loss: 0.1918\n",
      "Epoch 8, 100% \t Train loss: 0.1828 took: 1.52s  Val. loss: 0.1832\n",
      "Epoch 9, 100% \t Train loss: 0.1760 took: 1.85s  Val. loss: 0.1764\n",
      "Epoch 10, 100% \t Train loss: 0.1674 took: 1.84s  Val. loss: 0.1714\n",
      "Epoch 11, 100% \t Train loss: 0.1610 took: 1.83s  Val. loss: 0.1702\n",
      "Epoch 12, 100% \t Train loss: 0.1571 took: 1.84s  Val. loss: 0.1668\n",
      "Epoch 13, 100% \t Train loss: 0.1520 took: 1.85s  Val. loss: 0.1571\n",
      "Epoch 14, 100% \t Train loss: 0.1485 took: 1.84s  Val. loss: 0.1559\n",
      "Epoch 15, 100% \t Train loss: 0.1457 took: 1.84s  Val. loss: 0.1527\n",
      "Epoch 16, 100% \t Train loss: 0.1432 took: 1.83s  Val. loss: 0.1527\n",
      "Epoch 17, 100% \t Train loss: 0.1416 took: 1.84s  Val. loss: 0.1502\n",
      "Epoch 18, 100% \t Train loss: 0.1403 took: 1.83s  Val. loss: 0.1542\n",
      "Epoch 19, 100% \t Train loss: 0.1393 took: 1.84s  Val. loss: 0.1472\n",
      "Epoch 20, 100% \t Train loss: 0.1384 took: 1.84s  Val. loss: 0.1468\n",
      "Epoch 21, 100% \t Train loss: 0.1372 took: 1.83s  Val. loss: 0.1471\n",
      "Epoch 22, 100% \t Train loss: 0.1372 took: 1.83s  Val. loss: 0.1469\n",
      "Epoch 23, 100% \t Train loss: 0.1364 took: 1.84s  Val. loss: 0.1440\n",
      "Epoch 24, 100% \t Train loss: 0.1350 took: 1.82s  Val. loss: 0.1443\n",
      "Epoch 25, 100% \t Train loss: 0.1363 took: 1.86s  Val. loss: 0.1441\n",
      "Epoch 26, 100% \t Train loss: 0.1358 took: 1.84s  Val. loss: 0.1436\n",
      "Epoch 27, 100% \t Train loss: 0.1350 took: 1.84s  Val. loss: 0.1466\n",
      "Epoch 28, 100% \t Train loss: 0.1347 took: 1.86s  Val. loss: 0.1457\n",
      "Epoch 29, 100% \t Train loss: 0.1350 took: 1.87s  Val. loss: 0.1420\n",
      "Epoch 30, 100% \t Train loss: 0.1334 took: 1.87s  Val. loss: 0.1414\n",
      "Epoch 31, 100% \t Train loss: 0.1336 took: 1.87s  Val. loss: 0.1419\n",
      "Epoch 32, 100% \t Train loss: 0.1332 took: 1.94s  Val. loss: 0.1424\n",
      "Epoch 33, 100% \t Train loss: 0.1329 took: 2.14s  Val. loss: 0.1425\n",
      "Epoch 34, 100% \t Train loss: 0.1327 took: 2.17s  Val. loss: 0.1429\n",
      "Epoch 35, 100% \t Train loss: 0.1320 took: 2.19s  Val. loss: 0.1396\n",
      "Epoch 36, 100% \t Train loss: 0.1318 took: 2.19s  Val. loss: 0.1418\n",
      "Epoch 37, 100% \t Train loss: 0.1324 took: 2.23s  Val. loss: 0.1395\n",
      "Epoch 38, 100% \t Train loss: 0.1309 took: 1.50s  Val. loss: 0.1409\n",
      "Epoch 39, 100% \t Train loss: 0.1310 took: 2.24s  Val. loss: 0.1412\n",
      "Epoch 40, 100% \t Train loss: 0.1306 took: 2.25s  Val. loss: 0.1384\n",
      "Epoch 41, 100% \t Train loss: 0.1301 took: 2.26s  Val. loss: 0.1372\n",
      "Epoch 42, 100% \t Train loss: 0.1308 took: 2.28s  Val. loss: 0.1390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, 100% \t Train loss: 0.1307 took: 2.30s  Val. loss: 0.1380\n",
      "Epoch 44, 100% \t Train loss: 0.1300 took: 2.32s  Val. loss: 0.1385\n",
      "Epoch 45, 100% \t Train loss: 0.1301 took: 2.32s  Val. loss: 0.1369\n",
      "Epoch 46, 100% \t Train loss: 0.1299 took: 2.32s  Val. loss: 0.1393\n",
      "Epoch 47, 100% \t Train loss: 0.1290 took: 2.35s  Val. loss: 0.1400\n",
      "Epoch 48, 100% \t Train loss: 0.1287 took: 2.37s  Val. loss: 0.1403\n",
      "Epoch 49, 100% \t Train loss: 0.1285 took: 2.40s  Val. loss: 0.1379\n",
      "Epoch 50, 100% \t Train loss: 0.1287 took: 2.43s  Val. loss: 0.1387\n",
      "Training finished, took 106.36s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2613 took: 1.86s  Val. loss: 0.2583\n",
      "Epoch 2, 100% \t Train loss: 0.2606 took: 1.84s  Val. loss: 0.2589\n",
      "Epoch 3, 100% \t Train loss: 0.2606 took: 1.83s  Val. loss: 0.2580\n",
      "Epoch 4, 100% \t Train loss: 0.2606 took: 1.85s  Val. loss: 0.2581\n",
      "Epoch 5, 100% \t Train loss: 0.2604 took: 1.83s  Val. loss: 0.2584\n",
      "Epoch 6, 100% \t Train loss: 0.2599 took: 1.87s  Val. loss: 0.2565\n",
      "Epoch 7, 100% \t Train loss: 0.2563 took: 1.86s  Val. loss: 0.2480\n",
      "Epoch 8, 100% \t Train loss: 0.2383 took: 1.86s  Val. loss: 0.2190\n",
      "Epoch 9, 100% \t Train loss: 0.2140 took: 1.85s  Val. loss: 0.1987\n",
      "Epoch 10, 100% \t Train loss: 0.2037 took: 1.83s  Val. loss: 0.1978\n",
      "Epoch 11, 100% \t Train loss: 0.1997 took: 1.83s  Val. loss: 0.1963\n",
      "Epoch 12, 100% \t Train loss: 0.1979 took: 1.83s  Val. loss: 0.1964\n",
      "Epoch 13, 100% \t Train loss: 0.1965 took: 1.84s  Val. loss: 0.1922\n",
      "Epoch 14, 100% \t Train loss: 0.1955 took: 1.84s  Val. loss: 0.1916\n",
      "Epoch 15, 100% \t Train loss: 0.1946 took: 1.86s  Val. loss: 0.1899\n",
      "Epoch 16, 100% \t Train loss: 0.1936 took: 1.84s  Val. loss: 0.1928\n",
      "Epoch 17, 100% \t Train loss: 0.1932 took: 1.85s  Val. loss: 0.1900\n",
      "Epoch 18, 100% \t Train loss: 0.1932 took: 1.86s  Val. loss: 0.1914\n",
      "Epoch 19, 100% \t Train loss: 0.1926 took: 1.86s  Val. loss: 0.1891\n",
      "Epoch 20, 100% \t Train loss: 0.1917 took: 1.85s  Val. loss: 0.1897\n",
      "Epoch 21, 100% \t Train loss: 0.1912 took: 1.85s  Val. loss: 0.1877\n",
      "Epoch 22, 100% \t Train loss: 0.1909 took: 1.86s  Val. loss: 0.1882\n",
      "Epoch 23, 100% \t Train loss: 0.1907 took: 1.86s  Val. loss: 0.1880\n",
      "Epoch 24, 100% \t Train loss: 0.1917 took: 1.86s  Val. loss: 0.1906\n",
      "Epoch 25, 100% \t Train loss: 0.1907 took: 1.85s  Val. loss: 0.1880\n",
      "Epoch 26, 100% \t Train loss: 0.1900 took: 1.86s  Val. loss: 0.1875\n",
      "Epoch 27, 100% \t Train loss: 0.1911 took: 1.85s  Val. loss: 0.1870\n",
      "Epoch 28, 100% \t Train loss: 0.1900 took: 1.86s  Val. loss: 0.1870\n",
      "Epoch 29, 100% \t Train loss: 0.1892 took: 1.51s  Val. loss: 0.1864\n",
      "Epoch 30, 100% \t Train loss: 0.1890 took: 1.09s  Val. loss: 0.1854\n",
      "Epoch 31, 100% \t Train loss: 0.1897 took: 1.11s  Val. loss: 0.1864\n",
      "Epoch 32, 100% \t Train loss: 0.1891 took: 1.17s  Val. loss: 0.1880\n",
      "Epoch 33, 100% \t Train loss: 0.1890 took: 1.12s  Val. loss: 0.1861\n",
      "Epoch 34, 100% \t Train loss: 0.1883 took: 1.13s  Val. loss: 0.1852\n",
      "Epoch 35, 100% \t Train loss: 0.1890 took: 1.15s  Val. loss: 0.1861\n",
      "Epoch 36, 100% \t Train loss: 0.1882 took: 1.16s  Val. loss: 0.1859\n",
      "Epoch 37, 100% \t Train loss: 0.1881 took: 1.16s  Val. loss: 0.1846\n",
      "Epoch 38, 100% \t Train loss: 0.1882 took: 1.16s  Val. loss: 0.1876\n",
      "Epoch 39, 100% \t Train loss: 0.1882 took: 1.15s  Val. loss: 0.1852\n",
      "Epoch 40, 100% \t Train loss: 0.1878 took: 1.20s  Val. loss: 0.1843\n",
      "Epoch 41, 100% \t Train loss: 0.1875 took: 1.95s  Val. loss: 0.1862\n",
      "Epoch 42, 100% \t Train loss: 0.1883 took: 1.94s  Val. loss: 0.1846\n",
      "Epoch 43, 100% \t Train loss: 0.1871 took: 1.97s  Val. loss: 0.1858\n",
      "Epoch 44, 100% \t Train loss: 0.1871 took: 1.98s  Val. loss: 0.1880\n",
      "Epoch 45, 100% \t Train loss: 0.1863 took: 1.98s  Val. loss: 0.1827\n",
      "Epoch 46, 100% \t Train loss: 0.1859 took: 1.98s  Val. loss: 0.1830\n",
      "Epoch 47, 100% \t Train loss: 0.1857 took: 1.97s  Val. loss: 0.1843\n",
      "Epoch 48, 100% \t Train loss: 0.1853 took: 2.01s  Val. loss: 0.1830\n",
      "Epoch 49, 100% \t Train loss: 0.1851 took: 1.27s  Val. loss: 0.1829\n",
      "Epoch 50, 100% \t Train loss: 0.1853 took: 1.22s  Val. loss: 0.1844\n",
      "Training finished, took 95.78s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2598 took: 1.08s  Val. loss: 0.2608\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.07s  Val. loss: 0.2615\n",
      "Epoch 3, 100% \t Train loss: 0.2578 took: 1.07s  Val. loss: 0.2610\n",
      "Epoch 4, 100% \t Train loss: 0.2574 took: 1.07s  Val. loss: 0.2608\n",
      "Epoch 5, 100% \t Train loss: 0.2562 took: 1.07s  Val. loss: 0.2584\n",
      "Epoch 6, 100% \t Train loss: 0.2530 took: 1.07s  Val. loss: 0.2532\n",
      "Epoch 7, 100% \t Train loss: 0.2450 took: 1.07s  Val. loss: 0.2416\n",
      "Epoch 8, 100% \t Train loss: 0.2311 took: 1.07s  Val. loss: 0.2275\n",
      "Epoch 9, 100% \t Train loss: 0.2169 took: 1.07s  Val. loss: 0.2142\n",
      "Epoch 10, 100% \t Train loss: 0.2079 took: 1.07s  Val. loss: 0.2114\n",
      "Epoch 11, 100% \t Train loss: 0.2041 took: 1.08s  Val. loss: 0.2088\n",
      "Epoch 12, 100% \t Train loss: 0.2028 took: 1.07s  Val. loss: 0.2076\n",
      "Epoch 13, 100% \t Train loss: 0.2017 took: 1.07s  Val. loss: 0.2099\n",
      "Epoch 14, 100% \t Train loss: 0.2012 took: 1.07s  Val. loss: 0.2091\n",
      "Epoch 15, 100% \t Train loss: 0.2006 took: 1.07s  Val. loss: 0.2072\n",
      "Epoch 16, 100% \t Train loss: 0.1998 took: 1.08s  Val. loss: 0.2065\n",
      "Epoch 17, 100% \t Train loss: 0.1993 took: 1.08s  Val. loss: 0.2048\n",
      "Epoch 18, 100% \t Train loss: 0.1985 took: 1.59s  Val. loss: 0.2066\n",
      "Epoch 19, 100% \t Train loss: 0.1977 took: 1.84s  Val. loss: 0.2056\n",
      "Epoch 20, 100% \t Train loss: 0.1968 took: 1.85s  Val. loss: 0.2038\n",
      "Epoch 21, 100% \t Train loss: 0.1963 took: 1.85s  Val. loss: 0.2039\n",
      "Epoch 22, 100% \t Train loss: 0.1956 took: 1.85s  Val. loss: 0.2029\n",
      "Epoch 23, 100% \t Train loss: 0.1951 took: 1.86s  Val. loss: 0.2021\n",
      "Epoch 24, 100% \t Train loss: 0.1942 took: 1.84s  Val. loss: 0.2036\n",
      "Epoch 25, 100% \t Train loss: 0.1940 took: 1.85s  Val. loss: 0.2024\n",
      "Epoch 26, 100% \t Train loss: 0.1936 took: 1.86s  Val. loss: 0.2019\n",
      "Epoch 27, 100% \t Train loss: 0.1929 took: 1.08s  Val. loss: 0.2015\n",
      "Epoch 28, 100% \t Train loss: 0.1922 took: 1.08s  Val. loss: 0.2022\n",
      "Epoch 29, 100% \t Train loss: 0.1918 took: 1.08s  Val. loss: 0.1998\n",
      "Epoch 30, 100% \t Train loss: 0.1913 took: 1.08s  Val. loss: 0.2016\n",
      "Epoch 31, 100% \t Train loss: 0.1911 took: 1.10s  Val. loss: 0.1998\n",
      "Epoch 32, 100% \t Train loss: 0.1903 took: 1.09s  Val. loss: 0.2001\n",
      "Epoch 33, 100% \t Train loss: 0.1901 took: 1.10s  Val. loss: 0.1973\n",
      "Epoch 34, 100% \t Train loss: 0.1899 took: 1.10s  Val. loss: 0.1998\n",
      "Epoch 35, 100% \t Train loss: 0.1890 took: 1.10s  Val. loss: 0.1984\n",
      "Epoch 36, 100% \t Train loss: 0.1890 took: 1.10s  Val. loss: 0.1984\n",
      "Epoch 37, 100% \t Train loss: 0.1885 took: 1.10s  Val. loss: 0.1996\n",
      "Epoch 38, 100% \t Train loss: 0.1890 took: 1.10s  Val. loss: 0.1978\n",
      "Epoch 39, 100% \t Train loss: 0.1882 took: 1.10s  Val. loss: 0.1976\n",
      "Epoch 40, 100% \t Train loss: 0.1878 took: 1.10s  Val. loss: 0.1979\n",
      "Epoch 41, 100% \t Train loss: 0.1876 took: 1.10s  Val. loss: 0.1973\n",
      "Epoch 42, 100% \t Train loss: 0.1875 took: 1.10s  Val. loss: 0.1970\n",
      "Epoch 43, 100% \t Train loss: 0.1869 took: 1.10s  Val. loss: 0.1968\n",
      "Epoch 44, 100% \t Train loss: 0.1869 took: 1.09s  Val. loss: 0.1965\n",
      "Epoch 45, 100% \t Train loss: 0.1863 took: 1.08s  Val. loss: 0.1972\n",
      "Epoch 46, 100% \t Train loss: 0.1861 took: 1.07s  Val. loss: 0.1994\n",
      "Epoch 47, 100% \t Train loss: 0.1863 took: 1.24s  Val. loss: 0.1950\n",
      "Epoch 48, 100% \t Train loss: 0.1857 took: 1.85s  Val. loss: 0.1955\n",
      "Epoch 49, 100% \t Train loss: 0.1855 took: 1.85s  Val. loss: 0.1976\n",
      "Epoch 50, 100% \t Train loss: 0.1858 took: 1.84s  Val. loss: 0.1967\n",
      "Training finished, took 71.72s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.845309\n",
      "lambda: 0.0010 - V: 0.801769\n",
      "lambda: 0.0005 - V: 0.790049\n",
      "Average V: 0.812375\n",
      "Time elapsed: 277.25 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2593 took: 1.91s  Val. loss: 0.2541\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.92s  Val. loss: 0.2560\n",
      "Epoch 3, 100% \t Train loss: 0.2580 took: 1.92s  Val. loss: 0.2558\n",
      "Epoch 4, 100% \t Train loss: 0.2584 took: 1.93s  Val. loss: 0.2553\n",
      "Epoch 5, 100% \t Train loss: 0.2580 took: 1.93s  Val. loss: 0.2546\n",
      "Epoch 6, 100% \t Train loss: 0.2582 took: 1.92s  Val. loss: 0.2542\n",
      "Epoch 7, 100% \t Train loss: 0.2580 took: 1.91s  Val. loss: 0.2552\n",
      "Epoch 8, 100% \t Train loss: 0.2581 took: 1.90s  Val. loss: 0.2542\n",
      "Epoch 9, 100% \t Train loss: 0.2581 took: 1.91s  Val. loss: 0.2553\n",
      "Epoch 10, 100% \t Train loss: 0.2580 took: 1.90s  Val. loss: 0.2544\n",
      "Epoch 11, 100% \t Train loss: 0.2579 took: 1.92s  Val. loss: 0.2539\n",
      "Epoch 12, 100% \t Train loss: 0.2555 took: 1.91s  Val. loss: 0.2418\n",
      "Epoch 13, 100% \t Train loss: 0.2165 took: 1.91s  Val. loss: 0.1906\n",
      "Epoch 14, 100% \t Train loss: 0.1865 took: 1.92s  Val. loss: 0.1793\n",
      "Epoch 15, 100% \t Train loss: 0.1728 took: 1.90s  Val. loss: 0.1716\n",
      "Epoch 16, 100% \t Train loss: 0.1656 took: 1.90s  Val. loss: 0.1697\n",
      "Epoch 17, 100% \t Train loss: 0.1642 took: 1.91s  Val. loss: 0.1695\n",
      "Epoch 18, 100% \t Train loss: 0.1627 took: 1.92s  Val. loss: 0.1689\n",
      "Epoch 19, 100% \t Train loss: 0.1612 took: 1.91s  Val. loss: 0.1739\n",
      "Epoch 20, 100% \t Train loss: 0.1609 took: 1.91s  Val. loss: 0.1706\n",
      "Epoch 21, 100% \t Train loss: 0.1602 took: 1.91s  Val. loss: 0.1683\n",
      "Epoch 22, 100% \t Train loss: 0.1592 took: 1.91s  Val. loss: 0.1675\n",
      "Epoch 23, 100% \t Train loss: 0.1575 took: 1.91s  Val. loss: 0.1657\n",
      "Epoch 24, 100% \t Train loss: 0.1536 took: 1.90s  Val. loss: 0.1604\n",
      "Epoch 25, 100% \t Train loss: 0.1495 took: 1.91s  Val. loss: 0.1615\n",
      "Epoch 26, 100% \t Train loss: 0.1440 took: 1.93s  Val. loss: 0.1514\n",
      "Epoch 27, 100% \t Train loss: 0.1402 took: 1.91s  Val. loss: 0.1473\n",
      "Epoch 28, 100% \t Train loss: 0.1334 took: 1.92s  Val. loss: 0.1424\n",
      "Epoch 29, 100% \t Train loss: 0.1306 took: 1.92s  Val. loss: 0.1419\n",
      "Epoch 30, 100% \t Train loss: 0.1279 took: 1.93s  Val. loss: 0.1368\n",
      "Epoch 31, 100% \t Train loss: 0.1230 took: 1.94s  Val. loss: 0.1373\n",
      "Epoch 32, 100% \t Train loss: 0.1170 took: 1.95s  Val. loss: 0.1321\n",
      "Epoch 33, 100% \t Train loss: 0.1156 took: 1.99s  Val. loss: 0.1260\n",
      "Epoch 34, 100% \t Train loss: 0.1110 took: 2.01s  Val. loss: 0.1218\n",
      "Epoch 35, 100% \t Train loss: 0.1059 took: 2.01s  Val. loss: 0.1131\n",
      "Epoch 36, 100% \t Train loss: 0.1061 took: 2.00s  Val. loss: 0.1091\n",
      "Epoch 37, 100% \t Train loss: 0.1011 took: 2.02s  Val. loss: 0.1128\n",
      "Epoch 38, 100% \t Train loss: 0.1008 took: 2.02s  Val. loss: 0.1125\n",
      "Epoch 39, 100% \t Train loss: 0.0989 took: 2.04s  Val. loss: 0.1101\n",
      "Epoch 40, 100% \t Train loss: 0.0972 took: 2.03s  Val. loss: 0.1092\n",
      "Epoch 41, 100% \t Train loss: 0.0976 took: 2.05s  Val. loss: 0.1061\n",
      "Epoch 42, 100% \t Train loss: 0.0917 took: 2.06s  Val. loss: 0.1101\n",
      "Epoch 43, 100% \t Train loss: 0.0923 took: 2.04s  Val. loss: 0.1018\n",
      "Epoch 44, 100% \t Train loss: 0.0904 took: 2.06s  Val. loss: 0.1024\n",
      "Epoch 45, 100% \t Train loss: 0.0888 took: 2.10s  Val. loss: 0.1045\n",
      "Epoch 46, 100% \t Train loss: 0.0888 took: 2.09s  Val. loss: 0.1047\n",
      "Epoch 47, 100% \t Train loss: 0.0886 took: 2.09s  Val. loss: 0.1033\n",
      "Epoch 48, 100% \t Train loss: 0.0900 took: 2.11s  Val. loss: 0.1071\n",
      "Epoch 49, 100% \t Train loss: 0.0878 took: 2.12s  Val. loss: 0.0997\n",
      "Epoch 50, 100% \t Train loss: 0.0843 took: 2.14s  Val. loss: 0.1031\n",
      "Training finished, took 111.22s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2579 took: 1.89s  Val. loss: 0.2521\n",
      "Epoch 2, 100% \t Train loss: 0.2571 took: 1.88s  Val. loss: 0.2522\n",
      "Epoch 3, 100% \t Train loss: 0.2571 took: 1.88s  Val. loss: 0.2521\n",
      "Epoch 4, 100% \t Train loss: 0.2569 took: 1.89s  Val. loss: 0.2518\n",
      "Epoch 5, 100% \t Train loss: 0.2553 took: 1.89s  Val. loss: 0.2477\n",
      "Epoch 6, 100% \t Train loss: 0.2344 took: 1.88s  Val. loss: 0.2119\n",
      "Epoch 7, 100% \t Train loss: 0.2092 took: 1.89s  Val. loss: 0.1877\n",
      "Epoch 8, 100% \t Train loss: 0.1866 took: 1.92s  Val. loss: 0.1775\n",
      "Epoch 9, 100% \t Train loss: 0.1768 took: 1.92s  Val. loss: 0.1691\n",
      "Epoch 10, 100% \t Train loss: 0.1722 took: 1.92s  Val. loss: 0.1684\n",
      "Epoch 11, 100% \t Train loss: 0.1695 took: 1.91s  Val. loss: 0.1644\n",
      "Epoch 12, 100% \t Train loss: 0.1719 took: 1.89s  Val. loss: 0.1643\n",
      "Epoch 13, 100% \t Train loss: 0.1686 took: 1.89s  Val. loss: 0.1667\n",
      "Epoch 14, 100% \t Train loss: 0.1655 took: 1.89s  Val. loss: 0.1704\n",
      "Epoch 15, 100% \t Train loss: 0.1650 took: 1.89s  Val. loss: 0.1669\n",
      "Epoch 16, 100% \t Train loss: 0.1637 took: 1.93s  Val. loss: 0.1610\n",
      "Epoch 17, 100% \t Train loss: 0.1629 took: 1.93s  Val. loss: 0.1608\n",
      "Epoch 18, 100% \t Train loss: 0.1595 took: 1.92s  Val. loss: 0.1587\n",
      "Epoch 19, 100% \t Train loss: 0.1623 took: 1.93s  Val. loss: 0.1589\n",
      "Epoch 20, 100% \t Train loss: 0.1580 took: 1.92s  Val. loss: 0.1563\n",
      "Epoch 21, 100% \t Train loss: 0.1590 took: 1.91s  Val. loss: 0.1531\n",
      "Epoch 22, 100% \t Train loss: 0.1580 took: 1.92s  Val. loss: 0.1580\n",
      "Epoch 23, 100% \t Train loss: 0.1559 took: 1.90s  Val. loss: 0.1555\n",
      "Epoch 24, 100% \t Train loss: 0.1585 took: 1.90s  Val. loss: 0.1540\n",
      "Epoch 25, 100% \t Train loss: 0.1560 took: 1.93s  Val. loss: 0.1566\n",
      "Epoch 26, 100% \t Train loss: 0.1550 took: 1.90s  Val. loss: 0.1533\n",
      "Epoch 27, 100% \t Train loss: 0.1555 took: 1.90s  Val. loss: 0.1543\n",
      "Epoch 28, 100% \t Train loss: 0.1540 took: 1.90s  Val. loss: 0.1516\n",
      "Epoch 29, 100% \t Train loss: 0.1547 took: 1.92s  Val. loss: 0.1508\n",
      "Epoch 30, 100% \t Train loss: 0.1521 took: 1.93s  Val. loss: 0.1555\n",
      "Epoch 31, 100% \t Train loss: 0.1536 took: 1.96s  Val. loss: 0.1520\n",
      "Epoch 32, 100% \t Train loss: 0.1526 took: 1.99s  Val. loss: 0.1498\n",
      "Epoch 33, 100% \t Train loss: 0.1513 took: 1.99s  Val. loss: 0.1509\n",
      "Epoch 34, 100% \t Train loss: 0.1509 took: 1.21s  Val. loss: 0.1529\n",
      "Epoch 35, 100% \t Train loss: 0.1524 took: 1.20s  Val. loss: 0.1517\n",
      "Epoch 36, 100% \t Train loss: 0.1510 took: 1.15s  Val. loss: 0.1591\n",
      "Epoch 37, 100% \t Train loss: 0.1502 took: 1.15s  Val. loss: 0.1518\n",
      "Epoch 38, 100% \t Train loss: 0.1506 took: 1.22s  Val. loss: 0.1511\n",
      "Epoch 39, 100% \t Train loss: 0.1496 took: 1.16s  Val. loss: 0.1499\n",
      "Epoch 40, 100% \t Train loss: 0.1486 took: 1.15s  Val. loss: 0.1501\n",
      "Epoch 41, 100% \t Train loss: 0.1491 took: 1.14s  Val. loss: 0.1522\n",
      "Epoch 42, 100% \t Train loss: 0.1485 took: 1.15s  Val. loss: 0.1497\n",
      "Epoch 43, 100% \t Train loss: 0.1468 took: 1.15s  Val. loss: 0.1491\n",
      "Epoch 44, 100% \t Train loss: 0.1462 took: 1.14s  Val. loss: 0.1550\n",
      "Epoch 45, 100% \t Train loss: 0.1465 took: 1.15s  Val. loss: 0.1511\n",
      "Epoch 46, 100% \t Train loss: 0.1444 took: 1.15s  Val. loss: 0.1492\n",
      "Epoch 47, 100% \t Train loss: 0.1440 took: 1.14s  Val. loss: 0.1485\n",
      "Epoch 48, 100% \t Train loss: 0.1424 took: 1.14s  Val. loss: 0.1491\n",
      "Epoch 49, 100% \t Train loss: 0.1409 took: 1.14s  Val. loss: 0.1456\n",
      "Epoch 50, 100% \t Train loss: 0.1380 took: 1.42s  Val. loss: 0.1492\n",
      "Training finished, took 93.60s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2595 took: 1.92s  Val. loss: 0.2645\n",
      "Epoch 2, 100% \t Train loss: 0.2589 took: 1.90s  Val. loss: 0.2648\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 1.93s  Val. loss: 0.2648\n",
      "Epoch 4, 100% \t Train loss: 0.2587 took: 1.91s  Val. loss: 0.2655\n",
      "Epoch 5, 100% \t Train loss: 0.2588 took: 1.92s  Val. loss: 0.2644\n",
      "Epoch 6, 100% \t Train loss: 0.2586 took: 1.91s  Val. loss: 0.2642\n",
      "Epoch 7, 100% \t Train loss: 0.2580 took: 1.90s  Val. loss: 0.2645\n",
      "Epoch 8, 100% \t Train loss: 0.2564 took: 1.92s  Val. loss: 0.2602\n",
      "Epoch 9, 100% \t Train loss: 0.2417 took: 1.90s  Val. loss: 0.2313\n",
      "Epoch 10, 100% \t Train loss: 0.2146 took: 1.91s  Val. loss: 0.2103\n",
      "Epoch 11, 100% \t Train loss: 0.1970 took: 1.89s  Val. loss: 0.2014\n",
      "Epoch 12, 100% \t Train loss: 0.1860 took: 1.89s  Val. loss: 0.1894\n",
      "Epoch 13, 100% \t Train loss: 0.1783 took: 1.91s  Val. loss: 0.1908\n",
      "Epoch 14, 100% \t Train loss: 0.1769 took: 1.88s  Val. loss: 0.1866\n",
      "Epoch 15, 100% \t Train loss: 0.1730 took: 1.90s  Val. loss: 0.1810\n",
      "Epoch 16, 100% \t Train loss: 0.1731 took: 1.91s  Val. loss: 0.1827\n",
      "Epoch 17, 100% \t Train loss: 0.1701 took: 1.90s  Val. loss: 0.1753\n",
      "Epoch 18, 100% \t Train loss: 0.1691 took: 1.91s  Val. loss: 0.1774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1694 took: 1.90s  Val. loss: 0.1753\n",
      "Epoch 20, 100% \t Train loss: 0.1668 took: 1.91s  Val. loss: 0.1750\n",
      "Epoch 21, 100% \t Train loss: 0.1655 took: 1.89s  Val. loss: 0.1749\n",
      "Epoch 22, 100% \t Train loss: 0.1654 took: 1.13s  Val. loss: 0.1723\n",
      "Epoch 23, 100% \t Train loss: 0.1659 took: 1.12s  Val. loss: 0.1717\n",
      "Epoch 24, 100% \t Train loss: 0.1637 took: 1.17s  Val. loss: 0.1718\n",
      "Epoch 25, 100% \t Train loss: 0.1629 took: 1.11s  Val. loss: 0.1869\n",
      "Epoch 26, 100% \t Train loss: 0.1630 took: 1.54s  Val. loss: 0.1714\n",
      "Epoch 27, 100% \t Train loss: 0.1618 took: 1.92s  Val. loss: 0.1748\n",
      "Epoch 28, 100% \t Train loss: 0.1612 took: 1.93s  Val. loss: 0.1705\n",
      "Epoch 29, 100% \t Train loss: 0.1608 took: 1.94s  Val. loss: 0.1782\n",
      "Epoch 30, 100% \t Train loss: 0.1629 took: 1.96s  Val. loss: 0.1695\n",
      "Epoch 31, 100% \t Train loss: 0.1587 took: 1.99s  Val. loss: 0.1692\n",
      "Epoch 32, 100% \t Train loss: 0.1601 took: 2.00s  Val. loss: 0.1691\n",
      "Epoch 33, 100% \t Train loss: 0.1574 took: 2.01s  Val. loss: 0.1688\n",
      "Epoch 34, 100% \t Train loss: 0.1584 took: 2.01s  Val. loss: 0.1695\n",
      "Epoch 35, 100% \t Train loss: 0.1582 took: 2.01s  Val. loss: 0.1695\n",
      "Epoch 36, 100% \t Train loss: 0.1575 took: 2.05s  Val. loss: 0.1678\n",
      "Epoch 37, 100% \t Train loss: 0.1574 took: 2.06s  Val. loss: 0.1684\n",
      "Epoch 38, 100% \t Train loss: 0.1557 took: 2.04s  Val. loss: 0.1684\n",
      "Epoch 39, 100% \t Train loss: 0.1553 took: 2.06s  Val. loss: 0.1708\n",
      "Epoch 40, 100% \t Train loss: 0.1557 took: 1.28s  Val. loss: 0.1681\n",
      "Epoch 41, 100% \t Train loss: 0.1544 took: 1.31s  Val. loss: 0.1694\n",
      "Epoch 42, 100% \t Train loss: 0.1556 took: 1.34s  Val. loss: 0.1671\n",
      "Epoch 43, 100% \t Train loss: 0.1544 took: 1.35s  Val. loss: 0.1674\n",
      "Epoch 44, 100% \t Train loss: 0.1534 took: 1.37s  Val. loss: 0.1678\n",
      "Epoch 45, 100% \t Train loss: 0.1529 took: 1.61s  Val. loss: 0.1668\n",
      "Epoch 46, 100% \t Train loss: 0.1543 took: 2.16s  Val. loss: 0.1712\n",
      "Epoch 47, 100% \t Train loss: 0.1535 took: 2.16s  Val. loss: 0.1675\n",
      "Epoch 48, 100% \t Train loss: 0.1527 took: 2.15s  Val. loss: 0.1667\n",
      "Epoch 49, 100% \t Train loss: 0.1528 took: 2.15s  Val. loss: 0.1665\n",
      "Epoch 50, 100% \t Train loss: 0.1530 took: 2.12s  Val. loss: 0.1666\n",
      "Training finished, took 102.54s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.835822\n",
      "lambda: 0.0010 - V: 0.832805\n",
      "lambda: 0.0005 - V: 0.810045\n",
      "Average V: 0.826224\n",
      "Time elapsed: 310.73 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2581 took: 1.87s  Val. loss: 0.2610\n",
      "Epoch 2, 100% \t Train loss: 0.2524 took: 1.86s  Val. loss: 0.2291\n",
      "Epoch 3, 100% \t Train loss: 0.1889 took: 1.86s  Val. loss: 0.1765\n",
      "Epoch 4, 100% \t Train loss: 0.1605 took: 1.86s  Val. loss: 0.1707\n",
      "Epoch 5, 100% \t Train loss: 0.1543 took: 1.88s  Val. loss: 0.1682\n",
      "Epoch 6, 100% \t Train loss: 0.1490 took: 1.85s  Val. loss: 0.1639\n",
      "Epoch 7, 100% \t Train loss: 0.1474 took: 1.87s  Val. loss: 0.1657\n",
      "Epoch 8, 100% \t Train loss: 0.1466 took: 1.86s  Val. loss: 0.1655\n",
      "Epoch 9, 100% \t Train loss: 0.1471 took: 1.85s  Val. loss: 0.1706\n",
      "Epoch 10, 100% \t Train loss: 0.1444 took: 1.87s  Val. loss: 0.1681\n",
      "Epoch 11, 100% \t Train loss: 0.1438 took: 1.87s  Val. loss: 0.1669\n",
      "Epoch 12, 100% \t Train loss: 0.1430 took: 1.86s  Val. loss: 0.1671\n",
      "Epoch 13, 100% \t Train loss: 0.1424 took: 1.86s  Val. loss: 0.1694\n",
      "Epoch 14, 100% \t Train loss: 0.1424 took: 1.87s  Val. loss: 0.1680\n",
      "Epoch 15, 100% \t Train loss: 0.1417 took: 1.87s  Val. loss: 0.1669\n",
      "Epoch 16, 100% \t Train loss: 0.1417 took: 1.87s  Val. loss: 0.1711\n",
      "Epoch 17, 100% \t Train loss: 0.1416 took: 1.87s  Val. loss: 0.1708\n",
      "Epoch 18, 100% \t Train loss: 0.1411 took: 1.86s  Val. loss: 0.1694\n",
      "Epoch 19, 100% \t Train loss: 0.1407 took: 1.84s  Val. loss: 0.1654\n",
      "Epoch 20, 100% \t Train loss: 0.1406 took: 1.85s  Val. loss: 0.1692\n",
      "Epoch 21, 100% \t Train loss: 0.1402 took: 1.08s  Val. loss: 0.1696\n",
      "Epoch 22, 100% \t Train loss: 0.1409 took: 1.09s  Val. loss: 0.1664\n",
      "Epoch 23, 100% \t Train loss: 0.1400 took: 1.09s  Val. loss: 0.1692\n",
      "Epoch 24, 100% \t Train loss: 0.1395 took: 1.10s  Val. loss: 0.1691\n",
      "Epoch 25, 100% \t Train loss: 0.1389 took: 1.10s  Val. loss: 0.1676\n",
      "Epoch 26, 100% \t Train loss: 0.1388 took: 1.10s  Val. loss: 0.1728\n",
      "Epoch 27, 100% \t Train loss: 0.1387 took: 1.11s  Val. loss: 0.1736\n",
      "Epoch 28, 100% \t Train loss: 0.1389 took: 1.12s  Val. loss: 0.1696\n",
      "Epoch 29, 100% \t Train loss: 0.1382 took: 1.15s  Val. loss: 0.1688\n",
      "Epoch 30, 100% \t Train loss: 0.1384 took: 1.18s  Val. loss: 0.1700\n",
      "Epoch 31, 100% \t Train loss: 0.1378 took: 1.23s  Val. loss: 0.1678\n",
      "Epoch 32, 100% \t Train loss: 0.1371 took: 1.44s  Val. loss: 0.1685\n",
      "Epoch 33, 100% \t Train loss: 0.1367 took: 2.40s  Val. loss: 0.1684\n",
      "Epoch 34, 100% \t Train loss: 0.1362 took: 2.50s  Val. loss: 0.1695\n",
      "Epoch 35, 100% \t Train loss: 0.1352 took: 2.51s  Val. loss: 0.1671\n",
      "Epoch 36, 100% \t Train loss: 0.1342 took: 2.48s  Val. loss: 0.1655\n",
      "Epoch 37, 100% \t Train loss: 0.1320 took: 2.53s  Val. loss: 0.1657\n",
      "Epoch 38, 100% \t Train loss: 0.1285 took: 2.64s  Val. loss: 0.1559\n",
      "Epoch 39, 100% \t Train loss: 0.1236 took: 2.73s  Val. loss: 0.1501\n",
      "Epoch 40, 100% \t Train loss: 0.1173 took: 2.05s  Val. loss: 0.1428\n",
      "Epoch 41, 100% \t Train loss: 0.1120 took: 2.05s  Val. loss: 0.1411\n",
      "Epoch 42, 100% \t Train loss: 0.1077 took: 2.01s  Val. loss: 0.1343\n",
      "Epoch 43, 100% \t Train loss: 0.1037 took: 2.02s  Val. loss: 0.1322\n",
      "Epoch 44, 100% \t Train loss: 0.1002 took: 2.04s  Val. loss: 0.1275\n",
      "Epoch 45, 100% \t Train loss: 0.0972 took: 2.78s  Val. loss: 0.1232\n",
      "Epoch 46, 100% \t Train loss: 0.0955 took: 2.82s  Val. loss: 0.1216\n",
      "Epoch 47, 100% \t Train loss: 0.0930 took: 2.82s  Val. loss: 0.1159\n",
      "Epoch 48, 100% \t Train loss: 0.0913 took: 2.85s  Val. loss: 0.1144\n",
      "Epoch 49, 100% \t Train loss: 0.0890 took: 2.89s  Val. loss: 0.1157\n",
      "Epoch 50, 100% \t Train loss: 0.0880 took: 2.87s  Val. loss: 0.1147\n",
      "Training finished, took 108.98s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2578 took: 1.88s  Val. loss: 0.2582\n",
      "Epoch 2, 100% \t Train loss: 0.2576 took: 1.88s  Val. loss: 0.2589\n",
      "Epoch 3, 100% \t Train loss: 0.2574 took: 1.87s  Val. loss: 0.2573\n",
      "Epoch 4, 100% \t Train loss: 0.2572 took: 1.89s  Val. loss: 0.2589\n",
      "Epoch 5, 100% \t Train loss: 0.2566 took: 1.92s  Val. loss: 0.2569\n",
      "Epoch 6, 100% \t Train loss: 0.2451 took: 1.88s  Val. loss: 0.2342\n",
      "Epoch 7, 100% \t Train loss: 0.2168 took: 1.88s  Val. loss: 0.2071\n",
      "Epoch 8, 100% \t Train loss: 0.1902 took: 1.88s  Val. loss: 0.1878\n",
      "Epoch 9, 100% \t Train loss: 0.1787 took: 1.89s  Val. loss: 0.1826\n",
      "Epoch 10, 100% \t Train loss: 0.1716 took: 1.89s  Val. loss: 0.1817\n",
      "Epoch 11, 100% \t Train loss: 0.1678 took: 1.87s  Val. loss: 0.1733\n",
      "Epoch 12, 100% \t Train loss: 0.1636 took: 1.86s  Val. loss: 0.1732\n",
      "Epoch 13, 100% \t Train loss: 0.1647 took: 1.87s  Val. loss: 0.1714\n",
      "Epoch 14, 100% \t Train loss: 0.1610 took: 1.88s  Val. loss: 0.1714\n",
      "Epoch 15, 100% \t Train loss: 0.1586 took: 1.87s  Val. loss: 0.1859\n",
      "Epoch 16, 100% \t Train loss: 0.1599 took: 1.87s  Val. loss: 0.1691\n",
      "Epoch 17, 100% \t Train loss: 0.1569 took: 1.87s  Val. loss: 0.1702\n",
      "Epoch 18, 100% \t Train loss: 0.1562 took: 1.88s  Val. loss: 0.1709\n",
      "Epoch 19, 100% \t Train loss: 0.1557 took: 1.88s  Val. loss: 0.1810\n",
      "Epoch 20, 100% \t Train loss: 0.1558 took: 1.89s  Val. loss: 0.1701\n",
      "Epoch 21, 100% \t Train loss: 0.1539 took: 1.89s  Val. loss: 0.1740\n",
      "Epoch 22, 100% \t Train loss: 0.1543 took: 1.87s  Val. loss: 0.1683\n",
      "Epoch 23, 100% \t Train loss: 0.1534 took: 1.86s  Val. loss: 0.1705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1519 took: 1.90s  Val. loss: 0.1693\n",
      "Epoch 25, 100% \t Train loss: 0.1523 took: 1.88s  Val. loss: 0.1695\n",
      "Epoch 26, 100% \t Train loss: 0.1525 took: 1.89s  Val. loss: 0.1696\n",
      "Epoch 27, 100% \t Train loss: 0.1509 took: 1.89s  Val. loss: 0.1685\n",
      "Epoch 28, 100% \t Train loss: 0.1503 took: 1.89s  Val. loss: 0.1685\n",
      "Epoch 29, 100% \t Train loss: 0.1496 took: 1.91s  Val. loss: 0.1713\n",
      "Epoch 30, 100% \t Train loss: 0.1510 took: 1.93s  Val. loss: 0.1702\n",
      "Epoch 31, 100% \t Train loss: 0.1498 took: 1.97s  Val. loss: 0.1695\n",
      "Epoch 32, 100% \t Train loss: 0.1504 took: 2.02s  Val. loss: 0.1699\n",
      "Epoch 33, 100% \t Train loss: 0.1501 took: 2.12s  Val. loss: 0.1685\n",
      "Epoch 34, 100% \t Train loss: 0.1483 took: 2.22s  Val. loss: 0.1683\n",
      "Epoch 35, 100% \t Train loss: 0.1477 took: 2.34s  Val. loss: 0.1695\n",
      "Epoch 36, 100% \t Train loss: 0.1484 took: 2.15s  Val. loss: 0.1687\n",
      "Epoch 37, 100% \t Train loss: 0.1483 took: 2.46s  Val. loss: 0.1688\n",
      "Epoch 38, 100% \t Train loss: 0.1473 took: 2.57s  Val. loss: 0.1737\n",
      "Epoch 39, 100% \t Train loss: 0.1475 took: 2.58s  Val. loss: 0.1684\n",
      "Epoch 40, 100% \t Train loss: 0.1471 took: 2.59s  Val. loss: 0.1676\n",
      "Epoch 41, 100% \t Train loss: 0.1459 took: 2.15s  Val. loss: 0.1694\n",
      "Epoch 42, 100% \t Train loss: 0.1459 took: 2.24s  Val. loss: 0.1664\n",
      "Epoch 43, 100% \t Train loss: 0.1456 took: 2.25s  Val. loss: 0.1670\n",
      "Epoch 44, 100% \t Train loss: 0.1451 took: 2.26s  Val. loss: 0.1668\n",
      "Epoch 45, 100% \t Train loss: 0.1460 took: 2.25s  Val. loss: 0.1689\n",
      "Epoch 46, 100% \t Train loss: 0.1458 took: 2.27s  Val. loss: 0.1679\n",
      "Epoch 47, 100% \t Train loss: 0.1444 took: 2.37s  Val. loss: 0.1683\n",
      "Epoch 48, 100% \t Train loss: 0.1445 took: 2.46s  Val. loss: 0.1719\n",
      "Epoch 49, 100% \t Train loss: 0.1438 took: 2.26s  Val. loss: 0.1668\n",
      "Epoch 50, 100% \t Train loss: 0.1442 took: 2.35s  Val. loss: 0.1675\n",
      "Training finished, took 115.98s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2579 took: 1.92s  Val. loss: 0.2609\n",
      "Epoch 2, 100% \t Train loss: 0.2577 took: 1.21s  Val. loss: 0.2619\n",
      "Epoch 3, 100% \t Train loss: 0.2576 took: 1.12s  Val. loss: 0.2600\n",
      "Epoch 4, 100% \t Train loss: 0.2572 took: 1.12s  Val. loss: 0.2594\n",
      "Epoch 5, 100% \t Train loss: 0.2562 took: 1.12s  Val. loss: 0.2580\n",
      "Epoch 6, 100% \t Train loss: 0.2473 took: 1.13s  Val. loss: 0.2457\n",
      "Epoch 7, 100% \t Train loss: 0.2317 took: 1.13s  Val. loss: 0.2314\n",
      "Epoch 8, 100% \t Train loss: 0.2162 took: 1.13s  Val. loss: 0.2195\n",
      "Epoch 9, 100% \t Train loss: 0.2009 took: 1.12s  Val. loss: 0.2051\n",
      "Epoch 10, 100% \t Train loss: 0.1894 took: 1.12s  Val. loss: 0.1950\n",
      "Epoch 11, 100% \t Train loss: 0.1808 took: 1.12s  Val. loss: 0.1873\n",
      "Epoch 12, 100% \t Train loss: 0.1755 took: 1.12s  Val. loss: 0.1848\n",
      "Epoch 13, 100% \t Train loss: 0.1715 took: 1.12s  Val. loss: 0.1823\n",
      "Epoch 14, 100% \t Train loss: 0.1696 took: 1.12s  Val. loss: 0.1773\n",
      "Epoch 15, 100% \t Train loss: 0.1687 took: 1.13s  Val. loss: 0.1761\n",
      "Epoch 16, 100% \t Train loss: 0.1666 took: 1.50s  Val. loss: 0.1746\n",
      "Epoch 17, 100% \t Train loss: 0.1662 took: 1.86s  Val. loss: 0.1753\n",
      "Epoch 18, 100% \t Train loss: 0.1643 took: 1.86s  Val. loss: 0.1742\n",
      "Epoch 19, 100% \t Train loss: 0.1648 took: 1.87s  Val. loss: 0.1778\n",
      "Epoch 20, 100% \t Train loss: 0.1663 took: 1.89s  Val. loss: 0.1729\n",
      "Epoch 21, 100% \t Train loss: 0.1641 took: 1.85s  Val. loss: 0.1731\n",
      "Epoch 22, 100% \t Train loss: 0.1629 took: 1.87s  Val. loss: 0.1703\n",
      "Epoch 23, 100% \t Train loss: 0.1620 took: 1.86s  Val. loss: 0.1706\n",
      "Epoch 24, 100% \t Train loss: 0.1606 took: 1.85s  Val. loss: 0.1752\n",
      "Epoch 25, 100% \t Train loss: 0.1617 took: 1.86s  Val. loss: 0.1685\n",
      "Epoch 26, 100% \t Train loss: 0.1593 took: 1.85s  Val. loss: 0.1717\n",
      "Epoch 27, 100% \t Train loss: 0.1598 took: 1.86s  Val. loss: 0.1726\n",
      "Epoch 28, 100% \t Train loss: 0.1601 took: 1.87s  Val. loss: 0.1703\n",
      "Epoch 29, 100% \t Train loss: 0.1571 took: 1.89s  Val. loss: 0.1698\n",
      "Epoch 30, 100% \t Train loss: 0.1581 took: 1.91s  Val. loss: 0.1678\n",
      "Epoch 31, 100% \t Train loss: 0.1563 took: 1.94s  Val. loss: 0.1700\n",
      "Epoch 32, 100% \t Train loss: 0.1575 took: 1.94s  Val. loss: 0.1687\n",
      "Epoch 33, 100% \t Train loss: 0.1560 took: 1.95s  Val. loss: 0.1664\n",
      "Epoch 34, 100% \t Train loss: 0.1562 took: 1.96s  Val. loss: 0.1684\n",
      "Epoch 35, 100% \t Train loss: 0.1550 took: 1.97s  Val. loss: 0.1650\n",
      "Epoch 36, 100% \t Train loss: 0.1547 took: 1.99s  Val. loss: 0.1691\n",
      "Epoch 37, 100% \t Train loss: 0.1543 took: 2.00s  Val. loss: 0.1669\n",
      "Epoch 38, 100% \t Train loss: 0.1554 took: 2.03s  Val. loss: 0.1673\n",
      "Epoch 39, 100% \t Train loss: 0.1543 took: 2.07s  Val. loss: 0.1671\n",
      "Epoch 40, 100% \t Train loss: 0.1529 took: 2.11s  Val. loss: 0.1678\n",
      "Epoch 41, 100% \t Train loss: 0.1535 took: 2.14s  Val. loss: 0.1688\n",
      "Epoch 42, 100% \t Train loss: 0.1530 took: 2.18s  Val. loss: 0.1654\n",
      "Epoch 43, 100% \t Train loss: 0.1524 took: 2.27s  Val. loss: 0.1661\n",
      "Epoch 44, 100% \t Train loss: 0.1520 took: 2.27s  Val. loss: 0.1650\n",
      "Epoch 45, 100% \t Train loss: 0.1514 took: 2.26s  Val. loss: 0.1664\n",
      "Epoch 46, 100% \t Train loss: 0.1511 took: 2.26s  Val. loss: 0.1667\n",
      "Epoch 47, 100% \t Train loss: 0.1505 took: 2.27s  Val. loss: 0.1666\n",
      "Epoch 48, 100% \t Train loss: 0.1515 took: 2.37s  Val. loss: 0.1674\n",
      "Epoch 49, 100% \t Train loss: 0.1511 took: 2.40s  Val. loss: 0.1659\n",
      "Epoch 50, 100% \t Train loss: 0.1507 took: 2.19s  Val. loss: 0.1680\n",
      "Training finished, took 99.60s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.22\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.838359\n",
      "lambda: 0.0010 - V: 0.818123\n",
      "lambda: 0.0005 - V: 0.815359\n",
      "Average V: 0.823947\n",
      "Time elapsed: 327.93 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2573 took: 1.73s  Val. loss: 0.2584\n",
      "Epoch 2, 100% \t Train loss: 0.2309 took: 1.73s  Val. loss: 0.1890\n",
      "Epoch 3, 100% \t Train loss: 0.1732 took: 1.73s  Val. loss: 0.1847\n",
      "Epoch 4, 100% \t Train loss: 0.1680 took: 1.73s  Val. loss: 0.1753\n",
      "Epoch 5, 100% \t Train loss: 0.1647 took: 1.73s  Val. loss: 0.1734\n",
      "Epoch 6, 100% \t Train loss: 0.1622 took: 1.72s  Val. loss: 0.1772\n",
      "Epoch 7, 100% \t Train loss: 0.1601 took: 1.72s  Val. loss: 0.1745\n",
      "Epoch 8, 100% \t Train loss: 0.1577 took: 1.72s  Val. loss: 0.1728\n",
      "Epoch 9, 100% \t Train loss: 0.1566 took: 1.73s  Val. loss: 0.1745\n",
      "Epoch 10, 100% \t Train loss: 0.1547 took: 1.73s  Val. loss: 0.1764\n",
      "Epoch 11, 100% \t Train loss: 0.1552 took: 1.74s  Val. loss: 0.1725\n",
      "Epoch 12, 100% \t Train loss: 0.1528 took: 1.73s  Val. loss: 0.1743\n",
      "Epoch 13, 100% \t Train loss: 0.1521 took: 1.73s  Val. loss: 0.1740\n",
      "Epoch 14, 100% \t Train loss: 0.1515 took: 1.76s  Val. loss: 0.1720\n",
      "Epoch 15, 100% \t Train loss: 0.1513 took: 1.76s  Val. loss: 0.1756\n",
      "Epoch 16, 100% \t Train loss: 0.1506 took: 1.74s  Val. loss: 0.1745\n",
      "Epoch 17, 100% \t Train loss: 0.1506 took: 1.00s  Val. loss: 0.1749\n",
      "Epoch 18, 100% \t Train loss: 0.1496 took: 1.00s  Val. loss: 0.1745\n",
      "Epoch 19, 100% \t Train loss: 0.1492 took: 0.99s  Val. loss: 0.1737\n",
      "Epoch 20, 100% \t Train loss: 0.1483 took: 0.99s  Val. loss: 0.1724\n",
      "Epoch 21, 100% \t Train loss: 0.1481 took: 1.00s  Val. loss: 0.1738\n",
      "Epoch 22, 100% \t Train loss: 0.1474 took: 0.99s  Val. loss: 0.1693\n",
      "Epoch 23, 100% \t Train loss: 0.1461 took: 0.99s  Val. loss: 0.1679\n",
      "Epoch 24, 100% \t Train loss: 0.1449 took: 1.00s  Val. loss: 0.1729\n",
      "Epoch 25, 100% \t Train loss: 0.1440 took: 1.00s  Val. loss: 0.1705\n",
      "Epoch 26, 100% \t Train loss: 0.1421 took: 1.00s  Val. loss: 0.1678\n",
      "Epoch 27, 100% \t Train loss: 0.1415 took: 1.00s  Val. loss: 0.1677\n",
      "Epoch 28, 100% \t Train loss: 0.1395 took: 1.00s  Val. loss: 0.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.1368 took: 1.29s  Val. loss: 0.1639\n",
      "Epoch 30, 100% \t Train loss: 0.1346 took: 1.80s  Val. loss: 0.1592\n",
      "Epoch 31, 100% \t Train loss: 0.1323 took: 1.85s  Val. loss: 0.1550\n",
      "Epoch 32, 100% \t Train loss: 0.1304 took: 1.97s  Val. loss: 0.1506\n",
      "Epoch 33, 100% \t Train loss: 0.1275 took: 1.33s  Val. loss: 0.1491\n",
      "Epoch 34, 100% \t Train loss: 0.1258 took: 1.37s  Val. loss: 0.1489\n",
      "Epoch 35, 100% \t Train loss: 0.1232 took: 1.38s  Val. loss: 0.1439\n",
      "Epoch 36, 100% \t Train loss: 0.1203 took: 2.10s  Val. loss: 0.1402\n",
      "Epoch 37, 100% \t Train loss: 0.1181 took: 2.14s  Val. loss: 0.1361\n",
      "Epoch 38, 100% \t Train loss: 0.1159 took: 2.12s  Val. loss: 0.1332\n",
      "Epoch 39, 100% \t Train loss: 0.1146 took: 2.13s  Val. loss: 0.1321\n",
      "Epoch 40, 100% \t Train loss: 0.1112 took: 2.13s  Val. loss: 0.1282\n",
      "Epoch 41, 100% \t Train loss: 0.1088 took: 2.13s  Val. loss: 0.1274\n",
      "Epoch 42, 100% \t Train loss: 0.1069 took: 2.14s  Val. loss: 0.1261\n",
      "Epoch 43, 100% \t Train loss: 0.1051 took: 2.12s  Val. loss: 0.1244\n",
      "Epoch 44, 100% \t Train loss: 0.1029 took: 2.12s  Val. loss: 0.1246\n",
      "Epoch 45, 100% \t Train loss: 0.1016 took: 2.10s  Val. loss: 0.1193\n",
      "Epoch 46, 100% \t Train loss: 0.1000 took: 2.09s  Val. loss: 0.1193\n",
      "Epoch 47, 100% \t Train loss: 0.0997 took: 2.11s  Val. loss: 0.1155\n",
      "Epoch 48, 100% \t Train loss: 0.0964 took: 2.09s  Val. loss: 0.1149\n",
      "Epoch 49, 100% \t Train loss: 0.0943 took: 2.10s  Val. loss: 0.1133\n",
      "Epoch 50, 100% \t Train loss: 0.0934 took: 2.09s  Val. loss: 0.1109\n",
      "Training finished, took 94.07s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2600 took: 1.76s  Val. loss: 0.2557\n",
      "Epoch 2, 100% \t Train loss: 0.2595 took: 1.74s  Val. loss: 0.2553\n",
      "Epoch 3, 100% \t Train loss: 0.2579 took: 1.74s  Val. loss: 0.2499\n",
      "Epoch 4, 100% \t Train loss: 0.2338 took: 1.82s  Val. loss: 0.2061\n",
      "Epoch 5, 100% \t Train loss: 0.1905 took: 1.72s  Val. loss: 0.1736\n",
      "Epoch 6, 100% \t Train loss: 0.1745 took: 1.72s  Val. loss: 0.1678\n",
      "Epoch 7, 100% \t Train loss: 0.1710 took: 1.73s  Val. loss: 0.1667\n",
      "Epoch 8, 100% \t Train loss: 0.1683 took: 1.74s  Val. loss: 0.1640\n",
      "Epoch 9, 100% \t Train loss: 0.1650 took: 1.76s  Val. loss: 0.1588\n",
      "Epoch 10, 100% \t Train loss: 0.1637 took: 1.75s  Val. loss: 0.1598\n",
      "Epoch 11, 100% \t Train loss: 0.1617 took: 1.74s  Val. loss: 0.1562\n",
      "Epoch 12, 100% \t Train loss: 0.1610 took: 1.76s  Val. loss: 0.1554\n",
      "Epoch 13, 100% \t Train loss: 0.1611 took: 1.74s  Val. loss: 0.1567\n",
      "Epoch 14, 100% \t Train loss: 0.1598 took: 1.73s  Val. loss: 0.1555\n",
      "Epoch 15, 100% \t Train loss: 0.1607 took: 1.73s  Val. loss: 0.1565\n",
      "Epoch 16, 100% \t Train loss: 0.1578 took: 1.74s  Val. loss: 0.1531\n",
      "Epoch 17, 100% \t Train loss: 0.1572 took: 1.76s  Val. loss: 0.1526\n",
      "Epoch 18, 100% \t Train loss: 0.1565 took: 1.75s  Val. loss: 0.1517\n",
      "Epoch 19, 100% \t Train loss: 0.1567 took: 1.73s  Val. loss: 0.1531\n",
      "Epoch 20, 100% \t Train loss: 0.1552 took: 1.73s  Val. loss: 0.1523\n",
      "Epoch 21, 100% \t Train loss: 0.1547 took: 1.74s  Val. loss: 0.1509\n",
      "Epoch 22, 100% \t Train loss: 0.1550 took: 1.73s  Val. loss: 0.1521\n",
      "Epoch 23, 100% \t Train loss: 0.1548 took: 1.73s  Val. loss: 0.1520\n",
      "Epoch 24, 100% \t Train loss: 0.1543 took: 1.73s  Val. loss: 0.1523\n",
      "Epoch 25, 100% \t Train loss: 0.1547 took: 1.75s  Val. loss: 0.1526\n",
      "Epoch 26, 100% \t Train loss: 0.1547 took: 1.73s  Val. loss: 0.1523\n",
      "Epoch 27, 100% \t Train loss: 0.1554 took: 1.73s  Val. loss: 0.1503\n",
      "Epoch 28, 100% \t Train loss: 0.1525 took: 1.76s  Val. loss: 0.1498\n",
      "Epoch 29, 100% \t Train loss: 0.1525 took: 1.77s  Val. loss: 0.1502\n",
      "Epoch 30, 100% \t Train loss: 0.1525 took: 1.80s  Val. loss: 0.1493\n",
      "Epoch 31, 100% \t Train loss: 0.1518 took: 1.81s  Val. loss: 0.1494\n",
      "Epoch 32, 100% \t Train loss: 0.1518 took: 1.86s  Val. loss: 0.1504\n",
      "Epoch 33, 100% \t Train loss: 0.1514 took: 1.89s  Val. loss: 0.1488\n",
      "Epoch 34, 100% \t Train loss: 0.1510 took: 1.87s  Val. loss: 0.1489\n",
      "Epoch 35, 100% \t Train loss: 0.1497 took: 1.90s  Val. loss: 0.1462\n",
      "Epoch 36, 100% \t Train loss: 0.1486 took: 1.92s  Val. loss: 0.1462\n",
      "Epoch 37, 100% \t Train loss: 0.1475 took: 1.92s  Val. loss: 0.1462\n",
      "Epoch 38, 100% \t Train loss: 0.1461 took: 1.91s  Val. loss: 0.1441\n",
      "Epoch 39, 100% \t Train loss: 0.1443 took: 1.90s  Val. loss: 0.1414\n",
      "Epoch 40, 100% \t Train loss: 0.1413 took: 1.90s  Val. loss: 0.1380\n",
      "Epoch 41, 100% \t Train loss: 0.1380 took: 1.91s  Val. loss: 0.1341\n",
      "Epoch 42, 100% \t Train loss: 0.1333 took: 1.88s  Val. loss: 0.1309\n",
      "Epoch 43, 100% \t Train loss: 0.1300 took: 1.87s  Val. loss: 0.1239\n",
      "Epoch 44, 100% \t Train loss: 0.1249 took: 1.82s  Val. loss: 0.1203\n",
      "Epoch 45, 100% \t Train loss: 0.1212 took: 1.83s  Val. loss: 0.1159\n",
      "Epoch 46, 100% \t Train loss: 0.1177 took: 1.81s  Val. loss: 0.1113\n",
      "Epoch 47, 100% \t Train loss: 0.1148 took: 1.82s  Val. loss: 0.1091\n",
      "Epoch 48, 100% \t Train loss: 0.1112 took: 1.82s  Val. loss: 0.1075\n",
      "Epoch 49, 100% \t Train loss: 0.1084 took: 1.81s  Val. loss: 0.1078\n",
      "Epoch 50, 100% \t Train loss: 0.1056 took: 1.81s  Val. loss: 0.1044\n",
      "Training finished, took 101.94s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2553 took: 1.73s  Val. loss: 0.2655\n",
      "Epoch 2, 100% \t Train loss: 0.2546 took: 1.72s  Val. loss: 0.2669\n",
      "Epoch 3, 100% \t Train loss: 0.2546 took: 1.73s  Val. loss: 0.2666\n",
      "Epoch 4, 100% \t Train loss: 0.2545 took: 1.72s  Val. loss: 0.2661\n",
      "Epoch 5, 100% \t Train loss: 0.2543 took: 1.71s  Val. loss: 0.2658\n",
      "Epoch 6, 100% \t Train loss: 0.2536 took: 1.72s  Val. loss: 0.2642\n",
      "Epoch 7, 100% \t Train loss: 0.2509 took: 1.73s  Val. loss: 0.2580\n",
      "Epoch 8, 100% \t Train loss: 0.2392 took: 1.74s  Val. loss: 0.2386\n",
      "Epoch 9, 100% \t Train loss: 0.2167 took: 1.73s  Val. loss: 0.2194\n",
      "Epoch 10, 100% \t Train loss: 0.1998 took: 1.74s  Val. loss: 0.2010\n",
      "Epoch 11, 100% \t Train loss: 0.1858 took: 1.75s  Val. loss: 0.1888\n",
      "Epoch 12, 100% \t Train loss: 0.1783 took: 1.74s  Val. loss: 0.1824\n",
      "Epoch 13, 100% \t Train loss: 0.1744 took: 1.74s  Val. loss: 0.1804\n",
      "Epoch 14, 100% \t Train loss: 0.1730 took: 1.75s  Val. loss: 0.1781\n",
      "Epoch 15, 100% \t Train loss: 0.1722 took: 1.73s  Val. loss: 0.1805\n",
      "Epoch 16, 100% \t Train loss: 0.1712 took: 1.73s  Val. loss: 0.1771\n",
      "Epoch 17, 100% \t Train loss: 0.1705 took: 1.73s  Val. loss: 0.1785\n",
      "Epoch 18, 100% \t Train loss: 0.1703 took: 1.75s  Val. loss: 0.1768\n",
      "Epoch 19, 100% \t Train loss: 0.1702 took: 1.73s  Val. loss: 0.1757\n",
      "Epoch 20, 100% \t Train loss: 0.1691 took: 1.74s  Val. loss: 0.1799\n",
      "Epoch 21, 100% \t Train loss: 0.1693 took: 1.72s  Val. loss: 0.1782\n",
      "Epoch 22, 100% \t Train loss: 0.1694 took: 1.73s  Val. loss: 0.1771\n",
      "Epoch 23, 100% \t Train loss: 0.1688 took: 1.74s  Val. loss: 0.1753\n",
      "Epoch 24, 100% \t Train loss: 0.1682 took: 1.73s  Val. loss: 0.1760\n",
      "Epoch 25, 100% \t Train loss: 0.1679 took: 1.01s  Val. loss: 0.1765\n",
      "Epoch 26, 100% \t Train loss: 0.1681 took: 1.00s  Val. loss: 0.1763\n",
      "Epoch 27, 100% \t Train loss: 0.1677 took: 1.48s  Val. loss: 0.1762\n",
      "Epoch 28, 100% \t Train loss: 0.1678 took: 1.80s  Val. loss: 0.1779\n",
      "Epoch 29, 100% \t Train loss: 0.1676 took: 1.76s  Val. loss: 0.1771\n",
      "Epoch 30, 100% \t Train loss: 0.1673 took: 1.78s  Val. loss: 0.1744\n",
      "Epoch 31, 100% \t Train loss: 0.1669 took: 1.78s  Val. loss: 0.1765\n",
      "Epoch 32, 100% \t Train loss: 0.1668 took: 1.82s  Val. loss: 0.1767\n",
      "Epoch 33, 100% \t Train loss: 0.1665 took: 1.83s  Val. loss: 0.1732\n",
      "Epoch 34, 100% \t Train loss: 0.1663 took: 1.81s  Val. loss: 0.1772\n",
      "Epoch 35, 100% \t Train loss: 0.1660 took: 1.81s  Val. loss: 0.1739\n",
      "Epoch 36, 100% \t Train loss: 0.1662 took: 1.80s  Val. loss: 0.1733\n",
      "Epoch 37, 100% \t Train loss: 0.1655 took: 1.80s  Val. loss: 0.1740\n",
      "Epoch 38, 100% \t Train loss: 0.1651 took: 1.80s  Val. loss: 0.1755\n",
      "Epoch 39, 100% \t Train loss: 0.1649 took: 1.82s  Val. loss: 0.1738\n",
      "Epoch 40, 100% \t Train loss: 0.1644 took: 1.82s  Val. loss: 0.1739\n",
      "Epoch 41, 100% \t Train loss: 0.1642 took: 1.86s  Val. loss: 0.1737\n",
      "Epoch 42, 100% \t Train loss: 0.1636 took: 1.87s  Val. loss: 0.1734\n",
      "Epoch 43, 100% \t Train loss: 0.1632 took: 1.86s  Val. loss: 0.1728\n",
      "Epoch 44, 100% \t Train loss: 0.1636 took: 1.86s  Val. loss: 0.1745\n",
      "Epoch 45, 100% \t Train loss: 0.1624 took: 1.87s  Val. loss: 0.1714\n",
      "Epoch 46, 100% \t Train loss: 0.1619 took: 1.89s  Val. loss: 0.1720\n",
      "Epoch 47, 100% \t Train loss: 0.1613 took: 1.88s  Val. loss: 0.1747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1608 took: 1.88s  Val. loss: 0.1714\n",
      "Epoch 49, 100% \t Train loss: 0.1607 took: 1.91s  Val. loss: 0.1718\n",
      "Epoch 50, 100% \t Train loss: 0.1608 took: 1.88s  Val. loss: 0.1707\n",
      "Training finished, took 99.52s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.842321\n",
      "lambda: 0.0010 - V: 0.847259\n",
      "lambda: 0.0005 - V: 0.809003\n",
      "Average V: 0.832861\n",
      "Time elapsed: 298.93 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2612 took: 1.45s  Val. loss: 0.2561\n",
      "Epoch 2, 100% \t Train loss: 0.2595 took: 1.09s  Val. loss: 0.2570\n",
      "Epoch 3, 100% \t Train loss: 0.2596 took: 1.09s  Val. loss: 0.2571\n",
      "Epoch 4, 100% \t Train loss: 0.2524 took: 1.09s  Val. loss: 0.2173\n",
      "Epoch 5, 100% \t Train loss: 0.2043 took: 1.09s  Val. loss: 0.1965\n",
      "Epoch 6, 100% \t Train loss: 0.1948 took: 1.10s  Val. loss: 0.2006\n",
      "Epoch 7, 100% \t Train loss: 0.1918 took: 1.10s  Val. loss: 0.1954\n",
      "Epoch 8, 100% \t Train loss: 0.1905 took: 1.10s  Val. loss: 0.1930\n",
      "Epoch 9, 100% \t Train loss: 0.1893 took: 1.10s  Val. loss: 0.1961\n",
      "Epoch 10, 100% \t Train loss: 0.1878 took: 1.10s  Val. loss: 0.1916\n",
      "Epoch 11, 100% \t Train loss: 0.1875 took: 1.10s  Val. loss: 0.1952\n",
      "Epoch 12, 100% \t Train loss: 0.1869 took: 1.10s  Val. loss: 0.1906\n",
      "Epoch 13, 100% \t Train loss: 0.1860 took: 1.09s  Val. loss: 0.1896\n",
      "Epoch 14, 100% \t Train loss: 0.1849 took: 1.09s  Val. loss: 0.1886\n",
      "Epoch 15, 100% \t Train loss: 0.1854 took: 1.09s  Val. loss: 0.1936\n",
      "Epoch 16, 100% \t Train loss: 0.1828 took: 1.09s  Val. loss: 0.1855\n",
      "Epoch 17, 100% \t Train loss: 0.1812 took: 1.09s  Val. loss: 0.1859\n",
      "Epoch 18, 100% \t Train loss: 0.1791 took: 1.09s  Val. loss: 0.1848\n",
      "Epoch 19, 100% \t Train loss: 0.1771 took: 1.09s  Val. loss: 0.1864\n",
      "Epoch 20, 100% \t Train loss: 0.1760 took: 1.09s  Val. loss: 0.1850\n",
      "Epoch 21, 100% \t Train loss: 0.1740 took: 1.09s  Val. loss: 0.1810\n",
      "Epoch 22, 100% \t Train loss: 0.1718 took: 1.09s  Val. loss: 0.1829\n",
      "Epoch 23, 100% \t Train loss: 0.1720 took: 1.09s  Val. loss: 0.1793\n",
      "Epoch 24, 100% \t Train loss: 0.1701 took: 1.09s  Val. loss: 0.1817\n",
      "Epoch 25, 100% \t Train loss: 0.1704 took: 1.09s  Val. loss: 0.1802\n",
      "Epoch 26, 100% \t Train loss: 0.1690 took: 1.09s  Val. loss: 0.1832\n",
      "Epoch 27, 100% \t Train loss: 0.1659 took: 1.09s  Val. loss: 0.1810\n",
      "Epoch 28, 100% \t Train loss: 0.1647 took: 1.10s  Val. loss: 0.1791\n",
      "Epoch 29, 100% \t Train loss: 0.1658 took: 1.10s  Val. loss: 0.1768\n",
      "Epoch 30, 100% \t Train loss: 0.1609 took: 1.11s  Val. loss: 0.1773\n",
      "Epoch 31, 100% \t Train loss: 0.1633 took: 1.14s  Val. loss: 0.1735\n",
      "Epoch 32, 100% \t Train loss: 0.1599 took: 1.26s  Val. loss: 0.1673\n",
      "Epoch 33, 100% \t Train loss: 0.1595 took: 1.82s  Val. loss: 0.1713\n",
      "Epoch 34, 100% \t Train loss: 0.1581 took: 2.27s  Val. loss: 0.1674\n",
      "Epoch 35, 100% \t Train loss: 0.1557 took: 2.26s  Val. loss: 0.1720\n",
      "Epoch 36, 100% \t Train loss: 0.1557 took: 2.25s  Val. loss: 0.1630\n",
      "Epoch 37, 100% \t Train loss: 0.1555 took: 2.28s  Val. loss: 0.1644\n",
      "Epoch 38, 100% \t Train loss: 0.1525 took: 2.31s  Val. loss: 0.1608\n",
      "Epoch 39, 100% \t Train loss: 0.1529 took: 2.30s  Val. loss: 0.1601\n",
      "Epoch 40, 100% \t Train loss: 0.1514 took: 2.30s  Val. loss: 0.1583\n",
      "Epoch 41, 100% \t Train loss: 0.1501 took: 2.29s  Val. loss: 0.1590\n",
      "Epoch 42, 100% \t Train loss: 0.1497 took: 2.30s  Val. loss: 0.1552\n",
      "Epoch 43, 100% \t Train loss: 0.1484 took: 2.33s  Val. loss: 0.1617\n",
      "Epoch 44, 100% \t Train loss: 0.1485 took: 2.32s  Val. loss: 0.1554\n",
      "Epoch 45, 100% \t Train loss: 0.1486 took: 2.33s  Val. loss: 0.1572\n",
      "Epoch 46, 100% \t Train loss: 0.1478 took: 2.34s  Val. loss: 0.1587\n",
      "Epoch 47, 100% \t Train loss: 0.1462 took: 2.35s  Val. loss: 0.1546\n",
      "Epoch 48, 100% \t Train loss: 0.1457 took: 2.38s  Val. loss: 0.1556\n",
      "Epoch 49, 100% \t Train loss: 0.1463 took: 2.37s  Val. loss: 0.1528\n",
      "Epoch 50, 100% \t Train loss: 0.1450 took: 2.38s  Val. loss: 0.1547\n",
      "Training finished, took 86.54s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2572 took: 1.90s  Val. loss: 0.2577\n",
      "Epoch 2, 100% \t Train loss: 0.2561 took: 1.88s  Val. loss: 0.2551\n",
      "Epoch 3, 100% \t Train loss: 0.2501 took: 1.90s  Val. loss: 0.2388\n",
      "Epoch 4, 100% \t Train loss: 0.2194 took: 1.88s  Val. loss: 0.2040\n",
      "Epoch 5, 100% \t Train loss: 0.2033 took: 1.89s  Val. loss: 0.2048\n",
      "Epoch 6, 100% \t Train loss: 0.2004 took: 1.87s  Val. loss: 0.1993\n",
      "Epoch 7, 100% \t Train loss: 0.1986 took: 1.88s  Val. loss: 0.1973\n",
      "Epoch 8, 100% \t Train loss: 0.1972 took: 1.89s  Val. loss: 0.1996\n",
      "Epoch 9, 100% \t Train loss: 0.1989 took: 1.88s  Val. loss: 0.1950\n",
      "Epoch 10, 100% \t Train loss: 0.1955 took: 1.89s  Val. loss: 0.2006\n",
      "Epoch 11, 100% \t Train loss: 0.1950 took: 1.86s  Val. loss: 0.1996\n",
      "Epoch 12, 100% \t Train loss: 0.1937 took: 1.89s  Val. loss: 0.1996\n",
      "Epoch 13, 100% \t Train loss: 0.1941 took: 1.88s  Val. loss: 0.1985\n",
      "Epoch 14, 100% \t Train loss: 0.1937 took: 1.89s  Val. loss: 0.1969\n",
      "Epoch 15, 100% \t Train loss: 0.1931 took: 1.89s  Val. loss: 0.1967\n",
      "Epoch 16, 100% \t Train loss: 0.1914 took: 1.88s  Val. loss: 0.1920\n",
      "Epoch 17, 100% \t Train loss: 0.1909 took: 1.90s  Val. loss: 0.1920\n",
      "Epoch 18, 100% \t Train loss: 0.1907 took: 1.88s  Val. loss: 0.1992\n",
      "Epoch 19, 100% \t Train loss: 0.1906 took: 1.89s  Val. loss: 0.1959\n",
      "Epoch 20, 100% \t Train loss: 0.1906 took: 1.87s  Val. loss: 0.1911\n",
      "Epoch 21, 100% \t Train loss: 0.1895 took: 1.86s  Val. loss: 0.1951\n",
      "Epoch 22, 100% \t Train loss: 0.1894 took: 1.86s  Val. loss: 0.1928\n",
      "Epoch 23, 100% \t Train loss: 0.1890 took: 1.87s  Val. loss: 0.1931\n",
      "Epoch 24, 100% \t Train loss: 0.1881 took: 1.87s  Val. loss: 0.1908\n",
      "Epoch 25, 100% \t Train loss: 0.1881 took: 1.87s  Val. loss: 0.1900\n",
      "Epoch 26, 100% \t Train loss: 0.1873 took: 1.91s  Val. loss: 0.1908\n",
      "Epoch 27, 100% \t Train loss: 0.1867 took: 1.87s  Val. loss: 0.1914\n",
      "Epoch 28, 100% \t Train loss: 0.1860 took: 1.89s  Val. loss: 0.1891\n",
      "Epoch 29, 100% \t Train loss: 0.1855 took: 1.87s  Val. loss: 0.1907\n",
      "Epoch 30, 100% \t Train loss: 0.1852 took: 1.88s  Val. loss: 0.1874\n",
      "Epoch 31, 100% \t Train loss: 0.1850 took: 1.88s  Val. loss: 0.1880\n",
      "Epoch 32, 100% \t Train loss: 0.1851 took: 1.89s  Val. loss: 0.1859\n",
      "Epoch 33, 100% \t Train loss: 0.1846 took: 1.89s  Val. loss: 0.1930\n",
      "Epoch 34, 100% \t Train loss: 0.1850 took: 1.92s  Val. loss: 0.1884\n",
      "Epoch 35, 100% \t Train loss: 0.1839 took: 1.91s  Val. loss: 0.1862\n",
      "Epoch 36, 100% \t Train loss: 0.1833 took: 1.90s  Val. loss: 0.1886\n",
      "Epoch 37, 100% \t Train loss: 0.1832 took: 1.90s  Val. loss: 0.1854\n",
      "Epoch 38, 100% \t Train loss: 0.1827 took: 1.93s  Val. loss: 0.1862\n",
      "Epoch 39, 100% \t Train loss: 0.1826 took: 1.90s  Val. loss: 0.1871\n",
      "Epoch 40, 100% \t Train loss: 0.1820 took: 1.92s  Val. loss: 0.1853\n",
      "Epoch 41, 100% \t Train loss: 0.1821 took: 1.92s  Val. loss: 0.1882\n",
      "Epoch 42, 100% \t Train loss: 0.1798 took: 1.89s  Val. loss: 0.1873\n",
      "Epoch 43, 100% \t Train loss: 0.1803 took: 1.90s  Val. loss: 0.1848\n",
      "Epoch 44, 100% \t Train loss: 0.1792 took: 1.84s  Val. loss: 0.1826\n",
      "Epoch 45, 100% \t Train loss: 0.1774 took: 1.11s  Val. loss: 0.1878\n",
      "Epoch 46, 100% \t Train loss: 0.1752 took: 1.12s  Val. loss: 0.1817\n",
      "Epoch 47, 100% \t Train loss: 0.1742 took: 1.12s  Val. loss: 0.1809\n",
      "Epoch 48, 100% \t Train loss: 0.1719 took: 1.12s  Val. loss: 0.1800\n",
      "Epoch 49, 100% \t Train loss: 0.1707 took: 1.11s  Val. loss: 0.1749\n",
      "Epoch 50, 100% \t Train loss: 0.1696 took: 1.11s  Val. loss: 0.1741\n",
      "Training finished, took 101.66s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 1.88s  Val. loss: 0.2628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2566 took: 1.87s  Val. loss: 0.2618\n",
      "Epoch 3, 100% \t Train loss: 0.2556 took: 1.09s  Val. loss: 0.2598\n",
      "Epoch 4, 100% \t Train loss: 0.2525 took: 1.10s  Val. loss: 0.2537\n",
      "Epoch 5, 100% \t Train loss: 0.2410 took: 1.09s  Val. loss: 0.2318\n",
      "Epoch 6, 100% \t Train loss: 0.2230 took: 1.10s  Val. loss: 0.2142\n",
      "Epoch 7, 100% \t Train loss: 0.2123 took: 1.10s  Val. loss: 0.2065\n",
      "Epoch 8, 100% \t Train loss: 0.2075 took: 1.10s  Val. loss: 0.2039\n",
      "Epoch 9, 100% \t Train loss: 0.2047 took: 1.10s  Val. loss: 0.2009\n",
      "Epoch 10, 100% \t Train loss: 0.2041 took: 1.10s  Val. loss: 0.1990\n",
      "Epoch 11, 100% \t Train loss: 0.2020 took: 1.10s  Val. loss: 0.1979\n",
      "Epoch 12, 100% \t Train loss: 0.2011 took: 1.09s  Val. loss: 0.1991\n",
      "Epoch 13, 100% \t Train loss: 0.2005 took: 1.09s  Val. loss: 0.1979\n",
      "Epoch 14, 100% \t Train loss: 0.1990 took: 1.09s  Val. loss: 0.1943\n",
      "Epoch 15, 100% \t Train loss: 0.1986 took: 1.10s  Val. loss: 0.1954\n",
      "Epoch 16, 100% \t Train loss: 0.1976 took: 1.11s  Val. loss: 0.1937\n",
      "Epoch 17, 100% \t Train loss: 0.1969 took: 1.11s  Val. loss: 0.1935\n",
      "Epoch 18, 100% \t Train loss: 0.1957 took: 1.09s  Val. loss: 0.1914\n",
      "Epoch 19, 100% \t Train loss: 0.1950 took: 1.10s  Val. loss: 0.1905\n",
      "Epoch 20, 100% \t Train loss: 0.1954 took: 1.10s  Val. loss: 0.1938\n",
      "Epoch 21, 100% \t Train loss: 0.1940 took: 1.09s  Val. loss: 0.1936\n",
      "Epoch 22, 100% \t Train loss: 0.1939 took: 1.10s  Val. loss: 0.1905\n",
      "Epoch 23, 100% \t Train loss: 0.1935 took: 1.09s  Val. loss: 0.1953\n",
      "Epoch 24, 100% \t Train loss: 0.1929 took: 1.09s  Val. loss: 0.1925\n",
      "Epoch 25, 100% \t Train loss: 0.1927 took: 1.09s  Val. loss: 0.1916\n",
      "Epoch 26, 100% \t Train loss: 0.1926 took: 1.09s  Val. loss: 0.1884\n",
      "Epoch 27, 100% \t Train loss: 0.1920 took: 1.10s  Val. loss: 0.1912\n",
      "Epoch 28, 100% \t Train loss: 0.1911 took: 1.09s  Val. loss: 0.1913\n",
      "Epoch 29, 100% \t Train loss: 0.1920 took: 1.61s  Val. loss: 0.1957\n",
      "Epoch 30, 100% \t Train loss: 0.1910 took: 1.88s  Val. loss: 0.1897\n",
      "Epoch 31, 100% \t Train loss: 0.1902 took: 1.89s  Val. loss: 0.1890\n",
      "Epoch 32, 100% \t Train loss: 0.1905 took: 1.87s  Val. loss: 0.1897\n",
      "Epoch 33, 100% \t Train loss: 0.1902 took: 1.88s  Val. loss: 0.1895\n",
      "Epoch 34, 100% \t Train loss: 0.1899 took: 1.88s  Val. loss: 0.1915\n",
      "Epoch 35, 100% \t Train loss: 0.1901 took: 1.88s  Val. loss: 0.1890\n",
      "Epoch 36, 100% \t Train loss: 0.1896 took: 1.87s  Val. loss: 0.1896\n",
      "Epoch 37, 100% \t Train loss: 0.1886 took: 1.88s  Val. loss: 0.1881\n",
      "Epoch 38, 100% \t Train loss: 0.1883 took: 1.88s  Val. loss: 0.1917\n",
      "Epoch 39, 100% \t Train loss: 0.1887 took: 1.89s  Val. loss: 0.1889\n",
      "Epoch 40, 100% \t Train loss: 0.1883 took: 1.89s  Val. loss: 0.1872\n",
      "Epoch 41, 100% \t Train loss: 0.1877 took: 1.89s  Val. loss: 0.1878\n",
      "Epoch 42, 100% \t Train loss: 0.1871 took: 1.89s  Val. loss: 0.1903\n",
      "Epoch 43, 100% \t Train loss: 0.1872 took: 1.90s  Val. loss: 0.1889\n",
      "Epoch 44, 100% \t Train loss: 0.1866 took: 1.88s  Val. loss: 0.1892\n",
      "Epoch 45, 100% \t Train loss: 0.1863 took: 1.88s  Val. loss: 0.1873\n",
      "Epoch 46, 100% \t Train loss: 0.1856 took: 1.88s  Val. loss: 0.1881\n",
      "Epoch 47, 100% \t Train loss: 0.1855 took: 1.87s  Val. loss: 0.1851\n",
      "Epoch 48, 100% \t Train loss: 0.1846 took: 1.88s  Val. loss: 0.1846\n",
      "Epoch 49, 100% \t Train loss: 0.1844 took: 1.86s  Val. loss: 0.1879\n",
      "Epoch 50, 100% \t Train loss: 0.1841 took: 1.88s  Val. loss: 0.1877\n",
      "Training finished, took 82.84s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.818575\n",
      "lambda: 0.0010 - V: 0.805575\n",
      "lambda: 0.0005 - V: 0.801341\n",
      "Average V: 0.808497\n",
      "Time elapsed: 274.43 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2586 took: 1.69s  Val. loss: 0.2623\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 1.68s  Val. loss: 0.2626\n",
      "Epoch 3, 100% \t Train loss: 0.2583 took: 1.68s  Val. loss: 0.2618\n",
      "Epoch 4, 100% \t Train loss: 0.2559 took: 1.68s  Val. loss: 0.2481\n",
      "Epoch 5, 100% \t Train loss: 0.1955 took: 1.69s  Val. loss: 0.1839\n",
      "Epoch 6, 100% \t Train loss: 0.1715 took: 1.67s  Val. loss: 0.1771\n",
      "Epoch 7, 100% \t Train loss: 0.1674 took: 1.68s  Val. loss: 0.1769\n",
      "Epoch 8, 100% \t Train loss: 0.1660 took: 1.69s  Val. loss: 0.1775\n",
      "Epoch 9, 100% \t Train loss: 0.1641 took: 1.69s  Val. loss: 0.1760\n",
      "Epoch 10, 100% \t Train loss: 0.1624 took: 1.69s  Val. loss: 0.1739\n",
      "Epoch 11, 100% \t Train loss: 0.1603 took: 1.70s  Val. loss: 0.1725\n",
      "Epoch 12, 100% \t Train loss: 0.1580 took: 1.69s  Val. loss: 0.1690\n",
      "Epoch 13, 100% \t Train loss: 0.1588 took: 1.71s  Val. loss: 0.1761\n",
      "Epoch 14, 100% \t Train loss: 0.1571 took: 1.69s  Val. loss: 0.1681\n",
      "Epoch 15, 100% \t Train loss: 0.1561 took: 1.70s  Val. loss: 0.1679\n",
      "Epoch 16, 100% \t Train loss: 0.1562 took: 1.70s  Val. loss: 0.1725\n",
      "Epoch 17, 100% \t Train loss: 0.1549 took: 1.69s  Val. loss: 0.1667\n",
      "Epoch 18, 100% \t Train loss: 0.1536 took: 1.68s  Val. loss: 0.1659\n",
      "Epoch 19, 100% \t Train loss: 0.1541 took: 0.97s  Val. loss: 0.1693\n",
      "Epoch 20, 100% \t Train loss: 0.1534 took: 0.96s  Val. loss: 0.1674\n",
      "Epoch 21, 100% \t Train loss: 0.1528 took: 0.96s  Val. loss: 0.1650\n",
      "Epoch 22, 100% \t Train loss: 0.1521 took: 0.96s  Val. loss: 0.1637\n",
      "Epoch 23, 100% \t Train loss: 0.1519 took: 0.96s  Val. loss: 0.1683\n",
      "Epoch 24, 100% \t Train loss: 0.1522 took: 0.96s  Val. loss: 0.1655\n",
      "Epoch 25, 100% \t Train loss: 0.1507 took: 0.97s  Val. loss: 0.1649\n",
      "Epoch 26, 100% \t Train loss: 0.1504 took: 0.97s  Val. loss: 0.1644\n",
      "Epoch 27, 100% \t Train loss: 0.1504 took: 0.96s  Val. loss: 0.1667\n",
      "Epoch 28, 100% \t Train loss: 0.1495 took: 0.97s  Val. loss: 0.1703\n",
      "Epoch 29, 100% \t Train loss: 0.1501 took: 0.97s  Val. loss: 0.1661\n",
      "Epoch 30, 100% \t Train loss: 0.1491 took: 0.97s  Val. loss: 0.1632\n",
      "Epoch 31, 100% \t Train loss: 0.1486 took: 0.98s  Val. loss: 0.1673\n",
      "Epoch 32, 100% \t Train loss: 0.1487 took: 1.01s  Val. loss: 0.1630\n",
      "Epoch 33, 100% \t Train loss: 0.1483 took: 1.07s  Val. loss: 0.1648\n",
      "Epoch 34, 100% \t Train loss: 0.1482 took: 1.10s  Val. loss: 0.1658\n",
      "Epoch 35, 100% \t Train loss: 0.1476 took: 1.10s  Val. loss: 0.1674\n",
      "Epoch 36, 100% \t Train loss: 0.1477 took: 1.10s  Val. loss: 0.1652\n",
      "Epoch 37, 100% \t Train loss: 0.1475 took: 1.10s  Val. loss: 0.1639\n",
      "Epoch 38, 100% \t Train loss: 0.1469 took: 1.10s  Val. loss: 0.1632\n",
      "Epoch 39, 100% \t Train loss: 0.1459 took: 1.10s  Val. loss: 0.1642\n",
      "Epoch 40, 100% \t Train loss: 0.1457 took: 1.11s  Val. loss: 0.1644\n",
      "Epoch 41, 100% \t Train loss: 0.1447 took: 1.10s  Val. loss: 0.1640\n",
      "Epoch 42, 100% \t Train loss: 0.1447 took: 1.09s  Val. loss: 0.1627\n",
      "Epoch 43, 100% \t Train loss: 0.1428 took: 1.10s  Val. loss: 0.1607\n",
      "Epoch 44, 100% \t Train loss: 0.1429 took: 1.10s  Val. loss: 0.1588\n",
      "Epoch 45, 100% \t Train loss: 0.1411 took: 1.10s  Val. loss: 0.1586\n",
      "Epoch 46, 100% \t Train loss: 0.1396 took: 1.11s  Val. loss: 0.1610\n",
      "Epoch 47, 100% \t Train loss: 0.1372 took: 1.10s  Val. loss: 0.1564\n",
      "Epoch 48, 100% \t Train loss: 0.1354 took: 1.10s  Val. loss: 0.1544\n",
      "Epoch 49, 100% \t Train loss: 0.1339 took: 1.08s  Val. loss: 0.1512\n",
      "Epoch 50, 100% \t Train loss: 0.1305 took: 1.03s  Val. loss: 0.1487\n",
      "Training finished, took 72.73s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2557 took: 1.71s  Val. loss: 0.2615\n",
      "Epoch 2, 100% \t Train loss: 0.2547 took: 1.70s  Val. loss: 0.2603\n",
      "Epoch 3, 100% \t Train loss: 0.2543 took: 1.70s  Val. loss: 0.2592\n",
      "Epoch 4, 100% \t Train loss: 0.2523 took: 1.68s  Val. loss: 0.2545\n",
      "Epoch 5, 100% \t Train loss: 0.2379 took: 1.68s  Val. loss: 0.2255\n",
      "Epoch 6, 100% \t Train loss: 0.2022 took: 1.69s  Val. loss: 0.1956\n",
      "Epoch 7, 100% \t Train loss: 0.1844 took: 1.68s  Val. loss: 0.1935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.1781 took: 1.68s  Val. loss: 0.1838\n",
      "Epoch 9, 100% \t Train loss: 0.1738 took: 1.68s  Val. loss: 0.1811\n",
      "Epoch 10, 100% \t Train loss: 0.1710 took: 1.69s  Val. loss: 0.1785\n",
      "Epoch 11, 100% \t Train loss: 0.1691 took: 1.68s  Val. loss: 0.1743\n",
      "Epoch 12, 100% \t Train loss: 0.1658 took: 1.70s  Val. loss: 0.1749\n",
      "Epoch 13, 100% \t Train loss: 0.1643 took: 1.70s  Val. loss: 0.1725\n",
      "Epoch 14, 100% \t Train loss: 0.1624 took: 1.68s  Val. loss: 0.1724\n",
      "Epoch 15, 100% \t Train loss: 0.1608 took: 1.68s  Val. loss: 0.1738\n",
      "Epoch 16, 100% \t Train loss: 0.1606 took: 1.67s  Val. loss: 0.1711\n",
      "Epoch 17, 100% \t Train loss: 0.1598 took: 1.69s  Val. loss: 0.1700\n",
      "Epoch 18, 100% \t Train loss: 0.1586 took: 1.71s  Val. loss: 0.1684\n",
      "Epoch 19, 100% \t Train loss: 0.1582 took: 1.67s  Val. loss: 0.1697\n",
      "Epoch 20, 100% \t Train loss: 0.1561 took: 1.68s  Val. loss: 0.1707\n",
      "Epoch 21, 100% \t Train loss: 0.1578 took: 1.68s  Val. loss: 0.1692\n",
      "Epoch 22, 100% \t Train loss: 0.1556 took: 1.66s  Val. loss: 0.1690\n",
      "Epoch 23, 100% \t Train loss: 0.1547 took: 1.68s  Val. loss: 0.1680\n",
      "Epoch 24, 100% \t Train loss: 0.1561 took: 1.68s  Val. loss: 0.1696\n",
      "Epoch 25, 100% \t Train loss: 0.1562 took: 1.67s  Val. loss: 0.1702\n",
      "Epoch 26, 100% \t Train loss: 0.1537 took: 1.67s  Val. loss: 0.1674\n",
      "Epoch 27, 100% \t Train loss: 0.1537 took: 1.66s  Val. loss: 0.1709\n",
      "Epoch 28, 100% \t Train loss: 0.1543 took: 1.68s  Val. loss: 0.1677\n",
      "Epoch 29, 100% \t Train loss: 0.1531 took: 1.68s  Val. loss: 0.1689\n",
      "Epoch 30, 100% \t Train loss: 0.1535 took: 1.66s  Val. loss: 0.1689\n",
      "Epoch 31, 100% \t Train loss: 0.1519 took: 1.68s  Val. loss: 0.1675\n",
      "Epoch 32, 100% \t Train loss: 0.1523 took: 1.71s  Val. loss: 0.1674\n",
      "Epoch 33, 100% \t Train loss: 0.1521 took: 1.71s  Val. loss: 0.1695\n",
      "Epoch 34, 100% \t Train loss: 0.1527 took: 1.70s  Val. loss: 0.1651\n",
      "Epoch 35, 100% \t Train loss: 0.1521 took: 1.71s  Val. loss: 0.1669\n",
      "Epoch 36, 100% \t Train loss: 0.1517 took: 1.71s  Val. loss: 0.1670\n",
      "Epoch 37, 100% \t Train loss: 0.1509 took: 1.44s  Val. loss: 0.1696\n",
      "Epoch 38, 100% \t Train loss: 0.1511 took: 0.98s  Val. loss: 0.1667\n",
      "Epoch 39, 100% \t Train loss: 0.1515 took: 0.98s  Val. loss: 0.1683\n",
      "Epoch 40, 100% \t Train loss: 0.1518 took: 0.98s  Val. loss: 0.1684\n",
      "Epoch 41, 100% \t Train loss: 0.1505 took: 0.98s  Val. loss: 0.1663\n",
      "Epoch 42, 100% \t Train loss: 0.1511 took: 0.99s  Val. loss: 0.1665\n",
      "Epoch 43, 100% \t Train loss: 0.1504 took: 0.98s  Val. loss: 0.1669\n",
      "Epoch 44, 100% \t Train loss: 0.1501 took: 0.99s  Val. loss: 0.1643\n",
      "Epoch 45, 100% \t Train loss: 0.1496 took: 0.98s  Val. loss: 0.1653\n",
      "Epoch 46, 100% \t Train loss: 0.1498 took: 0.98s  Val. loss: 0.1666\n",
      "Epoch 47, 100% \t Train loss: 0.1497 took: 0.99s  Val. loss: 0.1667\n",
      "Epoch 48, 100% \t Train loss: 0.1492 took: 1.00s  Val. loss: 0.1667\n",
      "Epoch 49, 100% \t Train loss: 0.1492 took: 0.99s  Val. loss: 0.1662\n",
      "Epoch 50, 100% \t Train loss: 0.1498 took: 0.99s  Val. loss: 0.1675\n",
      "Training finished, took 85.70s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2581 took: 0.98s  Val. loss: 0.2587\n",
      "Epoch 2, 100% \t Train loss: 0.2574 took: 0.96s  Val. loss: 0.2587\n",
      "Epoch 3, 100% \t Train loss: 0.2573 took: 0.97s  Val. loss: 0.2591\n",
      "Epoch 4, 100% \t Train loss: 0.2573 took: 0.97s  Val. loss: 0.2590\n",
      "Epoch 5, 100% \t Train loss: 0.2572 took: 0.97s  Val. loss: 0.2597\n",
      "Epoch 6, 100% \t Train loss: 0.2571 took: 0.97s  Val. loss: 0.2591\n",
      "Epoch 7, 100% \t Train loss: 0.2568 took: 0.97s  Val. loss: 0.2577\n",
      "Epoch 8, 100% \t Train loss: 0.2563 took: 0.97s  Val. loss: 0.2575\n",
      "Epoch 9, 100% \t Train loss: 0.2550 took: 0.96s  Val. loss: 0.2553\n",
      "Epoch 10, 100% \t Train loss: 0.2511 took: 0.96s  Val. loss: 0.2487\n",
      "Epoch 11, 100% \t Train loss: 0.2390 took: 0.96s  Val. loss: 0.2301\n",
      "Epoch 12, 100% \t Train loss: 0.2129 took: 0.96s  Val. loss: 0.2033\n",
      "Epoch 13, 100% \t Train loss: 0.1898 took: 0.96s  Val. loss: 0.1870\n",
      "Epoch 14, 100% \t Train loss: 0.1792 took: 0.96s  Val. loss: 0.1817\n",
      "Epoch 15, 100% \t Train loss: 0.1742 took: 0.97s  Val. loss: 0.1780\n",
      "Epoch 16, 100% \t Train loss: 0.1714 took: 1.05s  Val. loss: 0.1792\n",
      "Epoch 17, 100% \t Train loss: 0.1694 took: 0.96s  Val. loss: 0.1745\n",
      "Epoch 18, 100% \t Train loss: 0.1685 took: 0.96s  Val. loss: 0.1767\n",
      "Epoch 19, 100% \t Train loss: 0.1677 took: 0.96s  Val. loss: 0.1759\n",
      "Epoch 20, 100% \t Train loss: 0.1671 took: 0.96s  Val. loss: 0.1716\n",
      "Epoch 21, 100% \t Train loss: 0.1652 took: 0.96s  Val. loss: 0.1707\n",
      "Epoch 22, 100% \t Train loss: 0.1655 took: 0.96s  Val. loss: 0.1731\n",
      "Epoch 23, 100% \t Train loss: 0.1647 took: 0.96s  Val. loss: 0.1711\n",
      "Epoch 24, 100% \t Train loss: 0.1635 took: 0.97s  Val. loss: 0.1737\n",
      "Epoch 25, 100% \t Train loss: 0.1637 took: 0.96s  Val. loss: 0.1712\n",
      "Epoch 26, 100% \t Train loss: 0.1629 took: 0.96s  Val. loss: 0.1740\n",
      "Epoch 27, 100% \t Train loss: 0.1634 took: 0.96s  Val. loss: 0.1735\n",
      "Epoch 28, 100% \t Train loss: 0.1626 took: 0.97s  Val. loss: 0.1700\n",
      "Epoch 29, 100% \t Train loss: 0.1611 took: 0.96s  Val. loss: 0.1685\n",
      "Epoch 30, 100% \t Train loss: 0.1608 took: 1.36s  Val. loss: 0.1706\n",
      "Epoch 31, 100% \t Train loss: 0.1610 took: 1.70s  Val. loss: 0.1690\n",
      "Epoch 32, 100% \t Train loss: 0.1622 took: 1.69s  Val. loss: 0.1713\n",
      "Epoch 33, 100% \t Train loss: 0.1599 took: 1.69s  Val. loss: 0.1680\n",
      "Epoch 34, 100% \t Train loss: 0.1605 took: 1.71s  Val. loss: 0.1678\n",
      "Epoch 35, 100% \t Train loss: 0.1608 took: 1.71s  Val. loss: 0.1739\n",
      "Epoch 36, 100% \t Train loss: 0.1590 took: 1.70s  Val. loss: 0.1707\n",
      "Epoch 37, 100% \t Train loss: 0.1589 took: 1.70s  Val. loss: 0.1680\n",
      "Epoch 38, 100% \t Train loss: 0.1591 took: 1.69s  Val. loss: 0.1669\n",
      "Epoch 39, 100% \t Train loss: 0.1595 took: 1.72s  Val. loss: 0.1688\n",
      "Epoch 40, 100% \t Train loss: 0.1585 took: 1.70s  Val. loss: 0.1693\n",
      "Epoch 41, 100% \t Train loss: 0.1579 took: 1.69s  Val. loss: 0.1665\n",
      "Epoch 42, 100% \t Train loss: 0.1576 took: 1.69s  Val. loss: 0.1668\n",
      "Epoch 43, 100% \t Train loss: 0.1574 took: 1.69s  Val. loss: 0.1688\n",
      "Epoch 44, 100% \t Train loss: 0.1572 took: 1.68s  Val. loss: 0.1680\n",
      "Epoch 45, 100% \t Train loss: 0.1572 took: 1.68s  Val. loss: 0.1687\n",
      "Epoch 46, 100% \t Train loss: 0.1572 took: 1.67s  Val. loss: 0.1675\n",
      "Epoch 47, 100% \t Train loss: 0.1565 took: 1.68s  Val. loss: 0.1683\n",
      "Epoch 48, 100% \t Train loss: 0.1573 took: 1.68s  Val. loss: 0.1685\n",
      "Epoch 49, 100% \t Train loss: 0.1566 took: 1.69s  Val. loss: 0.1713\n",
      "Epoch 50, 100% \t Train loss: 0.1577 took: 1.67s  Val. loss: 0.1670\n",
      "Training finished, took 72.34s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.826417\n",
      "lambda: 0.0010 - V: 0.821192\n",
      "lambda: 0.0005 - V: 0.809540\n",
      "Average V: 0.819050\n",
      "Time elapsed: 234.17 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2571 took: 1.98s  Val. loss: 0.2582\n",
      "Epoch 2, 100% \t Train loss: 0.2565 took: 1.98s  Val. loss: 0.2580\n",
      "Epoch 3, 100% \t Train loss: 0.2411 took: 2.00s  Val. loss: 0.2082\n",
      "Epoch 4, 100% \t Train loss: 0.1788 took: 1.98s  Val. loss: 0.1832\n",
      "Epoch 5, 100% \t Train loss: 0.1651 took: 1.97s  Val. loss: 0.1775\n",
      "Epoch 6, 100% \t Train loss: 0.1592 took: 1.98s  Val. loss: 0.1765\n",
      "Epoch 7, 100% \t Train loss: 0.1553 took: 2.03s  Val. loss: 0.1732\n",
      "Epoch 8, 100% \t Train loss: 0.1519 took: 1.95s  Val. loss: 0.1788\n",
      "Epoch 9, 100% \t Train loss: 0.1517 took: 1.97s  Val. loss: 0.1714\n",
      "Epoch 10, 100% \t Train loss: 0.1491 took: 1.99s  Val. loss: 0.1697\n",
      "Epoch 11, 100% \t Train loss: 0.1477 took: 1.99s  Val. loss: 0.1707\n",
      "Epoch 12, 100% \t Train loss: 0.1472 took: 2.00s  Val. loss: 0.1688\n",
      "Epoch 13, 100% \t Train loss: 0.1466 took: 1.98s  Val. loss: 0.1696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.1459 took: 1.98s  Val. loss: 0.1706\n",
      "Epoch 15, 100% \t Train loss: 0.1443 took: 2.01s  Val. loss: 0.1714\n",
      "Epoch 16, 100% \t Train loss: 0.1449 took: 1.98s  Val. loss: 0.1727\n",
      "Epoch 17, 100% \t Train loss: 0.1433 took: 1.99s  Val. loss: 0.1773\n",
      "Epoch 18, 100% \t Train loss: 0.1428 took: 1.98s  Val. loss: 0.1675\n",
      "Epoch 19, 100% \t Train loss: 0.1394 took: 2.00s  Val. loss: 0.1663\n",
      "Epoch 20, 100% \t Train loss: 0.1332 took: 1.98s  Val. loss: 0.1574\n",
      "Epoch 21, 100% \t Train loss: 0.1258 took: 1.17s  Val. loss: 0.1515\n",
      "Epoch 22, 100% \t Train loss: 0.1179 took: 1.17s  Val. loss: 0.1434\n",
      "Epoch 23, 100% \t Train loss: 0.1109 took: 1.17s  Val. loss: 0.1361\n",
      "Epoch 24, 100% \t Train loss: 0.1040 took: 1.17s  Val. loss: 0.1207\n",
      "Epoch 25, 100% \t Train loss: 0.0973 took: 1.17s  Val. loss: 0.1199\n",
      "Epoch 26, 100% \t Train loss: 0.0934 took: 1.17s  Val. loss: 0.1131\n",
      "Epoch 27, 100% \t Train loss: 0.0898 took: 1.17s  Val. loss: 0.1116\n",
      "Epoch 28, 100% \t Train loss: 0.0863 took: 1.19s  Val. loss: 0.1061\n",
      "Epoch 29, 100% \t Train loss: 0.0845 took: 1.20s  Val. loss: 0.1054\n",
      "Epoch 30, 100% \t Train loss: 0.0827 took: 1.22s  Val. loss: 0.1026\n",
      "Epoch 31, 100% \t Train loss: 0.0824 took: 1.27s  Val. loss: 0.1010\n",
      "Epoch 32, 100% \t Train loss: 0.0798 took: 1.53s  Val. loss: 0.1005\n",
      "Epoch 33, 100% \t Train loss: 0.0790 took: 1.83s  Val. loss: 0.1034\n",
      "Epoch 34, 100% \t Train loss: 0.0777 took: 2.64s  Val. loss: 0.1022\n",
      "Epoch 35, 100% \t Train loss: 0.0780 took: 2.65s  Val. loss: 0.1023\n",
      "Epoch 36, 100% \t Train loss: 0.0754 took: 2.72s  Val. loss: 0.1009\n",
      "Epoch 37, 100% \t Train loss: 0.0746 took: 2.76s  Val. loss: 0.1004\n",
      "Epoch 38, 100% \t Train loss: 0.0736 took: 2.78s  Val. loss: 0.0979\n",
      "Epoch 39, 100% \t Train loss: 0.0730 took: 2.81s  Val. loss: 0.0960\n",
      "Epoch 40, 100% \t Train loss: 0.0713 took: 2.78s  Val. loss: 0.0996\n",
      "Epoch 41, 100% \t Train loss: 0.0719 took: 2.78s  Val. loss: 0.0991\n",
      "Epoch 42, 100% \t Train loss: 0.0715 took: 2.79s  Val. loss: 0.0941\n",
      "Epoch 43, 100% \t Train loss: 0.0705 took: 2.81s  Val. loss: 0.0994\n",
      "Epoch 44, 100% \t Train loss: 0.0704 took: 2.79s  Val. loss: 0.0964\n",
      "Epoch 45, 100% \t Train loss: 0.0702 took: 2.79s  Val. loss: 0.0957\n",
      "Epoch 46, 100% \t Train loss: 0.0694 took: 2.79s  Val. loss: 0.0948\n",
      "Epoch 47, 100% \t Train loss: 0.0687 took: 2.77s  Val. loss: 0.0986\n",
      "Epoch 48, 100% \t Train loss: 0.0688 took: 2.76s  Val. loss: 0.0957\n",
      "Epoch 49, 100% \t Train loss: 0.0682 took: 2.76s  Val. loss: 0.0980\n",
      "Epoch 50, 100% \t Train loss: 0.0686 took: 2.76s  Val. loss: 0.0941\n",
      "Training finished, took 116.64s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 2.00s  Val. loss: 0.2599\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.99s  Val. loss: 0.2588\n",
      "Epoch 3, 100% \t Train loss: 0.2579 took: 1.97s  Val. loss: 0.2570\n",
      "Epoch 4, 100% \t Train loss: 0.2540 took: 1.97s  Val. loss: 0.2452\n",
      "Epoch 5, 100% \t Train loss: 0.2183 took: 1.98s  Val. loss: 0.1927\n",
      "Epoch 6, 100% \t Train loss: 0.1818 took: 1.99s  Val. loss: 0.1763\n",
      "Epoch 7, 100% \t Train loss: 0.1700 took: 1.99s  Val. loss: 0.1683\n",
      "Epoch 8, 100% \t Train loss: 0.1655 took: 1.98s  Val. loss: 0.1631\n",
      "Epoch 9, 100% \t Train loss: 0.1627 took: 1.95s  Val. loss: 0.1609\n",
      "Epoch 10, 100% \t Train loss: 0.1605 took: 1.98s  Val. loss: 0.1602\n",
      "Epoch 11, 100% \t Train loss: 0.1582 took: 1.97s  Val. loss: 0.1595\n",
      "Epoch 12, 100% \t Train loss: 0.1571 took: 1.98s  Val. loss: 0.1598\n",
      "Epoch 13, 100% \t Train loss: 0.1544 took: 1.97s  Val. loss: 0.1596\n",
      "Epoch 14, 100% \t Train loss: 0.1530 took: 1.96s  Val. loss: 0.1537\n",
      "Epoch 15, 100% \t Train loss: 0.1522 took: 1.97s  Val. loss: 0.1553\n",
      "Epoch 16, 100% \t Train loss: 0.1511 took: 1.78s  Val. loss: 0.1531\n",
      "Epoch 17, 100% \t Train loss: 0.1509 took: 1.16s  Val. loss: 0.1586\n",
      "Epoch 18, 100% \t Train loss: 0.1527 took: 1.16s  Val. loss: 0.1610\n",
      "Epoch 19, 100% \t Train loss: 0.1501 took: 1.17s  Val. loss: 0.1550\n",
      "Epoch 20, 100% \t Train loss: 0.1487 took: 1.17s  Val. loss: 0.1562\n",
      "Epoch 21, 100% \t Train loss: 0.1484 took: 1.17s  Val. loss: 0.1547\n",
      "Epoch 22, 100% \t Train loss: 0.1473 took: 1.17s  Val. loss: 0.1538\n",
      "Epoch 23, 100% \t Train loss: 0.1467 took: 1.17s  Val. loss: 0.1528\n",
      "Epoch 24, 100% \t Train loss: 0.1465 took: 1.18s  Val. loss: 0.1556\n",
      "Epoch 25, 100% \t Train loss: 0.1458 took: 1.17s  Val. loss: 0.1557\n",
      "Epoch 26, 100% \t Train loss: 0.1455 took: 1.17s  Val. loss: 0.1559\n",
      "Epoch 27, 100% \t Train loss: 0.1453 took: 1.17s  Val. loss: 0.1591\n",
      "Epoch 28, 100% \t Train loss: 0.1448 took: 1.17s  Val. loss: 0.1534\n",
      "Epoch 29, 100% \t Train loss: 0.1438 took: 1.19s  Val. loss: 0.1530\n",
      "Epoch 30, 100% \t Train loss: 0.1441 took: 1.21s  Val. loss: 0.1553\n",
      "Epoch 31, 100% \t Train loss: 0.1425 took: 1.25s  Val. loss: 0.1541\n",
      "Epoch 32, 100% \t Train loss: 0.1413 took: 1.33s  Val. loss: 0.1552\n",
      "Epoch 33, 100% \t Train loss: 0.1410 took: 1.38s  Val. loss: 0.1516\n",
      "Epoch 34, 100% \t Train loss: 0.1405 took: 1.43s  Val. loss: 0.1509\n",
      "Epoch 35, 100% \t Train loss: 0.1396 took: 1.49s  Val. loss: 0.1498\n",
      "Epoch 36, 100% \t Train loss: 0.1378 took: 1.57s  Val. loss: 0.1494\n",
      "Epoch 37, 100% \t Train loss: 0.1354 took: 1.67s  Val. loss: 0.1484\n",
      "Epoch 38, 100% \t Train loss: 0.1329 took: 2.54s  Val. loss: 0.1474\n",
      "Epoch 39, 100% \t Train loss: 0.1314 took: 2.46s  Val. loss: 0.1441\n",
      "Epoch 40, 100% \t Train loss: 0.1284 took: 2.54s  Val. loss: 0.1426\n",
      "Epoch 41, 100% \t Train loss: 0.1260 took: 2.55s  Val. loss: 0.1390\n",
      "Epoch 42, 100% \t Train loss: 0.1236 took: 2.59s  Val. loss: 0.1335\n",
      "Epoch 43, 100% \t Train loss: 0.1195 took: 2.63s  Val. loss: 0.1327\n",
      "Epoch 44, 100% \t Train loss: 0.1164 took: 2.05s  Val. loss: 0.1287\n",
      "Epoch 45, 100% \t Train loss: 0.1127 took: 2.05s  Val. loss: 0.1266\n",
      "Epoch 46, 100% \t Train loss: 0.1105 took: 2.04s  Val. loss: 0.1201\n",
      "Epoch 47, 100% \t Train loss: 0.1063 took: 2.04s  Val. loss: 0.1145\n",
      "Epoch 48, 100% \t Train loss: 0.1024 took: 2.03s  Val. loss: 0.1122\n",
      "Epoch 49, 100% \t Train loss: 0.1011 took: 2.04s  Val. loss: 0.1106\n",
      "Epoch 50, 100% \t Train loss: 0.0969 took: 2.04s  Val. loss: 0.1118\n",
      "Training finished, took 98.65s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2605 took: 1.99s  Val. loss: 0.2583\n",
      "Epoch 2, 100% \t Train loss: 0.2598 took: 1.96s  Val. loss: 0.2573\n",
      "Epoch 3, 100% \t Train loss: 0.2598 took: 1.99s  Val. loss: 0.2575\n",
      "Epoch 4, 100% \t Train loss: 0.2595 took: 1.98s  Val. loss: 0.2569\n",
      "Epoch 5, 100% \t Train loss: 0.2584 took: 1.97s  Val. loss: 0.2546\n",
      "Epoch 6, 100% \t Train loss: 0.2509 took: 1.99s  Val. loss: 0.2363\n",
      "Epoch 7, 100% \t Train loss: 0.2245 took: 1.98s  Val. loss: 0.2080\n",
      "Epoch 8, 100% \t Train loss: 0.2014 took: 2.00s  Val. loss: 0.1873\n",
      "Epoch 9, 100% \t Train loss: 0.1868 took: 1.99s  Val. loss: 0.1769\n",
      "Epoch 10, 100% \t Train loss: 0.1822 took: 1.96s  Val. loss: 0.1717\n",
      "Epoch 11, 100% \t Train loss: 0.1763 took: 1.97s  Val. loss: 0.1735\n",
      "Epoch 12, 100% \t Train loss: 0.1742 took: 1.99s  Val. loss: 0.1728\n",
      "Epoch 13, 100% \t Train loss: 0.1728 took: 1.99s  Val. loss: 0.1689\n",
      "Epoch 14, 100% \t Train loss: 0.1708 took: 1.99s  Val. loss: 0.1752\n",
      "Epoch 15, 100% \t Train loss: 0.1717 took: 1.99s  Val. loss: 0.1681\n",
      "Epoch 16, 100% \t Train loss: 0.1692 took: 1.99s  Val. loss: 0.1682\n",
      "Epoch 17, 100% \t Train loss: 0.1682 took: 2.02s  Val. loss: 0.1672\n",
      "Epoch 18, 100% \t Train loss: 0.1686 took: 2.00s  Val. loss: 0.1672\n",
      "Epoch 19, 100% \t Train loss: 0.1672 took: 2.00s  Val. loss: 0.1668\n",
      "Epoch 20, 100% \t Train loss: 0.1661 took: 1.99s  Val. loss: 0.1686\n",
      "Epoch 21, 100% \t Train loss: 0.1654 took: 2.00s  Val. loss: 0.1721\n",
      "Epoch 22, 100% \t Train loss: 0.1657 took: 2.01s  Val. loss: 0.1660\n",
      "Epoch 23, 100% \t Train loss: 0.1642 took: 2.00s  Val. loss: 0.1667\n",
      "Epoch 24, 100% \t Train loss: 0.1644 took: 2.03s  Val. loss: 0.1662\n",
      "Epoch 25, 100% \t Train loss: 0.1644 took: 1.98s  Val. loss: 0.1635\n",
      "Epoch 26, 100% \t Train loss: 0.1632 took: 2.00s  Val. loss: 0.1633\n",
      "Epoch 27, 100% \t Train loss: 0.1622 took: 1.98s  Val. loss: 0.1644\n",
      "Epoch 28, 100% \t Train loss: 0.1614 took: 1.98s  Val. loss: 0.1648\n",
      "Epoch 29, 100% \t Train loss: 0.1621 took: 2.01s  Val. loss: 0.1692\n",
      "Epoch 30, 100% \t Train loss: 0.1610 took: 2.02s  Val. loss: 0.1640\n",
      "Epoch 31, 100% \t Train loss: 0.1607 took: 2.04s  Val. loss: 0.1624\n",
      "Epoch 32, 100% \t Train loss: 0.1584 took: 2.04s  Val. loss: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, 100% \t Train loss: 0.1591 took: 2.06s  Val. loss: 0.1645\n",
      "Epoch 34, 100% \t Train loss: 0.1568 took: 2.06s  Val. loss: 0.1600\n",
      "Epoch 35, 100% \t Train loss: 0.1561 took: 2.06s  Val. loss: 0.1615\n",
      "Epoch 36, 100% \t Train loss: 0.1559 took: 2.07s  Val. loss: 0.1602\n",
      "Epoch 37, 100% \t Train loss: 0.1539 took: 2.07s  Val. loss: 0.1591\n",
      "Epoch 38, 100% \t Train loss: 0.1532 took: 2.08s  Val. loss: 0.1623\n",
      "Epoch 39, 100% \t Train loss: 0.1508 took: 2.11s  Val. loss: 0.1550\n",
      "Epoch 40, 100% \t Train loss: 0.1497 took: 2.10s  Val. loss: 0.1557\n",
      "Epoch 41, 100% \t Train loss: 0.1470 took: 2.17s  Val. loss: 0.1510\n",
      "Epoch 42, 100% \t Train loss: 0.1450 took: 2.19s  Val. loss: 0.1515\n",
      "Epoch 43, 100% \t Train loss: 0.1429 took: 1.39s  Val. loss: 0.1485\n",
      "Epoch 44, 100% \t Train loss: 0.1397 took: 1.39s  Val. loss: 0.1437\n",
      "Epoch 45, 100% \t Train loss: 0.1370 took: 1.41s  Val. loss: 0.1432\n",
      "Epoch 46, 100% \t Train loss: 0.1355 took: 1.41s  Val. loss: 0.1460\n",
      "Epoch 47, 100% \t Train loss: 0.1331 took: 1.53s  Val. loss: 0.1394\n",
      "Epoch 48, 100% \t Train loss: 0.1300 took: 2.21s  Val. loss: 0.1357\n",
      "Epoch 49, 100% \t Train loss: 0.1266 took: 2.24s  Val. loss: 0.1291\n",
      "Epoch 50, 100% \t Train loss: 0.1243 took: 2.26s  Val. loss: 0.1303\n",
      "Training finished, took 111.69s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.863453\n",
      "lambda: 0.0010 - V: 0.842269\n",
      "lambda: 0.0005 - V: 0.827058\n",
      "Average V: 0.844260\n",
      "Time elapsed: 330.37 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2584 took: 1.78s  Val. loss: 0.2544\n",
      "Epoch 2, 100% \t Train loss: 0.2570 took: 1.81s  Val. loss: 0.2539\n",
      "Epoch 3, 100% \t Train loss: 0.2568 took: 1.80s  Val. loss: 0.2538\n",
      "Epoch 4, 100% \t Train loss: 0.2563 took: 1.79s  Val. loss: 0.2515\n",
      "Epoch 5, 100% \t Train loss: 0.2030 took: 1.80s  Val. loss: 0.1763\n",
      "Epoch 6, 100% \t Train loss: 0.1726 took: 1.80s  Val. loss: 0.1750\n",
      "Epoch 7, 100% \t Train loss: 0.1671 took: 1.79s  Val. loss: 0.1753\n",
      "Epoch 8, 100% \t Train loss: 0.1591 took: 1.79s  Val. loss: 0.1672\n",
      "Epoch 9, 100% \t Train loss: 0.1554 took: 1.03s  Val. loss: 0.1591\n",
      "Epoch 10, 100% \t Train loss: 0.1493 took: 1.03s  Val. loss: 0.1570\n",
      "Epoch 11, 100% \t Train loss: 0.1385 took: 1.03s  Val. loss: 0.1410\n",
      "Epoch 12, 100% \t Train loss: 0.1201 took: 1.04s  Val. loss: 0.1179\n",
      "Epoch 13, 100% \t Train loss: 0.1088 took: 1.04s  Val. loss: 0.1156\n",
      "Epoch 14, 100% \t Train loss: 0.0996 took: 1.03s  Val. loss: 0.1077\n",
      "Epoch 15, 100% \t Train loss: 0.0955 took: 1.04s  Val. loss: 0.1006\n",
      "Epoch 16, 100% \t Train loss: 0.0911 took: 1.03s  Val. loss: 0.0972\n",
      "Epoch 17, 100% \t Train loss: 0.0886 took: 1.03s  Val. loss: 0.0935\n",
      "Epoch 18, 100% \t Train loss: 0.0885 took: 1.03s  Val. loss: 0.0903\n",
      "Epoch 19, 100% \t Train loss: 0.0858 took: 1.03s  Val. loss: 0.0906\n",
      "Epoch 20, 100% \t Train loss: 0.0836 took: 1.03s  Val. loss: 0.0899\n",
      "Epoch 21, 100% \t Train loss: 0.0829 took: 1.03s  Val. loss: 0.0929\n",
      "Epoch 22, 100% \t Train loss: 0.0831 took: 1.03s  Val. loss: 0.0926\n",
      "Epoch 23, 100% \t Train loss: 0.0829 took: 1.03s  Val. loss: 0.0934\n",
      "Epoch 24, 100% \t Train loss: 0.0801 took: 1.03s  Val. loss: 0.0883\n",
      "Epoch 25, 100% \t Train loss: 0.0802 took: 1.03s  Val. loss: 0.0921\n",
      "Epoch 26, 100% \t Train loss: 0.0804 took: 1.03s  Val. loss: 0.0887\n",
      "Epoch 27, 100% \t Train loss: 0.0788 took: 1.03s  Val. loss: 0.0898\n",
      "Epoch 28, 100% \t Train loss: 0.0800 took: 1.04s  Val. loss: 0.0879\n",
      "Epoch 29, 100% \t Train loss: 0.0777 took: 1.04s  Val. loss: 0.0851\n",
      "Epoch 30, 100% \t Train loss: 0.0782 took: 1.05s  Val. loss: 0.0924\n",
      "Epoch 31, 100% \t Train loss: 0.0778 took: 1.81s  Val. loss: 0.0887\n",
      "Epoch 32, 100% \t Train loss: 0.0772 took: 1.90s  Val. loss: 0.0884\n",
      "Epoch 33, 100% \t Train loss: 0.0769 took: 1.96s  Val. loss: 0.0877\n",
      "Epoch 34, 100% \t Train loss: 0.0761 took: 1.98s  Val. loss: 0.0898\n",
      "Epoch 35, 100% \t Train loss: 0.0756 took: 2.00s  Val. loss: 0.0893\n",
      "Epoch 36, 100% \t Train loss: 0.0770 took: 2.02s  Val. loss: 0.0897\n",
      "Epoch 37, 100% \t Train loss: 0.0755 took: 2.01s  Val. loss: 0.0902\n",
      "Epoch 38, 100% \t Train loss: 0.0754 took: 2.00s  Val. loss: 0.0846\n",
      "Epoch 39, 100% \t Train loss: 0.0741 took: 2.01s  Val. loss: 0.0872\n",
      "Epoch 40, 100% \t Train loss: 0.0739 took: 2.02s  Val. loss: 0.0889\n",
      "Epoch 41, 100% \t Train loss: 0.0746 took: 1.26s  Val. loss: 0.0942\n",
      "Epoch 42, 100% \t Train loss: 0.0747 took: 1.26s  Val. loss: 0.0866\n",
      "Epoch 43, 100% \t Train loss: 0.0735 took: 1.28s  Val. loss: 0.0888\n",
      "Epoch 44, 100% \t Train loss: 0.0753 took: 1.28s  Val. loss: 0.0910\n",
      "Epoch 45, 100% \t Train loss: 0.0736 took: 1.28s  Val. loss: 0.0866\n",
      "Epoch 46, 100% \t Train loss: 0.0734 took: 1.28s  Val. loss: 0.0867\n",
      "Epoch 47, 100% \t Train loss: 0.0730 took: 1.30s  Val. loss: 0.0883\n",
      "Epoch 48, 100% \t Train loss: 0.0725 took: 1.29s  Val. loss: 0.0885\n",
      "Epoch 49, 100% \t Train loss: 0.0729 took: 2.08s  Val. loss: 0.0898\n",
      "Epoch 50, 100% \t Train loss: 0.0723 took: 2.11s  Val. loss: 0.0859\n",
      "Training finished, took 80.96s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2609 took: 1.81s  Val. loss: 0.2633\n",
      "Epoch 2, 100% \t Train loss: 0.2604 took: 1.78s  Val. loss: 0.2614\n",
      "Epoch 3, 100% \t Train loss: 0.2600 took: 1.03s  Val. loss: 0.2619\n",
      "Epoch 4, 100% \t Train loss: 0.2597 took: 1.03s  Val. loss: 0.2628\n",
      "Epoch 5, 100% \t Train loss: 0.2572 took: 1.02s  Val. loss: 0.2524\n",
      "Epoch 6, 100% \t Train loss: 0.2317 took: 1.03s  Val. loss: 0.2058\n",
      "Epoch 7, 100% \t Train loss: 0.1974 took: 1.02s  Val. loss: 0.1870\n",
      "Epoch 8, 100% \t Train loss: 0.1880 took: 1.03s  Val. loss: 0.1759\n",
      "Epoch 9, 100% \t Train loss: 0.1823 took: 1.03s  Val. loss: 0.1786\n",
      "Epoch 10, 100% \t Train loss: 0.1795 took: 1.02s  Val. loss: 0.1758\n",
      "Epoch 11, 100% \t Train loss: 0.1768 took: 1.02s  Val. loss: 0.1743\n",
      "Epoch 12, 100% \t Train loss: 0.1749 took: 1.02s  Val. loss: 0.1682\n",
      "Epoch 13, 100% \t Train loss: 0.1711 took: 1.02s  Val. loss: 0.1670\n",
      "Epoch 14, 100% \t Train loss: 0.1723 took: 1.02s  Val. loss: 0.1660\n",
      "Epoch 15, 100% \t Train loss: 0.1714 took: 1.02s  Val. loss: 0.1697\n",
      "Epoch 16, 100% \t Train loss: 0.1701 took: 1.03s  Val. loss: 0.1665\n",
      "Epoch 17, 100% \t Train loss: 0.1683 took: 1.02s  Val. loss: 0.1666\n",
      "Epoch 18, 100% \t Train loss: 0.1687 took: 1.03s  Val. loss: 0.1637\n",
      "Epoch 19, 100% \t Train loss: 0.1657 took: 1.03s  Val. loss: 0.1660\n",
      "Epoch 20, 100% \t Train loss: 0.1649 took: 1.02s  Val. loss: 0.1655\n",
      "Epoch 21, 100% \t Train loss: 0.1654 took: 1.18s  Val. loss: 0.1636\n",
      "Epoch 22, 100% \t Train loss: 0.1653 took: 1.80s  Val. loss: 0.1706\n",
      "Epoch 23, 100% \t Train loss: 0.1650 took: 1.03s  Val. loss: 0.1649\n",
      "Epoch 24, 100% \t Train loss: 0.1614 took: 1.03s  Val. loss: 0.1625\n",
      "Epoch 25, 100% \t Train loss: 0.1607 took: 1.03s  Val. loss: 0.1716\n",
      "Epoch 26, 100% \t Train loss: 0.1609 took: 1.03s  Val. loss: 0.1627\n",
      "Epoch 27, 100% \t Train loss: 0.1604 took: 1.04s  Val. loss: 0.1634\n",
      "Epoch 28, 100% \t Train loss: 0.1608 took: 1.04s  Val. loss: 0.1605\n",
      "Epoch 29, 100% \t Train loss: 0.1603 took: 1.06s  Val. loss: 0.1632\n",
      "Epoch 30, 100% \t Train loss: 0.1594 took: 1.07s  Val. loss: 0.1663\n",
      "Epoch 31, 100% \t Train loss: 0.1588 took: 1.10s  Val. loss: 0.1619\n",
      "Epoch 32, 100% \t Train loss: 0.1573 took: 1.13s  Val. loss: 0.1639\n",
      "Epoch 33, 100% \t Train loss: 0.1561 took: 1.16s  Val. loss: 0.1606\n",
      "Epoch 34, 100% \t Train loss: 0.1559 took: 1.17s  Val. loss: 0.1611\n",
      "Epoch 35, 100% \t Train loss: 0.1546 took: 1.17s  Val. loss: 0.1626\n",
      "Epoch 36, 100% \t Train loss: 0.1560 took: 1.19s  Val. loss: 0.1594\n",
      "Epoch 37, 100% \t Train loss: 0.1528 took: 1.19s  Val. loss: 0.1605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, 100% \t Train loss: 0.1542 took: 1.20s  Val. loss: 0.1566\n",
      "Epoch 39, 100% \t Train loss: 0.1538 took: 1.20s  Val. loss: 0.1546\n",
      "Epoch 40, 100% \t Train loss: 0.1484 took: 1.19s  Val. loss: 0.1562\n",
      "Epoch 41, 100% \t Train loss: 0.1481 took: 1.19s  Val. loss: 0.1569\n",
      "Epoch 42, 100% \t Train loss: 0.1455 took: 1.17s  Val. loss: 0.1499\n",
      "Epoch 43, 100% \t Train loss: 0.1426 took: 1.16s  Val. loss: 0.1454\n",
      "Epoch 44, 100% \t Train loss: 0.1388 took: 1.15s  Val. loss: 0.1425\n",
      "Epoch 45, 100% \t Train loss: 0.1351 took: 1.15s  Val. loss: 0.1379\n",
      "Epoch 46, 100% \t Train loss: 0.1308 took: 1.15s  Val. loss: 0.1344\n",
      "Epoch 47, 100% \t Train loss: 0.1272 took: 1.16s  Val. loss: 0.1309\n",
      "Epoch 48, 100% \t Train loss: 0.1238 took: 1.15s  Val. loss: 0.1263\n",
      "Epoch 49, 100% \t Train loss: 0.1216 took: 1.16s  Val. loss: 0.1282\n",
      "Epoch 50, 100% \t Train loss: 0.1198 took: 1.16s  Val. loss: 0.1229\n",
      "Training finished, took 63.93s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 1.04s  Val. loss: 0.2606\n",
      "Epoch 2, 100% \t Train loss: 0.2590 took: 1.04s  Val. loss: 0.2602\n",
      "Epoch 3, 100% \t Train loss: 0.2588 took: 1.03s  Val. loss: 0.2604\n",
      "Epoch 4, 100% \t Train loss: 0.2575 took: 1.03s  Val. loss: 0.2567\n",
      "Epoch 5, 100% \t Train loss: 0.2471 took: 1.04s  Val. loss: 0.2362\n",
      "Epoch 6, 100% \t Train loss: 0.2192 took: 1.03s  Val. loss: 0.2074\n",
      "Epoch 7, 100% \t Train loss: 0.1947 took: 1.03s  Val. loss: 0.1853\n",
      "Epoch 8, 100% \t Train loss: 0.1812 took: 1.04s  Val. loss: 0.1794\n",
      "Epoch 9, 100% \t Train loss: 0.1777 took: 1.03s  Val. loss: 0.1749\n",
      "Epoch 10, 100% \t Train loss: 0.1758 took: 1.03s  Val. loss: 0.1751\n",
      "Epoch 11, 100% \t Train loss: 0.1719 took: 1.04s  Val. loss: 0.1704\n",
      "Epoch 12, 100% \t Train loss: 0.1698 took: 1.03s  Val. loss: 0.1673\n",
      "Epoch 13, 100% \t Train loss: 0.1680 took: 1.03s  Val. loss: 0.1715\n",
      "Epoch 14, 100% \t Train loss: 0.1654 took: 1.03s  Val. loss: 0.1668\n",
      "Epoch 15, 100% \t Train loss: 0.1654 took: 1.04s  Val. loss: 0.1698\n",
      "Epoch 16, 100% \t Train loss: 0.1629 took: 1.09s  Val. loss: 0.1628\n",
      "Epoch 17, 100% \t Train loss: 0.1628 took: 1.04s  Val. loss: 0.1627\n",
      "Epoch 18, 100% \t Train loss: 0.1621 took: 1.22s  Val. loss: 0.1636\n",
      "Epoch 19, 100% \t Train loss: 0.1606 took: 1.76s  Val. loss: 0.1599\n",
      "Epoch 20, 100% \t Train loss: 0.1618 took: 1.78s  Val. loss: 0.1607\n",
      "Epoch 21, 100% \t Train loss: 0.1584 took: 1.78s  Val. loss: 0.1630\n",
      "Epoch 22, 100% \t Train loss: 0.1612 took: 1.80s  Val. loss: 0.1619\n",
      "Epoch 23, 100% \t Train loss: 0.1593 took: 1.24s  Val. loss: 0.1583\n",
      "Epoch 24, 100% \t Train loss: 0.1592 took: 1.03s  Val. loss: 0.1583\n",
      "Epoch 25, 100% \t Train loss: 0.1576 took: 1.03s  Val. loss: 0.1591\n",
      "Epoch 26, 100% \t Train loss: 0.1588 took: 1.04s  Val. loss: 0.1626\n",
      "Epoch 27, 100% \t Train loss: 0.1582 took: 1.04s  Val. loss: 0.1625\n",
      "Epoch 28, 100% \t Train loss: 0.1569 took: 1.05s  Val. loss: 0.1637\n",
      "Epoch 29, 100% \t Train loss: 0.1571 took: 1.06s  Val. loss: 0.1574\n",
      "Epoch 30, 100% \t Train loss: 0.1552 took: 1.07s  Val. loss: 0.1634\n",
      "Epoch 31, 100% \t Train loss: 0.1569 took: 1.09s  Val. loss: 0.1588\n",
      "Epoch 32, 100% \t Train loss: 0.1560 took: 1.12s  Val. loss: 0.1612\n",
      "Epoch 33, 100% \t Train loss: 0.1561 took: 1.11s  Val. loss: 0.1641\n",
      "Epoch 34, 100% \t Train loss: 0.1587 took: 1.12s  Val. loss: 0.1586\n",
      "Epoch 35, 100% \t Train loss: 0.1557 took: 1.12s  Val. loss: 0.1617\n",
      "Epoch 36, 100% \t Train loss: 0.1550 took: 1.13s  Val. loss: 0.1560\n",
      "Epoch 37, 100% \t Train loss: 0.1559 took: 1.14s  Val. loss: 0.1588\n",
      "Epoch 38, 100% \t Train loss: 0.1559 took: 1.14s  Val. loss: 0.1598\n",
      "Epoch 39, 100% \t Train loss: 0.1537 took: 1.16s  Val. loss: 0.1565\n",
      "Epoch 40, 100% \t Train loss: 0.1533 took: 1.17s  Val. loss: 0.1600\n",
      "Epoch 41, 100% \t Train loss: 0.1547 took: 1.18s  Val. loss: 0.1590\n",
      "Epoch 42, 100% \t Train loss: 0.1523 took: 1.18s  Val. loss: 0.1584\n",
      "Epoch 43, 100% \t Train loss: 0.1538 took: 1.18s  Val. loss: 0.1576\n",
      "Epoch 44, 100% \t Train loss: 0.1528 took: 1.20s  Val. loss: 0.1567\n",
      "Epoch 45, 100% \t Train loss: 0.1511 took: 1.20s  Val. loss: 0.1545\n",
      "Epoch 46, 100% \t Train loss: 0.1516 took: 1.20s  Val. loss: 0.1562\n",
      "Epoch 47, 100% \t Train loss: 0.1508 took: 1.20s  Val. loss: 0.1589\n",
      "Epoch 48, 100% \t Train loss: 0.1504 took: 1.19s  Val. loss: 0.1556\n",
      "Epoch 49, 100% \t Train loss: 0.1501 took: 1.19s  Val. loss: 0.1555\n",
      "Epoch 50, 100% \t Train loss: 0.1493 took: 1.19s  Val. loss: 0.1552\n",
      "Training finished, took 65.22s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.885161\n",
      "lambda: 0.0010 - V: 0.829595\n",
      "lambda: 0.0005 - V: 0.827496\n",
      "Average V: 0.847417\n",
      "Time elapsed: 213.53 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2572 took: 1.82s  Val. loss: 0.2568\n",
      "Epoch 2, 100% \t Train loss: 0.2558 took: 1.81s  Val. loss: 0.2571\n",
      "Epoch 3, 100% \t Train loss: 0.2555 took: 1.81s  Val. loss: 0.2565\n",
      "Epoch 4, 100% \t Train loss: 0.2476 took: 1.80s  Val. loss: 0.2219\n",
      "Epoch 5, 100% \t Train loss: 0.1818 took: 1.15s  Val. loss: 0.1682\n",
      "Epoch 6, 100% \t Train loss: 0.1642 took: 1.04s  Val. loss: 0.1641\n",
      "Epoch 7, 100% \t Train loss: 0.1619 took: 1.04s  Val. loss: 0.1639\n",
      "Epoch 8, 100% \t Train loss: 0.1611 took: 1.04s  Val. loss: 0.1632\n",
      "Epoch 9, 100% \t Train loss: 0.1595 took: 1.04s  Val. loss: 0.1620\n",
      "Epoch 10, 100% \t Train loss: 0.1570 took: 1.04s  Val. loss: 0.1606\n",
      "Epoch 11, 100% \t Train loss: 0.1527 took: 1.04s  Val. loss: 0.1563\n",
      "Epoch 12, 100% \t Train loss: 0.1507 took: 1.04s  Val. loss: 0.1589\n",
      "Epoch 13, 100% \t Train loss: 0.1498 took: 1.04s  Val. loss: 0.1546\n",
      "Epoch 14, 100% \t Train loss: 0.1479 took: 1.03s  Val. loss: 0.1554\n",
      "Epoch 15, 100% \t Train loss: 0.1468 took: 1.04s  Val. loss: 0.1571\n",
      "Epoch 16, 100% \t Train loss: 0.1466 took: 1.68s  Val. loss: 0.1541\n",
      "Epoch 17, 100% \t Train loss: 0.1456 took: 1.81s  Val. loss: 0.1532\n",
      "Epoch 18, 100% \t Train loss: 0.1447 took: 1.82s  Val. loss: 0.1516\n",
      "Epoch 19, 100% \t Train loss: 0.1441 took: 1.83s  Val. loss: 0.1517\n",
      "Epoch 20, 100% \t Train loss: 0.1436 took: 1.81s  Val. loss: 0.1557\n",
      "Epoch 21, 100% \t Train loss: 0.1436 took: 1.81s  Val. loss: 0.1522\n",
      "Epoch 22, 100% \t Train loss: 0.1428 took: 1.80s  Val. loss: 0.1515\n",
      "Epoch 23, 100% \t Train loss: 0.1424 took: 1.82s  Val. loss: 0.1523\n",
      "Epoch 24, 100% \t Train loss: 0.1416 took: 1.82s  Val. loss: 0.1529\n",
      "Epoch 25, 100% \t Train loss: 0.1402 took: 1.81s  Val. loss: 0.1512\n",
      "Epoch 26, 100% \t Train loss: 0.1401 took: 1.82s  Val. loss: 0.1486\n",
      "Epoch 27, 100% \t Train loss: 0.1370 took: 1.81s  Val. loss: 0.1504\n",
      "Epoch 28, 100% \t Train loss: 0.1363 took: 1.81s  Val. loss: 0.1482\n",
      "Epoch 29, 100% \t Train loss: 0.1346 took: 1.83s  Val. loss: 0.1489\n",
      "Epoch 30, 100% \t Train loss: 0.1309 took: 1.82s  Val. loss: 0.1450\n",
      "Epoch 31, 100% \t Train loss: 0.1283 took: 1.82s  Val. loss: 0.1446\n",
      "Epoch 32, 100% \t Train loss: 0.1259 took: 1.83s  Val. loss: 0.1366\n",
      "Epoch 33, 100% \t Train loss: 0.1190 took: 1.83s  Val. loss: 0.1331\n",
      "Epoch 34, 100% \t Train loss: 0.1164 took: 1.82s  Val. loss: 0.1295\n",
      "Epoch 35, 100% \t Train loss: 0.1103 took: 1.82s  Val. loss: 0.1298\n",
      "Epoch 36, 100% \t Train loss: 0.1073 took: 1.82s  Val. loss: 0.1192\n",
      "Epoch 37, 100% \t Train loss: 0.1049 took: 1.82s  Val. loss: 0.1199\n",
      "Epoch 38, 100% \t Train loss: 0.1020 took: 1.85s  Val. loss: 0.1159\n",
      "Epoch 39, 100% \t Train loss: 0.0999 took: 1.83s  Val. loss: 0.1120\n",
      "Epoch 40, 100% \t Train loss: 0.0971 took: 1.84s  Val. loss: 0.1099\n",
      "Epoch 41, 100% \t Train loss: 0.0952 took: 1.85s  Val. loss: 0.1098\n",
      "Epoch 42, 100% \t Train loss: 0.0937 took: 1.83s  Val. loss: 0.1129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, 100% \t Train loss: 0.0934 took: 1.82s  Val. loss: 0.1127\n",
      "Epoch 44, 100% \t Train loss: 0.0921 took: 1.83s  Val. loss: 0.1090\n",
      "Epoch 45, 100% \t Train loss: 0.0909 took: 1.82s  Val. loss: 0.1114\n",
      "Epoch 46, 100% \t Train loss: 0.0885 took: 1.82s  Val. loss: 0.1042\n",
      "Epoch 47, 100% \t Train loss: 0.0859 took: 1.84s  Val. loss: 0.1072\n",
      "Epoch 48, 100% \t Train loss: 0.0865 took: 1.81s  Val. loss: 0.1052\n",
      "Epoch 49, 100% \t Train loss: 0.0857 took: 1.83s  Val. loss: 0.1044\n",
      "Epoch 50, 100% \t Train loss: 0.0852 took: 1.84s  Val. loss: 0.1065\n",
      "Training finished, took 93.47s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 1.83s  Val. loss: 0.2656\n",
      "Epoch 2, 100% \t Train loss: 0.2587 took: 1.80s  Val. loss: 0.2655\n",
      "Epoch 3, 100% \t Train loss: 0.2588 took: 1.81s  Val. loss: 0.2661\n",
      "Epoch 4, 100% \t Train loss: 0.2585 took: 1.81s  Val. loss: 0.2656\n",
      "Epoch 5, 100% \t Train loss: 0.2583 took: 1.81s  Val. loss: 0.2666\n",
      "Epoch 6, 100% \t Train loss: 0.2578 took: 1.79s  Val. loss: 0.2631\n",
      "Epoch 7, 100% \t Train loss: 0.2546 took: 1.81s  Val. loss: 0.2572\n",
      "Epoch 8, 100% \t Train loss: 0.2420 took: 1.80s  Val. loss: 0.2407\n",
      "Epoch 9, 100% \t Train loss: 0.2226 took: 1.81s  Val. loss: 0.2179\n",
      "Epoch 10, 100% \t Train loss: 0.2045 took: 1.81s  Val. loss: 0.2129\n",
      "Epoch 11, 100% \t Train loss: 0.1899 took: 1.80s  Val. loss: 0.2023\n",
      "Epoch 12, 100% \t Train loss: 0.1849 took: 1.81s  Val. loss: 0.1949\n",
      "Epoch 13, 100% \t Train loss: 0.1784 took: 1.83s  Val. loss: 0.1889\n",
      "Epoch 14, 100% \t Train loss: 0.1753 took: 1.82s  Val. loss: 0.1817\n",
      "Epoch 15, 100% \t Train loss: 0.1734 took: 1.82s  Val. loss: 0.1795\n",
      "Epoch 16, 100% \t Train loss: 0.1722 took: 1.81s  Val. loss: 0.1784\n",
      "Epoch 17, 100% \t Train loss: 0.1695 took: 1.82s  Val. loss: 0.1803\n",
      "Epoch 18, 100% \t Train loss: 0.1656 took: 1.82s  Val. loss: 0.1774\n",
      "Epoch 19, 100% \t Train loss: 0.1658 took: 1.82s  Val. loss: 0.1795\n",
      "Epoch 20, 100% \t Train loss: 0.1639 took: 1.83s  Val. loss: 0.1710\n",
      "Epoch 21, 100% \t Train loss: 0.1610 took: 1.84s  Val. loss: 0.1736\n",
      "Epoch 22, 100% \t Train loss: 0.1628 took: 1.82s  Val. loss: 0.1727\n",
      "Epoch 23, 100% \t Train loss: 0.1602 took: 1.80s  Val. loss: 0.1703\n",
      "Epoch 24, 100% \t Train loss: 0.1597 took: 1.79s  Val. loss: 0.1719\n",
      "Epoch 25, 100% \t Train loss: 0.1600 took: 1.83s  Val. loss: 0.1654\n",
      "Epoch 26, 100% \t Train loss: 0.1571 took: 1.82s  Val. loss: 0.1725\n",
      "Epoch 27, 100% \t Train loss: 0.1569 took: 1.82s  Val. loss: 0.1760\n",
      "Epoch 28, 100% \t Train loss: 0.1561 took: 1.04s  Val. loss: 0.1724\n",
      "Epoch 29, 100% \t Train loss: 0.1563 took: 1.04s  Val. loss: 0.1679\n",
      "Epoch 30, 100% \t Train loss: 0.1552 took: 1.04s  Val. loss: 0.1720\n",
      "Epoch 31, 100% \t Train loss: 0.1519 took: 1.06s  Val. loss: 0.1678\n",
      "Epoch 32, 100% \t Train loss: 0.1506 took: 1.08s  Val. loss: 0.1663\n",
      "Epoch 33, 100% \t Train loss: 0.1510 took: 1.09s  Val. loss: 0.1671\n",
      "Epoch 34, 100% \t Train loss: 0.1480 took: 1.09s  Val. loss: 0.1705\n",
      "Epoch 35, 100% \t Train loss: 0.1471 took: 1.09s  Val. loss: 0.1655\n",
      "Epoch 36, 100% \t Train loss: 0.1435 took: 1.10s  Val. loss: 0.1639\n",
      "Epoch 37, 100% \t Train loss: 0.1426 took: 1.08s  Val. loss: 0.1634\n",
      "Epoch 38, 100% \t Train loss: 0.1421 took: 1.08s  Val. loss: 0.1622\n",
      "Epoch 39, 100% \t Train loss: 0.1401 took: 1.07s  Val. loss: 0.1575\n",
      "Epoch 40, 100% \t Train loss: 0.1394 took: 1.07s  Val. loss: 0.1640\n",
      "Epoch 41, 100% \t Train loss: 0.1374 took: 1.07s  Val. loss: 0.1564\n",
      "Epoch 42, 100% \t Train loss: 0.1394 took: 1.08s  Val. loss: 0.1571\n",
      "Epoch 43, 100% \t Train loss: 0.1334 took: 1.08s  Val. loss: 0.1552\n",
      "Epoch 44, 100% \t Train loss: 0.1328 took: 1.07s  Val. loss: 0.1523\n",
      "Epoch 45, 100% \t Train loss: 0.1292 took: 1.07s  Val. loss: 0.1527\n",
      "Epoch 46, 100% \t Train loss: 0.1325 took: 1.07s  Val. loss: 0.1540\n",
      "Epoch 47, 100% \t Train loss: 0.1274 took: 1.08s  Val. loss: 0.1477\n",
      "Epoch 48, 100% \t Train loss: 0.1254 took: 1.08s  Val. loss: 0.1481\n",
      "Epoch 49, 100% \t Train loss: 0.1260 took: 1.09s  Val. loss: 0.1717\n",
      "Epoch 50, 100% \t Train loss: 0.1272 took: 1.09s  Val. loss: 0.1442\n",
      "Training finished, took 83.51s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2619 took: 1.04s  Val. loss: 0.2558\n",
      "Epoch 2, 100% \t Train loss: 0.2616 took: 1.04s  Val. loss: 0.2571\n",
      "Epoch 3, 100% \t Train loss: 0.2617 took: 1.03s  Val. loss: 0.2560\n",
      "Epoch 4, 100% \t Train loss: 0.2616 took: 1.03s  Val. loss: 0.2565\n",
      "Epoch 5, 100% \t Train loss: 0.2617 took: 1.03s  Val. loss: 0.2580\n",
      "Epoch 6, 100% \t Train loss: 0.2616 took: 1.03s  Val. loss: 0.2581\n",
      "Epoch 7, 100% \t Train loss: 0.2616 took: 1.03s  Val. loss: 0.2567\n",
      "Epoch 8, 100% \t Train loss: 0.2615 took: 1.04s  Val. loss: 0.2576\n",
      "Epoch 9, 100% \t Train loss: 0.2616 took: 1.03s  Val. loss: 0.2564\n",
      "Epoch 10, 100% \t Train loss: 0.2616 took: 1.03s  Val. loss: 0.2567\n",
      "Epoch 11, 100% \t Train loss: 0.2616 took: 1.05s  Val. loss: 0.2570\n",
      "Epoch 12, 100% \t Train loss: 0.2616 took: 1.10s  Val. loss: 0.2569\n",
      "Epoch 13, 100% \t Train loss: 0.2616 took: 1.04s  Val. loss: 0.2572\n",
      "Epoch 14, 100% \t Train loss: 0.2615 took: 1.82s  Val. loss: 0.2565\n",
      "Epoch 15, 100% \t Train loss: 0.2613 took: 1.81s  Val. loss: 0.2563\n",
      "Epoch 16, 100% \t Train loss: 0.2605 took: 1.80s  Val. loss: 0.2554\n",
      "Epoch 17, 100% \t Train loss: 0.2573 took: 1.18s  Val. loss: 0.2476\n",
      "Epoch 18, 100% \t Train loss: 0.2415 took: 1.80s  Val. loss: 0.2303\n",
      "Epoch 19, 100% \t Train loss: 0.2234 took: 1.80s  Val. loss: 0.2159\n",
      "Epoch 20, 100% \t Train loss: 0.2125 took: 1.81s  Val. loss: 0.2266\n",
      "Epoch 21, 100% \t Train loss: 0.1999 took: 1.83s  Val. loss: 0.1945\n",
      "Epoch 22, 100% \t Train loss: 0.1908 took: 1.81s  Val. loss: 0.1940\n",
      "Epoch 23, 100% \t Train loss: 0.1859 took: 1.81s  Val. loss: 0.1858\n",
      "Epoch 24, 100% \t Train loss: 0.1830 took: 1.81s  Val. loss: 0.1838\n",
      "Epoch 25, 100% \t Train loss: 0.1816 took: 1.83s  Val. loss: 0.1844\n",
      "Epoch 26, 100% \t Train loss: 0.1813 took: 1.81s  Val. loss: 0.1849\n",
      "Epoch 27, 100% \t Train loss: 0.1812 took: 1.82s  Val. loss: 0.1889\n",
      "Epoch 28, 100% \t Train loss: 0.1806 took: 1.82s  Val. loss: 0.1860\n",
      "Epoch 29, 100% \t Train loss: 0.1798 took: 1.83s  Val. loss: 0.1891\n",
      "Epoch 30, 100% \t Train loss: 0.1797 took: 1.82s  Val. loss: 0.1866\n",
      "Epoch 31, 100% \t Train loss: 0.1787 took: 1.83s  Val. loss: 0.1839\n",
      "Epoch 32, 100% \t Train loss: 0.1782 took: 1.84s  Val. loss: 0.1900\n",
      "Epoch 33, 100% \t Train loss: 0.1772 took: 1.86s  Val. loss: 0.1825\n",
      "Epoch 34, 100% \t Train loss: 0.1766 took: 1.87s  Val. loss: 0.1814\n",
      "Epoch 35, 100% \t Train loss: 0.1761 took: 1.88s  Val. loss: 0.1825\n",
      "Epoch 36, 100% \t Train loss: 0.1767 took: 1.86s  Val. loss: 0.1840\n",
      "Epoch 37, 100% \t Train loss: 0.1783 took: 1.86s  Val. loss: 0.1840\n",
      "Epoch 38, 100% \t Train loss: 0.1753 took: 1.89s  Val. loss: 0.1829\n",
      "Epoch 39, 100% \t Train loss: 0.1751 took: 1.86s  Val. loss: 0.1823\n",
      "Epoch 40, 100% \t Train loss: 0.1747 took: 1.86s  Val. loss: 0.1831\n",
      "Epoch 41, 100% \t Train loss: 0.1754 took: 1.85s  Val. loss: 0.1818\n",
      "Epoch 42, 100% \t Train loss: 0.1747 took: 1.86s  Val. loss: 0.1826\n",
      "Epoch 43, 100% \t Train loss: 0.1749 took: 1.85s  Val. loss: 0.1840\n",
      "Epoch 44, 100% \t Train loss: 0.1754 took: 1.87s  Val. loss: 0.1834\n",
      "Epoch 45, 100% \t Train loss: 0.1755 took: 1.87s  Val. loss: 0.1867\n",
      "Epoch 46, 100% \t Train loss: 0.1734 took: 1.89s  Val. loss: 0.1831\n",
      "Epoch 47, 100% \t Train loss: 0.1728 took: 1.10s  Val. loss: 0.1812\n",
      "Epoch 48, 100% \t Train loss: 0.1729 took: 1.10s  Val. loss: 0.1812\n",
      "Epoch 49, 100% \t Train loss: 0.1724 took: 1.12s  Val. loss: 0.1824\n",
      "Epoch 50, 100% \t Train loss: 0.1728 took: 1.12s  Val. loss: 0.1834\n",
      "Training finished, took 88.48s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.852849\n",
      "lambda: 0.0010 - V: 0.814850\n",
      "lambda: 0.0005 - V: 0.788542\n",
      "Average V: 0.818747\n",
      "Time elapsed: 268.87 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2578 took: 1.07s  Val. loss: 0.2583\n",
      "Epoch 2, 100% \t Train loss: 0.2571 took: 1.06s  Val. loss: 0.2534\n",
      "Epoch 3, 100% \t Train loss: 0.2568 took: 1.06s  Val. loss: 0.2541\n",
      "Epoch 4, 100% \t Train loss: 0.2566 took: 1.06s  Val. loss: 0.2546\n",
      "Epoch 5, 100% \t Train loss: 0.2562 took: 1.06s  Val. loss: 0.2515\n",
      "Epoch 6, 100% \t Train loss: 0.2211 took: 1.06s  Val. loss: 0.1795\n",
      "Epoch 7, 100% \t Train loss: 0.1757 took: 1.06s  Val. loss: 0.1644\n",
      "Epoch 8, 100% \t Train loss: 0.1692 took: 1.07s  Val. loss: 0.1610\n",
      "Epoch 9, 100% \t Train loss: 0.1659 took: 1.07s  Val. loss: 0.1565\n",
      "Epoch 10, 100% \t Train loss: 0.1616 took: 1.07s  Val. loss: 0.1553\n",
      "Epoch 11, 100% \t Train loss: 0.1571 took: 1.06s  Val. loss: 0.1469\n",
      "Epoch 12, 100% \t Train loss: 0.1519 took: 1.06s  Val. loss: 0.1450\n",
      "Epoch 13, 100% \t Train loss: 0.1477 took: 1.06s  Val. loss: 0.1393\n",
      "Epoch 14, 100% \t Train loss: 0.1438 took: 1.07s  Val. loss: 0.1347\n",
      "Epoch 15, 100% \t Train loss: 0.1391 took: 1.06s  Val. loss: 0.1311\n",
      "Epoch 16, 100% \t Train loss: 0.1346 took: 1.07s  Val. loss: 0.1320\n",
      "Epoch 17, 100% \t Train loss: 0.1301 took: 1.07s  Val. loss: 0.1252\n",
      "Epoch 18, 100% \t Train loss: 0.1215 took: 1.06s  Val. loss: 0.1201\n",
      "Epoch 19, 100% \t Train loss: 0.1145 took: 1.06s  Val. loss: 0.1138\n",
      "Epoch 20, 100% \t Train loss: 0.1101 took: 1.06s  Val. loss: 0.1101\n",
      "Epoch 21, 100% \t Train loss: 0.1044 took: 1.07s  Val. loss: 0.1066\n",
      "Epoch 22, 100% \t Train loss: 0.1009 took: 1.06s  Val. loss: 0.1078\n",
      "Epoch 23, 100% \t Train loss: 0.0974 took: 1.07s  Val. loss: 0.1018\n",
      "Epoch 24, 100% \t Train loss: 0.0954 took: 1.07s  Val. loss: 0.1023\n",
      "Epoch 25, 100% \t Train loss: 0.0931 took: 1.08s  Val. loss: 0.1012\n",
      "Epoch 26, 100% \t Train loss: 0.0927 took: 1.14s  Val. loss: 0.0975\n",
      "Epoch 27, 100% \t Train loss: 0.0901 took: 1.86s  Val. loss: 0.0995\n",
      "Epoch 28, 100% \t Train loss: 0.0891 took: 1.85s  Val. loss: 0.0949\n",
      "Epoch 29, 100% \t Train loss: 0.0867 took: 1.87s  Val. loss: 0.0996\n",
      "Epoch 30, 100% \t Train loss: 0.0868 took: 1.86s  Val. loss: 0.0986\n",
      "Epoch 31, 100% \t Train loss: 0.0858 took: 1.22s  Val. loss: 0.0940\n",
      "Epoch 32, 100% \t Train loss: 0.0851 took: 2.37s  Val. loss: 0.0946\n",
      "Epoch 33, 100% \t Train loss: 0.0842 took: 2.67s  Val. loss: 0.0959\n",
      "Epoch 34, 100% \t Train loss: 0.0840 took: 2.75s  Val. loss: 0.0930\n",
      "Epoch 35, 100% \t Train loss: 0.0831 took: 2.77s  Val. loss: 0.0928\n",
      "Epoch 36, 100% \t Train loss: 0.0827 took: 2.78s  Val. loss: 0.0943\n",
      "Epoch 37, 100% \t Train loss: 0.0817 took: 2.82s  Val. loss: 0.0965\n",
      "Epoch 38, 100% \t Train loss: 0.0815 took: 2.88s  Val. loss: 0.0945\n",
      "Epoch 39, 100% \t Train loss: 0.0829 took: 2.88s  Val. loss: 0.0925\n",
      "Epoch 40, 100% \t Train loss: 0.0818 took: 2.90s  Val. loss: 0.0888\n",
      "Epoch 41, 100% \t Train loss: 0.0813 took: 2.93s  Val. loss: 0.0926\n",
      "Epoch 42, 100% \t Train loss: 0.0808 took: 2.94s  Val. loss: 0.0904\n",
      "Epoch 43, 100% \t Train loss: 0.0802 took: 2.96s  Val. loss: 0.0927\n",
      "Epoch 44, 100% \t Train loss: 0.0807 took: 2.96s  Val. loss: 0.0923\n",
      "Epoch 45, 100% \t Train loss: 0.0800 took: 2.95s  Val. loss: 0.0911\n",
      "Epoch 46, 100% \t Train loss: 0.0789 took: 2.95s  Val. loss: 0.0933\n",
      "Epoch 47, 100% \t Train loss: 0.0794 took: 2.70s  Val. loss: 0.0895\n",
      "Epoch 48, 100% \t Train loss: 0.0791 took: 2.64s  Val. loss: 0.0900\n",
      "Epoch 49, 100% \t Train loss: 0.0789 took: 2.65s  Val. loss: 0.0910\n",
      "Epoch 50, 100% \t Train loss: 0.0783 took: 2.69s  Val. loss: 0.0912\n",
      "Training finished, took 101.72s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 1.83s  Val. loss: 0.2594\n",
      "Epoch 2, 100% \t Train loss: 0.2554 took: 1.81s  Val. loss: 0.2570\n",
      "Epoch 3, 100% \t Train loss: 0.2327 took: 1.85s  Val. loss: 0.2174\n",
      "Epoch 4, 100% \t Train loss: 0.1937 took: 1.82s  Val. loss: 0.1903\n",
      "Epoch 5, 100% \t Train loss: 0.1804 took: 1.08s  Val. loss: 0.1839\n",
      "Epoch 6, 100% \t Train loss: 0.1748 took: 1.60s  Val. loss: 0.1833\n",
      "Epoch 7, 100% \t Train loss: 0.1726 took: 1.83s  Val. loss: 0.1946\n",
      "Epoch 8, 100% \t Train loss: 0.1676 took: 1.80s  Val. loss: 0.1745\n",
      "Epoch 9, 100% \t Train loss: 0.1673 took: 1.83s  Val. loss: 0.1707\n",
      "Epoch 10, 100% \t Train loss: 0.1645 took: 1.81s  Val. loss: 0.1736\n",
      "Epoch 11, 100% \t Train loss: 0.1652 took: 1.84s  Val. loss: 0.1728\n",
      "Epoch 12, 100% \t Train loss: 0.1627 took: 1.82s  Val. loss: 0.1687\n",
      "Epoch 13, 100% \t Train loss: 0.1601 took: 1.84s  Val. loss: 0.1691\n",
      "Epoch 14, 100% \t Train loss: 0.1587 took: 1.83s  Val. loss: 0.1667\n",
      "Epoch 15, 100% \t Train loss: 0.1591 took: 1.84s  Val. loss: 0.1700\n",
      "Epoch 16, 100% \t Train loss: 0.1578 took: 1.82s  Val. loss: 0.1657\n",
      "Epoch 17, 100% \t Train loss: 0.1558 took: 1.85s  Val. loss: 0.1675\n",
      "Epoch 18, 100% \t Train loss: 0.1558 took: 1.84s  Val. loss: 0.1693\n",
      "Epoch 19, 100% \t Train loss: 0.1565 took: 1.82s  Val. loss: 0.1668\n",
      "Epoch 20, 100% \t Train loss: 0.1547 took: 1.83s  Val. loss: 0.1671\n",
      "Epoch 21, 100% \t Train loss: 0.1558 took: 1.84s  Val. loss: 0.1663\n",
      "Epoch 22, 100% \t Train loss: 0.1533 took: 1.85s  Val. loss: 0.1653\n",
      "Epoch 23, 100% \t Train loss: 0.1534 took: 1.08s  Val. loss: 0.1641\n",
      "Epoch 24, 100% \t Train loss: 0.1528 took: 1.06s  Val. loss: 0.1688\n",
      "Epoch 25, 100% \t Train loss: 0.1530 took: 1.06s  Val. loss: 0.1657\n",
      "Epoch 26, 100% \t Train loss: 0.1515 took: 1.07s  Val. loss: 0.1698\n",
      "Epoch 27, 100% \t Train loss: 0.1510 took: 1.07s  Val. loss: 0.1634\n",
      "Epoch 28, 100% \t Train loss: 0.1501 took: 1.09s  Val. loss: 0.1651\n",
      "Epoch 29, 100% \t Train loss: 0.1498 took: 1.12s  Val. loss: 0.1647\n",
      "Epoch 30, 100% \t Train loss: 0.1491 took: 1.14s  Val. loss: 0.1645\n",
      "Epoch 31, 100% \t Train loss: 0.1495 took: 1.19s  Val. loss: 0.1632\n",
      "Epoch 32, 100% \t Train loss: 0.1481 took: 1.23s  Val. loss: 0.1627\n",
      "Epoch 33, 100% \t Train loss: 0.1475 took: 1.24s  Val. loss: 0.1646\n",
      "Epoch 34, 100% \t Train loss: 0.1485 took: 1.29s  Val. loss: 0.1639\n",
      "Epoch 35, 100% \t Train loss: 0.1465 took: 1.32s  Val. loss: 0.1639\n",
      "Epoch 36, 100% \t Train loss: 0.1462 took: 2.03s  Val. loss: 0.1629\n",
      "Epoch 37, 100% \t Train loss: 0.1462 took: 2.04s  Val. loss: 0.1638\n",
      "Epoch 38, 100% \t Train loss: 0.1457 took: 2.04s  Val. loss: 0.1620\n",
      "Epoch 39, 100% \t Train loss: 0.1444 took: 2.06s  Val. loss: 0.1614\n",
      "Epoch 40, 100% \t Train loss: 0.1432 took: 2.07s  Val. loss: 0.1603\n",
      "Epoch 41, 100% \t Train loss: 0.1424 took: 2.09s  Val. loss: 0.1593\n",
      "Epoch 42, 100% \t Train loss: 0.1414 took: 2.06s  Val. loss: 0.1579\n",
      "Epoch 43, 100% \t Train loss: 0.1389 took: 2.06s  Val. loss: 0.1562\n",
      "Epoch 44, 100% \t Train loss: 0.1372 took: 2.07s  Val. loss: 0.1559\n",
      "Epoch 45, 100% \t Train loss: 0.1342 took: 2.10s  Val. loss: 0.1531\n",
      "Epoch 46, 100% \t Train loss: 0.1325 took: 2.11s  Val. loss: 0.1520\n",
      "Epoch 47, 100% \t Train loss: 0.1301 took: 2.11s  Val. loss: 0.1482\n",
      "Epoch 48, 100% \t Train loss: 0.1273 took: 2.13s  Val. loss: 0.1483\n",
      "Epoch 49, 100% \t Train loss: 0.1260 took: 2.17s  Val. loss: 0.1468\n",
      "Epoch 50, 100% \t Train loss: 0.1221 took: 2.19s  Val. loss: 0.1415\n",
      "Training finished, took 97.24s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2587 took: 1.81s  Val. loss: 0.2623\n",
      "Epoch 2, 100% \t Train loss: 0.2569 took: 1.82s  Val. loss: 0.2625\n",
      "Epoch 3, 100% \t Train loss: 0.2567 took: 1.82s  Val. loss: 0.2614\n",
      "Epoch 4, 100% \t Train loss: 0.2566 took: 1.82s  Val. loss: 0.2602\n",
      "Epoch 5, 100% \t Train loss: 0.2559 took: 1.82s  Val. loss: 0.2611\n",
      "Epoch 6, 100% \t Train loss: 0.2515 took: 1.82s  Val. loss: 0.2549\n",
      "Epoch 7, 100% \t Train loss: 0.2336 took: 1.83s  Val. loss: 0.2304\n",
      "Epoch 8, 100% \t Train loss: 0.2110 took: 1.07s  Val. loss: 0.2171\n",
      "Epoch 9, 100% \t Train loss: 0.1937 took: 1.07s  Val. loss: 0.2016\n",
      "Epoch 10, 100% \t Train loss: 0.1811 took: 1.07s  Val. loss: 0.1932\n",
      "Epoch 11, 100% \t Train loss: 0.1747 took: 1.08s  Val. loss: 0.1831\n",
      "Epoch 12, 100% \t Train loss: 0.1672 took: 1.07s  Val. loss: 0.1821\n",
      "Epoch 13, 100% \t Train loss: 0.1638 took: 1.06s  Val. loss: 0.1841\n",
      "Epoch 14, 100% \t Train loss: 0.1646 took: 1.06s  Val. loss: 0.1833\n",
      "Epoch 15, 100% \t Train loss: 0.1621 took: 1.07s  Val. loss: 0.1777\n",
      "Epoch 16, 100% \t Train loss: 0.1611 took: 1.40s  Val. loss: 0.1796\n",
      "Epoch 17, 100% \t Train loss: 0.1596 took: 1.84s  Val. loss: 0.1788\n",
      "Epoch 18, 100% \t Train loss: 0.1577 took: 1.83s  Val. loss: 0.1735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1568 took: 1.83s  Val. loss: 0.1756\n",
      "Epoch 20, 100% \t Train loss: 0.1566 took: 1.83s  Val. loss: 0.1734\n",
      "Epoch 21, 100% \t Train loss: 0.1555 took: 1.81s  Val. loss: 0.1733\n",
      "Epoch 22, 100% \t Train loss: 0.1555 took: 1.83s  Val. loss: 0.1747\n",
      "Epoch 23, 100% \t Train loss: 0.1534 took: 1.84s  Val. loss: 0.1730\n",
      "Epoch 24, 100% \t Train loss: 0.1541 took: 1.80s  Val. loss: 0.1730\n",
      "Epoch 25, 100% \t Train loss: 0.1520 took: 1.82s  Val. loss: 0.1814\n",
      "Epoch 26, 100% \t Train loss: 0.1523 took: 1.81s  Val. loss: 0.1728\n",
      "Epoch 27, 100% \t Train loss: 0.1513 took: 1.82s  Val. loss: 0.1718\n",
      "Epoch 28, 100% \t Train loss: 0.1517 took: 1.85s  Val. loss: 0.1755\n",
      "Epoch 29, 100% \t Train loss: 0.1523 took: 1.84s  Val. loss: 0.1709\n",
      "Epoch 30, 100% \t Train loss: 0.1521 took: 1.85s  Val. loss: 0.1721\n",
      "Epoch 31, 100% \t Train loss: 0.1510 took: 1.88s  Val. loss: 0.1772\n",
      "Epoch 32, 100% \t Train loss: 0.1519 took: 1.92s  Val. loss: 0.1736\n",
      "Epoch 33, 100% \t Train loss: 0.1493 took: 1.92s  Val. loss: 0.1711\n",
      "Epoch 34, 100% \t Train loss: 0.1485 took: 1.95s  Val. loss: 0.1701\n",
      "Epoch 35, 100% \t Train loss: 0.1493 took: 1.97s  Val. loss: 0.1714\n",
      "Epoch 36, 100% \t Train loss: 0.1483 took: 1.97s  Val. loss: 0.1693\n",
      "Epoch 37, 100% \t Train loss: 0.1487 took: 1.99s  Val. loss: 0.1704\n",
      "Epoch 38, 100% \t Train loss: 0.1476 took: 2.01s  Val. loss: 0.1697\n",
      "Epoch 39, 100% \t Train loss: 0.1480 took: 2.03s  Val. loss: 0.1712\n",
      "Epoch 40, 100% \t Train loss: 0.1466 took: 2.03s  Val. loss: 0.1691\n",
      "Epoch 41, 100% \t Train loss: 0.1472 took: 2.08s  Val. loss: 0.1714\n",
      "Epoch 42, 100% \t Train loss: 0.1459 took: 2.08s  Val. loss: 0.1693\n",
      "Epoch 43, 100% \t Train loss: 0.1458 took: 2.11s  Val. loss: 0.1676\n",
      "Epoch 44, 100% \t Train loss: 0.1463 took: 2.16s  Val. loss: 0.1694\n",
      "Epoch 45, 100% \t Train loss: 0.1459 took: 2.17s  Val. loss: 0.1700\n",
      "Epoch 46, 100% \t Train loss: 0.1454 took: 2.18s  Val. loss: 0.1706\n",
      "Epoch 47, 100% \t Train loss: 0.1457 took: 2.18s  Val. loss: 0.1722\n",
      "Epoch 48, 100% \t Train loss: 0.1448 took: 2.19s  Val. loss: 0.1680\n",
      "Epoch 49, 100% \t Train loss: 0.1447 took: 2.20s  Val. loss: 0.1694\n",
      "Epoch 50, 100% \t Train loss: 0.1446 took: 2.22s  Val. loss: 0.1708\n",
      "Training finished, took 101.42s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.875052\n",
      "lambda: 0.0010 - V: 0.830121\n",
      "lambda: 0.0005 - V: 0.813074\n",
      "Average V: 0.839416\n",
      "Time elapsed: 303.76 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2550 took: 1.74s  Val. loss: 0.2416\n",
      "Epoch 2, 100% \t Train loss: 0.1973 took: 1.73s  Val. loss: 0.1763\n",
      "Epoch 3, 100% \t Train loss: 0.1683 took: 1.74s  Val. loss: 0.1672\n",
      "Epoch 4, 100% \t Train loss: 0.1643 took: 1.73s  Val. loss: 0.1658\n",
      "Epoch 5, 100% \t Train loss: 0.1622 took: 1.75s  Val. loss: 0.1645\n",
      "Epoch 6, 100% \t Train loss: 0.1612 took: 1.73s  Val. loss: 0.1677\n",
      "Epoch 7, 100% \t Train loss: 0.1598 took: 1.72s  Val. loss: 0.1670\n",
      "Epoch 8, 100% \t Train loss: 0.1593 took: 1.72s  Val. loss: 0.1664\n",
      "Epoch 9, 100% \t Train loss: 0.1590 took: 1.72s  Val. loss: 0.1671\n",
      "Epoch 10, 100% \t Train loss: 0.1582 took: 1.72s  Val. loss: 0.1677\n",
      "Epoch 11, 100% \t Train loss: 0.1581 took: 1.74s  Val. loss: 0.1676\n",
      "Epoch 12, 100% \t Train loss: 0.1574 took: 1.73s  Val. loss: 0.1669\n",
      "Epoch 13, 100% \t Train loss: 0.1569 took: 1.73s  Val. loss: 0.1663\n",
      "Epoch 14, 100% \t Train loss: 0.1572 took: 1.73s  Val. loss: 0.1666\n",
      "Epoch 15, 100% \t Train loss: 0.1566 took: 1.73s  Val. loss: 0.1661\n",
      "Epoch 16, 100% \t Train loss: 0.1568 took: 1.75s  Val. loss: 0.1670\n",
      "Epoch 17, 100% \t Train loss: 0.1562 took: 1.72s  Val. loss: 0.1678\n",
      "Epoch 18, 100% \t Train loss: 0.1559 took: 1.73s  Val. loss: 0.1651\n",
      "Epoch 19, 100% \t Train loss: 0.1561 took: 1.71s  Val. loss: 0.1684\n",
      "Epoch 20, 100% \t Train loss: 0.1562 took: 1.71s  Val. loss: 0.1685\n",
      "Epoch 21, 100% \t Train loss: 0.1555 took: 1.72s  Val. loss: 0.1657\n",
      "Epoch 22, 100% \t Train loss: 0.1556 took: 1.72s  Val. loss: 0.1649\n",
      "Epoch 23, 100% \t Train loss: 0.1557 took: 1.72s  Val. loss: 0.1671\n",
      "Epoch 24, 100% \t Train loss: 0.1549 took: 1.73s  Val. loss: 0.1680\n",
      "Epoch 25, 100% \t Train loss: 0.1557 took: 1.72s  Val. loss: 0.1657\n",
      "Epoch 26, 100% \t Train loss: 0.1553 took: 1.72s  Val. loss: 0.1661\n",
      "Epoch 27, 100% \t Train loss: 0.1552 took: 1.73s  Val. loss: 0.1652\n",
      "Epoch 28, 100% \t Train loss: 0.1550 took: 1.75s  Val. loss: 0.1668\n",
      "Epoch 29, 100% \t Train loss: 0.1549 took: 1.74s  Val. loss: 0.1671\n",
      "Epoch 30, 100% \t Train loss: 0.1550 took: 1.75s  Val. loss: 0.1658\n",
      "Epoch 31, 100% \t Train loss: 0.1550 took: 1.77s  Val. loss: 0.1655\n",
      "Epoch 32, 100% \t Train loss: 0.1547 took: 1.86s  Val. loss: 0.1678\n",
      "Epoch 33, 100% \t Train loss: 0.1547 took: 1.97s  Val. loss: 0.1689\n",
      "Epoch 34, 100% \t Train loss: 0.1551 took: 1.98s  Val. loss: 0.1663\n",
      "Epoch 35, 100% \t Train loss: 0.1546 took: 1.95s  Val. loss: 0.1664\n",
      "Epoch 36, 100% \t Train loss: 0.1544 took: 1.99s  Val. loss: 0.1651\n",
      "Epoch 37, 100% \t Train loss: 0.1543 took: 1.29s  Val. loss: 0.1665\n",
      "Epoch 38, 100% \t Train loss: 0.1539 took: 1.29s  Val. loss: 0.1683\n",
      "Epoch 39, 100% \t Train loss: 0.1551 took: 1.29s  Val. loss: 0.1664\n",
      "Epoch 40, 100% \t Train loss: 0.1541 took: 1.29s  Val. loss: 0.1673\n",
      "Epoch 41, 100% \t Train loss: 0.1546 took: 1.31s  Val. loss: 0.1662\n",
      "Epoch 42, 100% \t Train loss: 0.1540 took: 1.29s  Val. loss: 0.1662\n",
      "Epoch 43, 100% \t Train loss: 0.1538 took: 1.32s  Val. loss: 0.1666\n",
      "Epoch 44, 100% \t Train loss: 0.1541 took: 2.05s  Val. loss: 0.1663\n",
      "Epoch 45, 100% \t Train loss: 0.1533 took: 2.06s  Val. loss: 0.1672\n",
      "Epoch 46, 100% \t Train loss: 0.1528 took: 2.11s  Val. loss: 0.1680\n",
      "Epoch 47, 100% \t Train loss: 0.1524 took: 2.09s  Val. loss: 0.1669\n",
      "Epoch 48, 100% \t Train loss: 0.1515 took: 2.10s  Val. loss: 0.1636\n",
      "Epoch 49, 100% \t Train loss: 0.1501 took: 2.10s  Val. loss: 0.1619\n",
      "Epoch 50, 100% \t Train loss: 0.1487 took: 2.10s  Val. loss: 0.1641\n",
      "Training finished, took 99.87s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 1.75s  Val. loss: 0.2560\n",
      "Epoch 2, 100% \t Train loss: 0.2561 took: 1.72s  Val. loss: 0.2546\n",
      "Epoch 3, 100% \t Train loss: 0.2560 took: 1.71s  Val. loss: 0.2550\n",
      "Epoch 4, 100% \t Train loss: 0.2558 took: 1.74s  Val. loss: 0.2545\n",
      "Epoch 5, 100% \t Train loss: 0.2544 took: 1.72s  Val. loss: 0.2518\n",
      "Epoch 6, 100% \t Train loss: 0.2441 took: 1.73s  Val. loss: 0.2336\n",
      "Epoch 7, 100% \t Train loss: 0.2226 took: 1.74s  Val. loss: 0.2180\n",
      "Epoch 8, 100% \t Train loss: 0.2082 took: 1.72s  Val. loss: 0.2041\n",
      "Epoch 9, 100% \t Train loss: 0.1925 took: 1.73s  Val. loss: 0.1854\n",
      "Epoch 10, 100% \t Train loss: 0.1772 took: 1.74s  Val. loss: 0.1714\n",
      "Epoch 11, 100% \t Train loss: 0.1709 took: 1.73s  Val. loss: 0.1684\n",
      "Epoch 12, 100% \t Train loss: 0.1667 took: 1.71s  Val. loss: 0.1674\n",
      "Epoch 13, 100% \t Train loss: 0.1654 took: 1.73s  Val. loss: 0.1626\n",
      "Epoch 14, 100% \t Train loss: 0.1634 took: 1.71s  Val. loss: 0.1622\n",
      "Epoch 15, 100% \t Train loss: 0.1629 took: 1.72s  Val. loss: 0.1624\n",
      "Epoch 16, 100% \t Train loss: 0.1610 took: 1.70s  Val. loss: 0.1566\n",
      "Epoch 17, 100% \t Train loss: 0.1620 took: 1.71s  Val. loss: 0.1582\n",
      "Epoch 18, 100% \t Train loss: 0.1595 took: 1.72s  Val. loss: 0.1596\n",
      "Epoch 19, 100% \t Train loss: 0.1596 took: 1.71s  Val. loss: 0.1576\n",
      "Epoch 20, 100% \t Train loss: 0.1579 took: 1.72s  Val. loss: 0.1546\n",
      "Epoch 21, 100% \t Train loss: 0.1581 took: 1.74s  Val. loss: 0.1579\n",
      "Epoch 22, 100% \t Train loss: 0.1583 took: 1.73s  Val. loss: 0.1603\n",
      "Epoch 23, 100% \t Train loss: 0.1571 took: 1.75s  Val. loss: 0.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1575 took: 1.74s  Val. loss: 0.1550\n",
      "Epoch 25, 100% \t Train loss: 0.1558 took: 1.73s  Val. loss: 0.1535\n",
      "Epoch 26, 100% \t Train loss: 0.1549 took: 1.75s  Val. loss: 0.1537\n",
      "Epoch 27, 100% \t Train loss: 0.1550 took: 1.72s  Val. loss: 0.1575\n",
      "Epoch 28, 100% \t Train loss: 0.1540 took: 1.73s  Val. loss: 0.1538\n",
      "Epoch 29, 100% \t Train loss: 0.1537 took: 1.73s  Val. loss: 0.1537\n",
      "Epoch 30, 100% \t Train loss: 0.1535 took: 1.64s  Val. loss: 0.1525\n",
      "Epoch 31, 100% \t Train loss: 0.1534 took: 1.01s  Val. loss: 0.1528\n",
      "Epoch 32, 100% \t Train loss: 0.1550 took: 1.03s  Val. loss: 0.1543\n",
      "Epoch 33, 100% \t Train loss: 0.1525 took: 1.79s  Val. loss: 0.1515\n",
      "Epoch 34, 100% \t Train loss: 0.1535 took: 1.79s  Val. loss: 0.1529\n",
      "Epoch 35, 100% \t Train loss: 0.1518 took: 1.78s  Val. loss: 0.1528\n",
      "Epoch 36, 100% \t Train loss: 0.1522 took: 1.79s  Val. loss: 0.1520\n",
      "Epoch 37, 100% \t Train loss: 0.1514 took: 1.77s  Val. loss: 0.1510\n",
      "Epoch 38, 100% \t Train loss: 0.1508 took: 1.78s  Val. loss: 0.1523\n",
      "Epoch 39, 100% \t Train loss: 0.1509 took: 1.80s  Val. loss: 0.1508\n",
      "Epoch 40, 100% \t Train loss: 0.1513 took: 1.78s  Val. loss: 0.1524\n",
      "Epoch 41, 100% \t Train loss: 0.1498 took: 1.76s  Val. loss: 0.1498\n",
      "Epoch 42, 100% \t Train loss: 0.1495 took: 1.79s  Val. loss: 0.1495\n",
      "Epoch 43, 100% \t Train loss: 0.1488 took: 1.78s  Val. loss: 0.1500\n",
      "Epoch 44, 100% \t Train loss: 0.1488 took: 1.80s  Val. loss: 0.1530\n",
      "Epoch 45, 100% \t Train loss: 0.1495 took: 1.79s  Val. loss: 0.1495\n",
      "Epoch 46, 100% \t Train loss: 0.1476 took: 1.79s  Val. loss: 0.1507\n",
      "Epoch 47, 100% \t Train loss: 0.1479 took: 1.78s  Val. loss: 0.1468\n",
      "Epoch 48, 100% \t Train loss: 0.1458 took: 1.80s  Val. loss: 0.1474\n",
      "Epoch 49, 100% \t Train loss: 0.1454 took: 1.79s  Val. loss: 0.1490\n",
      "Epoch 50, 100% \t Train loss: 0.1447 took: 1.79s  Val. loss: 0.1461\n",
      "Training finished, took 97.93s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2564 took: 1.76s  Val. loss: 0.2607\n",
      "Epoch 2, 100% \t Train loss: 0.2564 took: 1.73s  Val. loss: 0.2604\n",
      "Epoch 3, 100% \t Train loss: 0.2563 took: 1.74s  Val. loss: 0.2609\n",
      "Epoch 4, 100% \t Train loss: 0.2563 took: 1.76s  Val. loss: 0.2609\n",
      "Epoch 5, 100% \t Train loss: 0.2563 took: 1.73s  Val. loss: 0.2598\n",
      "Epoch 6, 100% \t Train loss: 0.2563 took: 1.72s  Val. loss: 0.2598\n",
      "Epoch 7, 100% \t Train loss: 0.2563 took: 1.73s  Val. loss: 0.2601\n",
      "Epoch 8, 100% \t Train loss: 0.2562 took: 1.73s  Val. loss: 0.2608\n",
      "Epoch 9, 100% \t Train loss: 0.2561 took: 1.72s  Val. loss: 0.2603\n",
      "Epoch 10, 100% \t Train loss: 0.2560 took: 1.72s  Val. loss: 0.2607\n",
      "Epoch 11, 100% \t Train loss: 0.2557 took: 1.72s  Val. loss: 0.2602\n",
      "Epoch 12, 100% \t Train loss: 0.2552 took: 1.75s  Val. loss: 0.2590\n",
      "Epoch 13, 100% \t Train loss: 0.2539 took: 1.73s  Val. loss: 0.2563\n",
      "Epoch 14, 100% \t Train loss: 0.2468 took: 1.76s  Val. loss: 0.2390\n",
      "Epoch 15, 100% \t Train loss: 0.2266 took: 1.74s  Val. loss: 0.2212\n",
      "Epoch 16, 100% \t Train loss: 0.2156 took: 1.73s  Val. loss: 0.2104\n",
      "Epoch 17, 100% \t Train loss: 0.2060 took: 1.74s  Val. loss: 0.2028\n",
      "Epoch 18, 100% \t Train loss: 0.1981 took: 1.74s  Val. loss: 0.1960\n",
      "Epoch 19, 100% \t Train loss: 0.1925 took: 1.73s  Val. loss: 0.1900\n",
      "Epoch 20, 100% \t Train loss: 0.1873 took: 1.72s  Val. loss: 0.1858\n",
      "Epoch 21, 100% \t Train loss: 0.1840 took: 1.72s  Val. loss: 0.1824\n",
      "Epoch 22, 100% \t Train loss: 0.1822 took: 1.73s  Val. loss: 0.1816\n",
      "Epoch 23, 100% \t Train loss: 0.1801 took: 1.68s  Val. loss: 0.1797\n",
      "Epoch 24, 100% \t Train loss: 0.1767 took: 1.71s  Val. loss: 0.1802\n",
      "Epoch 25, 100% \t Train loss: 0.1786 took: 1.73s  Val. loss: 0.1762\n",
      "Epoch 26, 100% \t Train loss: 0.1749 took: 1.74s  Val. loss: 0.1769\n",
      "Epoch 27, 100% \t Train loss: 0.1737 took: 1.72s  Val. loss: 0.1748\n",
      "Epoch 28, 100% \t Train loss: 0.1738 took: 1.74s  Val. loss: 0.1758\n",
      "Epoch 29, 100% \t Train loss: 0.1720 took: 1.74s  Val. loss: 0.1736\n",
      "Epoch 30, 100% \t Train loss: 0.1710 took: 1.75s  Val. loss: 0.1727\n",
      "Epoch 31, 100% \t Train loss: 0.1714 took: 1.78s  Val. loss: 0.1732\n",
      "Epoch 32, 100% \t Train loss: 0.1728 took: 1.77s  Val. loss: 0.1722\n",
      "Epoch 33, 100% \t Train loss: 0.1703 took: 1.78s  Val. loss: 0.1703\n",
      "Epoch 34, 100% \t Train loss: 0.1688 took: 1.80s  Val. loss: 0.1696\n",
      "Epoch 35, 100% \t Train loss: 0.1692 took: 1.78s  Val. loss: 0.1698\n",
      "Epoch 36, 100% \t Train loss: 0.1683 took: 1.74s  Val. loss: 0.1718\n",
      "Epoch 37, 100% \t Train loss: 0.1687 took: 1.73s  Val. loss: 0.1699\n",
      "Epoch 38, 100% \t Train loss: 0.1674 took: 1.76s  Val. loss: 0.1695\n",
      "Epoch 39, 100% \t Train loss: 0.1678 took: 1.74s  Val. loss: 0.1684\n",
      "Epoch 40, 100% \t Train loss: 0.1682 took: 1.76s  Val. loss: 0.1693\n",
      "Epoch 41, 100% \t Train loss: 0.1676 took: 1.73s  Val. loss: 0.1731\n",
      "Epoch 42, 100% \t Train loss: 0.1688 took: 1.73s  Val. loss: 0.1687\n",
      "Epoch 43, 100% \t Train loss: 0.1670 took: 1.72s  Val. loss: 0.1688\n",
      "Epoch 44, 100% \t Train loss: 0.1679 took: 1.73s  Val. loss: 0.1677\n",
      "Epoch 45, 100% \t Train loss: 0.1676 took: 1.74s  Val. loss: 0.1707\n",
      "Epoch 46, 100% \t Train loss: 0.1663 took: 1.75s  Val. loss: 0.1675\n",
      "Epoch 47, 100% \t Train loss: 0.1652 took: 1.75s  Val. loss: 0.1676\n",
      "Epoch 48, 100% \t Train loss: 0.1686 took: 1.74s  Val. loss: 0.1694\n",
      "Epoch 49, 100% \t Train loss: 0.1677 took: 1.76s  Val. loss: 0.1712\n",
      "Epoch 50, 100% \t Train loss: 0.1664 took: 1.76s  Val. loss: 0.1662\n",
      "Training finished, took 99.57s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.831809\n",
      "lambda: 0.0010 - V: 0.830748\n",
      "lambda: 0.0005 - V: 0.800125\n",
      "Average V: 0.820894\n",
      "Time elapsed: 300.77 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2629 took: 1.82s  Val. loss: 0.2669\n",
      "Epoch 2, 100% \t Train loss: 0.2618 took: 1.81s  Val. loss: 0.2662\n",
      "Epoch 3, 100% \t Train loss: 0.2619 took: 1.82s  Val. loss: 0.2673\n",
      "Epoch 4, 100% \t Train loss: 0.2617 took: 1.82s  Val. loss: 0.2656\n",
      "Epoch 5, 100% \t Train loss: 0.2618 took: 1.82s  Val. loss: 0.2690\n",
      "Epoch 6, 100% \t Train loss: 0.2614 took: 1.81s  Val. loss: 0.2661\n",
      "Epoch 7, 100% \t Train loss: 0.2615 took: 1.82s  Val. loss: 0.2682\n",
      "Epoch 8, 100% \t Train loss: 0.2609 took: 1.80s  Val. loss: 0.2671\n",
      "Epoch 9, 100% \t Train loss: 0.2432 took: 1.81s  Val. loss: 0.2170\n",
      "Epoch 10, 100% \t Train loss: 0.2105 took: 1.81s  Val. loss: 0.1989\n",
      "Epoch 11, 100% \t Train loss: 0.2063 took: 1.82s  Val. loss: 0.1919\n",
      "Epoch 12, 100% \t Train loss: 0.2020 took: 1.81s  Val. loss: 0.1913\n",
      "Epoch 13, 100% \t Train loss: 0.2013 took: 1.83s  Val. loss: 0.1913\n",
      "Epoch 14, 100% \t Train loss: 0.1999 took: 1.84s  Val. loss: 0.1871\n",
      "Epoch 15, 100% \t Train loss: 0.1984 took: 1.81s  Val. loss: 0.1902\n",
      "Epoch 16, 100% \t Train loss: 0.1988 took: 1.84s  Val. loss: 0.1899\n",
      "Epoch 17, 100% \t Train loss: 0.1980 took: 1.85s  Val. loss: 0.1883\n",
      "Epoch 18, 100% \t Train loss: 0.1969 took: 1.82s  Val. loss: 0.1889\n",
      "Epoch 19, 100% \t Train loss: 0.1965 took: 1.83s  Val. loss: 0.1888\n",
      "Epoch 20, 100% \t Train loss: 0.1955 took: 1.81s  Val. loss: 0.1841\n",
      "Epoch 21, 100% \t Train loss: 0.1941 took: 1.86s  Val. loss: 0.1942\n",
      "Epoch 22, 100% \t Train loss: 0.1942 took: 1.80s  Val. loss: 0.1836\n",
      "Epoch 23, 100% \t Train loss: 0.1917 took: 1.81s  Val. loss: 0.1848\n",
      "Epoch 24, 100% \t Train loss: 0.1907 took: 1.81s  Val. loss: 0.1844\n",
      "Epoch 25, 100% \t Train loss: 0.1915 took: 1.81s  Val. loss: 0.1861\n",
      "Epoch 26, 100% \t Train loss: 0.1904 took: 1.80s  Val. loss: 0.1803\n",
      "Epoch 27, 100% \t Train loss: 0.1876 took: 1.81s  Val. loss: 0.1812\n",
      "Epoch 28, 100% \t Train loss: 0.1867 took: 1.81s  Val. loss: 0.1796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.1816 took: 1.81s  Val. loss: 0.1763\n",
      "Epoch 30, 100% \t Train loss: 0.1791 took: 1.82s  Val. loss: 0.1742\n",
      "Epoch 31, 100% \t Train loss: 0.1771 took: 1.83s  Val. loss: 0.1739\n",
      "Epoch 32, 100% \t Train loss: 0.1746 took: 1.87s  Val. loss: 0.1675\n",
      "Epoch 33, 100% \t Train loss: 0.1733 took: 1.89s  Val. loss: 0.1660\n",
      "Epoch 34, 100% \t Train loss: 0.1684 took: 1.93s  Val. loss: 0.1613\n",
      "Epoch 35, 100% \t Train loss: 0.1685 took: 1.94s  Val. loss: 0.1682\n",
      "Epoch 36, 100% \t Train loss: 0.1663 took: 1.94s  Val. loss: 0.1609\n",
      "Epoch 37, 100% \t Train loss: 0.1629 took: 1.94s  Val. loss: 0.1603\n",
      "Epoch 38, 100% \t Train loss: 0.1631 took: 1.93s  Val. loss: 0.1548\n",
      "Epoch 39, 100% \t Train loss: 0.1599 took: 1.95s  Val. loss: 0.1548\n",
      "Epoch 40, 100% \t Train loss: 0.1589 took: 1.96s  Val. loss: 0.1573\n",
      "Epoch 41, 100% \t Train loss: 0.1574 took: 1.97s  Val. loss: 0.1566\n",
      "Epoch 42, 100% \t Train loss: 0.1563 took: 1.98s  Val. loss: 0.1470\n",
      "Epoch 43, 100% \t Train loss: 0.1546 took: 1.20s  Val. loss: 0.1490\n",
      "Epoch 44, 100% \t Train loss: 0.1522 took: 1.20s  Val. loss: 0.1516\n",
      "Epoch 45, 100% \t Train loss: 0.1516 took: 1.20s  Val. loss: 0.1441\n",
      "Epoch 46, 100% \t Train loss: 0.1514 took: 1.21s  Val. loss: 0.1466\n",
      "Epoch 47, 100% \t Train loss: 0.1486 took: 1.21s  Val. loss: 0.1469\n",
      "Epoch 48, 100% \t Train loss: 0.1489 took: 1.22s  Val. loss: 0.1519\n",
      "Epoch 49, 100% \t Train loss: 0.1485 took: 1.22s  Val. loss: 0.1401\n",
      "Epoch 50, 100% \t Train loss: 0.1455 took: 1.23s  Val. loss: 0.1440\n",
      "Training finished, took 99.28s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 1.03s  Val. loss: 0.2620\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 1.03s  Val. loss: 0.2611\n",
      "Epoch 3, 100% \t Train loss: 0.2581 took: 1.03s  Val. loss: 0.2615\n",
      "Epoch 4, 100% \t Train loss: 0.2576 took: 1.02s  Val. loss: 0.2619\n",
      "Epoch 5, 100% \t Train loss: 0.2553 took: 1.03s  Val. loss: 0.2553\n",
      "Epoch 6, 100% \t Train loss: 0.2421 took: 1.03s  Val. loss: 0.2386\n",
      "Epoch 7, 100% \t Train loss: 0.2193 took: 1.71s  Val. loss: 0.2157\n",
      "Epoch 8, 100% \t Train loss: 0.2057 took: 1.82s  Val. loss: 0.2083\n",
      "Epoch 9, 100% \t Train loss: 0.2025 took: 1.83s  Val. loss: 0.2034\n",
      "Epoch 10, 100% \t Train loss: 0.1996 took: 1.80s  Val. loss: 0.2024\n",
      "Epoch 11, 100% \t Train loss: 0.1985 took: 1.81s  Val. loss: 0.2001\n",
      "Epoch 12, 100% \t Train loss: 0.1979 took: 1.80s  Val. loss: 0.2022\n",
      "Epoch 13, 100% \t Train loss: 0.1981 took: 1.79s  Val. loss: 0.2005\n",
      "Epoch 14, 100% \t Train loss: 0.1974 took: 1.79s  Val. loss: 0.2023\n",
      "Epoch 15, 100% \t Train loss: 0.1965 took: 1.81s  Val. loss: 0.2009\n",
      "Epoch 16, 100% \t Train loss: 0.1966 took: 1.82s  Val. loss: 0.1993\n",
      "Epoch 17, 100% \t Train loss: 0.1968 took: 1.04s  Val. loss: 0.1997\n",
      "Epoch 18, 100% \t Train loss: 0.1947 took: 1.03s  Val. loss: 0.1986\n",
      "Epoch 19, 100% \t Train loss: 0.1940 took: 1.03s  Val. loss: 0.1983\n",
      "Epoch 20, 100% \t Train loss: 0.1956 took: 1.04s  Val. loss: 0.2010\n",
      "Epoch 21, 100% \t Train loss: 0.1951 took: 1.04s  Val. loss: 0.2002\n",
      "Epoch 22, 100% \t Train loss: 0.1936 took: 1.03s  Val. loss: 0.1990\n",
      "Epoch 23, 100% \t Train loss: 0.1940 took: 1.04s  Val. loss: 0.1975\n",
      "Epoch 24, 100% \t Train loss: 0.1924 took: 1.03s  Val. loss: 0.1979\n",
      "Epoch 25, 100% \t Train loss: 0.1926 took: 1.03s  Val. loss: 0.1973\n",
      "Epoch 26, 100% \t Train loss: 0.1926 took: 1.03s  Val. loss: 0.1989\n",
      "Epoch 27, 100% \t Train loss: 0.1919 took: 1.02s  Val. loss: 0.1962\n",
      "Epoch 28, 100% \t Train loss: 0.1921 took: 1.03s  Val. loss: 0.1987\n",
      "Epoch 29, 100% \t Train loss: 0.1915 took: 1.04s  Val. loss: 0.1986\n",
      "Epoch 30, 100% \t Train loss: 0.1907 took: 1.04s  Val. loss: 0.1966\n",
      "Epoch 31, 100% \t Train loss: 0.1908 took: 1.05s  Val. loss: 0.1966\n",
      "Epoch 32, 100% \t Train loss: 0.1912 took: 1.05s  Val. loss: 0.1992\n",
      "Epoch 33, 100% \t Train loss: 0.1911 took: 1.05s  Val. loss: 0.1985\n",
      "Epoch 34, 100% \t Train loss: 0.1904 took: 1.04s  Val. loss: 0.1983\n",
      "Epoch 35, 100% \t Train loss: 0.1901 took: 1.04s  Val. loss: 0.1979\n",
      "Epoch 36, 100% \t Train loss: 0.1892 took: 1.04s  Val. loss: 0.1973\n",
      "Epoch 37, 100% \t Train loss: 0.1890 took: 1.05s  Val. loss: 0.1942\n",
      "Epoch 38, 100% \t Train loss: 0.1880 took: 1.05s  Val. loss: 0.1949\n",
      "Epoch 39, 100% \t Train loss: 0.1880 took: 1.05s  Val. loss: 0.1956\n",
      "Epoch 40, 100% \t Train loss: 0.1867 took: 1.05s  Val. loss: 0.1947\n",
      "Epoch 41, 100% \t Train loss: 0.1869 took: 1.04s  Val. loss: 0.1957\n",
      "Epoch 42, 100% \t Train loss: 0.1855 took: 1.04s  Val. loss: 0.1941\n",
      "Epoch 43, 100% \t Train loss: 0.1860 took: 1.05s  Val. loss: 0.1931\n",
      "Epoch 44, 100% \t Train loss: 0.1854 took: 1.06s  Val. loss: 0.1936\n",
      "Epoch 45, 100% \t Train loss: 0.1843 took: 1.08s  Val. loss: 0.1942\n",
      "Epoch 46, 100% \t Train loss: 0.1846 took: 1.13s  Val. loss: 0.1925\n",
      "Epoch 47, 100% \t Train loss: 0.1827 took: 1.06s  Val. loss: 0.1914\n",
      "Epoch 48, 100% \t Train loss: 0.1822 took: 1.07s  Val. loss: 0.1897\n",
      "Epoch 49, 100% \t Train loss: 0.1805 took: 1.07s  Val. loss: 0.1895\n",
      "Epoch 50, 100% \t Train loss: 0.1805 took: 1.08s  Val. loss: 0.1908\n",
      "Training finished, took 67.41s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2593 took: 1.04s  Val. loss: 0.2590\n",
      "Epoch 2, 100% \t Train loss: 0.2588 took: 1.04s  Val. loss: 0.2591\n",
      "Epoch 3, 100% \t Train loss: 0.2586 took: 1.03s  Val. loss: 0.2589\n",
      "Epoch 4, 100% \t Train loss: 0.2586 took: 1.04s  Val. loss: 0.2590\n",
      "Epoch 5, 100% \t Train loss: 0.2584 took: 1.04s  Val. loss: 0.2586\n",
      "Epoch 6, 100% \t Train loss: 0.2581 took: 1.04s  Val. loss: 0.2590\n",
      "Epoch 7, 100% \t Train loss: 0.2574 took: 1.03s  Val. loss: 0.2565\n",
      "Epoch 8, 100% \t Train loss: 0.2554 took: 1.03s  Val. loss: 0.2533\n",
      "Epoch 9, 100% \t Train loss: 0.2501 took: 1.04s  Val. loss: 0.2447\n",
      "Epoch 10, 100% \t Train loss: 0.2374 took: 1.04s  Val. loss: 0.2303\n",
      "Epoch 11, 100% \t Train loss: 0.2236 took: 1.03s  Val. loss: 0.2181\n",
      "Epoch 12, 100% \t Train loss: 0.2099 took: 1.04s  Val. loss: 0.2089\n",
      "Epoch 13, 100% \t Train loss: 0.2053 took: 1.04s  Val. loss: 0.2090\n",
      "Epoch 14, 100% \t Train loss: 0.2027 took: 1.04s  Val. loss: 0.2041\n",
      "Epoch 15, 100% \t Train loss: 0.2000 took: 1.04s  Val. loss: 0.2036\n",
      "Epoch 16, 100% \t Train loss: 0.1987 took: 1.04s  Val. loss: 0.2023\n",
      "Epoch 17, 100% \t Train loss: 0.1972 took: 1.04s  Val. loss: 0.1996\n",
      "Epoch 18, 100% \t Train loss: 0.1963 took: 1.04s  Val. loss: 0.2016\n",
      "Epoch 19, 100% \t Train loss: 0.1958 took: 1.04s  Val. loss: 0.1993\n",
      "Epoch 20, 100% \t Train loss: 0.1954 took: 1.04s  Val. loss: 0.2000\n",
      "Epoch 21, 100% \t Train loss: 0.1943 took: 1.04s  Val. loss: 0.2004\n",
      "Epoch 22, 100% \t Train loss: 0.1938 took: 1.03s  Val. loss: 0.2002\n",
      "Epoch 23, 100% \t Train loss: 0.1930 took: 1.04s  Val. loss: 0.1986\n",
      "Epoch 24, 100% \t Train loss: 0.1932 took: 1.05s  Val. loss: 0.1961\n",
      "Epoch 25, 100% \t Train loss: 0.1931 took: 1.05s  Val. loss: 0.1977\n",
      "Epoch 26, 100% \t Train loss: 0.1917 took: 1.04s  Val. loss: 0.1976\n",
      "Epoch 27, 100% \t Train loss: 0.1919 took: 1.04s  Val. loss: 0.1977\n",
      "Epoch 28, 100% \t Train loss: 0.1904 took: 1.03s  Val. loss: 0.1970\n",
      "Epoch 29, 100% \t Train loss: 0.1902 took: 1.03s  Val. loss: 0.1986\n",
      "Epoch 30, 100% \t Train loss: 0.1905 took: 1.03s  Val. loss: 0.2016\n",
      "Epoch 31, 100% \t Train loss: 0.1905 took: 1.04s  Val. loss: 0.1974\n",
      "Epoch 32, 100% \t Train loss: 0.1893 took: 1.04s  Val. loss: 0.1961\n",
      "Epoch 33, 100% \t Train loss: 0.1906 took: 1.03s  Val. loss: 0.1980\n",
      "Epoch 34, 100% \t Train loss: 0.1897 took: 1.03s  Val. loss: 0.1963\n",
      "Epoch 35, 100% \t Train loss: 0.1889 took: 1.04s  Val. loss: 0.1949\n",
      "Epoch 36, 100% \t Train loss: 0.1885 took: 1.04s  Val. loss: 0.1968\n",
      "Epoch 37, 100% \t Train loss: 0.1894 took: 1.04s  Val. loss: 0.1983\n",
      "Epoch 38, 100% \t Train loss: 0.1884 took: 1.04s  Val. loss: 0.1946\n",
      "Epoch 39, 100% \t Train loss: 0.1882 took: 1.04s  Val. loss: 0.1963\n",
      "Epoch 40, 100% \t Train loss: 0.1876 took: 1.61s  Val. loss: 0.1969\n",
      "Epoch 41, 100% \t Train loss: 0.1885 took: 1.83s  Val. loss: 0.1961\n",
      "Epoch 42, 100% \t Train loss: 0.1876 took: 1.83s  Val. loss: 0.1959\n",
      "Epoch 43, 100% \t Train loss: 0.1873 took: 1.84s  Val. loss: 0.1956\n",
      "Epoch 44, 100% \t Train loss: 0.1865 took: 1.82s  Val. loss: 0.1965\n",
      "Epoch 45, 100% \t Train loss: 0.1873 took: 1.83s  Val. loss: 0.1947\n",
      "Epoch 46, 100% \t Train loss: 0.1864 took: 1.82s  Val. loss: 0.1964\n",
      "Epoch 47, 100% \t Train loss: 0.1867 took: 1.84s  Val. loss: 0.1964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1861 took: 1.82s  Val. loss: 0.1950\n",
      "Epoch 49, 100% \t Train loss: 0.1859 took: 1.83s  Val. loss: 0.1987\n",
      "Epoch 50, 100% \t Train loss: 0.1859 took: 1.81s  Val. loss: 0.1951\n",
      "Training finished, took 68.16s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.812570\n",
      "lambda: 0.0010 - V: 0.795089\n",
      "lambda: 0.0005 - V: 0.790073\n",
      "Average V: 0.799244\n",
      "Time elapsed: 238.43 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2609 took: 1.84s  Val. loss: 0.2569\n",
      "Epoch 2, 100% \t Train loss: 0.2576 took: 1.82s  Val. loss: 0.2462\n",
      "Epoch 3, 100% \t Train loss: 0.1993 took: 1.82s  Val. loss: 0.1825\n",
      "Epoch 4, 100% \t Train loss: 0.1725 took: 1.82s  Val. loss: 0.1807\n",
      "Epoch 5, 100% \t Train loss: 0.1679 took: 1.83s  Val. loss: 0.1761\n",
      "Epoch 6, 100% \t Train loss: 0.1638 took: 1.82s  Val. loss: 0.1745\n",
      "Epoch 7, 100% \t Train loss: 0.1624 took: 1.82s  Val. loss: 0.1715\n",
      "Epoch 8, 100% \t Train loss: 0.1591 took: 1.84s  Val. loss: 0.1740\n",
      "Epoch 9, 100% \t Train loss: 0.1574 took: 1.85s  Val. loss: 0.1784\n",
      "Epoch 10, 100% \t Train loss: 0.1574 took: 1.81s  Val. loss: 0.1732\n",
      "Epoch 11, 100% \t Train loss: 0.1561 took: 1.82s  Val. loss: 0.1695\n",
      "Epoch 12, 100% \t Train loss: 0.1559 took: 1.81s  Val. loss: 0.1690\n",
      "Epoch 13, 100% \t Train loss: 0.1531 took: 1.81s  Val. loss: 0.1700\n",
      "Epoch 14, 100% \t Train loss: 0.1527 took: 1.81s  Val. loss: 0.1700\n",
      "Epoch 15, 100% \t Train loss: 0.1516 took: 1.81s  Val. loss: 0.1708\n",
      "Epoch 16, 100% \t Train loss: 0.1523 took: 1.81s  Val. loss: 0.1701\n",
      "Epoch 17, 100% \t Train loss: 0.1508 took: 1.82s  Val. loss: 0.1668\n",
      "Epoch 18, 100% \t Train loss: 0.1501 took: 1.81s  Val. loss: 0.1674\n",
      "Epoch 19, 100% \t Train loss: 0.1508 took: 1.79s  Val. loss: 0.1684\n",
      "Epoch 20, 100% \t Train loss: 0.1502 took: 1.80s  Val. loss: 0.1695\n",
      "Epoch 21, 100% \t Train loss: 0.1499 took: 1.82s  Val. loss: 0.1706\n",
      "Epoch 22, 100% \t Train loss: 0.1505 took: 1.80s  Val. loss: 0.1695\n",
      "Epoch 23, 100% \t Train loss: 0.1490 took: 1.80s  Val. loss: 0.1708\n",
      "Epoch 24, 100% \t Train loss: 0.1490 took: 1.80s  Val. loss: 0.1695\n",
      "Epoch 25, 100% \t Train loss: 0.1485 took: 1.81s  Val. loss: 0.1733\n",
      "Epoch 26, 100% \t Train loss: 0.1489 took: 1.82s  Val. loss: 0.1712\n",
      "Epoch 27, 100% \t Train loss: 0.1485 took: 1.82s  Val. loss: 0.1678\n",
      "Epoch 28, 100% \t Train loss: 0.1487 took: 1.83s  Val. loss: 0.1706\n",
      "Epoch 29, 100% \t Train loss: 0.1473 took: 1.82s  Val. loss: 0.1694\n",
      "Epoch 30, 100% \t Train loss: 0.1468 took: 1.84s  Val. loss: 0.1701\n",
      "Epoch 31, 100% \t Train loss: 0.1469 took: 1.83s  Val. loss: 0.1703\n",
      "Epoch 32, 100% \t Train loss: 0.1476 took: 1.88s  Val. loss: 0.1737\n",
      "Epoch 33, 100% \t Train loss: 0.1466 took: 2.04s  Val. loss: 0.1699\n",
      "Epoch 34, 100% \t Train loss: 0.1465 took: 2.08s  Val. loss: 0.1714\n",
      "Epoch 35, 100% \t Train loss: 0.1466 took: 2.08s  Val. loss: 0.1751\n",
      "Epoch 36, 100% \t Train loss: 0.1457 took: 2.10s  Val. loss: 0.1701\n",
      "Epoch 37, 100% \t Train loss: 0.1458 took: 2.10s  Val. loss: 0.1718\n",
      "Epoch 38, 100% \t Train loss: 0.1460 took: 2.11s  Val. loss: 0.1712\n",
      "Epoch 39, 100% \t Train loss: 0.1455 took: 2.10s  Val. loss: 0.1723\n",
      "Epoch 40, 100% \t Train loss: 0.1455 took: 2.10s  Val. loss: 0.1764\n",
      "Epoch 41, 100% \t Train loss: 0.1443 took: 2.10s  Val. loss: 0.1696\n",
      "Epoch 42, 100% \t Train loss: 0.1428 took: 2.11s  Val. loss: 0.1698\n",
      "Epoch 43, 100% \t Train loss: 0.1416 took: 2.09s  Val. loss: 0.1720\n",
      "Epoch 44, 100% \t Train loss: 0.1391 took: 2.10s  Val. loss: 0.1647\n",
      "Epoch 45, 100% \t Train loss: 0.1354 took: 2.12s  Val. loss: 0.1625\n",
      "Epoch 46, 100% \t Train loss: 0.1314 took: 2.14s  Val. loss: 0.1557\n",
      "Epoch 47, 100% \t Train loss: 0.1251 took: 2.11s  Val. loss: 0.1580\n",
      "Epoch 48, 100% \t Train loss: 0.1229 took: 2.12s  Val. loss: 0.1457\n",
      "Epoch 49, 100% \t Train loss: 0.1182 took: 2.11s  Val. loss: 0.1506\n",
      "Epoch 50, 100% \t Train loss: 0.1148 took: 2.09s  Val. loss: 0.1419\n",
      "Training finished, took 109.38s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 1.83s  Val. loss: 0.2603\n",
      "Epoch 2, 100% \t Train loss: 0.2585 took: 1.82s  Val. loss: 0.2580\n",
      "Epoch 3, 100% \t Train loss: 0.2585 took: 1.83s  Val. loss: 0.2588\n",
      "Epoch 4, 100% \t Train loss: 0.2584 took: 1.81s  Val. loss: 0.2589\n",
      "Epoch 5, 100% \t Train loss: 0.2584 took: 1.81s  Val. loss: 0.2600\n",
      "Epoch 6, 100% \t Train loss: 0.2585 took: 1.82s  Val. loss: 0.2593\n",
      "Epoch 7, 100% \t Train loss: 0.2585 took: 1.82s  Val. loss: 0.2568\n",
      "Epoch 8, 100% \t Train loss: 0.2583 took: 1.82s  Val. loss: 0.2578\n",
      "Epoch 9, 100% \t Train loss: 0.2577 took: 1.82s  Val. loss: 0.2582\n",
      "Epoch 10, 100% \t Train loss: 0.2533 took: 1.82s  Val. loss: 0.2437\n",
      "Epoch 11, 100% \t Train loss: 0.2280 took: 1.82s  Val. loss: 0.2152\n",
      "Epoch 12, 100% \t Train loss: 0.2059 took: 1.82s  Val. loss: 0.1937\n",
      "Epoch 13, 100% \t Train loss: 0.1859 took: 1.82s  Val. loss: 0.1822\n",
      "Epoch 14, 100% \t Train loss: 0.1785 took: 1.86s  Val. loss: 0.1711\n",
      "Epoch 15, 100% \t Train loss: 0.1731 took: 1.84s  Val. loss: 0.1700\n",
      "Epoch 16, 100% \t Train loss: 0.1714 took: 1.82s  Val. loss: 0.1688\n",
      "Epoch 17, 100% \t Train loss: 0.1683 took: 1.81s  Val. loss: 0.1643\n",
      "Epoch 18, 100% \t Train loss: 0.1682 took: 1.82s  Val. loss: 0.1670\n",
      "Epoch 19, 100% \t Train loss: 0.1672 took: 1.81s  Val. loss: 0.1651\n",
      "Epoch 20, 100% \t Train loss: 0.1648 took: 1.82s  Val. loss: 0.1692\n",
      "Epoch 21, 100% \t Train loss: 0.1655 took: 1.82s  Val. loss: 0.1644\n",
      "Epoch 22, 100% \t Train loss: 0.1645 took: 1.84s  Val. loss: 0.1612\n",
      "Epoch 23, 100% \t Train loss: 0.1637 took: 1.82s  Val. loss: 0.1590\n",
      "Epoch 24, 100% \t Train loss: 0.1620 took: 1.82s  Val. loss: 0.1614\n",
      "Epoch 25, 100% \t Train loss: 0.1598 took: 1.83s  Val. loss: 0.1583\n",
      "Epoch 26, 100% \t Train loss: 0.1598 took: 1.82s  Val. loss: 0.1619\n",
      "Epoch 27, 100% \t Train loss: 0.1589 took: 1.83s  Val. loss: 0.1560\n",
      "Epoch 28, 100% \t Train loss: 0.1580 took: 1.82s  Val. loss: 0.1550\n",
      "Epoch 29, 100% \t Train loss: 0.1583 took: 1.83s  Val. loss: 0.1583\n",
      "Epoch 30, 100% \t Train loss: 0.1569 took: 1.84s  Val. loss: 0.1562\n",
      "Epoch 31, 100% \t Train loss: 0.1572 took: 1.82s  Val. loss: 0.1525\n",
      "Epoch 32, 100% \t Train loss: 0.1570 took: 1.82s  Val. loss: 0.1555\n",
      "Epoch 33, 100% \t Train loss: 0.1547 took: 1.83s  Val. loss: 0.1561\n",
      "Epoch 34, 100% \t Train loss: 0.1567 took: 1.80s  Val. loss: 0.1546\n",
      "Epoch 35, 100% \t Train loss: 0.1542 took: 1.05s  Val. loss: 0.1549\n",
      "Epoch 36, 100% \t Train loss: 0.1555 took: 1.05s  Val. loss: 0.1541\n",
      "Epoch 37, 100% \t Train loss: 0.1530 took: 1.06s  Val. loss: 0.1542\n",
      "Epoch 38, 100% \t Train loss: 0.1555 took: 1.06s  Val. loss: 0.1503\n",
      "Epoch 39, 100% \t Train loss: 0.1534 took: 1.06s  Val. loss: 0.1516\n",
      "Epoch 40, 100% \t Train loss: 0.1541 took: 1.05s  Val. loss: 0.1567\n",
      "Epoch 41, 100% \t Train loss: 0.1528 took: 1.05s  Val. loss: 0.1525\n",
      "Epoch 42, 100% \t Train loss: 0.1514 took: 1.05s  Val. loss: 0.1550\n",
      "Epoch 43, 100% \t Train loss: 0.1534 took: 1.05s  Val. loss: 0.1544\n",
      "Epoch 44, 100% \t Train loss: 0.1535 took: 1.06s  Val. loss: 0.1527\n",
      "Epoch 45, 100% \t Train loss: 0.1513 took: 1.06s  Val. loss: 0.1519\n",
      "Epoch 46, 100% \t Train loss: 0.1512 took: 1.05s  Val. loss: 0.1496\n",
      "Epoch 47, 100% \t Train loss: 0.1517 took: 1.07s  Val. loss: 0.1515\n",
      "Epoch 48, 100% \t Train loss: 0.1513 took: 1.08s  Val. loss: 0.1511\n",
      "Epoch 49, 100% \t Train loss: 0.1509 took: 1.08s  Val. loss: 0.1514\n",
      "Epoch 50, 100% \t Train loss: 0.1506 took: 1.08s  Val. loss: 0.1538\n",
      "Training finished, took 89.73s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 1.04s  Val. loss: 0.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2561 took: 1.04s  Val. loss: 0.2532\n",
      "Epoch 3, 100% \t Train loss: 0.2559 took: 1.04s  Val. loss: 0.2541\n",
      "Epoch 4, 100% \t Train loss: 0.2560 took: 1.04s  Val. loss: 0.2542\n",
      "Epoch 5, 100% \t Train loss: 0.2560 took: 1.04s  Val. loss: 0.2539\n",
      "Epoch 6, 100% \t Train loss: 0.2560 took: 1.05s  Val. loss: 0.2543\n",
      "Epoch 7, 100% \t Train loss: 0.2560 took: 1.04s  Val. loss: 0.2540\n",
      "Epoch 8, 100% \t Train loss: 0.2560 took: 1.04s  Val. loss: 0.2542\n",
      "Epoch 9, 100% \t Train loss: 0.2560 took: 1.04s  Val. loss: 0.2536\n",
      "Epoch 10, 100% \t Train loss: 0.2559 took: 1.04s  Val. loss: 0.2535\n",
      "Epoch 11, 100% \t Train loss: 0.2557 took: 1.05s  Val. loss: 0.2536\n",
      "Epoch 12, 100% \t Train loss: 0.2555 took: 1.05s  Val. loss: 0.2527\n",
      "Epoch 13, 100% \t Train loss: 0.2547 took: 1.05s  Val. loss: 0.2506\n",
      "Epoch 14, 100% \t Train loss: 0.2504 took: 1.81s  Val. loss: 0.2428\n",
      "Epoch 15, 100% \t Train loss: 0.2328 took: 1.83s  Val. loss: 0.2230\n",
      "Epoch 16, 100% \t Train loss: 0.2147 took: 1.81s  Val. loss: 0.2198\n",
      "Epoch 17, 100% \t Train loss: 0.2004 took: 1.82s  Val. loss: 0.1971\n",
      "Epoch 18, 100% \t Train loss: 0.1879 took: 1.81s  Val. loss: 0.1867\n",
      "Epoch 19, 100% \t Train loss: 0.1804 took: 1.80s  Val. loss: 0.1829\n",
      "Epoch 20, 100% \t Train loss: 0.1768 took: 1.82s  Val. loss: 0.1870\n",
      "Epoch 21, 100% \t Train loss: 0.1745 took: 1.83s  Val. loss: 0.1788\n",
      "Epoch 22, 100% \t Train loss: 0.1714 took: 1.82s  Val. loss: 0.1811\n",
      "Epoch 23, 100% \t Train loss: 0.1732 took: 1.81s  Val. loss: 0.1807\n",
      "Epoch 24, 100% \t Train loss: 0.1703 took: 1.82s  Val. loss: 0.1787\n",
      "Epoch 25, 100% \t Train loss: 0.1686 took: 1.82s  Val. loss: 0.1761\n",
      "Epoch 26, 100% \t Train loss: 0.1668 took: 1.82s  Val. loss: 0.1751\n",
      "Epoch 27, 100% \t Train loss: 0.1667 took: 1.82s  Val. loss: 0.1814\n",
      "Epoch 28, 100% \t Train loss: 0.1660 took: 1.81s  Val. loss: 0.1775\n",
      "Epoch 29, 100% \t Train loss: 0.1648 took: 1.81s  Val. loss: 0.1752\n",
      "Epoch 30, 100% \t Train loss: 0.1638 took: 1.82s  Val. loss: 0.1785\n",
      "Epoch 31, 100% \t Train loss: 0.1649 took: 1.82s  Val. loss: 0.1755\n",
      "Epoch 32, 100% \t Train loss: 0.1641 took: 1.84s  Val. loss: 0.1765\n",
      "Epoch 33, 100% \t Train loss: 0.1625 took: 1.84s  Val. loss: 0.1745\n",
      "Epoch 34, 100% \t Train loss: 0.1615 took: 1.82s  Val. loss: 0.1721\n",
      "Epoch 35, 100% \t Train loss: 0.1620 took: 1.84s  Val. loss: 0.1711\n",
      "Epoch 36, 100% \t Train loss: 0.1610 took: 1.80s  Val. loss: 0.1738\n",
      "Epoch 37, 100% \t Train loss: 0.1625 took: 1.81s  Val. loss: 0.1799\n",
      "Epoch 38, 100% \t Train loss: 0.1607 took: 1.81s  Val. loss: 0.1712\n",
      "Epoch 39, 100% \t Train loss: 0.1596 took: 1.83s  Val. loss: 0.1709\n",
      "Epoch 40, 100% \t Train loss: 0.1604 took: 1.83s  Val. loss: 0.1721\n",
      "Epoch 41, 100% \t Train loss: 0.1615 took: 1.83s  Val. loss: 0.1730\n",
      "Epoch 42, 100% \t Train loss: 0.1577 took: 1.83s  Val. loss: 0.1708\n",
      "Epoch 43, 100% \t Train loss: 0.1578 took: 1.83s  Val. loss: 0.1732\n",
      "Epoch 44, 100% \t Train loss: 0.1575 took: 1.82s  Val. loss: 0.1704\n",
      "Epoch 45, 100% \t Train loss: 0.1572 took: 1.85s  Val. loss: 0.1696\n",
      "Epoch 46, 100% \t Train loss: 0.1575 took: 1.84s  Val. loss: 0.1715\n",
      "Epoch 47, 100% \t Train loss: 0.1563 took: 1.87s  Val. loss: 0.1707\n",
      "Epoch 48, 100% \t Train loss: 0.1551 took: 1.85s  Val. loss: 0.1715\n",
      "Epoch 49, 100% \t Train loss: 0.1561 took: 1.82s  Val. loss: 0.1706\n",
      "Epoch 50, 100% \t Train loss: 0.1556 took: 1.86s  Val. loss: 0.1680\n",
      "Training finished, took 92.29s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.827584\n",
      "lambda: 0.0010 - V: 0.820109\n",
      "lambda: 0.0005 - V: 0.800686\n",
      "Average V: 0.816126\n",
      "Time elapsed: 294.77 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2588 took: 2.43s  Val. loss: 0.2592\n",
      "Epoch 2, 100% \t Train loss: 0.2583 took: 2.42s  Val. loss: 0.2585\n",
      "Epoch 3, 100% \t Train loss: 0.2583 took: 2.42s  Val. loss: 0.2595\n",
      "Epoch 4, 100% \t Train loss: 0.2581 took: 2.44s  Val. loss: 0.2589\n",
      "Epoch 5, 100% \t Train loss: 0.2583 took: 2.45s  Val. loss: 0.2585\n",
      "Epoch 6, 100% \t Train loss: 0.2583 took: 2.42s  Val. loss: 0.2591\n",
      "Epoch 7, 100% \t Train loss: 0.2582 took: 2.43s  Val. loss: 0.2587\n",
      "Epoch 8, 100% \t Train loss: 0.2582 took: 2.43s  Val. loss: 0.2604\n",
      "Epoch 9, 100% \t Train loss: 0.2584 took: 2.45s  Val. loss: 0.2599\n",
      "Epoch 10, 100% \t Train loss: 0.2582 took: 2.44s  Val. loss: 0.2588\n",
      "Epoch 11, 100% \t Train loss: 0.2582 took: 2.44s  Val. loss: 0.2590\n",
      "Epoch 12, 100% \t Train loss: 0.2581 took: 2.43s  Val. loss: 0.2584\n",
      "Epoch 13, 100% \t Train loss: 0.2583 took: 2.45s  Val. loss: 0.2591\n",
      "Epoch 14, 100% \t Train loss: 0.2582 took: 2.46s  Val. loss: 0.2590\n",
      "Epoch 15, 100% \t Train loss: 0.2582 took: 2.45s  Val. loss: 0.2591\n",
      "Epoch 16, 100% \t Train loss: 0.2582 took: 2.45s  Val. loss: 0.2586\n",
      "Epoch 17, 100% \t Train loss: 0.2581 took: 2.42s  Val. loss: 0.2592\n",
      "Epoch 18, 100% \t Train loss: 0.2582 took: 2.46s  Val. loss: 0.2593\n",
      "Epoch 19, 100% \t Train loss: 0.2581 took: 2.43s  Val. loss: 0.2586\n",
      "Epoch 20, 100% \t Train loss: 0.2581 took: 2.48s  Val. loss: 0.2580\n",
      "Epoch 21, 100% \t Train loss: 0.2582 took: 2.45s  Val. loss: 0.2592\n",
      "Epoch 22, 100% \t Train loss: 0.2582 took: 2.44s  Val. loss: 0.2600\n",
      "Epoch 23, 100% \t Train loss: 0.2582 took: 2.47s  Val. loss: 0.2596\n",
      "Epoch 24, 100% \t Train loss: 0.2582 took: 2.47s  Val. loss: 0.2593\n",
      "Epoch 25, 100% \t Train loss: 0.2582 took: 2.48s  Val. loss: 0.2587\n",
      "Epoch 26, 100% \t Train loss: 0.2582 took: 2.52s  Val. loss: 0.2593\n",
      "Epoch 27, 100% \t Train loss: 0.2581 took: 2.53s  Val. loss: 0.2584\n",
      "Epoch 28, 100% \t Train loss: 0.2582 took: 2.62s  Val. loss: 0.2589\n",
      "Epoch 29, 100% \t Train loss: 0.2581 took: 2.64s  Val. loss: 0.2587\n",
      "Epoch 30, 100% \t Train loss: 0.2582 took: 2.71s  Val. loss: 0.2597\n",
      "Epoch 31, 100% \t Train loss: 0.2581 took: 2.80s  Val. loss: 0.2586\n",
      "Epoch 32, 100% \t Train loss: 0.2582 took: 2.95s  Val. loss: 0.2591\n",
      "Epoch 33, 100% \t Train loss: 0.2581 took: 3.26s  Val. loss: 0.2593\n",
      "Epoch 34, 100% \t Train loss: 0.2581 took: 3.30s  Val. loss: 0.2585\n",
      "Epoch 35, 100% \t Train loss: 0.2581 took: 3.40s  Val. loss: 0.2593\n",
      "Epoch 36, 100% \t Train loss: 0.2581 took: 3.45s  Val. loss: 0.2592\n",
      "Epoch 37, 100% \t Train loss: 0.2581 took: 2.50s  Val. loss: 0.2585\n",
      "Epoch 38, 100% \t Train loss: 0.2581 took: 3.53s  Val. loss: 0.2586\n",
      "Epoch 39, 100% \t Train loss: 0.2581 took: 3.52s  Val. loss: 0.2586\n",
      "Epoch 40, 100% \t Train loss: 0.2581 took: 3.51s  Val. loss: 0.2585\n",
      "Epoch 41, 100% \t Train loss: 0.2582 took: 2.93s  Val. loss: 0.2583\n",
      "Epoch 42, 100% \t Train loss: 0.2581 took: 2.52s  Val. loss: 0.2588\n",
      "Epoch 43, 100% \t Train loss: 0.2582 took: 2.49s  Val. loss: 0.2588\n",
      "Epoch 44, 100% \t Train loss: 0.2581 took: 3.48s  Val. loss: 0.2593\n",
      "Epoch 45, 100% \t Train loss: 0.2582 took: 3.42s  Val. loss: 0.2591\n",
      "Epoch 46, 100% \t Train loss: 0.2581 took: 3.43s  Val. loss: 0.2597\n",
      "Epoch 47, 100% \t Train loss: 0.2582 took: 3.48s  Val. loss: 0.2587\n",
      "Epoch 48, 100% \t Train loss: 0.2581 took: 3.50s  Val. loss: 0.2598\n",
      "Epoch 49, 100% \t Train loss: 0.2581 took: 3.45s  Val. loss: 0.2585\n",
      "Epoch 50, 100% \t Train loss: 0.2581 took: 3.35s  Val. loss: 0.2596\n",
      "Training finished, took 153.92s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2599 took: 2.43s  Val. loss: 0.2614\n",
      "Epoch 2, 100% \t Train loss: 0.2588 took: 2.40s  Val. loss: 0.2616\n",
      "Epoch 3, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2615\n",
      "Epoch 4, 100% \t Train loss: 0.2587 took: 2.41s  Val. loss: 0.2617\n",
      "Epoch 5, 100% \t Train loss: 0.2587 took: 2.40s  Val. loss: 0.2611\n",
      "Epoch 6, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2621\n",
      "Epoch 7, 100% \t Train loss: 0.2588 took: 2.41s  Val. loss: 0.2616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2613\n",
      "Epoch 9, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2606\n",
      "Epoch 10, 100% \t Train loss: 0.2587 took: 2.41s  Val. loss: 0.2611\n",
      "Epoch 11, 100% \t Train loss: 0.2587 took: 2.43s  Val. loss: 0.2615\n",
      "Epoch 12, 100% \t Train loss: 0.2587 took: 2.44s  Val. loss: 0.2613\n",
      "Epoch 13, 100% \t Train loss: 0.2587 took: 2.41s  Val. loss: 0.2609\n",
      "Epoch 14, 100% \t Train loss: 0.2587 took: 2.40s  Val. loss: 0.2597\n",
      "Epoch 15, 100% \t Train loss: 0.2587 took: 2.41s  Val. loss: 0.2613\n",
      "Epoch 16, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2609\n",
      "Epoch 17, 100% \t Train loss: 0.2587 took: 2.40s  Val. loss: 0.2613\n",
      "Epoch 18, 100% \t Train loss: 0.2587 took: 2.39s  Val. loss: 0.2615\n",
      "Epoch 19, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2614\n",
      "Epoch 20, 100% \t Train loss: 0.2587 took: 2.43s  Val. loss: 0.2620\n",
      "Epoch 21, 100% \t Train loss: 0.2587 took: 2.41s  Val. loss: 0.2614\n",
      "Epoch 22, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2609\n",
      "Epoch 23, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2615\n",
      "Epoch 24, 100% \t Train loss: 0.2587 took: 2.43s  Val. loss: 0.2617\n",
      "Epoch 25, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2609\n",
      "Epoch 26, 100% \t Train loss: 0.2587 took: 2.43s  Val. loss: 0.2615\n",
      "Epoch 27, 100% \t Train loss: 0.2587 took: 2.42s  Val. loss: 0.2621\n",
      "Epoch 28, 100% \t Train loss: 0.2587 took: 2.16s  Val. loss: 0.2614\n",
      "Epoch 29, 100% \t Train loss: 0.2587 took: 2.47s  Val. loss: 0.2611\n",
      "Epoch 30, 100% \t Train loss: 0.2587 took: 2.45s  Val. loss: 0.2625\n",
      "Epoch 31, 100% \t Train loss: 0.2586 took: 2.47s  Val. loss: 0.2612\n",
      "Epoch 32, 100% \t Train loss: 0.2583 took: 2.55s  Val. loss: 0.2599\n",
      "Epoch 33, 100% \t Train loss: 0.2576 took: 2.55s  Val. loss: 0.2588\n",
      "Epoch 34, 100% \t Train loss: 0.2542 took: 2.51s  Val. loss: 0.2507\n",
      "Epoch 35, 100% \t Train loss: 0.2451 took: 2.56s  Val. loss: 0.2392\n",
      "Epoch 36, 100% \t Train loss: 0.2395 took: 2.56s  Val. loss: 0.2351\n",
      "Epoch 37, 100% \t Train loss: 0.2376 took: 2.58s  Val. loss: 0.2341\n",
      "Epoch 38, 100% \t Train loss: 0.2358 took: 2.58s  Val. loss: 0.2328\n",
      "Epoch 39, 100% \t Train loss: 0.2333 took: 2.60s  Val. loss: 0.2291\n",
      "Epoch 40, 100% \t Train loss: 0.2294 took: 2.62s  Val. loss: 0.2217\n",
      "Epoch 41, 100% \t Train loss: 0.2224 took: 2.67s  Val. loss: 0.2164\n",
      "Epoch 42, 100% \t Train loss: 0.2153 took: 2.67s  Val. loss: 0.2054\n",
      "Epoch 43, 100% \t Train loss: 0.2105 took: 2.74s  Val. loss: 0.2057\n",
      "Epoch 44, 100% \t Train loss: 0.2043 took: 2.74s  Val. loss: 0.2013\n",
      "Epoch 45, 100% \t Train loss: 0.2014 took: 2.79s  Val. loss: 0.1946\n",
      "Epoch 46, 100% \t Train loss: 0.2001 took: 2.82s  Val. loss: 0.1959\n",
      "Epoch 47, 100% \t Train loss: 0.1998 took: 2.81s  Val. loss: 0.1951\n",
      "Epoch 48, 100% \t Train loss: 0.1975 took: 2.82s  Val. loss: 0.1934\n",
      "Epoch 49, 100% \t Train loss: 0.1962 took: 2.80s  Val. loss: 0.1939\n",
      "Epoch 50, 100% \t Train loss: 0.1964 took: 2.86s  Val. loss: 0.1930\n",
      "Training finished, took 139.41s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2608 took: 2.43s  Val. loss: 0.2575\n",
      "Epoch 2, 100% \t Train loss: 0.2572 took: 2.41s  Val. loss: 0.2568\n",
      "Epoch 3, 100% \t Train loss: 0.2566 took: 2.43s  Val. loss: 0.2562\n",
      "Epoch 4, 100% \t Train loss: 0.2564 took: 2.42s  Val. loss: 0.2554\n",
      "Epoch 5, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2563\n",
      "Epoch 6, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2564\n",
      "Epoch 7, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2565\n",
      "Epoch 8, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2547\n",
      "Epoch 9, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2558\n",
      "Epoch 10, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2558\n",
      "Epoch 11, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2555\n",
      "Epoch 12, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2557\n",
      "Epoch 13, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2563\n",
      "Epoch 14, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2550\n",
      "Epoch 15, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2557\n",
      "Epoch 16, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2555\n",
      "Epoch 17, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2556\n",
      "Epoch 18, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2559\n",
      "Epoch 19, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2550\n",
      "Epoch 20, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2559\n",
      "Epoch 21, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2569\n",
      "Epoch 22, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2555\n",
      "Epoch 23, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2563\n",
      "Epoch 24, 100% \t Train loss: 0.2564 took: 1.47s  Val. loss: 0.2558\n",
      "Epoch 25, 100% \t Train loss: 0.2565 took: 1.47s  Val. loss: 0.2554\n",
      "Epoch 26, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2560\n",
      "Epoch 27, 100% \t Train loss: 0.2564 took: 1.48s  Val. loss: 0.2562\n",
      "Epoch 28, 100% \t Train loss: 0.2564 took: 1.49s  Val. loss: 0.2566\n",
      "Epoch 29, 100% \t Train loss: 0.2564 took: 1.50s  Val. loss: 0.2558\n",
      "Epoch 30, 100% \t Train loss: 0.2565 took: 1.87s  Val. loss: 0.2565\n",
      "Epoch 31, 100% \t Train loss: 0.2564 took: 2.49s  Val. loss: 0.2560\n",
      "Epoch 32, 100% \t Train loss: 0.2564 took: 1.58s  Val. loss: 0.2550\n",
      "Epoch 33, 100% \t Train loss: 0.2564 took: 1.66s  Val. loss: 0.2558\n",
      "Epoch 34, 100% \t Train loss: 0.2564 took: 2.48s  Val. loss: 0.2549\n",
      "Epoch 35, 100% \t Train loss: 0.2564 took: 2.46s  Val. loss: 0.2556\n",
      "Epoch 36, 100% \t Train loss: 0.2564 took: 2.45s  Val. loss: 0.2555\n",
      "Epoch 37, 100% \t Train loss: 0.2564 took: 2.42s  Val. loss: 0.2560\n",
      "Epoch 38, 100% \t Train loss: 0.2565 took: 2.43s  Val. loss: 0.2558\n",
      "Epoch 39, 100% \t Train loss: 0.2564 took: 2.45s  Val. loss: 0.2563\n",
      "Epoch 40, 100% \t Train loss: 0.2565 took: 2.46s  Val. loss: 0.2549\n",
      "Epoch 41, 100% \t Train loss: 0.2564 took: 2.46s  Val. loss: 0.2557\n",
      "Epoch 42, 100% \t Train loss: 0.2564 took: 2.48s  Val. loss: 0.2558\n",
      "Epoch 43, 100% \t Train loss: 0.2564 took: 2.47s  Val. loss: 0.2557\n",
      "Epoch 44, 100% \t Train loss: 0.2564 took: 2.57s  Val. loss: 0.2564\n",
      "Epoch 45, 100% \t Train loss: 0.2564 took: 2.59s  Val. loss: 0.2559\n",
      "Epoch 46, 100% \t Train loss: 0.2564 took: 1.62s  Val. loss: 0.2559\n",
      "Epoch 47, 100% \t Train loss: 0.2564 took: 1.62s  Val. loss: 0.2557\n",
      "Epoch 48, 100% \t Train loss: 0.2564 took: 1.69s  Val. loss: 0.2561\n",
      "Epoch 49, 100% \t Train loss: 0.2565 took: 1.55s  Val. loss: 0.2554\n",
      "Epoch 50, 100% \t Train loss: 0.2564 took: 1.56s  Val. loss: 0.2556\n",
      "Training finished, took 101.84s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.740994\n",
      "lambda: 0.0010 - V: 0.754841\n",
      "lambda: 0.0005 - V: 0.744144\n",
      "Average V: 0.746660\n",
      "Time elapsed: 398.58 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2587 took: 1.69s  Val. loss: 0.2587\n",
      "Epoch 2, 100% \t Train loss: 0.2565 took: 1.74s  Val. loss: 0.2567\n",
      "Epoch 3, 100% \t Train loss: 0.2566 took: 1.72s  Val. loss: 0.2575\n",
      "Epoch 4, 100% \t Train loss: 0.2566 took: 1.73s  Val. loss: 0.2590\n",
      "Epoch 5, 100% \t Train loss: 0.2565 took: 1.73s  Val. loss: 0.2587\n",
      "Epoch 6, 100% \t Train loss: 0.2567 took: 1.73s  Val. loss: 0.2570\n",
      "Epoch 7, 100% \t Train loss: 0.2563 took: 1.74s  Val. loss: 0.2579\n",
      "Epoch 8, 100% \t Train loss: 0.2537 took: 1.74s  Val. loss: 0.2391\n",
      "Epoch 9, 100% \t Train loss: 0.1961 took: 1.75s  Val. loss: 0.1731\n",
      "Epoch 10, 100% \t Train loss: 0.1741 took: 1.73s  Val. loss: 0.1653\n",
      "Epoch 11, 100% \t Train loss: 0.1676 took: 1.01s  Val. loss: 0.1665\n",
      "Epoch 12, 100% \t Train loss: 0.1672 took: 1.00s  Val. loss: 0.1665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 100% \t Train loss: 0.1649 took: 0.99s  Val. loss: 0.1605\n",
      "Epoch 14, 100% \t Train loss: 0.1622 took: 0.99s  Val. loss: 0.1597\n",
      "Epoch 15, 100% \t Train loss: 0.1621 took: 0.99s  Val. loss: 0.1595\n",
      "Epoch 16, 100% \t Train loss: 0.1613 took: 0.99s  Val. loss: 0.1603\n",
      "Epoch 17, 100% \t Train loss: 0.1587 took: 0.99s  Val. loss: 0.1547\n",
      "Epoch 18, 100% \t Train loss: 0.1583 took: 0.99s  Val. loss: 0.1589\n",
      "Epoch 19, 100% \t Train loss: 0.1552 took: 0.99s  Val. loss: 0.1620\n",
      "Epoch 20, 100% \t Train loss: 0.1533 took: 0.99s  Val. loss: 0.1533\n",
      "Epoch 21, 100% \t Train loss: 0.1514 took: 0.99s  Val. loss: 0.1523\n",
      "Epoch 22, 100% \t Train loss: 0.1509 took: 0.99s  Val. loss: 0.1506\n",
      "Epoch 23, 100% \t Train loss: 0.1496 took: 0.99s  Val. loss: 0.1515\n",
      "Epoch 24, 100% \t Train loss: 0.1486 took: 0.99s  Val. loss: 0.1493\n",
      "Epoch 25, 100% \t Train loss: 0.1465 took: 0.99s  Val. loss: 0.1469\n",
      "Epoch 26, 100% \t Train loss: 0.1458 took: 0.99s  Val. loss: 0.1482\n",
      "Epoch 27, 100% \t Train loss: 0.1445 took: 0.99s  Val. loss: 0.1448\n",
      "Epoch 28, 100% \t Train loss: 0.1414 took: 1.00s  Val. loss: 0.1475\n",
      "Epoch 29, 100% \t Train loss: 0.1404 took: 1.00s  Val. loss: 0.1432\n",
      "Epoch 30, 100% \t Train loss: 0.1353 took: 1.01s  Val. loss: 0.1385\n",
      "Epoch 31, 100% \t Train loss: 0.1325 took: 1.04s  Val. loss: 0.1409\n",
      "Epoch 32, 100% \t Train loss: 0.1304 took: 1.08s  Val. loss: 0.1336\n",
      "Epoch 33, 100% \t Train loss: 0.1260 took: 1.12s  Val. loss: 0.1346\n",
      "Epoch 34, 100% \t Train loss: 0.1239 took: 1.15s  Val. loss: 0.1354\n",
      "Epoch 35, 100% \t Train loss: 0.1209 took: 1.16s  Val. loss: 0.1318\n",
      "Epoch 36, 100% \t Train loss: 0.1172 took: 1.16s  Val. loss: 0.1261\n",
      "Epoch 37, 100% \t Train loss: 0.1145 took: 1.16s  Val. loss: 0.1244\n",
      "Epoch 38, 100% \t Train loss: 0.1120 took: 1.16s  Val. loss: 0.1212\n",
      "Epoch 39, 100% \t Train loss: 0.1080 took: 1.17s  Val. loss: 0.1184\n",
      "Epoch 40, 100% \t Train loss: 0.1057 took: 1.18s  Val. loss: 0.1186\n",
      "Epoch 41, 100% \t Train loss: 0.1029 took: 1.18s  Val. loss: 0.1154\n",
      "Epoch 42, 100% \t Train loss: 0.1006 took: 1.18s  Val. loss: 0.1165\n",
      "Epoch 43, 100% \t Train loss: 0.1002 took: 1.18s  Val. loss: 0.1187\n",
      "Epoch 44, 100% \t Train loss: 0.0978 took: 1.18s  Val. loss: 0.1162\n",
      "Epoch 45, 100% \t Train loss: 0.0955 took: 1.18s  Val. loss: 0.1096\n",
      "Epoch 46, 100% \t Train loss: 0.0947 took: 1.17s  Val. loss: 0.1130\n",
      "Epoch 47, 100% \t Train loss: 0.0945 took: 1.17s  Val. loss: 0.1068\n",
      "Epoch 48, 100% \t Train loss: 0.0908 took: 1.18s  Val. loss: 0.1134\n",
      "Epoch 49, 100% \t Train loss: 0.0898 took: 1.17s  Val. loss: 0.1067\n",
      "Epoch 50, 100% \t Train loss: 0.0884 took: 1.17s  Val. loss: 0.1115\n",
      "Training finished, took 68.53s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2593 took: 1.72s  Val. loss: 0.2558\n",
      "Epoch 2, 100% \t Train loss: 0.2585 took: 1.75s  Val. loss: 0.2545\n",
      "Epoch 3, 100% \t Train loss: 0.2589 took: 1.74s  Val. loss: 0.2549\n",
      "Epoch 4, 100% \t Train loss: 0.2584 took: 1.75s  Val. loss: 0.2561\n",
      "Epoch 5, 100% \t Train loss: 0.2585 took: 1.73s  Val. loss: 0.2559\n",
      "Epoch 6, 100% \t Train loss: 0.2587 took: 1.73s  Val. loss: 0.2556\n",
      "Epoch 7, 100% \t Train loss: 0.2584 took: 1.75s  Val. loss: 0.2556\n",
      "Epoch 8, 100% \t Train loss: 0.2582 took: 1.75s  Val. loss: 0.2533\n",
      "Epoch 9, 100% \t Train loss: 0.2551 took: 1.73s  Val. loss: 0.2456\n",
      "Epoch 10, 100% \t Train loss: 0.2211 took: 1.75s  Val. loss: 0.2114\n",
      "Epoch 11, 100% \t Train loss: 0.1819 took: 1.76s  Val. loss: 0.2001\n",
      "Epoch 12, 100% \t Train loss: 0.1736 took: 1.75s  Val. loss: 0.1907\n",
      "Epoch 13, 100% \t Train loss: 0.1668 took: 1.73s  Val. loss: 0.1852\n",
      "Epoch 14, 100% \t Train loss: 0.1632 took: 1.73s  Val. loss: 0.1821\n",
      "Epoch 15, 100% \t Train loss: 0.1607 took: 1.71s  Val. loss: 0.1838\n",
      "Epoch 16, 100% \t Train loss: 0.1567 took: 1.72s  Val. loss: 0.1809\n",
      "Epoch 17, 100% \t Train loss: 0.1567 took: 1.72s  Val. loss: 0.1770\n",
      "Epoch 18, 100% \t Train loss: 0.1547 took: 1.73s  Val. loss: 0.1805\n",
      "Epoch 19, 100% \t Train loss: 0.1524 took: 1.72s  Val. loss: 0.1745\n",
      "Epoch 20, 100% \t Train loss: 0.1506 took: 1.73s  Val. loss: 0.1717\n",
      "Epoch 21, 100% \t Train loss: 0.1502 took: 1.74s  Val. loss: 0.1721\n",
      "Epoch 22, 100% \t Train loss: 0.1473 took: 1.76s  Val. loss: 0.1704\n",
      "Epoch 23, 100% \t Train loss: 0.1449 took: 1.70s  Val. loss: 0.1697\n",
      "Epoch 24, 100% \t Train loss: 0.1399 took: 1.73s  Val. loss: 0.1641\n",
      "Epoch 25, 100% \t Train loss: 0.1329 took: 1.71s  Val. loss: 0.1529\n",
      "Epoch 26, 100% \t Train loss: 0.1251 took: 1.71s  Val. loss: 0.1464\n",
      "Epoch 27, 100% \t Train loss: 0.1167 took: 1.75s  Val. loss: 0.1336\n",
      "Epoch 28, 100% \t Train loss: 0.1106 took: 1.76s  Val. loss: 0.1331\n",
      "Epoch 29, 100% \t Train loss: 0.1053 took: 1.74s  Val. loss: 0.1234\n",
      "Epoch 30, 100% \t Train loss: 0.1010 took: 1.75s  Val. loss: 0.1165\n",
      "Epoch 31, 100% \t Train loss: 0.0981 took: 1.75s  Val. loss: 0.1141\n",
      "Epoch 32, 100% \t Train loss: 0.0921 took: 1.73s  Val. loss: 0.1116\n",
      "Epoch 33, 100% \t Train loss: 0.0902 took: 1.74s  Val. loss: 0.1115\n",
      "Epoch 34, 100% \t Train loss: 0.0869 took: 1.74s  Val. loss: 0.1088\n",
      "Epoch 35, 100% \t Train loss: 0.0852 took: 1.73s  Val. loss: 0.1055\n",
      "Epoch 36, 100% \t Train loss: 0.0829 took: 1.73s  Val. loss: 0.1034\n",
      "Epoch 37, 100% \t Train loss: 0.0843 took: 1.73s  Val. loss: 0.1016\n",
      "Epoch 38, 100% \t Train loss: 0.0814 took: 1.74s  Val. loss: 0.1012\n",
      "Epoch 39, 100% \t Train loss: 0.0780 took: 1.75s  Val. loss: 0.0996\n",
      "Epoch 40, 100% \t Train loss: 0.0765 took: 1.75s  Val. loss: 0.1010\n",
      "Epoch 41, 100% \t Train loss: 0.0758 took: 1.76s  Val. loss: 0.0990\n",
      "Epoch 42, 100% \t Train loss: 0.0743 took: 1.76s  Val. loss: 0.0979\n",
      "Epoch 43, 100% \t Train loss: 0.0743 took: 1.78s  Val. loss: 0.0975\n",
      "Epoch 44, 100% \t Train loss: 0.0732 took: 1.80s  Val. loss: 0.0974\n",
      "Epoch 45, 100% \t Train loss: 0.0728 took: 1.77s  Val. loss: 0.1005\n",
      "Epoch 46, 100% \t Train loss: 0.0717 took: 1.77s  Val. loss: 0.0932\n",
      "Epoch 47, 100% \t Train loss: 0.0714 took: 1.79s  Val. loss: 0.0936\n",
      "Epoch 48, 100% \t Train loss: 0.0704 took: 1.81s  Val. loss: 0.0943\n",
      "Epoch 49, 100% \t Train loss: 0.0693 took: 1.79s  Val. loss: 0.0935\n",
      "Epoch 50, 100% \t Train loss: 0.0698 took: 1.78s  Val. loss: 0.0929\n",
      "Training finished, took 99.35s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2571 took: 1.72s  Val. loss: 0.2571\n",
      "Epoch 2, 100% \t Train loss: 0.2565 took: 1.72s  Val. loss: 0.2592\n",
      "Epoch 3, 100% \t Train loss: 0.2566 took: 1.71s  Val. loss: 0.2586\n",
      "Epoch 4, 100% \t Train loss: 0.2558 took: 1.72s  Val. loss: 0.2561\n",
      "Epoch 5, 100% \t Train loss: 0.2527 took: 1.71s  Val. loss: 0.2516\n",
      "Epoch 6, 100% \t Train loss: 0.2313 took: 1.71s  Val. loss: 0.2174\n",
      "Epoch 7, 100% \t Train loss: 0.1969 took: 1.71s  Val. loss: 0.1957\n",
      "Epoch 8, 100% \t Train loss: 0.1823 took: 1.71s  Val. loss: 0.1827\n",
      "Epoch 9, 100% \t Train loss: 0.1768 took: 1.71s  Val. loss: 0.1808\n",
      "Epoch 10, 100% \t Train loss: 0.1775 took: 1.71s  Val. loss: 0.1799\n",
      "Epoch 11, 100% \t Train loss: 0.1731 took: 1.71s  Val. loss: 0.1788\n",
      "Epoch 12, 100% \t Train loss: 0.1721 took: 1.72s  Val. loss: 0.1776\n",
      "Epoch 13, 100% \t Train loss: 0.1707 took: 1.74s  Val. loss: 0.1780\n",
      "Epoch 14, 100% \t Train loss: 0.1710 took: 1.69s  Val. loss: 0.1763\n",
      "Epoch 15, 100% \t Train loss: 0.1684 took: 1.70s  Val. loss: 0.1804\n",
      "Epoch 16, 100% \t Train loss: 0.1675 took: 1.72s  Val. loss: 0.1737\n",
      "Epoch 17, 100% \t Train loss: 0.1668 took: 1.72s  Val. loss: 0.1787\n",
      "Epoch 18, 100% \t Train loss: 0.1689 took: 1.75s  Val. loss: 0.1813\n",
      "Epoch 19, 100% \t Train loss: 0.1684 took: 1.71s  Val. loss: 0.1798\n",
      "Epoch 20, 100% \t Train loss: 0.1659 took: 1.72s  Val. loss: 0.1752\n",
      "Epoch 21, 100% \t Train loss: 0.1646 took: 1.73s  Val. loss: 0.1737\n",
      "Epoch 22, 100% \t Train loss: 0.1629 took: 1.76s  Val. loss: 0.1737\n",
      "Epoch 23, 100% \t Train loss: 0.1635 took: 1.74s  Val. loss: 0.1702\n",
      "Epoch 24, 100% \t Train loss: 0.1623 took: 1.75s  Val. loss: 0.1714\n",
      "Epoch 25, 100% \t Train loss: 0.1631 took: 1.73s  Val. loss: 0.1723\n",
      "Epoch 26, 100% \t Train loss: 0.1619 took: 1.73s  Val. loss: 0.1718\n",
      "Epoch 27, 100% \t Train loss: 0.1614 took: 1.73s  Val. loss: 0.1689\n",
      "Epoch 28, 100% \t Train loss: 0.1606 took: 1.74s  Val. loss: 0.1717\n",
      "Epoch 29, 100% \t Train loss: 0.1581 took: 1.76s  Val. loss: 0.1738\n",
      "Epoch 30, 100% \t Train loss: 0.1616 took: 1.76s  Val. loss: 0.1702\n",
      "Epoch 31, 100% \t Train loss: 0.1588 took: 1.77s  Val. loss: 0.1681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, 100% \t Train loss: 0.1584 took: 1.79s  Val. loss: 0.1678\n",
      "Epoch 33, 100% \t Train loss: 0.1576 took: 1.80s  Val. loss: 0.1695\n",
      "Epoch 34, 100% \t Train loss: 0.1563 took: 1.82s  Val. loss: 0.1695\n",
      "Epoch 35, 100% \t Train loss: 0.1558 took: 1.78s  Val. loss: 0.1710\n",
      "Epoch 36, 100% \t Train loss: 0.1577 took: 1.79s  Val. loss: 0.1737\n",
      "Epoch 37, 100% \t Train loss: 0.1570 took: 1.79s  Val. loss: 0.1727\n",
      "Epoch 38, 100% \t Train loss: 0.1578 took: 1.80s  Val. loss: 0.1695\n",
      "Epoch 39, 100% \t Train loss: 0.1554 took: 1.79s  Val. loss: 0.1707\n",
      "Epoch 40, 100% \t Train loss: 0.1539 took: 1.80s  Val. loss: 0.1710\n",
      "Epoch 41, 100% \t Train loss: 0.1550 took: 1.79s  Val. loss: 0.1696\n",
      "Epoch 42, 100% \t Train loss: 0.1561 took: 1.80s  Val. loss: 0.1709\n",
      "Epoch 43, 100% \t Train loss: 0.1534 took: 1.80s  Val. loss: 0.1679\n",
      "Epoch 44, 100% \t Train loss: 0.1548 took: 1.83s  Val. loss: 0.1720\n",
      "Epoch 45, 100% \t Train loss: 0.1552 took: 1.82s  Val. loss: 0.1703\n",
      "Epoch 46, 100% \t Train loss: 0.1530 took: 1.83s  Val. loss: 0.1705\n",
      "Epoch 47, 100% \t Train loss: 0.1531 took: 1.82s  Val. loss: 0.1656\n",
      "Epoch 48, 100% \t Train loss: 0.1514 took: 1.82s  Val. loss: 0.1698\n",
      "Epoch 49, 100% \t Train loss: 0.1519 took: 1.81s  Val. loss: 0.1647\n",
      "Epoch 50, 100% \t Train loss: 0.1525 took: 1.82s  Val. loss: 0.1736\n",
      "Training finished, took 99.97s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.842591\n",
      "lambda: 0.0010 - V: 0.843486\n",
      "lambda: 0.0005 - V: 0.817297\n",
      "Average V: 0.834458\n",
      "Time elapsed: 271.52 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2401 took: 2.01s  Val. loss: 0.1845\n",
      "Epoch 2, 100% \t Train loss: 0.1697 took: 2.00s  Val. loss: 0.1710\n",
      "Epoch 3, 100% \t Train loss: 0.1623 took: 2.01s  Val. loss: 0.1684\n",
      "Epoch 4, 100% \t Train loss: 0.1585 took: 2.00s  Val. loss: 0.1706\n",
      "Epoch 5, 100% \t Train loss: 0.1563 took: 1.96s  Val. loss: 0.1716\n",
      "Epoch 6, 100% \t Train loss: 0.1563 took: 1.99s  Val. loss: 0.1712\n",
      "Epoch 7, 100% \t Train loss: 0.1547 took: 1.99s  Val. loss: 0.1711\n",
      "Epoch 8, 100% \t Train loss: 0.1497 took: 1.97s  Val. loss: 0.1663\n",
      "Epoch 9, 100% \t Train loss: 0.1480 took: 1.98s  Val. loss: 0.1641\n",
      "Epoch 10, 100% \t Train loss: 0.1439 took: 2.00s  Val. loss: 0.1622\n",
      "Epoch 11, 100% \t Train loss: 0.1427 took: 2.02s  Val. loss: 0.1668\n",
      "Epoch 12, 100% \t Train loss: 0.1420 took: 2.01s  Val. loss: 0.1620\n",
      "Epoch 13, 100% \t Train loss: 0.1428 took: 2.01s  Val. loss: 0.1654\n",
      "Epoch 14, 100% \t Train loss: 0.1407 took: 2.04s  Val. loss: 0.1585\n",
      "Epoch 15, 100% \t Train loss: 0.1404 took: 2.02s  Val. loss: 0.1642\n",
      "Epoch 16, 100% \t Train loss: 0.1401 took: 1.99s  Val. loss: 0.1641\n",
      "Epoch 17, 100% \t Train loss: 0.1405 took: 1.99s  Val. loss: 0.1632\n",
      "Epoch 18, 100% \t Train loss: 0.1399 took: 1.99s  Val. loss: 0.1611\n",
      "Epoch 19, 100% \t Train loss: 0.1389 took: 2.00s  Val. loss: 0.1636\n",
      "Epoch 20, 100% \t Train loss: 0.1374 took: 1.96s  Val. loss: 0.1651\n",
      "Epoch 21, 100% \t Train loss: 0.1380 took: 1.86s  Val. loss: 0.1660\n",
      "Epoch 22, 100% \t Train loss: 0.1382 took: 1.94s  Val. loss: 0.1610\n",
      "Epoch 23, 100% \t Train loss: 0.1363 took: 2.02s  Val. loss: 0.1627\n",
      "Epoch 24, 100% \t Train loss: 0.1352 took: 2.01s  Val. loss: 0.1601\n",
      "Epoch 25, 100% \t Train loss: 0.1334 took: 1.97s  Val. loss: 0.1578\n",
      "Epoch 26, 100% \t Train loss: 0.1278 took: 2.06s  Val. loss: 0.1500\n",
      "Epoch 27, 100% \t Train loss: 0.1182 took: 2.05s  Val. loss: 0.1375\n",
      "Epoch 28, 100% \t Train loss: 0.1054 took: 2.14s  Val. loss: 0.1242\n",
      "Epoch 29, 100% \t Train loss: 0.0979 took: 2.11s  Val. loss: 0.1148\n",
      "Epoch 30, 100% \t Train loss: 0.0893 took: 2.05s  Val. loss: 0.1036\n",
      "Epoch 31, 100% \t Train loss: 0.0833 took: 1.76s  Val. loss: 0.0998\n",
      "Epoch 32, 100% \t Train loss: 0.0788 took: 2.21s  Val. loss: 0.0956\n",
      "Epoch 33, 100% \t Train loss: 0.0769 took: 2.10s  Val. loss: 0.0979\n",
      "Epoch 34, 100% \t Train loss: 0.0765 took: 2.12s  Val. loss: 0.0915\n",
      "Epoch 35, 100% \t Train loss: 0.0727 took: 2.11s  Val. loss: 0.0900\n",
      "Epoch 36, 100% \t Train loss: 0.0712 took: 2.12s  Val. loss: 0.0871\n",
      "Epoch 37, 100% \t Train loss: 0.0712 took: 2.12s  Val. loss: 0.0880\n",
      "Epoch 38, 100% \t Train loss: 0.0690 took: 2.12s  Val. loss: 0.0882\n",
      "Epoch 39, 100% \t Train loss: 0.0688 took: 2.12s  Val. loss: 0.0924\n",
      "Epoch 40, 100% \t Train loss: 0.0691 took: 2.11s  Val. loss: 0.0882\n",
      "Epoch 41, 100% \t Train loss: 0.0675 took: 2.11s  Val. loss: 0.0889\n",
      "Epoch 42, 100% \t Train loss: 0.0662 took: 2.12s  Val. loss: 0.0894\n",
      "Epoch 43, 100% \t Train loss: 0.0655 took: 2.12s  Val. loss: 0.0936\n",
      "Epoch 44, 100% \t Train loss: 0.0667 took: 2.11s  Val. loss: 0.0892\n",
      "Epoch 45, 100% \t Train loss: 0.0647 took: 2.13s  Val. loss: 0.0854\n",
      "Epoch 46, 100% \t Train loss: 0.0648 took: 2.14s  Val. loss: 0.0866\n",
      "Epoch 47, 100% \t Train loss: 0.0645 took: 2.16s  Val. loss: 0.0908\n",
      "Epoch 48, 100% \t Train loss: 0.0639 took: 2.15s  Val. loss: 0.0914\n",
      "Epoch 49, 100% \t Train loss: 0.0635 took: 2.16s  Val. loss: 0.0911\n",
      "Epoch 50, 100% \t Train loss: 0.0624 took: 2.16s  Val. loss: 0.0910\n",
      "Training finished, took 115.34s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 2.02s  Val. loss: 0.2664\n",
      "Epoch 2, 100% \t Train loss: 0.2543 took: 2.00s  Val. loss: 0.2485\n",
      "Epoch 3, 100% \t Train loss: 0.2134 took: 2.00s  Val. loss: 0.1998\n",
      "Epoch 4, 100% \t Train loss: 0.1801 took: 2.03s  Val. loss: 0.1844\n",
      "Epoch 5, 100% \t Train loss: 0.1731 took: 2.00s  Val. loss: 0.1807\n",
      "Epoch 6, 100% \t Train loss: 0.1669 took: 2.02s  Val. loss: 0.1825\n",
      "Epoch 7, 100% \t Train loss: 0.1668 took: 2.03s  Val. loss: 0.1821\n",
      "Epoch 8, 100% \t Train loss: 0.1621 took: 2.03s  Val. loss: 0.1765\n",
      "Epoch 9, 100% \t Train loss: 0.1606 took: 2.02s  Val. loss: 0.1785\n",
      "Epoch 10, 100% \t Train loss: 0.1604 took: 1.99s  Val. loss: 0.1864\n",
      "Epoch 11, 100% \t Train loss: 0.1593 took: 2.02s  Val. loss: 0.1772\n",
      "Epoch 12, 100% \t Train loss: 0.1564 took: 2.01s  Val. loss: 0.1773\n",
      "Epoch 13, 100% \t Train loss: 0.1558 took: 2.01s  Val. loss: 0.1895\n",
      "Epoch 14, 100% \t Train loss: 0.1561 took: 2.01s  Val. loss: 0.1767\n",
      "Epoch 15, 100% \t Train loss: 0.1542 took: 2.02s  Val. loss: 0.1769\n",
      "Epoch 16, 100% \t Train loss: 0.1516 took: 2.00s  Val. loss: 0.1760\n",
      "Epoch 17, 100% \t Train loss: 0.1527 took: 2.01s  Val. loss: 0.1757\n",
      "Epoch 18, 100% \t Train loss: 0.1514 took: 1.19s  Val. loss: 0.1764\n",
      "Epoch 19, 100% \t Train loss: 0.1507 took: 1.31s  Val. loss: 0.1709\n",
      "Epoch 20, 100% \t Train loss: 0.1479 took: 2.04s  Val. loss: 0.1718\n",
      "Epoch 21, 100% \t Train loss: 0.1466 took: 2.01s  Val. loss: 0.1658\n",
      "Epoch 22, 100% \t Train loss: 0.1412 took: 2.01s  Val. loss: 0.1647\n",
      "Epoch 23, 100% \t Train loss: 0.1380 took: 1.98s  Val. loss: 0.1565\n",
      "Epoch 24, 100% \t Train loss: 0.1312 took: 2.00s  Val. loss: 0.1528\n",
      "Epoch 25, 100% \t Train loss: 0.1277 took: 1.99s  Val. loss: 0.1470\n",
      "Epoch 26, 100% \t Train loss: 0.1217 took: 2.01s  Val. loss: 0.1399\n",
      "Epoch 27, 100% \t Train loss: 0.1185 took: 1.98s  Val. loss: 0.1366\n",
      "Epoch 28, 100% \t Train loss: 0.1152 took: 1.99s  Val. loss: 0.1281\n",
      "Epoch 29, 100% \t Train loss: 0.1103 took: 2.00s  Val. loss: 0.1277\n",
      "Epoch 30, 100% \t Train loss: 0.1090 took: 2.00s  Val. loss: 0.1241\n",
      "Epoch 31, 100% \t Train loss: 0.1068 took: 2.00s  Val. loss: 0.1243\n",
      "Epoch 32, 100% \t Train loss: 0.1046 took: 2.03s  Val. loss: 0.1140\n",
      "Epoch 33, 100% \t Train loss: 0.0994 took: 2.04s  Val. loss: 0.1095\n",
      "Epoch 34, 100% \t Train loss: 0.0959 took: 2.06s  Val. loss: 0.1077\n",
      "Epoch 35, 100% \t Train loss: 0.0932 took: 2.05s  Val. loss: 0.1096\n",
      "Epoch 36, 100% \t Train loss: 0.0926 took: 2.07s  Val. loss: 0.1098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, 100% \t Train loss: 0.0920 took: 2.05s  Val. loss: 0.1013\n",
      "Epoch 38, 100% \t Train loss: 0.0881 took: 2.10s  Val. loss: 0.1044\n",
      "Epoch 39, 100% \t Train loss: 0.0867 took: 2.10s  Val. loss: 0.0984\n",
      "Epoch 40, 100% \t Train loss: 0.0845 took: 2.10s  Val. loss: 0.1027\n",
      "Epoch 41, 100% \t Train loss: 0.0853 took: 2.12s  Val. loss: 0.1004\n",
      "Epoch 42, 100% \t Train loss: 0.0852 took: 2.12s  Val. loss: 0.0981\n",
      "Epoch 43, 100% \t Train loss: 0.0814 took: 2.13s  Val. loss: 0.0939\n",
      "Epoch 44, 100% \t Train loss: 0.0802 took: 2.13s  Val. loss: 0.0955\n",
      "Epoch 45, 100% \t Train loss: 0.0779 took: 2.18s  Val. loss: 0.0931\n",
      "Epoch 46, 100% \t Train loss: 0.0791 took: 2.20s  Val. loss: 0.0975\n",
      "Epoch 47, 100% \t Train loss: 0.0781 took: 2.23s  Val. loss: 0.0947\n",
      "Epoch 48, 100% \t Train loss: 0.0775 took: 2.24s  Val. loss: 0.0908\n",
      "Epoch 49, 100% \t Train loss: 0.0767 took: 2.24s  Val. loss: 0.0906\n",
      "Epoch 50, 100% \t Train loss: 0.0749 took: 2.24s  Val. loss: 0.0924\n",
      "Training finished, took 114.14s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2555 took: 2.03s  Val. loss: 0.2567\n",
      "Epoch 2, 100% \t Train loss: 0.2547 took: 2.03s  Val. loss: 0.2578\n",
      "Epoch 3, 100% \t Train loss: 0.2546 took: 2.01s  Val. loss: 0.2569\n",
      "Epoch 4, 100% \t Train loss: 0.2542 took: 2.00s  Val. loss: 0.2573\n",
      "Epoch 5, 100% \t Train loss: 0.2540 took: 1.99s  Val. loss: 0.2573\n",
      "Epoch 6, 100% \t Train loss: 0.2530 took: 2.00s  Val. loss: 0.2554\n",
      "Epoch 7, 100% \t Train loss: 0.2441 took: 2.00s  Val. loss: 0.2314\n",
      "Epoch 8, 100% \t Train loss: 0.2071 took: 2.00s  Val. loss: 0.1985\n",
      "Epoch 9, 100% \t Train loss: 0.1799 took: 2.00s  Val. loss: 0.1872\n",
      "Epoch 10, 100% \t Train loss: 0.1735 took: 2.00s  Val. loss: 0.1852\n",
      "Epoch 11, 100% \t Train loss: 0.1706 took: 2.00s  Val. loss: 0.1926\n",
      "Epoch 12, 100% \t Train loss: 0.1681 took: 2.04s  Val. loss: 0.1817\n",
      "Epoch 13, 100% \t Train loss: 0.1645 took: 2.01s  Val. loss: 0.1781\n",
      "Epoch 14, 100% \t Train loss: 0.1659 took: 2.01s  Val. loss: 0.1862\n",
      "Epoch 15, 100% \t Train loss: 0.1630 took: 2.01s  Val. loss: 0.1783\n",
      "Epoch 16, 100% \t Train loss: 0.1616 took: 1.19s  Val. loss: 0.1767\n",
      "Epoch 17, 100% \t Train loss: 0.1635 took: 1.18s  Val. loss: 0.1761\n",
      "Epoch 18, 100% \t Train loss: 0.1620 took: 1.19s  Val. loss: 0.1844\n",
      "Epoch 19, 100% \t Train loss: 0.1600 took: 1.19s  Val. loss: 0.1746\n",
      "Epoch 20, 100% \t Train loss: 0.1616 took: 1.19s  Val. loss: 0.1753\n",
      "Epoch 21, 100% \t Train loss: 0.1589 took: 1.18s  Val. loss: 0.1776\n",
      "Epoch 22, 100% \t Train loss: 0.1594 took: 1.19s  Val. loss: 0.1761\n",
      "Epoch 23, 100% \t Train loss: 0.1584 took: 1.19s  Val. loss: 0.1746\n",
      "Epoch 24, 100% \t Train loss: 0.1583 took: 1.21s  Val. loss: 0.1762\n",
      "Epoch 25, 100% \t Train loss: 0.1566 took: 2.02s  Val. loss: 0.1803\n",
      "Epoch 26, 100% \t Train loss: 0.1562 took: 2.02s  Val. loss: 0.1806\n",
      "Epoch 27, 100% \t Train loss: 0.1544 took: 2.02s  Val. loss: 0.1766\n",
      "Epoch 28, 100% \t Train loss: 0.1550 took: 2.02s  Val. loss: 0.1744\n",
      "Epoch 29, 100% \t Train loss: 0.1553 took: 2.03s  Val. loss: 0.1746\n",
      "Epoch 30, 100% \t Train loss: 0.1546 took: 2.03s  Val. loss: 0.1747\n",
      "Epoch 31, 100% \t Train loss: 0.1552 took: 2.07s  Val. loss: 0.1797\n",
      "Epoch 32, 100% \t Train loss: 0.1529 took: 2.06s  Val. loss: 0.1750\n",
      "Epoch 33, 100% \t Train loss: 0.1527 took: 1.24s  Val. loss: 0.1735\n",
      "Epoch 34, 100% \t Train loss: 0.1522 took: 1.23s  Val. loss: 0.1728\n",
      "Epoch 35, 100% \t Train loss: 0.1522 took: 1.23s  Val. loss: 0.1727\n",
      "Epoch 36, 100% \t Train loss: 0.1499 took: 1.23s  Val. loss: 0.1718\n",
      "Epoch 37, 100% \t Train loss: 0.1524 took: 1.23s  Val. loss: 0.1730\n",
      "Epoch 38, 100% \t Train loss: 0.1495 took: 1.23s  Val. loss: 0.1754\n",
      "Epoch 39, 100% \t Train loss: 0.1493 took: 1.23s  Val. loss: 0.1716\n",
      "Epoch 40, 100% \t Train loss: 0.1493 took: 1.23s  Val. loss: 0.1750\n",
      "Epoch 41, 100% \t Train loss: 0.1490 took: 1.23s  Val. loss: 0.1744\n",
      "Epoch 42, 100% \t Train loss: 0.1476 took: 1.24s  Val. loss: 0.1711\n",
      "Epoch 43, 100% \t Train loss: 0.1479 took: 1.24s  Val. loss: 0.1712\n",
      "Epoch 44, 100% \t Train loss: 0.1476 took: 1.25s  Val. loss: 0.1729\n",
      "Epoch 45, 100% \t Train loss: 0.1466 took: 1.25s  Val. loss: 0.1744\n",
      "Epoch 46, 100% \t Train loss: 0.1468 took: 1.26s  Val. loss: 0.1719\n",
      "Epoch 47, 100% \t Train loss: 0.1467 took: 1.26s  Val. loss: 0.1816\n",
      "Epoch 48, 100% \t Train loss: 0.1480 took: 1.26s  Val. loss: 0.1732\n",
      "Epoch 49, 100% \t Train loss: 0.1445 took: 1.27s  Val. loss: 0.1699\n",
      "Epoch 50, 100% \t Train loss: 0.1443 took: 1.29s  Val. loss: 0.1818\n",
      "Training finished, took 89.47s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  4  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.868225\n",
      "lambda: 0.0010 - V: 0.855470\n",
      "lambda: 0.0005 - V: 0.812074\n",
      "Average V: 0.845256\n",
      "Time elapsed: 322.35 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2585 took: 1.08s  Val. loss: 0.2545\n",
      "Epoch 2, 100% \t Train loss: 0.2581 took: 0.99s  Val. loss: 0.2561\n",
      "Epoch 3, 100% \t Train loss: 0.2578 took: 0.99s  Val. loss: 0.2543\n",
      "Epoch 4, 100% \t Train loss: 0.2576 took: 0.99s  Val. loss: 0.2541\n",
      "Epoch 5, 100% \t Train loss: 0.2575 took: 0.99s  Val. loss: 0.2538\n",
      "Epoch 6, 100% \t Train loss: 0.2576 took: 0.98s  Val. loss: 0.2549\n",
      "Epoch 7, 100% \t Train loss: 0.2574 took: 0.98s  Val. loss: 0.2540\n",
      "Epoch 8, 100% \t Train loss: 0.2574 took: 0.98s  Val. loss: 0.2553\n",
      "Epoch 9, 100% \t Train loss: 0.2576 took: 1.45s  Val. loss: 0.2539\n",
      "Epoch 10, 100% \t Train loss: 0.2575 took: 1.71s  Val. loss: 0.2542\n",
      "Epoch 11, 100% \t Train loss: 0.2576 took: 1.73s  Val. loss: 0.2545\n",
      "Epoch 12, 100% \t Train loss: 0.2574 took: 1.73s  Val. loss: 0.2544\n",
      "Epoch 13, 100% \t Train loss: 0.2575 took: 1.73s  Val. loss: 0.2541\n",
      "Epoch 14, 100% \t Train loss: 0.2575 took: 1.73s  Val. loss: 0.2533\n",
      "Epoch 15, 100% \t Train loss: 0.2575 took: 1.73s  Val. loss: 0.2534\n",
      "Epoch 16, 100% \t Train loss: 0.2575 took: 1.73s  Val. loss: 0.2539\n",
      "Epoch 17, 100% \t Train loss: 0.2575 took: 1.75s  Val. loss: 0.2538\n",
      "Epoch 18, 100% \t Train loss: 0.2574 took: 1.71s  Val. loss: 0.2540\n",
      "Epoch 19, 100% \t Train loss: 0.2574 took: 1.73s  Val. loss: 0.2525\n",
      "Epoch 20, 100% \t Train loss: 0.2574 took: 1.73s  Val. loss: 0.2537\n",
      "Epoch 21, 100% \t Train loss: 0.2574 took: 1.72s  Val. loss: 0.2544\n",
      "Epoch 22, 100% \t Train loss: 0.2574 took: 1.72s  Val. loss: 0.2535\n",
      "Epoch 23, 100% \t Train loss: 0.2574 took: 1.73s  Val. loss: 0.2535\n",
      "Epoch 24, 100% \t Train loss: 0.2575 took: 1.73s  Val. loss: 0.2541\n",
      "Epoch 25, 100% \t Train loss: 0.2574 took: 1.72s  Val. loss: 0.2548\n",
      "Epoch 26, 100% \t Train loss: 0.2574 took: 1.74s  Val. loss: 0.2543\n",
      "Epoch 27, 100% \t Train loss: 0.2574 took: 1.72s  Val. loss: 0.2536\n",
      "Epoch 28, 100% \t Train loss: 0.2574 took: 1.75s  Val. loss: 0.2537\n",
      "Epoch 29, 100% \t Train loss: 0.2574 took: 1.01s  Val. loss: 0.2547\n",
      "Epoch 30, 100% \t Train loss: 0.2575 took: 1.01s  Val. loss: 0.2545\n",
      "Epoch 31, 100% \t Train loss: 0.2574 took: 1.02s  Val. loss: 0.2549\n",
      "Epoch 32, 100% \t Train loss: 0.2574 took: 1.08s  Val. loss: 0.2538\n",
      "Epoch 33, 100% \t Train loss: 0.2574 took: 1.16s  Val. loss: 0.2534\n",
      "Epoch 34, 100% \t Train loss: 0.2574 took: 1.20s  Val. loss: 0.2548\n",
      "Epoch 35, 100% \t Train loss: 0.2575 took: 1.21s  Val. loss: 0.2544\n",
      "Epoch 36, 100% \t Train loss: 0.2574 took: 1.21s  Val. loss: 0.2535\n",
      "Epoch 37, 100% \t Train loss: 0.2574 took: 1.22s  Val. loss: 0.2544\n",
      "Epoch 38, 100% \t Train loss: 0.2574 took: 1.22s  Val. loss: 0.2540\n",
      "Epoch 39, 100% \t Train loss: 0.2574 took: 1.22s  Val. loss: 0.2540\n",
      "Epoch 40, 100% \t Train loss: 0.2574 took: 1.22s  Val. loss: 0.2540\n",
      "Epoch 41, 100% \t Train loss: 0.2574 took: 1.22s  Val. loss: 0.2542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, 100% \t Train loss: 0.2574 took: 1.22s  Val. loss: 0.2539\n",
      "Epoch 43, 100% \t Train loss: 0.2574 took: 1.24s  Val. loss: 0.2537\n",
      "Epoch 44, 100% \t Train loss: 0.2573 took: 1.26s  Val. loss: 0.2545\n",
      "Epoch 45, 100% \t Train loss: 0.2573 took: 2.01s  Val. loss: 0.2540\n",
      "Epoch 46, 100% \t Train loss: 0.2574 took: 2.02s  Val. loss: 0.2541\n",
      "Epoch 47, 100% \t Train loss: 0.2574 took: 2.03s  Val. loss: 0.2538\n",
      "Epoch 48, 100% \t Train loss: 0.2574 took: 2.02s  Val. loss: 0.2545\n",
      "Epoch 49, 100% \t Train loss: 0.2574 took: 2.04s  Val. loss: 0.2537\n",
      "Epoch 50, 100% \t Train loss: 0.2574 took: 2.06s  Val. loss: 0.2544\n",
      "Training finished, took 83.60s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2574 took: 1.74s  Val. loss: 0.2588\n",
      "Epoch 2, 100% \t Train loss: 0.2568 took: 1.72s  Val. loss: 0.2596\n",
      "Epoch 3, 100% \t Train loss: 0.2568 took: 1.75s  Val. loss: 0.2598\n",
      "Epoch 4, 100% \t Train loss: 0.2556 took: 1.75s  Val. loss: 0.2559\n",
      "Epoch 5, 100% \t Train loss: 0.2383 took: 1.73s  Val. loss: 0.2192\n",
      "Epoch 6, 100% \t Train loss: 0.2079 took: 1.72s  Val. loss: 0.1934\n",
      "Epoch 7, 100% \t Train loss: 0.1883 took: 1.74s  Val. loss: 0.1843\n",
      "Epoch 8, 100% \t Train loss: 0.1764 took: 1.74s  Val. loss: 0.1857\n",
      "Epoch 9, 100% \t Train loss: 0.1713 took: 1.69s  Val. loss: 0.1790\n",
      "Epoch 10, 100% \t Train loss: 0.1694 took: 1.72s  Val. loss: 0.1754\n",
      "Epoch 11, 100% \t Train loss: 0.1673 took: 1.73s  Val. loss: 0.1758\n",
      "Epoch 12, 100% \t Train loss: 0.1665 took: 1.73s  Val. loss: 0.1748\n",
      "Epoch 13, 100% \t Train loss: 0.1668 took: 1.72s  Val. loss: 0.1786\n",
      "Epoch 14, 100% \t Train loss: 0.1624 took: 1.72s  Val. loss: 0.1749\n",
      "Epoch 15, 100% \t Train loss: 0.1605 took: 1.73s  Val. loss: 0.1698\n",
      "Epoch 16, 100% \t Train loss: 0.1599 took: 1.73s  Val. loss: 0.1782\n",
      "Epoch 17, 100% \t Train loss: 0.1601 took: 1.75s  Val. loss: 0.1700\n",
      "Epoch 18, 100% \t Train loss: 0.1580 took: 1.75s  Val. loss: 0.1720\n",
      "Epoch 19, 100% \t Train loss: 0.1585 took: 1.74s  Val. loss: 0.1741\n",
      "Epoch 20, 100% \t Train loss: 0.1564 took: 1.73s  Val. loss: 0.1682\n",
      "Epoch 21, 100% \t Train loss: 0.1540 took: 1.75s  Val. loss: 0.1679\n",
      "Epoch 22, 100% \t Train loss: 0.1543 took: 1.72s  Val. loss: 0.1684\n",
      "Epoch 23, 100% \t Train loss: 0.1538 took: 1.07s  Val. loss: 0.1660\n",
      "Epoch 24, 100% \t Train loss: 0.1509 took: 1.68s  Val. loss: 0.1654\n",
      "Epoch 25, 100% \t Train loss: 0.1522 took: 1.71s  Val. loss: 0.1663\n",
      "Epoch 26, 100% \t Train loss: 0.1519 took: 1.71s  Val. loss: 0.1674\n",
      "Epoch 27, 100% \t Train loss: 0.1498 took: 1.70s  Val. loss: 0.1648\n",
      "Epoch 28, 100% \t Train loss: 0.1509 took: 1.72s  Val. loss: 0.1646\n",
      "Epoch 29, 100% \t Train loss: 0.1488 took: 1.77s  Val. loss: 0.1639\n",
      "Epoch 30, 100% \t Train loss: 0.1492 took: 1.76s  Val. loss: 0.1646\n",
      "Epoch 31, 100% \t Train loss: 0.1487 took: 1.79s  Val. loss: 0.1677\n",
      "Epoch 32, 100% \t Train loss: 0.1475 took: 1.82s  Val. loss: 0.1637\n",
      "Epoch 33, 100% \t Train loss: 0.1469 took: 1.83s  Val. loss: 0.1675\n",
      "Epoch 34, 100% \t Train loss: 0.1495 took: 1.84s  Val. loss: 0.1665\n",
      "Epoch 35, 100% \t Train loss: 0.1468 took: 1.83s  Val. loss: 0.1650\n",
      "Epoch 36, 100% \t Train loss: 0.1462 took: 1.85s  Val. loss: 0.1640\n",
      "Epoch 37, 100% \t Train loss: 0.1453 took: 1.87s  Val. loss: 0.1643\n",
      "Epoch 38, 100% \t Train loss: 0.1459 took: 1.88s  Val. loss: 0.1634\n",
      "Epoch 39, 100% \t Train loss: 0.1456 took: 1.90s  Val. loss: 0.1687\n",
      "Epoch 40, 100% \t Train loss: 0.1469 took: 1.90s  Val. loss: 0.1624\n",
      "Epoch 41, 100% \t Train loss: 0.1444 took: 1.93s  Val. loss: 0.1638\n",
      "Epoch 42, 100% \t Train loss: 0.1442 took: 1.90s  Val. loss: 0.1631\n",
      "Epoch 43, 100% \t Train loss: 0.1436 took: 1.91s  Val. loss: 0.1634\n",
      "Epoch 44, 100% \t Train loss: 0.1447 took: 1.94s  Val. loss: 0.1627\n",
      "Epoch 45, 100% \t Train loss: 0.1434 took: 1.09s  Val. loss: 0.1653\n",
      "Epoch 46, 100% \t Train loss: 0.1433 took: 1.08s  Val. loss: 0.1654\n",
      "Epoch 47, 100% \t Train loss: 0.1437 took: 1.09s  Val. loss: 0.1661\n",
      "Epoch 48, 100% \t Train loss: 0.1431 took: 1.09s  Val. loss: 0.1629\n",
      "Epoch 49, 100% \t Train loss: 0.1421 took: 1.09s  Val. loss: 0.1636\n",
      "Epoch 50, 100% \t Train loss: 0.1420 took: 1.08s  Val. loss: 0.1638\n",
      "Training finished, took 95.64s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2612 took: 1.70s  Val. loss: 0.2559\n",
      "Epoch 2, 100% \t Train loss: 0.2609 took: 1.71s  Val. loss: 0.2566\n",
      "Epoch 3, 100% \t Train loss: 0.2608 took: 1.71s  Val. loss: 0.2557\n",
      "Epoch 4, 100% \t Train loss: 0.2609 took: 1.71s  Val. loss: 0.2561\n",
      "Epoch 5, 100% \t Train loss: 0.2608 took: 1.71s  Val. loss: 0.2568\n",
      "Epoch 6, 100% \t Train loss: 0.2608 took: 1.71s  Val. loss: 0.2552\n",
      "Epoch 7, 100% \t Train loss: 0.2608 took: 1.71s  Val. loss: 0.2566\n",
      "Epoch 8, 100% \t Train loss: 0.2609 took: 1.72s  Val. loss: 0.2559\n",
      "Epoch 9, 100% \t Train loss: 0.2608 took: 1.72s  Val. loss: 0.2556\n",
      "Epoch 10, 100% \t Train loss: 0.2607 took: 1.71s  Val. loss: 0.2566\n",
      "Epoch 11, 100% \t Train loss: 0.2606 took: 1.72s  Val. loss: 0.2565\n",
      "Epoch 12, 100% \t Train loss: 0.2604 took: 1.73s  Val. loss: 0.2555\n",
      "Epoch 13, 100% \t Train loss: 0.2598 took: 1.71s  Val. loss: 0.2539\n",
      "Epoch 14, 100% \t Train loss: 0.2544 took: 1.71s  Val. loss: 0.2455\n",
      "Epoch 15, 100% \t Train loss: 0.2374 took: 1.69s  Val. loss: 0.2300\n",
      "Epoch 16, 100% \t Train loss: 0.2249 took: 1.01s  Val. loss: 0.2248\n",
      "Epoch 17, 100% \t Train loss: 0.2154 took: 0.99s  Val. loss: 0.2116\n",
      "Epoch 18, 100% \t Train loss: 0.2074 took: 0.99s  Val. loss: 0.2035\n",
      "Epoch 19, 100% \t Train loss: 0.2014 took: 0.98s  Val. loss: 0.1981\n",
      "Epoch 20, 100% \t Train loss: 0.1941 took: 0.99s  Val. loss: 0.2026\n",
      "Epoch 21, 100% \t Train loss: 0.1932 took: 0.98s  Val. loss: 0.1897\n",
      "Epoch 22, 100% \t Train loss: 0.1884 took: 0.98s  Val. loss: 0.1898\n",
      "Epoch 23, 100% \t Train loss: 0.1886 took: 0.98s  Val. loss: 0.1989\n",
      "Epoch 24, 100% \t Train loss: 0.1859 took: 0.98s  Val. loss: 0.1982\n",
      "Epoch 25, 100% \t Train loss: 0.1854 took: 0.98s  Val. loss: 0.1845\n",
      "Epoch 26, 100% \t Train loss: 0.1794 took: 0.98s  Val. loss: 0.1807\n",
      "Epoch 27, 100% \t Train loss: 0.1802 took: 0.98s  Val. loss: 0.1822\n",
      "Epoch 28, 100% \t Train loss: 0.1785 took: 0.98s  Val. loss: 0.1832\n",
      "Epoch 29, 100% \t Train loss: 0.1775 took: 0.98s  Val. loss: 0.1836\n",
      "Epoch 30, 100% \t Train loss: 0.1734 took: 0.99s  Val. loss: 0.1793\n",
      "Epoch 31, 100% \t Train loss: 0.1757 took: 1.00s  Val. loss: 0.1819\n",
      "Epoch 32, 100% \t Train loss: 0.1727 took: 1.01s  Val. loss: 0.1770\n",
      "Epoch 33, 100% \t Train loss: 0.1712 took: 1.00s  Val. loss: 0.1793\n",
      "Epoch 34, 100% \t Train loss: 0.1723 took: 1.00s  Val. loss: 0.1787\n",
      "Epoch 35, 100% \t Train loss: 0.1728 took: 1.01s  Val. loss: 0.1754\n",
      "Epoch 36, 100% \t Train loss: 0.1703 took: 1.01s  Val. loss: 0.1715\n",
      "Epoch 37, 100% \t Train loss: 0.1684 took: 1.00s  Val. loss: 0.1741\n",
      "Epoch 38, 100% \t Train loss: 0.1713 took: 1.00s  Val. loss: 0.1719\n",
      "Epoch 39, 100% \t Train loss: 0.1682 took: 1.01s  Val. loss: 0.1751\n",
      "Epoch 40, 100% \t Train loss: 0.1679 took: 1.02s  Val. loss: 0.1702\n",
      "Epoch 41, 100% \t Train loss: 0.1664 took: 1.02s  Val. loss: 0.1693\n",
      "Epoch 42, 100% \t Train loss: 0.1661 took: 1.02s  Val. loss: 0.1738\n",
      "Epoch 43, 100% \t Train loss: 0.1669 took: 1.03s  Val. loss: 0.1731\n",
      "Epoch 44, 100% \t Train loss: 0.1646 took: 1.03s  Val. loss: 0.1733\n",
      "Epoch 45, 100% \t Train loss: 0.1656 took: 1.03s  Val. loss: 0.1711\n",
      "Epoch 46, 100% \t Train loss: 0.1634 took: 1.04s  Val. loss: 0.1685\n",
      "Epoch 47, 100% \t Train loss: 0.1637 took: 1.04s  Val. loss: 0.1696\n",
      "Epoch 48, 100% \t Train loss: 0.1634 took: 1.04s  Val. loss: 0.1685\n",
      "Epoch 49, 100% \t Train loss: 0.1612 took: 1.06s  Val. loss: 0.1683\n",
      "Epoch 50, 100% \t Train loss: 0.1618 took: 1.07s  Val. loss: 0.1676\n",
      "Training finished, took 69.19s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.745886\n",
      "lambda: 0.0010 - V: 0.822803\n",
      "lambda: 0.0005 - V: 0.796572\n",
      "Average V: 0.788421\n",
      "Time elapsed: 251.83 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2596 took: 1.77s  Val. loss: 0.2580\n",
      "Epoch 2, 100% \t Train loss: 0.2594 took: 1.80s  Val. loss: 0.2580\n",
      "Epoch 3, 100% \t Train loss: 0.2590 took: 1.83s  Val. loss: 0.2597\n",
      "Epoch 4, 100% \t Train loss: 0.2592 took: 1.81s  Val. loss: 0.2592\n",
      "Epoch 5, 100% \t Train loss: 0.2588 took: 1.79s  Val. loss: 0.2602\n",
      "Epoch 6, 100% \t Train loss: 0.2590 took: 1.80s  Val. loss: 0.2587\n",
      "Epoch 7, 100% \t Train loss: 0.2590 took: 1.80s  Val. loss: 0.2582\n",
      "Epoch 8, 100% \t Train loss: 0.2552 took: 1.80s  Val. loss: 0.2342\n",
      "Epoch 9, 100% \t Train loss: 0.1974 took: 1.79s  Val. loss: 0.1794\n",
      "Epoch 10, 100% \t Train loss: 0.1665 took: 1.80s  Val. loss: 0.1748\n",
      "Epoch 11, 100% \t Train loss: 0.1595 took: 1.80s  Val. loss: 0.1720\n",
      "Epoch 12, 100% \t Train loss: 0.1563 took: 1.79s  Val. loss: 0.1713\n",
      "Epoch 13, 100% \t Train loss: 0.1546 took: 1.78s  Val. loss: 0.1723\n",
      "Epoch 14, 100% \t Train loss: 0.1540 took: 1.81s  Val. loss: 0.1720\n",
      "Epoch 15, 100% \t Train loss: 0.1528 took: 1.80s  Val. loss: 0.1690\n",
      "Epoch 16, 100% \t Train loss: 0.1511 took: 1.80s  Val. loss: 0.1698\n",
      "Epoch 17, 100% \t Train loss: 0.1505 took: 1.80s  Val. loss: 0.1725\n",
      "Epoch 18, 100% \t Train loss: 0.1510 took: 1.80s  Val. loss: 0.1722\n",
      "Epoch 19, 100% \t Train loss: 0.1504 took: 1.81s  Val. loss: 0.1684\n",
      "Epoch 20, 100% \t Train loss: 0.1487 took: 1.81s  Val. loss: 0.1711\n",
      "Epoch 21, 100% \t Train loss: 0.1489 took: 1.81s  Val. loss: 0.1734\n",
      "Epoch 22, 100% \t Train loss: 0.1489 took: 1.82s  Val. loss: 0.1677\n",
      "Epoch 23, 100% \t Train loss: 0.1479 took: 1.81s  Val. loss: 0.1719\n",
      "Epoch 24, 100% \t Train loss: 0.1477 took: 1.80s  Val. loss: 0.1751\n",
      "Epoch 25, 100% \t Train loss: 0.1479 took: 1.81s  Val. loss: 0.1698\n",
      "Epoch 26, 100% \t Train loss: 0.1475 took: 1.80s  Val. loss: 0.1678\n",
      "Epoch 27, 100% \t Train loss: 0.1469 took: 1.80s  Val. loss: 0.1708\n",
      "Epoch 28, 100% \t Train loss: 0.1461 took: 1.80s  Val. loss: 0.1698\n",
      "Epoch 29, 100% \t Train loss: 0.1464 took: 1.82s  Val. loss: 0.1743\n",
      "Epoch 30, 100% \t Train loss: 0.1456 took: 1.85s  Val. loss: 0.1731\n",
      "Epoch 31, 100% \t Train loss: 0.1456 took: 1.84s  Val. loss: 0.1736\n",
      "Epoch 32, 100% \t Train loss: 0.1465 took: 1.86s  Val. loss: 0.1743\n",
      "Epoch 33, 100% \t Train loss: 0.1457 took: 1.88s  Val. loss: 0.1721\n",
      "Epoch 34, 100% \t Train loss: 0.1452 took: 1.89s  Val. loss: 0.1764\n",
      "Epoch 35, 100% \t Train loss: 0.1452 took: 1.91s  Val. loss: 0.1710\n",
      "Epoch 36, 100% \t Train loss: 0.1455 took: 1.90s  Val. loss: 0.1713\n",
      "Epoch 37, 100% \t Train loss: 0.1449 took: 1.91s  Val. loss: 0.1736\n",
      "Epoch 38, 100% \t Train loss: 0.1444 took: 1.91s  Val. loss: 0.1708\n",
      "Epoch 39, 100% \t Train loss: 0.1442 took: 1.92s  Val. loss: 0.1765\n",
      "Epoch 40, 100% \t Train loss: 0.1440 took: 1.90s  Val. loss: 0.1701\n",
      "Epoch 41, 100% \t Train loss: 0.1447 took: 1.92s  Val. loss: 0.1751\n",
      "Epoch 42, 100% \t Train loss: 0.1443 took: 1.91s  Val. loss: 0.1746\n",
      "Epoch 43, 100% \t Train loss: 0.1439 took: 1.92s  Val. loss: 0.1769\n",
      "Epoch 44, 100% \t Train loss: 0.1432 took: 1.91s  Val. loss: 0.1748\n",
      "Epoch 45, 100% \t Train loss: 0.1426 took: 1.89s  Val. loss: 0.1765\n",
      "Epoch 46, 100% \t Train loss: 0.1434 took: 1.89s  Val. loss: 0.1787\n",
      "Epoch 47, 100% \t Train loss: 0.1430 took: 1.89s  Val. loss: 0.1769\n",
      "Epoch 48, 100% \t Train loss: 0.1423 took: 1.89s  Val. loss: 0.1779\n",
      "Epoch 49, 100% \t Train loss: 0.1426 took: 1.90s  Val. loss: 0.1808\n",
      "Epoch 50, 100% \t Train loss: 0.1422 took: 1.90s  Val. loss: 0.1743\n",
      "Training finished, took 104.47s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2582 took: 1.82s  Val. loss: 0.2675\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.81s  Val. loss: 0.2682\n",
      "Epoch 3, 100% \t Train loss: 0.2578 took: 1.82s  Val. loss: 0.2675\n",
      "Epoch 4, 100% \t Train loss: 0.2577 took: 1.81s  Val. loss: 0.2674\n",
      "Epoch 5, 100% \t Train loss: 0.2577 took: 1.83s  Val. loss: 0.2674\n",
      "Epoch 6, 100% \t Train loss: 0.2572 took: 1.82s  Val. loss: 0.2667\n",
      "Epoch 7, 100% \t Train loss: 0.2512 took: 1.80s  Val. loss: 0.2483\n",
      "Epoch 8, 100% \t Train loss: 0.2187 took: 1.80s  Val. loss: 0.2180\n",
      "Epoch 9, 100% \t Train loss: 0.1962 took: 1.80s  Val. loss: 0.2025\n",
      "Epoch 10, 100% \t Train loss: 0.1853 took: 1.80s  Val. loss: 0.1968\n",
      "Epoch 11, 100% \t Train loss: 0.1804 took: 1.80s  Val. loss: 0.1947\n",
      "Epoch 12, 100% \t Train loss: 0.1764 took: 1.81s  Val. loss: 0.1865\n",
      "Epoch 13, 100% \t Train loss: 0.1738 took: 1.81s  Val. loss: 0.1866\n",
      "Epoch 14, 100% \t Train loss: 0.1736 took: 1.81s  Val. loss: 0.1897\n",
      "Epoch 15, 100% \t Train loss: 0.1726 took: 1.82s  Val. loss: 0.1825\n",
      "Epoch 16, 100% \t Train loss: 0.1709 took: 1.80s  Val. loss: 0.2007\n",
      "Epoch 17, 100% \t Train loss: 0.1701 took: 1.81s  Val. loss: 0.1819\n",
      "Epoch 18, 100% \t Train loss: 0.1692 took: 1.83s  Val. loss: 0.1817\n",
      "Epoch 19, 100% \t Train loss: 0.1660 took: 1.80s  Val. loss: 0.1839\n",
      "Epoch 20, 100% \t Train loss: 0.1661 took: 1.82s  Val. loss: 0.1822\n",
      "Epoch 21, 100% \t Train loss: 0.1646 took: 1.81s  Val. loss: 0.1750\n",
      "Epoch 22, 100% \t Train loss: 0.1630 took: 1.82s  Val. loss: 0.1789\n",
      "Epoch 23, 100% \t Train loss: 0.1612 took: 1.80s  Val. loss: 0.1779\n",
      "Epoch 24, 100% \t Train loss: 0.1606 took: 1.80s  Val. loss: 0.1747\n",
      "Epoch 25, 100% \t Train loss: 0.1601 took: 1.79s  Val. loss: 0.1757\n",
      "Epoch 26, 100% \t Train loss: 0.1593 took: 1.81s  Val. loss: 0.1806\n",
      "Epoch 27, 100% \t Train loss: 0.1600 took: 1.80s  Val. loss: 0.1770\n",
      "Epoch 28, 100% \t Train loss: 0.1595 took: 1.82s  Val. loss: 0.1720\n",
      "Epoch 29, 100% \t Train loss: 0.1569 took: 1.84s  Val. loss: 0.1713\n",
      "Epoch 30, 100% \t Train loss: 0.1628 took: 1.85s  Val. loss: 0.1780\n",
      "Epoch 31, 100% \t Train loss: 0.1571 took: 1.87s  Val. loss: 0.1698\n",
      "Epoch 32, 100% \t Train loss: 0.1573 took: 1.88s  Val. loss: 0.1739\n",
      "Epoch 33, 100% \t Train loss: 0.1578 took: 1.88s  Val. loss: 0.1713\n",
      "Epoch 34, 100% \t Train loss: 0.1546 took: 1.90s  Val. loss: 0.1715\n",
      "Epoch 35, 100% \t Train loss: 0.1543 took: 1.92s  Val. loss: 0.1729\n",
      "Epoch 36, 100% \t Train loss: 0.1549 took: 1.91s  Val. loss: 0.1707\n",
      "Epoch 37, 100% \t Train loss: 0.1562 took: 1.91s  Val. loss: 0.1798\n",
      "Epoch 38, 100% \t Train loss: 0.1548 took: 1.91s  Val. loss: 0.1695\n",
      "Epoch 39, 100% \t Train loss: 0.1537 took: 1.92s  Val. loss: 0.1722\n",
      "Epoch 40, 100% \t Train loss: 0.1533 took: 1.91s  Val. loss: 0.1727\n",
      "Epoch 41, 100% \t Train loss: 0.1538 took: 1.92s  Val. loss: 0.1697\n",
      "Epoch 42, 100% \t Train loss: 0.1529 took: 1.96s  Val. loss: 0.1711\n",
      "Epoch 43, 100% \t Train loss: 0.1526 took: 1.92s  Val. loss: 0.1711\n",
      "Epoch 44, 100% \t Train loss: 0.1538 took: 1.94s  Val. loss: 0.1720\n",
      "Epoch 45, 100% \t Train loss: 0.1533 took: 1.93s  Val. loss: 0.1693\n",
      "Epoch 46, 100% \t Train loss: 0.1518 took: 1.97s  Val. loss: 0.1718\n",
      "Epoch 47, 100% \t Train loss: 0.1521 took: 2.01s  Val. loss: 0.1707\n",
      "Epoch 48, 100% \t Train loss: 0.1517 took: 2.06s  Val. loss: 0.1702\n",
      "Epoch 49, 100% \t Train loss: 0.1515 took: 2.06s  Val. loss: 0.1696\n",
      "Epoch 50, 100% \t Train loss: 0.1529 took: 1.27s  Val. loss: 0.1721\n",
      "Training finished, took 105.04s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2608 took: 1.67s  Val. loss: 0.2588\n",
      "Epoch 2, 100% \t Train loss: 0.2595 took: 1.81s  Val. loss: 0.2579\n",
      "Epoch 3, 100% \t Train loss: 0.2592 took: 1.79s  Val. loss: 0.2570\n",
      "Epoch 4, 100% \t Train loss: 0.2579 took: 1.80s  Val. loss: 0.2556\n",
      "Epoch 5, 100% \t Train loss: 0.2524 took: 1.80s  Val. loss: 0.2430\n",
      "Epoch 6, 100% \t Train loss: 0.2191 took: 1.81s  Val. loss: 0.2040\n",
      "Epoch 7, 100% \t Train loss: 0.1893 took: 1.81s  Val. loss: 0.1910\n",
      "Epoch 8, 100% \t Train loss: 0.1767 took: 1.80s  Val. loss: 0.1839\n",
      "Epoch 9, 100% \t Train loss: 0.1714 took: 1.80s  Val. loss: 0.1783\n",
      "Epoch 10, 100% \t Train loss: 0.1686 took: 1.82s  Val. loss: 0.1842\n",
      "Epoch 11, 100% \t Train loss: 0.1683 took: 1.77s  Val. loss: 0.1822\n",
      "Epoch 12, 100% \t Train loss: 0.1661 took: 1.80s  Val. loss: 0.1749\n",
      "Epoch 13, 100% \t Train loss: 0.1648 took: 1.04s  Val. loss: 0.1748\n",
      "Epoch 14, 100% \t Train loss: 0.1629 took: 1.04s  Val. loss: 0.1727\n",
      "Epoch 15, 100% \t Train loss: 0.1625 took: 1.04s  Val. loss: 0.1749\n",
      "Epoch 16, 100% \t Train loss: 0.1622 took: 1.04s  Val. loss: 0.1752\n",
      "Epoch 17, 100% \t Train loss: 0.1611 took: 1.03s  Val. loss: 0.1733\n",
      "Epoch 18, 100% \t Train loss: 0.1595 took: 1.03s  Val. loss: 0.1776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1624 took: 1.05s  Val. loss: 0.1737\n",
      "Epoch 20, 100% \t Train loss: 0.1587 took: 1.03s  Val. loss: 0.1723\n",
      "Epoch 21, 100% \t Train loss: 0.1590 took: 1.03s  Val. loss: 0.1831\n",
      "Epoch 22, 100% \t Train loss: 0.1585 took: 1.03s  Val. loss: 0.1743\n",
      "Epoch 23, 100% \t Train loss: 0.1562 took: 1.03s  Val. loss: 0.1728\n",
      "Epoch 24, 100% \t Train loss: 0.1572 took: 1.04s  Val. loss: 0.1739\n",
      "Epoch 25, 100% \t Train loss: 0.1554 took: 1.03s  Val. loss: 0.1739\n",
      "Epoch 26, 100% \t Train loss: 0.1542 took: 1.03s  Val. loss: 0.1719\n",
      "Epoch 27, 100% \t Train loss: 0.1537 took: 1.03s  Val. loss: 0.1712\n",
      "Epoch 28, 100% \t Train loss: 0.1548 took: 1.03s  Val. loss: 0.1709\n",
      "Epoch 29, 100% \t Train loss: 0.1543 took: 1.03s  Val. loss: 0.1737\n",
      "Epoch 30, 100% \t Train loss: 0.1529 took: 1.04s  Val. loss: 0.1752\n",
      "Epoch 31, 100% \t Train loss: 0.1533 took: 1.05s  Val. loss: 0.1741\n",
      "Epoch 32, 100% \t Train loss: 0.1524 took: 1.05s  Val. loss: 0.1707\n",
      "Epoch 33, 100% \t Train loss: 0.1517 took: 1.06s  Val. loss: 0.1699\n",
      "Epoch 34, 100% \t Train loss: 0.1516 took: 1.06s  Val. loss: 0.1725\n",
      "Epoch 35, 100% \t Train loss: 0.1516 took: 1.08s  Val. loss: 0.1725\n",
      "Epoch 36, 100% \t Train loss: 0.1500 took: 1.08s  Val. loss: 0.1711\n",
      "Epoch 37, 100% \t Train loss: 0.1497 took: 1.08s  Val. loss: 0.1721\n",
      "Epoch 38, 100% \t Train loss: 0.1506 took: 1.09s  Val. loss: 0.1706\n",
      "Epoch 39, 100% \t Train loss: 0.1499 took: 1.09s  Val. loss: 0.1711\n",
      "Epoch 40, 100% \t Train loss: 0.1488 took: 1.10s  Val. loss: 0.1697\n",
      "Epoch 41, 100% \t Train loss: 0.1494 took: 1.12s  Val. loss: 0.1722\n",
      "Epoch 42, 100% \t Train loss: 0.1499 took: 1.11s  Val. loss: 0.1758\n",
      "Epoch 43, 100% \t Train loss: 0.1494 took: 1.11s  Val. loss: 0.1716\n",
      "Epoch 44, 100% \t Train loss: 0.1488 took: 1.11s  Val. loss: 0.1713\n",
      "Epoch 45, 100% \t Train loss: 0.1497 took: 1.10s  Val. loss: 0.1697\n",
      "Epoch 46, 100% \t Train loss: 0.1479 took: 1.10s  Val. loss: 0.1706\n",
      "Epoch 47, 100% \t Train loss: 0.1474 took: 1.10s  Val. loss: 0.1710\n",
      "Epoch 48, 100% \t Train loss: 0.1472 took: 1.10s  Val. loss: 0.1721\n",
      "Epoch 49, 100% \t Train loss: 0.1471 took: 1.10s  Val. loss: 0.1705\n",
      "Epoch 50, 100% \t Train loss: 0.1470 took: 1.11s  Val. loss: 0.1710\n",
      "Training finished, took 70.10s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  64  - prob: 0.34\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.813588\n",
      "lambda: 0.0010 - V: 0.809332\n",
      "lambda: 0.0005 - V: 0.817273\n",
      "Average V: 0.813398\n",
      "Time elapsed: 283.10 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2602 took: 1.07s  Val. loss: 0.2582\n",
      "Epoch 2, 100% \t Train loss: 0.2380 took: 1.06s  Val. loss: 0.1965\n",
      "Epoch 3, 100% \t Train loss: 0.1733 took: 1.06s  Val. loss: 0.1837\n",
      "Epoch 4, 100% \t Train loss: 0.1654 took: 1.07s  Val. loss: 0.1810\n",
      "Epoch 5, 100% \t Train loss: 0.1611 took: 1.06s  Val. loss: 0.1812\n",
      "Epoch 6, 100% \t Train loss: 0.1580 took: 1.06s  Val. loss: 0.1769\n",
      "Epoch 7, 100% \t Train loss: 0.1558 took: 1.06s  Val. loss: 0.1759\n",
      "Epoch 8, 100% \t Train loss: 0.1527 took: 1.06s  Val. loss: 0.1747\n",
      "Epoch 9, 100% \t Train loss: 0.1490 took: 1.06s  Val. loss: 0.1749\n",
      "Epoch 10, 100% \t Train loss: 0.1454 took: 1.06s  Val. loss: 0.1729\n",
      "Epoch 11, 100% \t Train loss: 0.1407 took: 1.06s  Val. loss: 0.1670\n",
      "Epoch 12, 100% \t Train loss: 0.1330 took: 1.06s  Val. loss: 0.1541\n",
      "Epoch 13, 100% \t Train loss: 0.1212 took: 1.05s  Val. loss: 0.1484\n",
      "Epoch 14, 100% \t Train loss: 0.1084 took: 1.06s  Val. loss: 0.1281\n",
      "Epoch 15, 100% \t Train loss: 0.0991 took: 1.06s  Val. loss: 0.1236\n",
      "Epoch 16, 100% \t Train loss: 0.0914 took: 1.05s  Val. loss: 0.1209\n",
      "Epoch 17, 100% \t Train loss: 0.0886 took: 1.05s  Val. loss: 0.1161\n",
      "Epoch 18, 100% \t Train loss: 0.0857 took: 1.06s  Val. loss: 0.1092\n",
      "Epoch 19, 100% \t Train loss: 0.0830 took: 1.06s  Val. loss: 0.1063\n",
      "Epoch 20, 100% \t Train loss: 0.0808 took: 1.06s  Val. loss: 0.1053\n",
      "Epoch 21, 100% \t Train loss: 0.0783 took: 1.06s  Val. loss: 0.1066\n",
      "Epoch 22, 100% \t Train loss: 0.0775 took: 1.06s  Val. loss: 0.1040\n",
      "Epoch 23, 100% \t Train loss: 0.0768 took: 1.06s  Val. loss: 0.1050\n",
      "Epoch 24, 100% \t Train loss: 0.0758 took: 1.07s  Val. loss: 0.1009\n",
      "Epoch 25, 100% \t Train loss: 0.0748 took: 1.12s  Val. loss: 0.0973\n",
      "Epoch 26, 100% \t Train loss: 0.0734 took: 1.06s  Val. loss: 0.1018\n",
      "Epoch 27, 100% \t Train loss: 0.0726 took: 1.07s  Val. loss: 0.1018\n",
      "Epoch 28, 100% \t Train loss: 0.0725 took: 1.06s  Val. loss: 0.1048\n",
      "Epoch 29, 100% \t Train loss: 0.0721 took: 1.08s  Val. loss: 0.1033\n",
      "Epoch 30, 100% \t Train loss: 0.0703 took: 1.09s  Val. loss: 0.0991\n",
      "Epoch 31, 100% \t Train loss: 0.0710 took: 1.10s  Val. loss: 0.1006\n",
      "Epoch 32, 100% \t Train loss: 0.0705 took: 1.11s  Val. loss: 0.1010\n",
      "Epoch 33, 100% \t Train loss: 0.0694 took: 1.17s  Val. loss: 0.1021\n",
      "Epoch 34, 100% \t Train loss: 0.0695 took: 1.18s  Val. loss: 0.1012\n",
      "Epoch 35, 100% \t Train loss: 0.0696 took: 1.20s  Val. loss: 0.0967\n",
      "Epoch 36, 100% \t Train loss: 0.0678 took: 1.20s  Val. loss: 0.0994\n",
      "Epoch 37, 100% \t Train loss: 0.0686 took: 1.19s  Val. loss: 0.0994\n",
      "Epoch 38, 100% \t Train loss: 0.0675 took: 1.20s  Val. loss: 0.1031\n",
      "Epoch 39, 100% \t Train loss: 0.0680 took: 1.20s  Val. loss: 0.1016\n",
      "Epoch 40, 100% \t Train loss: 0.0677 took: 1.19s  Val. loss: 0.1019\n",
      "Epoch 41, 100% \t Train loss: 0.0670 took: 1.19s  Val. loss: 0.1026\n",
      "Epoch 42, 100% \t Train loss: 0.0668 took: 1.20s  Val. loss: 0.1018\n",
      "Epoch 43, 100% \t Train loss: 0.0664 took: 1.20s  Val. loss: 0.1017\n",
      "Epoch 44, 100% \t Train loss: 0.0654 took: 1.21s  Val. loss: 0.1001\n",
      "Epoch 45, 100% \t Train loss: 0.0662 took: 1.21s  Val. loss: 0.1026\n",
      "Epoch 46, 100% \t Train loss: 0.0654 took: 1.21s  Val. loss: 0.1034\n",
      "Epoch 47, 100% \t Train loss: 0.0652 took: 1.21s  Val. loss: 0.1014\n",
      "Epoch 48, 100% \t Train loss: 0.0654 took: 1.21s  Val. loss: 0.1050\n",
      "Epoch 49, 100% \t Train loss: 0.0670 took: 1.22s  Val. loss: 0.0998\n",
      "Epoch 50, 100% \t Train loss: 0.0647 took: 1.21s  Val. loss: 0.1045\n",
      "Training finished, took 63.19s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 1.78s  Val. loss: 0.2605\n",
      "Epoch 2, 100% \t Train loss: 0.2593 took: 1.85s  Val. loss: 0.2593\n",
      "Epoch 3, 100% \t Train loss: 0.2581 took: 1.06s  Val. loss: 0.2555\n",
      "Epoch 4, 100% \t Train loss: 0.2460 took: 1.06s  Val. loss: 0.2232\n",
      "Epoch 5, 100% \t Train loss: 0.2059 took: 1.06s  Val. loss: 0.1888\n",
      "Epoch 6, 100% \t Train loss: 0.1838 took: 1.05s  Val. loss: 0.1815\n",
      "Epoch 7, 100% \t Train loss: 0.1772 took: 1.07s  Val. loss: 0.1840\n",
      "Epoch 8, 100% \t Train loss: 0.1747 took: 1.79s  Val. loss: 0.1765\n",
      "Epoch 9, 100% \t Train loss: 0.1715 took: 1.81s  Val. loss: 0.1807\n",
      "Epoch 10, 100% \t Train loss: 0.1702 took: 1.80s  Val. loss: 0.1744\n",
      "Epoch 11, 100% \t Train loss: 0.1679 took: 1.83s  Val. loss: 0.1839\n",
      "Epoch 12, 100% \t Train loss: 0.1695 took: 1.83s  Val. loss: 0.1727\n",
      "Epoch 13, 100% \t Train loss: 0.1657 took: 1.06s  Val. loss: 0.1713\n",
      "Epoch 14, 100% \t Train loss: 0.1638 took: 1.07s  Val. loss: 0.1705\n",
      "Epoch 15, 100% \t Train loss: 0.1626 took: 1.72s  Val. loss: 0.1689\n",
      "Epoch 16, 100% \t Train loss: 0.1603 took: 1.84s  Val. loss: 0.1717\n",
      "Epoch 17, 100% \t Train loss: 0.1603 took: 1.83s  Val. loss: 0.1696\n",
      "Epoch 18, 100% \t Train loss: 0.1582 took: 1.85s  Val. loss: 0.1694\n",
      "Epoch 19, 100% \t Train loss: 0.1589 took: 1.84s  Val. loss: 0.1683\n",
      "Epoch 20, 100% \t Train loss: 0.1557 took: 1.85s  Val. loss: 0.1680\n",
      "Epoch 21, 100% \t Train loss: 0.1540 took: 1.84s  Val. loss: 0.1677\n",
      "Epoch 22, 100% \t Train loss: 0.1550 took: 1.84s  Val. loss: 0.1689\n",
      "Epoch 23, 100% \t Train loss: 0.1546 took: 1.84s  Val. loss: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.1534 took: 1.83s  Val. loss: 0.1655\n",
      "Epoch 25, 100% \t Train loss: 0.1521 took: 1.81s  Val. loss: 0.1677\n",
      "Epoch 26, 100% \t Train loss: 0.1524 took: 1.83s  Val. loss: 0.1675\n",
      "Epoch 27, 100% \t Train loss: 0.1506 took: 1.85s  Val. loss: 0.1652\n",
      "Epoch 28, 100% \t Train loss: 0.1508 took: 1.82s  Val. loss: 0.1675\n",
      "Epoch 29, 100% \t Train loss: 0.1489 took: 1.81s  Val. loss: 0.1680\n",
      "Epoch 30, 100% \t Train loss: 0.1491 took: 1.81s  Val. loss: 0.1662\n",
      "Epoch 31, 100% \t Train loss: 0.1489 took: 1.81s  Val. loss: 0.1661\n",
      "Epoch 32, 100% \t Train loss: 0.1488 took: 1.81s  Val. loss: 0.1634\n",
      "Epoch 33, 100% \t Train loss: 0.1474 took: 1.84s  Val. loss: 0.1689\n",
      "Epoch 34, 100% \t Train loss: 0.1470 took: 1.82s  Val. loss: 0.1636\n",
      "Epoch 35, 100% \t Train loss: 0.1463 took: 1.82s  Val. loss: 0.1688\n",
      "Epoch 36, 100% \t Train loss: 0.1461 took: 1.83s  Val. loss: 0.1650\n",
      "Epoch 37, 100% \t Train loss: 0.1463 took: 1.82s  Val. loss: 0.1656\n",
      "Epoch 38, 100% \t Train loss: 0.1453 took: 1.83s  Val. loss: 0.1693\n",
      "Epoch 39, 100% \t Train loss: 0.1464 took: 1.06s  Val. loss: 0.1648\n",
      "Epoch 40, 100% \t Train loss: 0.1433 took: 1.06s  Val. loss: 0.1644\n",
      "Epoch 41, 100% \t Train loss: 0.1435 took: 1.12s  Val. loss: 0.1668\n",
      "Epoch 42, 100% \t Train loss: 0.1417 took: 1.80s  Val. loss: 0.1639\n",
      "Epoch 43, 100% \t Train loss: 0.1399 took: 1.83s  Val. loss: 0.1619\n",
      "Epoch 44, 100% \t Train loss: 0.1400 took: 1.82s  Val. loss: 0.1604\n",
      "Epoch 45, 100% \t Train loss: 0.1372 took: 1.81s  Val. loss: 0.1606\n",
      "Epoch 46, 100% \t Train loss: 0.1351 took: 1.83s  Val. loss: 0.1577\n",
      "Epoch 47, 100% \t Train loss: 0.1311 took: 1.81s  Val. loss: 0.1514\n",
      "Epoch 48, 100% \t Train loss: 0.1276 took: 1.80s  Val. loss: 0.1486\n",
      "Epoch 49, 100% \t Train loss: 0.1234 took: 1.81s  Val. loss: 0.1464\n",
      "Epoch 50, 100% \t Train loss: 0.1203 took: 1.82s  Val. loss: 0.1416\n",
      "Training finished, took 95.32s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2582 took: 1.08s  Val. loss: 0.2605\n",
      "Epoch 2, 100% \t Train loss: 0.2580 took: 1.07s  Val. loss: 0.2593\n",
      "Epoch 3, 100% \t Train loss: 0.2581 took: 1.07s  Val. loss: 0.2592\n",
      "Epoch 4, 100% \t Train loss: 0.2580 took: 1.06s  Val. loss: 0.2590\n",
      "Epoch 5, 100% \t Train loss: 0.2581 took: 1.07s  Val. loss: 0.2598\n",
      "Epoch 6, 100% \t Train loss: 0.2581 took: 1.07s  Val. loss: 0.2600\n",
      "Epoch 7, 100% \t Train loss: 0.2578 took: 1.07s  Val. loss: 0.2590\n",
      "Epoch 8, 100% \t Train loss: 0.2578 took: 1.07s  Val. loss: 0.2588\n",
      "Epoch 9, 100% \t Train loss: 0.2573 took: 1.07s  Val. loss: 0.2583\n",
      "Epoch 10, 100% \t Train loss: 0.2548 took: 1.07s  Val. loss: 0.2525\n",
      "Epoch 11, 100% \t Train loss: 0.2419 took: 1.07s  Val. loss: 0.2311\n",
      "Epoch 12, 100% \t Train loss: 0.2197 took: 1.07s  Val. loss: 0.2100\n",
      "Epoch 13, 100% \t Train loss: 0.2015 took: 1.07s  Val. loss: 0.1967\n",
      "Epoch 14, 100% \t Train loss: 0.1907 took: 1.07s  Val. loss: 0.1891\n",
      "Epoch 15, 100% \t Train loss: 0.1829 took: 1.07s  Val. loss: 0.1881\n",
      "Epoch 16, 100% \t Train loss: 0.1797 took: 1.06s  Val. loss: 0.1835\n",
      "Epoch 17, 100% \t Train loss: 0.1781 took: 1.07s  Val. loss: 0.1888\n",
      "Epoch 18, 100% \t Train loss: 0.1770 took: 1.07s  Val. loss: 0.1894\n",
      "Epoch 19, 100% \t Train loss: 0.1744 took: 1.07s  Val. loss: 0.1877\n",
      "Epoch 20, 100% \t Train loss: 0.1741 took: 1.07s  Val. loss: 0.1817\n",
      "Epoch 21, 100% \t Train loss: 0.1727 took: 1.07s  Val. loss: 0.1820\n",
      "Epoch 22, 100% \t Train loss: 0.1723 took: 1.07s  Val. loss: 0.1833\n",
      "Epoch 23, 100% \t Train loss: 0.1718 took: 1.07s  Val. loss: 0.1884\n",
      "Epoch 24, 100% \t Train loss: 0.1716 took: 1.07s  Val. loss: 0.1837\n",
      "Epoch 25, 100% \t Train loss: 0.1685 took: 1.07s  Val. loss: 0.1845\n",
      "Epoch 26, 100% \t Train loss: 0.1692 took: 1.07s  Val. loss: 0.1792\n",
      "Epoch 27, 100% \t Train loss: 0.1690 took: 1.08s  Val. loss: 0.1844\n",
      "Epoch 28, 100% \t Train loss: 0.1687 took: 1.08s  Val. loss: 0.1797\n",
      "Epoch 29, 100% \t Train loss: 0.1673 took: 1.07s  Val. loss: 0.1791\n",
      "Epoch 30, 100% \t Train loss: 0.1653 took: 1.07s  Val. loss: 0.1778\n",
      "Epoch 31, 100% \t Train loss: 0.1657 took: 1.08s  Val. loss: 0.1862\n",
      "Epoch 32, 100% \t Train loss: 0.1667 took: 1.10s  Val. loss: 0.1937\n",
      "Epoch 33, 100% \t Train loss: 0.1661 took: 1.09s  Val. loss: 0.1807\n",
      "Epoch 34, 100% \t Train loss: 0.1642 took: 1.86s  Val. loss: 0.1768\n",
      "Epoch 35, 100% \t Train loss: 0.1627 took: 1.85s  Val. loss: 0.1772\n",
      "Epoch 36, 100% \t Train loss: 0.1621 took: 1.84s  Val. loss: 0.1796\n",
      "Epoch 37, 100% \t Train loss: 0.1619 took: 1.85s  Val. loss: 0.1816\n",
      "Epoch 38, 100% \t Train loss: 0.1624 took: 1.85s  Val. loss: 0.1824\n",
      "Epoch 39, 100% \t Train loss: 0.1613 took: 1.88s  Val. loss: 0.1764\n",
      "Epoch 40, 100% \t Train loss: 0.1603 took: 1.87s  Val. loss: 0.1766\n",
      "Epoch 41, 100% \t Train loss: 0.1590 took: 1.84s  Val. loss: 0.1813\n",
      "Epoch 42, 100% \t Train loss: 0.1596 took: 1.85s  Val. loss: 0.1870\n",
      "Epoch 43, 100% \t Train loss: 0.1630 took: 1.86s  Val. loss: 0.1794\n",
      "Epoch 44, 100% \t Train loss: 0.1588 took: 1.87s  Val. loss: 0.1801\n",
      "Epoch 45, 100% \t Train loss: 0.1592 took: 1.85s  Val. loss: 0.1769\n",
      "Epoch 46, 100% \t Train loss: 0.1588 took: 1.86s  Val. loss: 0.1801\n",
      "Epoch 47, 100% \t Train loss: 0.1599 took: 1.83s  Val. loss: 0.1811\n",
      "Epoch 48, 100% \t Train loss: 0.1584 took: 1.87s  Val. loss: 0.1758\n",
      "Epoch 49, 100% \t Train loss: 0.1587 took: 1.89s  Val. loss: 0.1768\n",
      "Epoch 50, 100% \t Train loss: 0.1573 took: 1.90s  Val. loss: 0.1764\n",
      "Training finished, took 76.06s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  6  - prob: 0.33\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.875812\n",
      "lambda: 0.0010 - V: 0.826222\n",
      "lambda: 0.0005 - V: 0.800786\n",
      "Average V: 0.834273\n",
      "Time elapsed: 238.11 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2592 took: 2.27s  Val. loss: 0.2615\n",
      "Epoch 2, 100% \t Train loss: 0.2588 took: 2.26s  Val. loss: 0.2602\n",
      "Epoch 3, 100% \t Train loss: 0.2588 took: 2.27s  Val. loss: 0.2598\n",
      "Epoch 4, 100% \t Train loss: 0.2587 took: 2.27s  Val. loss: 0.2597\n",
      "Epoch 5, 100% \t Train loss: 0.2587 took: 2.27s  Val. loss: 0.2611\n",
      "Epoch 6, 100% \t Train loss: 0.2587 took: 2.25s  Val. loss: 0.2607\n",
      "Epoch 7, 100% \t Train loss: 0.2587 took: 1.36s  Val. loss: 0.2607\n",
      "Epoch 8, 100% \t Train loss: 0.2587 took: 1.36s  Val. loss: 0.2608\n",
      "Epoch 9, 100% \t Train loss: 0.2587 took: 1.37s  Val. loss: 0.2601\n",
      "Epoch 10, 100% \t Train loss: 0.2587 took: 1.36s  Val. loss: 0.2602\n",
      "Epoch 11, 100% \t Train loss: 0.2587 took: 1.36s  Val. loss: 0.2602\n",
      "Epoch 12, 100% \t Train loss: 0.2587 took: 2.28s  Val. loss: 0.2607\n",
      "Epoch 13, 100% \t Train loss: 0.2587 took: 2.27s  Val. loss: 0.2605\n",
      "Epoch 14, 100% \t Train loss: 0.2587 took: 2.29s  Val. loss: 0.2600\n",
      "Epoch 15, 100% \t Train loss: 0.2588 took: 2.33s  Val. loss: 0.2604\n",
      "Epoch 16, 100% \t Train loss: 0.2587 took: 2.29s  Val. loss: 0.2600\n",
      "Epoch 17, 100% \t Train loss: 0.2587 took: 2.27s  Val. loss: 0.2600\n",
      "Epoch 18, 100% \t Train loss: 0.2587 took: 2.29s  Val. loss: 0.2597\n",
      "Epoch 19, 100% \t Train loss: 0.2587 took: 2.30s  Val. loss: 0.2602\n",
      "Epoch 20, 100% \t Train loss: 0.2587 took: 2.29s  Val. loss: 0.2608\n",
      "Epoch 21, 100% \t Train loss: 0.2587 took: 2.00s  Val. loss: 0.2599\n",
      "Epoch 22, 100% \t Train loss: 0.2587 took: 2.27s  Val. loss: 0.2601\n",
      "Epoch 23, 100% \t Train loss: 0.2587 took: 2.29s  Val. loss: 0.2605\n",
      "Epoch 24, 100% \t Train loss: 0.2587 took: 2.30s  Val. loss: 0.2600\n",
      "Epoch 25, 100% \t Train loss: 0.2586 took: 2.31s  Val. loss: 0.2600\n",
      "Epoch 26, 100% \t Train loss: 0.2587 took: 2.30s  Val. loss: 0.2599\n",
      "Epoch 27, 100% \t Train loss: 0.2587 took: 2.30s  Val. loss: 0.2600\n",
      "Epoch 28, 100% \t Train loss: 0.2587 took: 2.30s  Val. loss: 0.2601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.2587 took: 2.32s  Val. loss: 0.2610\n",
      "Epoch 30, 100% \t Train loss: 0.2587 took: 2.37s  Val. loss: 0.2589\n",
      "Epoch 31, 100% \t Train loss: 0.2587 took: 2.46s  Val. loss: 0.2600\n",
      "Epoch 32, 100% \t Train loss: 0.2587 took: 2.61s  Val. loss: 0.2605\n",
      "Epoch 33, 100% \t Train loss: 0.2587 took: 2.79s  Val. loss: 0.2599\n",
      "Epoch 34, 100% \t Train loss: 0.2587 took: 3.03s  Val. loss: 0.2610\n",
      "Epoch 35, 100% \t Train loss: 0.2587 took: 2.94s  Val. loss: 0.2604\n",
      "Epoch 36, 100% \t Train loss: 0.2586 took: 2.76s  Val. loss: 0.2592\n",
      "Epoch 37, 100% \t Train loss: 0.2587 took: 2.82s  Val. loss: 0.2603\n",
      "Epoch 38, 100% \t Train loss: 0.2587 took: 2.81s  Val. loss: 0.2596\n",
      "Epoch 39, 100% \t Train loss: 0.2587 took: 2.83s  Val. loss: 0.2609\n",
      "Epoch 40, 100% \t Train loss: 0.2587 took: 2.80s  Val. loss: 0.2599\n",
      "Epoch 41, 100% \t Train loss: 0.2587 took: 2.81s  Val. loss: 0.2597\n",
      "Epoch 42, 100% \t Train loss: 0.2587 took: 2.82s  Val. loss: 0.2610\n",
      "Epoch 43, 100% \t Train loss: 0.2587 took: 2.81s  Val. loss: 0.2605\n",
      "Epoch 44, 100% \t Train loss: 0.2587 took: 2.84s  Val. loss: 0.2604\n",
      "Epoch 45, 100% \t Train loss: 0.2587 took: 2.81s  Val. loss: 0.2599\n",
      "Epoch 46, 100% \t Train loss: 0.2587 took: 2.87s  Val. loss: 0.2605\n",
      "Epoch 47, 100% \t Train loss: 0.2586 took: 2.86s  Val. loss: 0.2595\n",
      "Epoch 48, 100% \t Train loss: 0.2586 took: 2.88s  Val. loss: 0.2607\n",
      "Epoch 49, 100% \t Train loss: 0.2586 took: 2.88s  Val. loss: 0.2602\n",
      "Epoch 50, 100% \t Train loss: 0.2587 took: 2.82s  Val. loss: 0.2601\n",
      "Training finished, took 133.87s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 2.30s  Val. loss: 0.2627\n",
      "Epoch 2, 100% \t Train loss: 0.2590 took: 2.29s  Val. loss: 0.2622\n",
      "Epoch 3, 100% \t Train loss: 0.2591 took: 2.29s  Val. loss: 0.2617\n",
      "Epoch 4, 100% \t Train loss: 0.2590 took: 2.28s  Val. loss: 0.2621\n",
      "Epoch 5, 100% \t Train loss: 0.2589 took: 2.28s  Val. loss: 0.2615\n",
      "Epoch 6, 100% \t Train loss: 0.2589 took: 2.29s  Val. loss: 0.2621\n",
      "Epoch 7, 100% \t Train loss: 0.2590 took: 2.30s  Val. loss: 0.2626\n",
      "Epoch 8, 100% \t Train loss: 0.2589 took: 2.30s  Val. loss: 0.2620\n",
      "Epoch 9, 100% \t Train loss: 0.2589 took: 2.29s  Val. loss: 0.2619\n",
      "Epoch 10, 100% \t Train loss: 0.2589 took: 2.30s  Val. loss: 0.2624\n",
      "Epoch 11, 100% \t Train loss: 0.2589 took: 2.30s  Val. loss: 0.2622\n",
      "Epoch 12, 100% \t Train loss: 0.2589 took: 2.30s  Val. loss: 0.2632\n",
      "Epoch 13, 100% \t Train loss: 0.2589 took: 2.29s  Val. loss: 0.2620\n",
      "Epoch 14, 100% \t Train loss: 0.2589 took: 2.31s  Val. loss: 0.2621\n",
      "Epoch 15, 100% \t Train loss: 0.2589 took: 2.28s  Val. loss: 0.2619\n",
      "Epoch 16, 100% \t Train loss: 0.2589 took: 2.28s  Val. loss: 0.2618\n",
      "Epoch 17, 100% \t Train loss: 0.2588 took: 2.28s  Val. loss: 0.2623\n",
      "Epoch 18, 100% \t Train loss: 0.2590 took: 2.29s  Val. loss: 0.2617\n",
      "Epoch 19, 100% \t Train loss: 0.2588 took: 2.29s  Val. loss: 0.2620\n",
      "Epoch 20, 100% \t Train loss: 0.2589 took: 2.29s  Val. loss: 0.2617\n",
      "Epoch 21, 100% \t Train loss: 0.2588 took: 2.29s  Val. loss: 0.2617\n",
      "Epoch 22, 100% \t Train loss: 0.2587 took: 2.30s  Val. loss: 0.2610\n",
      "Epoch 23, 100% \t Train loss: 0.2574 took: 2.30s  Val. loss: 0.2577\n",
      "Epoch 24, 100% \t Train loss: 0.2379 took: 2.31s  Val. loss: 0.2040\n",
      "Epoch 25, 100% \t Train loss: 0.1834 took: 2.29s  Val. loss: 0.1797\n",
      "Epoch 26, 100% \t Train loss: 0.1714 took: 2.29s  Val. loss: 0.1766\n",
      "Epoch 27, 100% \t Train loss: 0.1692 took: 2.29s  Val. loss: 0.1749\n",
      "Epoch 28, 100% \t Train loss: 0.1664 took: 2.29s  Val. loss: 0.1783\n",
      "Epoch 29, 100% \t Train loss: 0.1638 took: 2.31s  Val. loss: 0.1713\n",
      "Epoch 30, 100% \t Train loss: 0.1610 took: 2.33s  Val. loss: 0.1722\n",
      "Epoch 31, 100% \t Train loss: 0.1585 took: 2.37s  Val. loss: 0.1673\n",
      "Epoch 32, 100% \t Train loss: 0.1577 took: 2.36s  Val. loss: 0.1706\n",
      "Epoch 33, 100% \t Train loss: 0.1564 took: 2.36s  Val. loss: 0.1671\n",
      "Epoch 34, 100% \t Train loss: 0.1546 took: 2.35s  Val. loss: 0.1704\n",
      "Epoch 35, 100% \t Train loss: 0.1565 took: 2.37s  Val. loss: 0.1671\n",
      "Epoch 36, 100% \t Train loss: 0.1550 took: 2.37s  Val. loss: 0.1675\n",
      "Epoch 37, 100% \t Train loss: 0.1540 took: 2.34s  Val. loss: 0.1673\n",
      "Epoch 38, 100% \t Train loss: 0.1540 took: 2.35s  Val. loss: 0.1679\n",
      "Epoch 39, 100% \t Train loss: 0.1538 took: 2.36s  Val. loss: 0.1682\n",
      "Epoch 40, 100% \t Train loss: 0.1543 took: 2.34s  Val. loss: 0.1687\n",
      "Epoch 41, 100% \t Train loss: 0.1544 took: 2.33s  Val. loss: 0.1659\n",
      "Epoch 42, 100% \t Train loss: 0.1541 took: 2.34s  Val. loss: 0.1662\n",
      "Epoch 43, 100% \t Train loss: 0.1525 took: 2.37s  Val. loss: 0.1669\n",
      "Epoch 44, 100% \t Train loss: 0.1527 took: 2.38s  Val. loss: 0.1668\n",
      "Epoch 45, 100% \t Train loss: 0.1531 took: 2.38s  Val. loss: 0.1674\n",
      "Epoch 46, 100% \t Train loss: 0.1528 took: 2.41s  Val. loss: 0.1690\n",
      "Epoch 47, 100% \t Train loss: 0.1521 took: 2.41s  Val. loss: 0.1689\n",
      "Epoch 48, 100% \t Train loss: 0.1522 took: 2.42s  Val. loss: 0.1684\n",
      "Epoch 49, 100% \t Train loss: 0.1522 took: 2.41s  Val. loss: 0.1667\n",
      "Epoch 50, 100% \t Train loss: 0.1516 took: 2.44s  Val. loss: 0.1701\n",
      "Training finished, took 129.80s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2591 took: 2.30s  Val. loss: 0.2593\n",
      "Epoch 2, 100% \t Train loss: 0.2588 took: 2.28s  Val. loss: 0.2591\n",
      "Epoch 3, 100% \t Train loss: 0.2588 took: 2.27s  Val. loss: 0.2580\n",
      "Epoch 4, 100% \t Train loss: 0.2589 took: 2.28s  Val. loss: 0.2581\n",
      "Epoch 5, 100% \t Train loss: 0.2587 took: 2.28s  Val. loss: 0.2585\n",
      "Epoch 6, 100% \t Train loss: 0.2588 took: 2.28s  Val. loss: 0.2598\n",
      "Epoch 7, 100% \t Train loss: 0.2587 took: 2.28s  Val. loss: 0.2588\n",
      "Epoch 8, 100% \t Train loss: 0.2588 took: 2.28s  Val. loss: 0.2592\n",
      "Epoch 9, 100% \t Train loss: 0.2588 took: 2.26s  Val. loss: 0.2584\n",
      "Epoch 10, 100% \t Train loss: 0.2588 took: 2.27s  Val. loss: 0.2584\n",
      "Epoch 11, 100% \t Train loss: 0.2588 took: 2.27s  Val. loss: 0.2588\n",
      "Epoch 12, 100% \t Train loss: 0.2588 took: 2.19s  Val. loss: 0.2586\n",
      "Epoch 13, 100% \t Train loss: 0.2587 took: 1.36s  Val. loss: 0.2591\n",
      "Epoch 14, 100% \t Train loss: 0.2588 took: 1.36s  Val. loss: 0.2589\n",
      "Epoch 15, 100% \t Train loss: 0.2588 took: 1.37s  Val. loss: 0.2590\n",
      "Epoch 16, 100% \t Train loss: 0.2588 took: 1.36s  Val. loss: 0.2592\n",
      "Epoch 17, 100% \t Train loss: 0.2588 took: 1.36s  Val. loss: 0.2582\n",
      "Epoch 18, 100% \t Train loss: 0.2588 took: 2.12s  Val. loss: 0.2583\n",
      "Epoch 19, 100% \t Train loss: 0.2588 took: 2.30s  Val. loss: 0.2589\n",
      "Epoch 20, 100% \t Train loss: 0.2588 took: 2.31s  Val. loss: 0.2595\n",
      "Epoch 21, 100% \t Train loss: 0.2588 took: 2.29s  Val. loss: 0.2589\n",
      "Epoch 22, 100% \t Train loss: 0.2588 took: 2.28s  Val. loss: 0.2592\n",
      "Epoch 23, 100% \t Train loss: 0.2588 took: 2.28s  Val. loss: 0.2584\n",
      "Epoch 24, 100% \t Train loss: 0.2588 took: 2.28s  Val. loss: 0.2582\n",
      "Epoch 25, 100% \t Train loss: 0.2588 took: 2.28s  Val. loss: 0.2589\n",
      "Epoch 26, 100% \t Train loss: 0.2588 took: 2.32s  Val. loss: 0.2586\n",
      "Epoch 27, 100% \t Train loss: 0.2588 took: 2.31s  Val. loss: 0.2587\n",
      "Epoch 28, 100% \t Train loss: 0.2588 took: 2.31s  Val. loss: 0.2589\n",
      "Epoch 29, 100% \t Train loss: 0.2588 took: 2.32s  Val. loss: 0.2590\n",
      "Epoch 30, 100% \t Train loss: 0.2588 took: 2.34s  Val. loss: 0.2597\n",
      "Epoch 31, 100% \t Train loss: 0.2588 took: 2.36s  Val. loss: 0.2581\n",
      "Epoch 32, 100% \t Train loss: 0.2588 took: 2.35s  Val. loss: 0.2589\n",
      "Epoch 33, 100% \t Train loss: 0.2588 took: 2.36s  Val. loss: 0.2588\n",
      "Epoch 34, 100% \t Train loss: 0.2588 took: 2.37s  Val. loss: 0.2592\n",
      "Epoch 35, 100% \t Train loss: 0.2588 took: 2.37s  Val. loss: 0.2590\n",
      "Epoch 36, 100% \t Train loss: 0.2588 took: 2.37s  Val. loss: 0.2578\n",
      "Epoch 37, 100% \t Train loss: 0.2588 took: 2.36s  Val. loss: 0.2589\n",
      "Epoch 38, 100% \t Train loss: 0.2588 took: 2.37s  Val. loss: 0.2593\n",
      "Epoch 39, 100% \t Train loss: 0.2587 took: 2.39s  Val. loss: 0.2591\n",
      "Epoch 40, 100% \t Train loss: 0.2588 took: 2.39s  Val. loss: 0.2596\n",
      "Epoch 41, 100% \t Train loss: 0.2588 took: 2.37s  Val. loss: 0.2582\n",
      "Epoch 42, 100% \t Train loss: 0.2588 took: 2.38s  Val. loss: 0.2586\n",
      "Epoch 43, 100% \t Train loss: 0.2588 took: 2.35s  Val. loss: 0.2586\n",
      "Epoch 44, 100% \t Train loss: 0.2587 took: 2.35s  Val. loss: 0.2588\n",
      "Epoch 45, 100% \t Train loss: 0.2588 took: 2.35s  Val. loss: 0.2592\n",
      "Epoch 46, 100% \t Train loss: 0.2587 took: 2.36s  Val. loss: 0.2593\n",
      "Epoch 47, 100% \t Train loss: 0.2587 took: 2.35s  Val. loss: 0.2589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.2588 took: 2.32s  Val. loss: 0.2593\n",
      "Epoch 49, 100% \t Train loss: 0.2587 took: 2.32s  Val. loss: 0.2587\n",
      "Epoch 50, 100% \t Train loss: 0.2587 took: 1.43s  Val. loss: 0.2580\n",
      "Training finished, took 122.24s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.34\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.739762\n",
      "lambda: 0.0010 - V: 0.787242\n",
      "lambda: 0.0005 - V: 0.741177\n",
      "Average V: 0.756060\n",
      "Time elapsed: 389.31 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.33\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2599 took: 1.81s  Val. loss: 0.2598\n",
      "Epoch 2, 100% \t Train loss: 0.2584 took: 1.83s  Val. loss: 0.2597\n",
      "Epoch 3, 100% \t Train loss: 0.2580 took: 1.83s  Val. loss: 0.2591\n",
      "Epoch 4, 100% \t Train loss: 0.2512 took: 1.79s  Val. loss: 0.2096\n",
      "Epoch 5, 100% \t Train loss: 0.1838 took: 1.81s  Val. loss: 0.1735\n",
      "Epoch 6, 100% \t Train loss: 0.1736 took: 1.80s  Val. loss: 0.1707\n",
      "Epoch 7, 100% \t Train loss: 0.1707 took: 1.83s  Val. loss: 0.1745\n",
      "Epoch 8, 100% \t Train loss: 0.1696 took: 1.81s  Val. loss: 0.1712\n",
      "Epoch 9, 100% \t Train loss: 0.1692 took: 1.83s  Val. loss: 0.1726\n",
      "Epoch 10, 100% \t Train loss: 0.1681 took: 1.05s  Val. loss: 0.1695\n",
      "Epoch 11, 100% \t Train loss: 0.1667 took: 1.05s  Val. loss: 0.1697\n",
      "Epoch 12, 100% \t Train loss: 0.1651 took: 1.06s  Val. loss: 0.1678\n",
      "Epoch 13, 100% \t Train loss: 0.1620 took: 1.05s  Val. loss: 0.1628\n",
      "Epoch 14, 100% \t Train loss: 0.1586 took: 1.06s  Val. loss: 0.1569\n",
      "Epoch 15, 100% \t Train loss: 0.1548 took: 1.06s  Val. loss: 0.1591\n",
      "Epoch 16, 100% \t Train loss: 0.1521 took: 1.06s  Val. loss: 0.1604\n",
      "Epoch 17, 100% \t Train loss: 0.1457 took: 1.06s  Val. loss: 0.1496\n",
      "Epoch 18, 100% \t Train loss: 0.1291 took: 1.07s  Val. loss: 0.1283\n",
      "Epoch 19, 100% \t Train loss: 0.1127 took: 1.06s  Val. loss: 0.1139\n",
      "Epoch 20, 100% \t Train loss: 0.1018 took: 1.06s  Val. loss: 0.1002\n",
      "Epoch 21, 100% \t Train loss: 0.0941 took: 1.06s  Val. loss: 0.0943\n",
      "Epoch 22, 100% \t Train loss: 0.0882 took: 1.05s  Val. loss: 0.0944\n",
      "Epoch 23, 100% \t Train loss: 0.0855 took: 1.06s  Val. loss: 0.0951\n",
      "Epoch 24, 100% \t Train loss: 0.0841 took: 1.05s  Val. loss: 0.0904\n",
      "Epoch 25, 100% \t Train loss: 0.0825 took: 1.06s  Val. loss: 0.0905\n",
      "Epoch 26, 100% \t Train loss: 0.0789 took: 1.13s  Val. loss: 0.0872\n",
      "Epoch 27, 100% \t Train loss: 0.0783 took: 1.06s  Val. loss: 0.0855\n",
      "Epoch 28, 100% \t Train loss: 0.0785 took: 1.07s  Val. loss: 0.0879\n",
      "Epoch 29, 100% \t Train loss: 0.0772 took: 1.08s  Val. loss: 0.0862\n",
      "Epoch 30, 100% \t Train loss: 0.0752 took: 1.09s  Val. loss: 0.0864\n",
      "Epoch 31, 100% \t Train loss: 0.0751 took: 1.10s  Val. loss: 0.0851\n",
      "Epoch 32, 100% \t Train loss: 0.0739 took: 1.18s  Val. loss: 0.0857\n",
      "Epoch 33, 100% \t Train loss: 0.0735 took: 1.28s  Val. loss: 0.0838\n",
      "Epoch 34, 100% \t Train loss: 0.0741 took: 1.30s  Val. loss: 0.0839\n",
      "Epoch 35, 100% \t Train loss: 0.0733 took: 1.31s  Val. loss: 0.0858\n",
      "Epoch 36, 100% \t Train loss: 0.0723 took: 1.30s  Val. loss: 0.0871\n",
      "Epoch 37, 100% \t Train loss: 0.0717 took: 1.85s  Val. loss: 0.0876\n",
      "Epoch 38, 100% \t Train loss: 0.0720 took: 2.07s  Val. loss: 0.0842\n",
      "Epoch 39, 100% \t Train loss: 0.0708 took: 2.06s  Val. loss: 0.0834\n",
      "Epoch 40, 100% \t Train loss: 0.0707 took: 2.07s  Val. loss: 0.0857\n",
      "Epoch 41, 100% \t Train loss: 0.0704 took: 2.08s  Val. loss: 0.0872\n",
      "Epoch 42, 100% \t Train loss: 0.0698 took: 2.08s  Val. loss: 0.0868\n",
      "Epoch 43, 100% \t Train loss: 0.0689 took: 2.08s  Val. loss: 0.0875\n",
      "Epoch 44, 100% \t Train loss: 0.0697 took: 2.08s  Val. loss: 0.0859\n",
      "Epoch 45, 100% \t Train loss: 0.0694 took: 2.08s  Val. loss: 0.0857\n",
      "Epoch 46, 100% \t Train loss: 0.0687 took: 2.10s  Val. loss: 0.0869\n",
      "Epoch 47, 100% \t Train loss: 0.0679 took: 2.11s  Val. loss: 0.0854\n",
      "Epoch 48, 100% \t Train loss: 0.0684 took: 2.13s  Val. loss: 0.0865\n",
      "Epoch 49, 100% \t Train loss: 0.0681 took: 2.17s  Val. loss: 0.0883\n",
      "Epoch 50, 100% \t Train loss: 0.0690 took: 2.17s  Val. loss: 0.0879\n",
      "Training finished, took 85.54s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2574 took: 1.82s  Val. loss: 0.2602\n",
      "Epoch 2, 100% \t Train loss: 0.2568 took: 1.83s  Val. loss: 0.2589\n",
      "Epoch 3, 100% \t Train loss: 0.2565 took: 1.83s  Val. loss: 0.2588\n",
      "Epoch 4, 100% \t Train loss: 0.2537 took: 1.82s  Val. loss: 0.2501\n",
      "Epoch 5, 100% \t Train loss: 0.2129 took: 1.82s  Val. loss: 0.1888\n",
      "Epoch 6, 100% \t Train loss: 0.1779 took: 1.83s  Val. loss: 0.1728\n",
      "Epoch 7, 100% \t Train loss: 0.1735 took: 1.82s  Val. loss: 0.1678\n",
      "Epoch 8, 100% \t Train loss: 0.1690 took: 1.84s  Val. loss: 0.1678\n",
      "Epoch 9, 100% \t Train loss: 0.1656 took: 1.81s  Val. loss: 0.1640\n",
      "Epoch 10, 100% \t Train loss: 0.1643 took: 1.82s  Val. loss: 0.1622\n",
      "Epoch 11, 100% \t Train loss: 0.1619 took: 1.83s  Val. loss: 0.1669\n",
      "Epoch 12, 100% \t Train loss: 0.1623 took: 1.81s  Val. loss: 0.1652\n",
      "Epoch 13, 100% \t Train loss: 0.1597 took: 1.82s  Val. loss: 0.1631\n",
      "Epoch 14, 100% \t Train loss: 0.1598 took: 1.80s  Val. loss: 0.1606\n",
      "Epoch 15, 100% \t Train loss: 0.1567 took: 1.81s  Val. loss: 0.1621\n",
      "Epoch 16, 100% \t Train loss: 0.1580 took: 1.81s  Val. loss: 0.1645\n",
      "Epoch 17, 100% \t Train loss: 0.1560 took: 1.82s  Val. loss: 0.1595\n",
      "Epoch 18, 100% \t Train loss: 0.1541 took: 1.83s  Val. loss: 0.1596\n",
      "Epoch 19, 100% \t Train loss: 0.1538 took: 1.84s  Val. loss: 0.1625\n",
      "Epoch 20, 100% \t Train loss: 0.1531 took: 1.82s  Val. loss: 0.1597\n",
      "Epoch 21, 100% \t Train loss: 0.1519 took: 1.81s  Val. loss: 0.1579\n",
      "Epoch 22, 100% \t Train loss: 0.1484 took: 1.81s  Val. loss: 0.1648\n",
      "Epoch 23, 100% \t Train loss: 0.1472 took: 1.80s  Val. loss: 0.1585\n",
      "Epoch 24, 100% \t Train loss: 0.1434 took: 1.81s  Val. loss: 0.1594\n",
      "Epoch 25, 100% \t Train loss: 0.1385 took: 1.80s  Val. loss: 0.1498\n",
      "Epoch 26, 100% \t Train loss: 0.1334 took: 1.81s  Val. loss: 0.1451\n",
      "Epoch 27, 100% \t Train loss: 0.1283 took: 1.80s  Val. loss: 0.1443\n",
      "Epoch 28, 100% \t Train loss: 0.1217 took: 1.80s  Val. loss: 0.1347\n",
      "Epoch 29, 100% \t Train loss: 0.1149 took: 1.80s  Val. loss: 0.1343\n",
      "Epoch 30, 100% \t Train loss: 0.1104 took: 1.81s  Val. loss: 0.1262\n",
      "Epoch 31, 100% \t Train loss: 0.1055 took: 1.81s  Val. loss: 0.1241\n",
      "Epoch 32, 100% \t Train loss: 0.1029 took: 1.82s  Val. loss: 0.1197\n",
      "Epoch 33, 100% \t Train loss: 0.1005 took: 1.83s  Val. loss: 0.1181\n",
      "Epoch 34, 100% \t Train loss: 0.0991 took: 1.83s  Val. loss: 0.1112\n",
      "Epoch 35, 100% \t Train loss: 0.0953 took: 1.82s  Val. loss: 0.1120\n",
      "Epoch 36, 100% \t Train loss: 0.0936 took: 1.81s  Val. loss: 0.1096\n",
      "Epoch 37, 100% \t Train loss: 0.0918 took: 1.80s  Val. loss: 0.1050\n",
      "Epoch 38, 100% \t Train loss: 0.0894 took: 1.80s  Val. loss: 0.1067\n",
      "Epoch 39, 100% \t Train loss: 0.0880 took: 1.81s  Val. loss: 0.1038\n",
      "Epoch 40, 100% \t Train loss: 0.0870 took: 1.82s  Val. loss: 0.1005\n",
      "Epoch 41, 100% \t Train loss: 0.0848 took: 1.82s  Val. loss: 0.1012\n",
      "Epoch 42, 100% \t Train loss: 0.0838 took: 1.82s  Val. loss: 0.0964\n",
      "Epoch 43, 100% \t Train loss: 0.0823 took: 1.81s  Val. loss: 0.1001\n",
      "Epoch 44, 100% \t Train loss: 0.0809 took: 1.79s  Val. loss: 0.0943\n",
      "Epoch 45, 100% \t Train loss: 0.0803 took: 1.81s  Val. loss: 0.0955\n",
      "Epoch 46, 100% \t Train loss: 0.0793 took: 1.82s  Val. loss: 0.0928\n",
      "Epoch 47, 100% \t Train loss: 0.0782 took: 1.82s  Val. loss: 0.0924\n",
      "Epoch 48, 100% \t Train loss: 0.0770 took: 1.83s  Val. loss: 0.0922\n",
      "Epoch 49, 100% \t Train loss: 0.0763 took: 1.81s  Val. loss: 0.0923\n",
      "Epoch 50, 100% \t Train loss: 0.0754 took: 1.81s  Val. loss: 0.0911\n",
      "Training finished, took 103.10s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2579 took: 1.82s  Val. loss: 0.2657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2562 took: 1.81s  Val. loss: 0.2624\n",
      "Epoch 3, 100% \t Train loss: 0.2479 took: 1.80s  Val. loss: 0.2419\n",
      "Epoch 4, 100% \t Train loss: 0.2167 took: 1.80s  Val. loss: 0.2088\n",
      "Epoch 5, 100% \t Train loss: 0.1882 took: 1.82s  Val. loss: 0.1953\n",
      "Epoch 6, 100% \t Train loss: 0.1786 took: 1.81s  Val. loss: 0.1776\n",
      "Epoch 7, 100% \t Train loss: 0.1713 took: 1.81s  Val. loss: 0.1742\n",
      "Epoch 8, 100% \t Train loss: 0.1683 took: 1.81s  Val. loss: 0.1750\n",
      "Epoch 9, 100% \t Train loss: 0.1664 took: 1.81s  Val. loss: 0.1826\n",
      "Epoch 10, 100% \t Train loss: 0.1643 took: 1.80s  Val. loss: 0.1781\n",
      "Epoch 11, 100% \t Train loss: 0.1631 took: 1.82s  Val. loss: 0.1680\n",
      "Epoch 12, 100% \t Train loss: 0.1627 took: 1.84s  Val. loss: 0.1717\n",
      "Epoch 13, 100% \t Train loss: 0.1614 took: 1.81s  Val. loss: 0.1674\n",
      "Epoch 14, 100% \t Train loss: 0.1580 took: 1.84s  Val. loss: 0.1658\n",
      "Epoch 15, 100% \t Train loss: 0.1582 took: 1.84s  Val. loss: 0.1669\n",
      "Epoch 16, 100% \t Train loss: 0.1595 took: 1.82s  Val. loss: 0.1657\n",
      "Epoch 17, 100% \t Train loss: 0.1621 took: 1.82s  Val. loss: 0.1684\n",
      "Epoch 18, 100% \t Train loss: 0.1592 took: 1.82s  Val. loss: 0.1620\n",
      "Epoch 19, 100% \t Train loss: 0.1572 took: 1.82s  Val. loss: 0.1692\n",
      "Epoch 20, 100% \t Train loss: 0.1559 took: 1.81s  Val. loss: 0.1679\n",
      "Epoch 21, 100% \t Train loss: 0.1552 took: 1.81s  Val. loss: 0.1634\n",
      "Epoch 22, 100% \t Train loss: 0.1559 took: 1.83s  Val. loss: 0.1642\n",
      "Epoch 23, 100% \t Train loss: 0.1546 took: 1.82s  Val. loss: 0.1628\n",
      "Epoch 24, 100% \t Train loss: 0.1525 took: 1.81s  Val. loss: 0.1658\n",
      "Epoch 25, 100% \t Train loss: 0.1516 took: 1.82s  Val. loss: 0.1653\n",
      "Epoch 26, 100% \t Train loss: 0.1516 took: 1.81s  Val. loss: 0.1611\n",
      "Epoch 27, 100% \t Train loss: 0.1498 took: 1.81s  Val. loss: 0.1604\n",
      "Epoch 28, 100% \t Train loss: 0.1526 took: 1.81s  Val. loss: 0.1668\n",
      "Epoch 29, 100% \t Train loss: 0.1515 took: 1.82s  Val. loss: 0.1679\n",
      "Epoch 30, 100% \t Train loss: 0.1500 took: 1.83s  Val. loss: 0.1618\n",
      "Epoch 31, 100% \t Train loss: 0.1482 took: 1.82s  Val. loss: 0.1630\n",
      "Epoch 32, 100% \t Train loss: 0.1478 took: 1.83s  Val. loss: 0.1626\n",
      "Epoch 33, 100% \t Train loss: 0.1478 took: 1.83s  Val. loss: 0.1597\n",
      "Epoch 34, 100% \t Train loss: 0.1461 took: 1.82s  Val. loss: 0.1682\n",
      "Epoch 35, 100% \t Train loss: 0.1481 took: 1.84s  Val. loss: 0.1644\n",
      "Epoch 36, 100% \t Train loss: 0.1459 took: 1.80s  Val. loss: 0.1609\n",
      "Epoch 37, 100% \t Train loss: 0.1453 took: 1.81s  Val. loss: 0.1670\n",
      "Epoch 38, 100% \t Train loss: 0.1472 took: 1.82s  Val. loss: 0.1616\n",
      "Epoch 39, 100% \t Train loss: 0.1440 took: 1.83s  Val. loss: 0.1602\n",
      "Epoch 40, 100% \t Train loss: 0.1428 took: 1.85s  Val. loss: 0.1626\n",
      "Epoch 41, 100% \t Train loss: 0.1427 took: 1.08s  Val. loss: 0.1573\n",
      "Epoch 42, 100% \t Train loss: 0.1422 took: 1.06s  Val. loss: 0.1586\n",
      "Epoch 43, 100% \t Train loss: 0.1428 took: 1.07s  Val. loss: 0.1577\n",
      "Epoch 44, 100% \t Train loss: 0.1410 took: 1.07s  Val. loss: 0.1593\n",
      "Epoch 45, 100% \t Train loss: 0.1404 took: 1.07s  Val. loss: 0.1600\n",
      "Epoch 46, 100% \t Train loss: 0.1417 took: 1.07s  Val. loss: 0.1574\n",
      "Epoch 47, 100% \t Train loss: 0.1399 took: 1.06s  Val. loss: 0.1573\n",
      "Epoch 48, 100% \t Train loss: 0.1401 took: 1.06s  Val. loss: 0.1554\n",
      "Epoch 49, 100% \t Train loss: 0.1379 took: 1.07s  Val. loss: 0.1603\n",
      "Epoch 50, 100% \t Train loss: 0.1373 took: 1.07s  Val. loss: 0.1606\n",
      "Training finished, took 94.87s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  6  - prob: 0.33\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.877848\n",
      "lambda: 0.0010 - V: 0.855822\n",
      "lambda: 0.0005 - V: 0.828237\n",
      "Average V: 0.853969\n",
      "Time elapsed: 286.88 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2590 took: 1.57s  Val. loss: 0.2603\n",
      "Epoch 2, 100% \t Train loss: 0.2579 took: 1.56s  Val. loss: 0.2595\n",
      "Epoch 3, 100% \t Train loss: 0.2579 took: 1.55s  Val. loss: 0.2637\n",
      "Epoch 4, 100% \t Train loss: 0.2580 took: 1.56s  Val. loss: 0.2619\n",
      "Epoch 5, 100% \t Train loss: 0.2577 took: 1.56s  Val. loss: 0.2618\n",
      "Epoch 6, 100% \t Train loss: 0.2579 took: 1.56s  Val. loss: 0.2612\n",
      "Epoch 7, 100% \t Train loss: 0.2578 took: 1.56s  Val. loss: 0.2603\n",
      "Epoch 8, 100% \t Train loss: 0.2578 took: 1.96s  Val. loss: 0.2602\n",
      "Epoch 9, 100% \t Train loss: 0.2577 took: 2.60s  Val. loss: 0.2607\n",
      "Epoch 10, 100% \t Train loss: 0.2577 took: 2.59s  Val. loss: 0.2610\n",
      "Epoch 11, 100% \t Train loss: 0.2578 took: 2.58s  Val. loss: 0.2606\n",
      "Epoch 12, 100% \t Train loss: 0.2577 took: 2.58s  Val. loss: 0.2625\n",
      "Epoch 13, 100% \t Train loss: 0.2578 took: 2.61s  Val. loss: 0.2593\n",
      "Epoch 14, 100% \t Train loss: 0.2578 took: 2.61s  Val. loss: 0.2593\n",
      "Epoch 15, 100% \t Train loss: 0.2577 took: 2.57s  Val. loss: 0.2613\n",
      "Epoch 16, 100% \t Train loss: 0.2576 took: 2.56s  Val. loss: 0.2605\n",
      "Epoch 17, 100% \t Train loss: 0.2577 took: 2.62s  Val. loss: 0.2611\n",
      "Epoch 18, 100% \t Train loss: 0.2578 took: 2.60s  Val. loss: 0.2624\n",
      "Epoch 19, 100% \t Train loss: 0.2577 took: 2.59s  Val. loss: 0.2619\n",
      "Epoch 20, 100% \t Train loss: 0.2577 took: 2.61s  Val. loss: 0.2607\n",
      "Epoch 21, 100% \t Train loss: 0.2577 took: 2.62s  Val. loss: 0.2607\n",
      "Epoch 22, 100% \t Train loss: 0.2577 took: 2.63s  Val. loss: 0.2607\n",
      "Epoch 23, 100% \t Train loss: 0.2577 took: 2.64s  Val. loss: 0.2611\n",
      "Epoch 24, 100% \t Train loss: 0.2576 took: 2.67s  Val. loss: 0.2615\n",
      "Epoch 25, 100% \t Train loss: 0.2577 took: 2.83s  Val. loss: 0.2613\n",
      "Epoch 26, 100% \t Train loss: 0.2577 took: 2.77s  Val. loss: 0.2616\n",
      "Epoch 27, 100% \t Train loss: 0.2577 took: 2.77s  Val. loss: 0.2615\n",
      "Epoch 28, 100% \t Train loss: 0.2578 took: 2.76s  Val. loss: 0.2612\n",
      "Epoch 29, 100% \t Train loss: 0.2577 took: 1.90s  Val. loss: 0.2609\n",
      "Epoch 30, 100% \t Train loss: 0.2577 took: 1.78s  Val. loss: 0.2606\n",
      "Epoch 31, 100% \t Train loss: 0.2577 took: 3.09s  Val. loss: 0.2607\n",
      "Epoch 32, 100% \t Train loss: 0.2577 took: 2.40s  Val. loss: 0.2604\n",
      "Epoch 33, 100% \t Train loss: 0.2577 took: 3.87s  Val. loss: 0.2598\n",
      "Epoch 34, 100% \t Train loss: 0.2577 took: 4.39s  Val. loss: 0.2607\n",
      "Epoch 35, 100% \t Train loss: 0.2577 took: 4.57s  Val. loss: 0.2600\n",
      "Epoch 36, 100% \t Train loss: 0.2576 took: 4.04s  Val. loss: 0.2603\n",
      "Epoch 37, 100% \t Train loss: 0.2576 took: 4.00s  Val. loss: 0.2615\n",
      "Epoch 38, 100% \t Train loss: 0.2577 took: 3.98s  Val. loss: 0.2616\n",
      "Epoch 39, 100% \t Train loss: 0.2577 took: 5.28s  Val. loss: 0.2611\n",
      "Epoch 40, 100% \t Train loss: 0.2578 took: 4.74s  Val. loss: 0.2613\n",
      "Epoch 41, 100% \t Train loss: 0.2576 took: 5.16s  Val. loss: 0.2600\n",
      "Epoch 42, 100% \t Train loss: 0.2577 took: 4.86s  Val. loss: 0.2607\n",
      "Epoch 43, 100% \t Train loss: 0.2576 took: 4.66s  Val. loss: 0.2604\n",
      "Epoch 44, 100% \t Train loss: 0.2576 took: 4.74s  Val. loss: 0.2607\n",
      "Epoch 45, 100% \t Train loss: 0.2576 took: 4.57s  Val. loss: 0.2604\n",
      "Epoch 46, 100% \t Train loss: 0.2577 took: 4.79s  Val. loss: 0.2615\n",
      "Epoch 47, 100% \t Train loss: 0.2576 took: 4.45s  Val. loss: 0.2602\n",
      "Epoch 48, 100% \t Train loss: 0.2576 took: 4.83s  Val. loss: 0.2609\n",
      "Epoch 49, 100% \t Train loss: 0.2577 took: 4.89s  Val. loss: 0.2607\n",
      "Epoch 50, 100% \t Train loss: 0.2577 took: 4.98s  Val. loss: 0.2614\n",
      "Training finished, took 174.09s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2574 took: 2.59s  Val. loss: 0.2529\n",
      "Epoch 2, 100% \t Train loss: 0.2568 took: 2.59s  Val. loss: 0.2523\n",
      "Epoch 3, 100% \t Train loss: 0.2569 took: 2.60s  Val. loss: 0.2534\n",
      "Epoch 4, 100% \t Train loss: 0.2570 took: 2.59s  Val. loss: 0.2542\n",
      "Epoch 5, 100% \t Train loss: 0.2568 took: 2.57s  Val. loss: 0.2524\n",
      "Epoch 6, 100% \t Train loss: 0.2570 took: 2.60s  Val. loss: 0.2528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, 100% \t Train loss: 0.2569 took: 2.61s  Val. loss: 0.2529\n",
      "Epoch 8, 100% \t Train loss: 0.2569 took: 2.61s  Val. loss: 0.2529\n",
      "Epoch 9, 100% \t Train loss: 0.2568 took: 2.63s  Val. loss: 0.2522\n",
      "Epoch 10, 100% \t Train loss: 0.2569 took: 2.58s  Val. loss: 0.2525\n",
      "Epoch 11, 100% \t Train loss: 0.2568 took: 2.61s  Val. loss: 0.2532\n",
      "Epoch 12, 100% \t Train loss: 0.2568 took: 2.58s  Val. loss: 0.2530\n",
      "Epoch 13, 100% \t Train loss: 0.2570 took: 2.57s  Val. loss: 0.2523\n",
      "Epoch 14, 100% \t Train loss: 0.2568 took: 2.57s  Val. loss: 0.2533\n",
      "Epoch 15, 100% \t Train loss: 0.2568 took: 2.59s  Val. loss: 0.2538\n",
      "Epoch 16, 100% \t Train loss: 0.2568 took: 2.60s  Val. loss: 0.2529\n",
      "Epoch 17, 100% \t Train loss: 0.2568 took: 2.58s  Val. loss: 0.2533\n",
      "Epoch 18, 100% \t Train loss: 0.2568 took: 2.60s  Val. loss: 0.2519\n",
      "Epoch 19, 100% \t Train loss: 0.2569 took: 2.58s  Val. loss: 0.2528\n",
      "Epoch 20, 100% \t Train loss: 0.2569 took: 2.56s  Val. loss: 0.2521\n",
      "Epoch 21, 100% \t Train loss: 0.2569 took: 2.57s  Val. loss: 0.2522\n",
      "Epoch 22, 100% \t Train loss: 0.2568 took: 1.57s  Val. loss: 0.2525\n",
      "Epoch 23, 100% \t Train loss: 0.2568 took: 1.57s  Val. loss: 0.2526\n",
      "Epoch 24, 100% \t Train loss: 0.2568 took: 1.58s  Val. loss: 0.2531\n",
      "Epoch 25, 100% \t Train loss: 0.2568 took: 1.58s  Val. loss: 0.2530\n",
      "Epoch 26, 100% \t Train loss: 0.2568 took: 1.58s  Val. loss: 0.2537\n",
      "Epoch 27, 100% \t Train loss: 0.2569 took: 1.58s  Val. loss: 0.2520\n",
      "Epoch 28, 100% \t Train loss: 0.2568 took: 1.59s  Val. loss: 0.2531\n",
      "Epoch 29, 100% \t Train loss: 0.2568 took: 1.60s  Val. loss: 0.2535\n",
      "Epoch 30, 100% \t Train loss: 0.2568 took: 1.62s  Val. loss: 0.2530\n",
      "Epoch 31, 100% \t Train loss: 0.2568 took: 1.74s  Val. loss: 0.2526\n",
      "Epoch 32, 100% \t Train loss: 0.2568 took: 2.85s  Val. loss: 0.2524\n",
      "Epoch 33, 100% \t Train loss: 0.2568 took: 3.20s  Val. loss: 0.2530\n",
      "Epoch 34, 100% \t Train loss: 0.2568 took: 3.56s  Val. loss: 0.2530\n",
      "Epoch 35, 100% \t Train loss: 0.2568 took: 4.08s  Val. loss: 0.2527\n",
      "Epoch 36, 100% \t Train loss: 0.2568 took: 3.88s  Val. loss: 0.2525\n",
      "Epoch 37, 100% \t Train loss: 0.2568 took: 3.49s  Val. loss: 0.2530\n",
      "Epoch 38, 100% \t Train loss: 0.2568 took: 2.79s  Val. loss: 0.2535\n",
      "Epoch 39, 100% \t Train loss: 0.2568 took: 3.09s  Val. loss: 0.2518\n",
      "Epoch 40, 100% \t Train loss: 0.2568 took: 2.75s  Val. loss: 0.2537\n",
      "Epoch 41, 100% \t Train loss: 0.2568 took: 2.81s  Val. loss: 0.2527\n",
      "Epoch 42, 100% \t Train loss: 0.2568 took: 4.44s  Val. loss: 0.2529\n",
      "Epoch 43, 100% \t Train loss: 0.2568 took: 4.36s  Val. loss: 0.2520\n",
      "Epoch 44, 100% \t Train loss: 0.2568 took: 4.55s  Val. loss: 0.2521\n",
      "Epoch 45, 100% \t Train loss: 0.2568 took: 4.62s  Val. loss: 0.2525\n",
      "Epoch 46, 100% \t Train loss: 0.2568 took: 4.50s  Val. loss: 0.2532\n",
      "Epoch 47, 100% \t Train loss: 0.2569 took: 4.36s  Val. loss: 0.2530\n",
      "Epoch 48, 100% \t Train loss: 0.2568 took: 4.33s  Val. loss: 0.2535\n",
      "Epoch 49, 100% \t Train loss: 0.2568 took: 4.53s  Val. loss: 0.2522\n",
      "Epoch 50, 100% \t Train loss: 0.2569 took: 4.45s  Val. loss: 0.2535\n",
      "Training finished, took 159.41s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2619 took: 2.61s  Val. loss: 0.2636\n",
      "Epoch 2, 100% \t Train loss: 0.2617 took: 2.60s  Val. loss: 0.2636\n",
      "Epoch 3, 100% \t Train loss: 0.2617 took: 2.59s  Val. loss: 0.2632\n",
      "Epoch 4, 100% \t Train loss: 0.2617 took: 2.60s  Val. loss: 0.2636\n",
      "Epoch 5, 100% \t Train loss: 0.2616 took: 2.60s  Val. loss: 0.2637\n",
      "Epoch 6, 100% \t Train loss: 0.2617 took: 2.19s  Val. loss: 0.2638\n",
      "Epoch 7, 100% \t Train loss: 0.2617 took: 1.60s  Val. loss: 0.2635\n",
      "Epoch 8, 100% \t Train loss: 0.2616 took: 1.60s  Val. loss: 0.2634\n",
      "Epoch 9, 100% \t Train loss: 0.2614 took: 1.59s  Val. loss: 0.2627\n",
      "Epoch 10, 100% \t Train loss: 0.2589 took: 1.59s  Val. loss: 0.2566\n",
      "Epoch 11, 100% \t Train loss: 0.2379 took: 1.59s  Val. loss: 0.2139\n",
      "Epoch 12, 100% \t Train loss: 0.1948 took: 1.59s  Val. loss: 0.1824\n",
      "Epoch 13, 100% \t Train loss: 0.1792 took: 1.60s  Val. loss: 0.1755\n",
      "Epoch 14, 100% \t Train loss: 0.1745 took: 1.74s  Val. loss: 0.1731\n",
      "Epoch 15, 100% \t Train loss: 0.1721 took: 2.60s  Val. loss: 0.1704\n",
      "Epoch 16, 100% \t Train loss: 0.1711 took: 2.58s  Val. loss: 0.1701\n",
      "Epoch 17, 100% \t Train loss: 0.1703 took: 2.59s  Val. loss: 0.1680\n",
      "Epoch 18, 100% \t Train loss: 0.1688 took: 2.59s  Val. loss: 0.1683\n",
      "Epoch 19, 100% \t Train loss: 0.1682 took: 2.61s  Val. loss: 0.1693\n",
      "Epoch 20, 100% \t Train loss: 0.1675 took: 2.60s  Val. loss: 0.1680\n",
      "Epoch 21, 100% \t Train loss: 0.1664 took: 2.59s  Val. loss: 0.1669\n",
      "Epoch 22, 100% \t Train loss: 0.1663 took: 2.60s  Val. loss: 0.1660\n",
      "Epoch 23, 100% \t Train loss: 0.1656 took: 2.60s  Val. loss: 0.1650\n",
      "Epoch 24, 100% \t Train loss: 0.1652 took: 2.59s  Val. loss: 0.1637\n",
      "Epoch 25, 100% \t Train loss: 0.1650 took: 2.60s  Val. loss: 0.1646\n",
      "Epoch 26, 100% \t Train loss: 0.1640 took: 2.58s  Val. loss: 0.1635\n",
      "Epoch 27, 100% \t Train loss: 0.1639 took: 2.61s  Val. loss: 0.1648\n",
      "Epoch 28, 100% \t Train loss: 0.1639 took: 2.69s  Val. loss: 0.1635\n",
      "Epoch 29, 100% \t Train loss: 0.1634 took: 2.71s  Val. loss: 0.1632\n",
      "Epoch 30, 100% \t Train loss: 0.1625 took: 2.74s  Val. loss: 0.1637\n",
      "Epoch 31, 100% \t Train loss: 0.1633 took: 2.84s  Val. loss: 0.1619\n",
      "Epoch 32, 100% \t Train loss: 0.1621 took: 2.89s  Val. loss: 0.1623\n",
      "Epoch 33, 100% \t Train loss: 0.1620 took: 2.91s  Val. loss: 0.1603\n",
      "Epoch 34, 100% \t Train loss: 0.1618 took: 2.92s  Val. loss: 0.1627\n",
      "Epoch 35, 100% \t Train loss: 0.1616 took: 2.99s  Val. loss: 0.1609\n",
      "Epoch 36, 100% \t Train loss: 0.1614 took: 2.99s  Val. loss: 0.1615\n",
      "Epoch 37, 100% \t Train loss: 0.1612 took: 3.05s  Val. loss: 0.1621\n",
      "Epoch 38, 100% \t Train loss: 0.1610 took: 3.05s  Val. loss: 0.1609\n",
      "Epoch 39, 100% \t Train loss: 0.1607 took: 3.14s  Val. loss: 0.1604\n",
      "Epoch 40, 100% \t Train loss: 0.1607 took: 3.17s  Val. loss: 0.1614\n",
      "Epoch 41, 100% \t Train loss: 0.1615 took: 3.31s  Val. loss: 0.1598\n",
      "Epoch 42, 100% \t Train loss: 0.1602 took: 3.34s  Val. loss: 0.1626\n",
      "Epoch 43, 100% \t Train loss: 0.1599 took: 3.39s  Val. loss: 0.1615\n",
      "Epoch 44, 100% \t Train loss: 0.1599 took: 3.41s  Val. loss: 0.1611\n",
      "Epoch 45, 100% \t Train loss: 0.1598 took: 3.42s  Val. loss: 0.1588\n",
      "Epoch 46, 100% \t Train loss: 0.1595 took: 3.43s  Val. loss: 0.1620\n",
      "Epoch 47, 100% \t Train loss: 0.1594 took: 3.37s  Val. loss: 0.1605\n",
      "Epoch 48, 100% \t Train loss: 0.1591 took: 3.02s  Val. loss: 0.1617\n",
      "Epoch 49, 100% \t Train loss: 0.1593 took: 2.92s  Val. loss: 0.1590\n",
      "Epoch 50, 100% \t Train loss: 0.1591 took: 2.94s  Val. loss: 0.1608\n",
      "Training finished, took 145.63s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  8  - prob: 0.35\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.739090\n",
      "lambda: 0.0010 - V: 0.747164\n",
      "lambda: 0.0005 - V: 0.814929\n",
      "Average V: 0.767061\n",
      "Time elapsed: 482.65 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2580 took: 1.82s  Val. loss: 0.2637\n",
      "Epoch 2, 100% \t Train loss: 0.2477 took: 1.84s  Val. loss: 0.2155\n",
      "Epoch 3, 100% \t Train loss: 0.1776 took: 1.83s  Val. loss: 0.1670\n",
      "Epoch 4, 100% \t Train loss: 0.1626 took: 1.83s  Val. loss: 0.1643\n",
      "Epoch 5, 100% \t Train loss: 0.1574 took: 1.08s  Val. loss: 0.1623\n",
      "Epoch 6, 100% \t Train loss: 0.1558 took: 1.09s  Val. loss: 0.1598\n",
      "Epoch 7, 100% \t Train loss: 0.1528 took: 1.79s  Val. loss: 0.1609\n",
      "Epoch 8, 100% \t Train loss: 0.1520 took: 1.84s  Val. loss: 0.1606\n",
      "Epoch 9, 100% \t Train loss: 0.1509 took: 1.83s  Val. loss: 0.1613\n",
      "Epoch 10, 100% \t Train loss: 0.1509 took: 1.08s  Val. loss: 0.1580\n",
      "Epoch 11, 100% \t Train loss: 0.1498 took: 1.07s  Val. loss: 0.1567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, 100% \t Train loss: 0.1489 took: 1.07s  Val. loss: 0.1575\n",
      "Epoch 13, 100% \t Train loss: 0.1487 took: 1.08s  Val. loss: 0.1590\n",
      "Epoch 14, 100% \t Train loss: 0.1476 took: 1.08s  Val. loss: 0.1558\n",
      "Epoch 15, 100% \t Train loss: 0.1472 took: 1.07s  Val. loss: 0.1576\n",
      "Epoch 16, 100% \t Train loss: 0.1465 took: 1.07s  Val. loss: 0.1577\n",
      "Epoch 17, 100% \t Train loss: 0.1462 took: 1.07s  Val. loss: 0.1558\n",
      "Epoch 18, 100% \t Train loss: 0.1454 took: 1.08s  Val. loss: 0.1563\n",
      "Epoch 19, 100% \t Train loss: 0.1447 took: 1.07s  Val. loss: 0.1551\n",
      "Epoch 20, 100% \t Train loss: 0.1443 took: 1.08s  Val. loss: 0.1527\n",
      "Epoch 21, 100% \t Train loss: 0.1427 took: 1.08s  Val. loss: 0.1527\n",
      "Epoch 22, 100% \t Train loss: 0.1399 took: 1.09s  Val. loss: 0.1486\n",
      "Epoch 23, 100% \t Train loss: 0.1363 took: 1.08s  Val. loss: 0.1427\n",
      "Epoch 24, 100% \t Train loss: 0.1307 took: 1.08s  Val. loss: 0.1394\n",
      "Epoch 25, 100% \t Train loss: 0.1239 took: 1.08s  Val. loss: 0.1350\n",
      "Epoch 26, 100% \t Train loss: 0.1176 took: 1.08s  Val. loss: 0.1250\n",
      "Epoch 27, 100% \t Train loss: 0.1102 took: 1.09s  Val. loss: 0.1179\n",
      "Epoch 28, 100% \t Train loss: 0.1046 took: 1.07s  Val. loss: 0.1125\n",
      "Epoch 29, 100% \t Train loss: 0.0999 took: 1.08s  Val. loss: 0.1090\n",
      "Epoch 30, 100% \t Train loss: 0.0965 took: 1.09s  Val. loss: 0.1061\n",
      "Epoch 31, 100% \t Train loss: 0.0933 took: 1.09s  Val. loss: 0.1016\n",
      "Epoch 32, 100% \t Train loss: 0.0919 took: 1.13s  Val. loss: 0.1023\n",
      "Epoch 33, 100% \t Train loss: 0.0902 took: 1.22s  Val. loss: 0.1014\n",
      "Epoch 34, 100% \t Train loss: 0.0872 took: 1.23s  Val. loss: 0.0979\n",
      "Epoch 35, 100% \t Train loss: 0.0858 took: 2.02s  Val. loss: 0.0960\n",
      "Epoch 36, 100% \t Train loss: 0.0844 took: 2.01s  Val. loss: 0.0954\n",
      "Epoch 37, 100% \t Train loss: 0.0828 took: 2.04s  Val. loss: 0.0946\n",
      "Epoch 38, 100% \t Train loss: 0.0815 took: 2.03s  Val. loss: 0.0948\n",
      "Epoch 39, 100% \t Train loss: 0.0813 took: 2.03s  Val. loss: 0.0962\n",
      "Epoch 40, 100% \t Train loss: 0.0805 took: 2.07s  Val. loss: 0.0932\n",
      "Epoch 41, 100% \t Train loss: 0.0795 took: 2.08s  Val. loss: 0.0954\n",
      "Epoch 42, 100% \t Train loss: 0.0789 took: 2.07s  Val. loss: 0.0920\n",
      "Epoch 43, 100% \t Train loss: 0.0789 took: 2.09s  Val. loss: 0.0937\n",
      "Epoch 44, 100% \t Train loss: 0.0776 took: 2.12s  Val. loss: 0.0936\n",
      "Epoch 45, 100% \t Train loss: 0.0774 took: 2.12s  Val. loss: 0.0922\n",
      "Epoch 46, 100% \t Train loss: 0.0774 took: 2.15s  Val. loss: 0.0917\n",
      "Epoch 47, 100% \t Train loss: 0.0764 took: 2.17s  Val. loss: 0.0916\n",
      "Epoch 48, 100% \t Train loss: 0.0759 took: 1.73s  Val. loss: 0.0901\n",
      "Epoch 49, 100% \t Train loss: 0.0758 took: 1.42s  Val. loss: 0.0906\n",
      "Epoch 50, 100% \t Train loss: 0.0762 took: 1.43s  Val. loss: 0.0919\n",
      "Training finished, took 83.82s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2579 took: 1.09s  Val. loss: 0.2601\n",
      "Epoch 2, 100% \t Train loss: 0.2572 took: 1.08s  Val. loss: 0.2580\n",
      "Epoch 3, 100% \t Train loss: 0.2502 took: 1.08s  Val. loss: 0.2411\n",
      "Epoch 4, 100% \t Train loss: 0.2072 took: 1.08s  Val. loss: 0.1912\n",
      "Epoch 5, 100% \t Train loss: 0.1778 took: 1.08s  Val. loss: 0.1839\n",
      "Epoch 6, 100% \t Train loss: 0.1750 took: 1.08s  Val. loss: 0.1816\n",
      "Epoch 7, 100% \t Train loss: 0.1715 took: 1.08s  Val. loss: 0.1787\n",
      "Epoch 8, 100% \t Train loss: 0.1692 took: 1.08s  Val. loss: 0.1767\n",
      "Epoch 9, 100% \t Train loss: 0.1674 took: 1.08s  Val. loss: 0.1732\n",
      "Epoch 10, 100% \t Train loss: 0.1663 took: 1.08s  Val. loss: 0.1729\n",
      "Epoch 11, 100% \t Train loss: 0.1647 took: 1.07s  Val. loss: 0.1720\n",
      "Epoch 12, 100% \t Train loss: 0.1631 took: 1.07s  Val. loss: 0.1772\n",
      "Epoch 13, 100% \t Train loss: 0.1637 took: 1.07s  Val. loss: 0.1724\n",
      "Epoch 14, 100% \t Train loss: 0.1629 took: 1.08s  Val. loss: 0.1728\n",
      "Epoch 15, 100% \t Train loss: 0.1627 took: 1.08s  Val. loss: 0.1709\n",
      "Epoch 16, 100% \t Train loss: 0.1616 took: 1.08s  Val. loss: 0.1703\n",
      "Epoch 17, 100% \t Train loss: 0.1627 took: 1.08s  Val. loss: 0.1729\n",
      "Epoch 18, 100% \t Train loss: 0.1608 took: 1.08s  Val. loss: 0.1710\n",
      "Epoch 19, 100% \t Train loss: 0.1612 took: 1.08s  Val. loss: 0.1677\n",
      "Epoch 20, 100% \t Train loss: 0.1598 took: 1.08s  Val. loss: 0.1694\n",
      "Epoch 21, 100% \t Train loss: 0.1593 took: 1.08s  Val. loss: 0.1693\n",
      "Epoch 22, 100% \t Train loss: 0.1601 took: 1.08s  Val. loss: 0.1681\n",
      "Epoch 23, 100% \t Train loss: 0.1595 took: 1.08s  Val. loss: 0.1680\n",
      "Epoch 24, 100% \t Train loss: 0.1592 took: 1.08s  Val. loss: 0.1685\n",
      "Epoch 25, 100% \t Train loss: 0.1589 took: 1.08s  Val. loss: 0.1672\n",
      "Epoch 26, 100% \t Train loss: 0.1582 took: 1.08s  Val. loss: 0.1717\n",
      "Epoch 27, 100% \t Train loss: 0.1580 took: 1.09s  Val. loss: 0.1723\n",
      "Epoch 28, 100% \t Train loss: 0.1587 took: 1.08s  Val. loss: 0.1695\n",
      "Epoch 29, 100% \t Train loss: 0.1582 took: 1.08s  Val. loss: 0.1677\n",
      "Epoch 30, 100% \t Train loss: 0.1584 took: 1.08s  Val. loss: 0.1669\n",
      "Epoch 31, 100% \t Train loss: 0.1582 took: 1.09s  Val. loss: 0.1670\n",
      "Epoch 32, 100% \t Train loss: 0.1573 took: 1.09s  Val. loss: 0.1650\n",
      "Epoch 33, 100% \t Train loss: 0.1577 took: 1.09s  Val. loss: 0.1685\n",
      "Epoch 34, 100% \t Train loss: 0.1578 took: 1.08s  Val. loss: 0.1648\n",
      "Epoch 35, 100% \t Train loss: 0.1567 took: 1.08s  Val. loss: 0.1649\n",
      "Epoch 36, 100% \t Train loss: 0.1564 took: 1.09s  Val. loss: 0.1666\n",
      "Epoch 37, 100% \t Train loss: 0.1567 took: 1.09s  Val. loss: 0.1668\n",
      "Epoch 38, 100% \t Train loss: 0.1565 took: 1.36s  Val. loss: 0.1649\n",
      "Epoch 39, 100% \t Train loss: 0.1560 took: 1.85s  Val. loss: 0.1640\n",
      "Epoch 40, 100% \t Train loss: 0.1560 took: 1.83s  Val. loss: 0.1634\n",
      "Epoch 41, 100% \t Train loss: 0.1556 took: 1.86s  Val. loss: 0.1660\n",
      "Epoch 42, 100% \t Train loss: 0.1557 took: 1.85s  Val. loss: 0.1652\n",
      "Epoch 43, 100% \t Train loss: 0.1551 took: 1.84s  Val. loss: 0.1653\n",
      "Epoch 44, 100% \t Train loss: 0.1552 took: 1.83s  Val. loss: 0.1649\n",
      "Epoch 45, 100% \t Train loss: 0.1550 took: 1.09s  Val. loss: 0.1660\n",
      "Epoch 46, 100% \t Train loss: 0.1543 took: 1.10s  Val. loss: 0.1656\n",
      "Epoch 47, 100% \t Train loss: 0.1540 took: 1.11s  Val. loss: 0.1646\n",
      "Epoch 48, 100% \t Train loss: 0.1543 took: 1.11s  Val. loss: 0.1646\n",
      "Epoch 49, 100% \t Train loss: 0.1542 took: 1.11s  Val. loss: 0.1643\n",
      "Epoch 50, 100% \t Train loss: 0.1542 took: 1.11s  Val. loss: 0.1650\n",
      "Training finished, took 66.85s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 1.84s  Val. loss: 0.2653\n",
      "Epoch 2, 100% \t Train loss: 0.2588 took: 1.82s  Val. loss: 0.2659\n",
      "Epoch 3, 100% \t Train loss: 0.2587 took: 1.81s  Val. loss: 0.2661\n",
      "Epoch 4, 100% \t Train loss: 0.2585 took: 1.83s  Val. loss: 0.2655\n",
      "Epoch 5, 100% \t Train loss: 0.2583 took: 1.81s  Val. loss: 0.2648\n",
      "Epoch 6, 100% \t Train loss: 0.2576 took: 1.83s  Val. loss: 0.2649\n",
      "Epoch 7, 100% \t Train loss: 0.2560 took: 1.84s  Val. loss: 0.2602\n",
      "Epoch 8, 100% \t Train loss: 0.2512 took: 1.84s  Val. loss: 0.2507\n",
      "Epoch 9, 100% \t Train loss: 0.2366 took: 1.66s  Val. loss: 0.2255\n",
      "Epoch 10, 100% \t Train loss: 0.2061 took: 1.08s  Val. loss: 0.1897\n",
      "Epoch 11, 100% \t Train loss: 0.1865 took: 1.08s  Val. loss: 0.1764\n",
      "Epoch 12, 100% \t Train loss: 0.1802 took: 1.08s  Val. loss: 0.1759\n",
      "Epoch 13, 100% \t Train loss: 0.1769 took: 1.09s  Val. loss: 0.1711\n",
      "Epoch 14, 100% \t Train loss: 0.1755 took: 1.08s  Val. loss: 0.1693\n",
      "Epoch 15, 100% \t Train loss: 0.1741 took: 1.08s  Val. loss: 0.1679\n",
      "Epoch 16, 100% \t Train loss: 0.1713 took: 1.08s  Val. loss: 0.1707\n",
      "Epoch 17, 100% \t Train loss: 0.1712 took: 1.08s  Val. loss: 0.1653\n",
      "Epoch 18, 100% \t Train loss: 0.1700 took: 1.08s  Val. loss: 0.1644\n",
      "Epoch 19, 100% \t Train loss: 0.1690 took: 1.09s  Val. loss: 0.1669\n",
      "Epoch 20, 100% \t Train loss: 0.1692 took: 1.66s  Val. loss: 0.1645\n",
      "Epoch 21, 100% \t Train loss: 0.1699 took: 1.84s  Val. loss: 0.1687\n",
      "Epoch 22, 100% \t Train loss: 0.1682 took: 1.85s  Val. loss: 0.1652\n",
      "Epoch 23, 100% \t Train loss: 0.1661 took: 1.84s  Val. loss: 0.1677\n",
      "Epoch 24, 100% \t Train loss: 0.1682 took: 1.84s  Val. loss: 0.1623\n",
      "Epoch 25, 100% \t Train loss: 0.1665 took: 1.85s  Val. loss: 0.1617\n",
      "Epoch 26, 100% \t Train loss: 0.1644 took: 1.83s  Val. loss: 0.1610\n",
      "Epoch 27, 100% \t Train loss: 0.1657 took: 1.84s  Val. loss: 0.1624\n",
      "Epoch 28, 100% \t Train loss: 0.1660 took: 1.84s  Val. loss: 0.1621\n",
      "Epoch 29, 100% \t Train loss: 0.1644 took: 1.86s  Val. loss: 0.1630\n",
      "Epoch 30, 100% \t Train loss: 0.1649 took: 1.86s  Val. loss: 0.1619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, 100% \t Train loss: 0.1631 took: 1.86s  Val. loss: 0.1594\n",
      "Epoch 32, 100% \t Train loss: 0.1640 took: 1.86s  Val. loss: 0.1623\n",
      "Epoch 33, 100% \t Train loss: 0.1626 took: 1.85s  Val. loss: 0.1635\n",
      "Epoch 34, 100% \t Train loss: 0.1638 took: 1.86s  Val. loss: 0.1608\n",
      "Epoch 35, 100% \t Train loss: 0.1621 took: 1.86s  Val. loss: 0.1612\n",
      "Epoch 36, 100% \t Train loss: 0.1618 took: 1.87s  Val. loss: 0.1601\n",
      "Epoch 37, 100% \t Train loss: 0.1641 took: 1.88s  Val. loss: 0.1649\n",
      "Epoch 38, 100% \t Train loss: 0.1625 took: 1.87s  Val. loss: 0.1621\n",
      "Epoch 39, 100% \t Train loss: 0.1622 took: 1.86s  Val. loss: 0.1617\n",
      "Epoch 40, 100% \t Train loss: 0.1614 took: 1.85s  Val. loss: 0.1662\n",
      "Epoch 41, 100% \t Train loss: 0.1622 took: 1.87s  Val. loss: 0.1593\n",
      "Epoch 42, 100% \t Train loss: 0.1619 took: 1.88s  Val. loss: 0.1637\n",
      "Epoch 43, 100% \t Train loss: 0.1601 took: 1.89s  Val. loss: 0.1592\n",
      "Epoch 44, 100% \t Train loss: 0.1599 took: 1.90s  Val. loss: 0.1589\n",
      "Epoch 45, 100% \t Train loss: 0.1607 took: 1.91s  Val. loss: 0.1587\n",
      "Epoch 46, 100% \t Train loss: 0.1607 took: 1.91s  Val. loss: 0.1581\n",
      "Epoch 47, 100% \t Train loss: 0.1594 took: 1.92s  Val. loss: 0.1598\n",
      "Epoch 48, 100% \t Train loss: 0.1590 took: 1.91s  Val. loss: 0.1587\n",
      "Epoch 49, 100% \t Train loss: 0.1594 took: 1.91s  Val. loss: 0.1609\n",
      "Epoch 50, 100% \t Train loss: 0.1598 took: 1.93s  Val. loss: 0.1608\n",
      "Training finished, took 96.37s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.869553\n",
      "lambda: 0.0010 - V: 0.825393\n",
      "lambda: 0.0005 - V: 0.818649\n",
      "Average V: 0.837865\n",
      "Time elapsed: 250.42 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.33\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.25\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2565 took: 2.40s  Val. loss: 0.2595\n",
      "Epoch 2, 100% \t Train loss: 0.2553 took: 2.37s  Val. loss: 0.2615\n",
      "Epoch 3, 100% \t Train loss: 0.2554 took: 2.38s  Val. loss: 0.2606\n",
      "Epoch 4, 100% \t Train loss: 0.2553 took: 2.37s  Val. loss: 0.2606\n",
      "Epoch 5, 100% \t Train loss: 0.2551 took: 2.38s  Val. loss: 0.2599\n",
      "Epoch 6, 100% \t Train loss: 0.2551 took: 2.38s  Val. loss: 0.2601\n",
      "Epoch 7, 100% \t Train loss: 0.2551 took: 2.40s  Val. loss: 0.2597\n",
      "Epoch 8, 100% \t Train loss: 0.2552 took: 2.39s  Val. loss: 0.2610\n",
      "Epoch 9, 100% \t Train loss: 0.2551 took: 2.40s  Val. loss: 0.2609\n",
      "Epoch 10, 100% \t Train loss: 0.2551 took: 2.39s  Val. loss: 0.2602\n",
      "Epoch 11, 100% \t Train loss: 0.2552 took: 2.35s  Val. loss: 0.2597\n",
      "Epoch 12, 100% \t Train loss: 0.2551 took: 2.40s  Val. loss: 0.2601\n",
      "Epoch 13, 100% \t Train loss: 0.2551 took: 2.39s  Val. loss: 0.2597\n",
      "Epoch 14, 100% \t Train loss: 0.2551 took: 2.40s  Val. loss: 0.2605\n",
      "Epoch 15, 100% \t Train loss: 0.2551 took: 2.40s  Val. loss: 0.2615\n",
      "Epoch 16, 100% \t Train loss: 0.2551 took: 2.44s  Val. loss: 0.2612\n",
      "Epoch 17, 100% \t Train loss: 0.2550 took: 2.40s  Val. loss: 0.2599\n",
      "Epoch 18, 100% \t Train loss: 0.2552 took: 2.40s  Val. loss: 0.2603\n",
      "Epoch 19, 100% \t Train loss: 0.2551 took: 2.42s  Val. loss: 0.2601\n",
      "Epoch 20, 100% \t Train loss: 0.2551 took: 2.40s  Val. loss: 0.2603\n",
      "Epoch 21, 100% \t Train loss: 0.2551 took: 2.47s  Val. loss: 0.2605\n",
      "Epoch 22, 100% \t Train loss: 0.2550 took: 2.57s  Val. loss: 0.2606\n",
      "Epoch 23, 100% \t Train loss: 0.2551 took: 2.46s  Val. loss: 0.2607\n",
      "Epoch 24, 100% \t Train loss: 0.2551 took: 2.39s  Val. loss: 0.2607\n",
      "Epoch 25, 100% \t Train loss: 0.2552 took: 2.40s  Val. loss: 0.2608\n",
      "Epoch 26, 100% \t Train loss: 0.2550 took: 2.43s  Val. loss: 0.2596\n",
      "Epoch 27, 100% \t Train loss: 0.2550 took: 2.46s  Val. loss: 0.2613\n",
      "Epoch 28, 100% \t Train loss: 0.2551 took: 2.57s  Val. loss: 0.2599\n",
      "Epoch 29, 100% \t Train loss: 0.2551 took: 2.78s  Val. loss: 0.2610\n",
      "Epoch 30, 100% \t Train loss: 0.2551 took: 2.43s  Val. loss: 0.2610\n",
      "Epoch 31, 100% \t Train loss: 0.2551 took: 2.48s  Val. loss: 0.2601\n",
      "Epoch 32, 100% \t Train loss: 0.2550 took: 2.66s  Val. loss: 0.2602\n",
      "Epoch 33, 100% \t Train loss: 0.2551 took: 2.92s  Val. loss: 0.2606\n",
      "Epoch 34, 100% \t Train loss: 0.2550 took: 3.04s  Val. loss: 0.2602\n",
      "Epoch 35, 100% \t Train loss: 0.2551 took: 3.16s  Val. loss: 0.2611\n",
      "Epoch 36, 100% \t Train loss: 0.2552 took: 3.10s  Val. loss: 0.2609\n",
      "Epoch 37, 100% \t Train loss: 0.2551 took: 3.15s  Val. loss: 0.2603\n",
      "Epoch 38, 100% \t Train loss: 0.2550 took: 3.27s  Val. loss: 0.2602\n",
      "Epoch 39, 100% \t Train loss: 0.2551 took: 3.29s  Val. loss: 0.2609\n",
      "Epoch 40, 100% \t Train loss: 0.2550 took: 3.32s  Val. loss: 0.2606\n",
      "Epoch 41, 100% \t Train loss: 0.2551 took: 3.35s  Val. loss: 0.2602\n",
      "Epoch 42, 100% \t Train loss: 0.2550 took: 3.33s  Val. loss: 0.2601\n",
      "Epoch 43, 100% \t Train loss: 0.2551 took: 3.30s  Val. loss: 0.2612\n",
      "Epoch 44, 100% \t Train loss: 0.2550 took: 3.33s  Val. loss: 0.2606\n",
      "Epoch 45, 100% \t Train loss: 0.2550 took: 3.29s  Val. loss: 0.2600\n",
      "Epoch 46, 100% \t Train loss: 0.2551 took: 3.36s  Val. loss: 0.2605\n",
      "Epoch 47, 100% \t Train loss: 0.2550 took: 3.30s  Val. loss: 0.2601\n",
      "Epoch 48, 100% \t Train loss: 0.2550 took: 3.35s  Val. loss: 0.2611\n",
      "Epoch 49, 100% \t Train loss: 0.2550 took: 3.48s  Val. loss: 0.2608\n",
      "Epoch 50, 100% \t Train loss: 0.2550 took: 3.52s  Val. loss: 0.2602\n",
      "Training finished, took 152.14s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2600 took: 2.38s  Val. loss: 0.2559\n",
      "Epoch 2, 100% \t Train loss: 0.2595 took: 2.37s  Val. loss: 0.2566\n",
      "Epoch 3, 100% \t Train loss: 0.2593 took: 2.37s  Val. loss: 0.2565\n",
      "Epoch 4, 100% \t Train loss: 0.2592 took: 2.37s  Val. loss: 0.2568\n",
      "Epoch 5, 100% \t Train loss: 0.2593 took: 2.37s  Val. loss: 0.2561\n",
      "Epoch 6, 100% \t Train loss: 0.2592 took: 2.37s  Val. loss: 0.2550\n",
      "Epoch 7, 100% \t Train loss: 0.2593 took: 2.36s  Val. loss: 0.2558\n",
      "Epoch 8, 100% \t Train loss: 0.2592 took: 2.36s  Val. loss: 0.2563\n",
      "Epoch 9, 100% \t Train loss: 0.2592 took: 2.37s  Val. loss: 0.2553\n",
      "Epoch 10, 100% \t Train loss: 0.2592 took: 2.36s  Val. loss: 0.2567\n",
      "Epoch 11, 100% \t Train loss: 0.2593 took: 2.38s  Val. loss: 0.2558\n",
      "Epoch 12, 100% \t Train loss: 0.2593 took: 2.38s  Val. loss: 0.2559\n",
      "Epoch 13, 100% \t Train loss: 0.2593 took: 2.36s  Val. loss: 0.2565\n",
      "Epoch 14, 100% \t Train loss: 0.2592 took: 2.40s  Val. loss: 0.2546\n",
      "Epoch 15, 100% \t Train loss: 0.2592 took: 2.37s  Val. loss: 0.2558\n",
      "Epoch 16, 100% \t Train loss: 0.2593 took: 2.36s  Val. loss: 0.2552\n",
      "Epoch 17, 100% \t Train loss: 0.2592 took: 2.36s  Val. loss: 0.2547\n",
      "Epoch 18, 100% \t Train loss: 0.2593 took: 2.35s  Val. loss: 0.2551\n",
      "Epoch 19, 100% \t Train loss: 0.2592 took: 2.38s  Val. loss: 0.2556\n",
      "Epoch 20, 100% \t Train loss: 0.2592 took: 2.37s  Val. loss: 0.2554\n",
      "Epoch 21, 100% \t Train loss: 0.2592 took: 2.39s  Val. loss: 0.2559\n",
      "Epoch 22, 100% \t Train loss: 0.2592 took: 2.39s  Val. loss: 0.2564\n",
      "Epoch 23, 100% \t Train loss: 0.2592 took: 2.38s  Val. loss: 0.2558\n",
      "Epoch 24, 100% \t Train loss: 0.2592 took: 2.38s  Val. loss: 0.2548\n",
      "Epoch 25, 100% \t Train loss: 0.2592 took: 2.41s  Val. loss: 0.2552\n",
      "Epoch 26, 100% \t Train loss: 0.2592 took: 2.39s  Val. loss: 0.2556\n",
      "Epoch 27, 100% \t Train loss: 0.2592 took: 2.40s  Val. loss: 0.2561\n",
      "Epoch 28, 100% \t Train loss: 0.2592 took: 2.41s  Val. loss: 0.2554\n",
      "Epoch 29, 100% \t Train loss: 0.2592 took: 2.42s  Val. loss: 0.2559\n",
      "Epoch 30, 100% \t Train loss: 0.2592 took: 2.42s  Val. loss: 0.2553\n",
      "Epoch 31, 100% \t Train loss: 0.2592 took: 2.42s  Val. loss: 0.2557\n",
      "Epoch 32, 100% \t Train loss: 0.2592 took: 2.44s  Val. loss: 0.2550\n",
      "Epoch 33, 100% \t Train loss: 0.2592 took: 2.47s  Val. loss: 0.2554\n",
      "Epoch 34, 100% \t Train loss: 0.2591 took: 2.46s  Val. loss: 0.2561\n",
      "Epoch 35, 100% \t Train loss: 0.2592 took: 2.46s  Val. loss: 0.2555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, 100% \t Train loss: 0.2592 took: 2.47s  Val. loss: 0.2555\n",
      "Epoch 37, 100% \t Train loss: 0.2592 took: 2.49s  Val. loss: 0.2554\n",
      "Epoch 38, 100% \t Train loss: 0.2592 took: 2.50s  Val. loss: 0.2555\n",
      "Epoch 39, 100% \t Train loss: 0.2592 took: 2.55s  Val. loss: 0.2559\n",
      "Epoch 40, 100% \t Train loss: 0.2592 took: 2.54s  Val. loss: 0.2556\n",
      "Epoch 41, 100% \t Train loss: 0.2592 took: 2.56s  Val. loss: 0.2540\n",
      "Epoch 42, 100% \t Train loss: 0.2592 took: 2.58s  Val. loss: 0.2551\n",
      "Epoch 43, 100% \t Train loss: 0.2592 took: 2.53s  Val. loss: 0.2560\n",
      "Epoch 44, 100% \t Train loss: 0.2592 took: 2.50s  Val. loss: 0.2551\n",
      "Epoch 45, 100% \t Train loss: 0.2593 took: 2.50s  Val. loss: 0.2550\n",
      "Epoch 46, 100% \t Train loss: 0.2592 took: 2.52s  Val. loss: 0.2564\n",
      "Epoch 47, 100% \t Train loss: 0.2592 took: 2.52s  Val. loss: 0.2556\n",
      "Epoch 48, 100% \t Train loss: 0.2592 took: 2.55s  Val. loss: 0.2555\n",
      "Epoch 49, 100% \t Train loss: 0.2592 took: 2.52s  Val. loss: 0.2558\n",
      "Epoch 50, 100% \t Train loss: 0.2592 took: 2.53s  Val. loss: 0.2557\n",
      "Training finished, took 134.87s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2557 took: 2.41s  Val. loss: 0.2593\n",
      "Epoch 2, 100% \t Train loss: 0.2555 took: 2.39s  Val. loss: 0.2597\n",
      "Epoch 3, 100% \t Train loss: 0.2554 took: 2.39s  Val. loss: 0.2605\n",
      "Epoch 4, 100% \t Train loss: 0.2554 took: 2.38s  Val. loss: 0.2593\n",
      "Epoch 5, 100% \t Train loss: 0.2554 took: 2.38s  Val. loss: 0.2598\n",
      "Epoch 6, 100% \t Train loss: 0.2554 took: 2.37s  Val. loss: 0.2600\n",
      "Epoch 7, 100% \t Train loss: 0.2553 took: 2.38s  Val. loss: 0.2590\n",
      "Epoch 8, 100% \t Train loss: 0.2554 took: 2.39s  Val. loss: 0.2588\n",
      "Epoch 9, 100% \t Train loss: 0.2554 took: 2.38s  Val. loss: 0.2599\n",
      "Epoch 10, 100% \t Train loss: 0.2554 took: 2.38s  Val. loss: 0.2591\n",
      "Epoch 11, 100% \t Train loss: 0.2554 took: 2.39s  Val. loss: 0.2586\n",
      "Epoch 12, 100% \t Train loss: 0.2553 took: 2.38s  Val. loss: 0.2593\n",
      "Epoch 13, 100% \t Train loss: 0.2554 took: 2.36s  Val. loss: 0.2586\n",
      "Epoch 14, 100% \t Train loss: 0.2551 took: 2.38s  Val. loss: 0.2592\n",
      "Epoch 15, 100% \t Train loss: 0.2542 took: 2.38s  Val. loss: 0.2560\n",
      "Epoch 16, 100% \t Train loss: 0.2417 took: 2.40s  Val. loss: 0.2261\n",
      "Epoch 17, 100% \t Train loss: 0.2001 took: 2.38s  Val. loss: 0.1824\n",
      "Epoch 18, 100% \t Train loss: 0.1771 took: 2.37s  Val. loss: 0.1707\n",
      "Epoch 19, 100% \t Train loss: 0.1726 took: 2.38s  Val. loss: 0.1688\n",
      "Epoch 20, 100% \t Train loss: 0.1708 took: 1.45s  Val. loss: 0.1688\n",
      "Epoch 21, 100% \t Train loss: 0.1700 took: 1.45s  Val. loss: 0.1677\n",
      "Epoch 22, 100% \t Train loss: 0.1671 took: 1.44s  Val. loss: 0.1665\n",
      "Epoch 23, 100% \t Train loss: 0.1656 took: 1.45s  Val. loss: 0.1655\n",
      "Epoch 24, 100% \t Train loss: 0.1651 took: 1.45s  Val. loss: 0.1649\n",
      "Epoch 25, 100% \t Train loss: 0.1637 took: 1.45s  Val. loss: 0.1626\n",
      "Epoch 26, 100% \t Train loss: 0.1623 took: 1.45s  Val. loss: 0.1695\n",
      "Epoch 27, 100% \t Train loss: 0.1614 took: 1.45s  Val. loss: 0.1587\n",
      "Epoch 28, 100% \t Train loss: 0.1610 took: 2.17s  Val. loss: 0.1596\n",
      "Epoch 29, 100% \t Train loss: 0.1576 took: 2.41s  Val. loss: 0.1595\n",
      "Epoch 30, 100% \t Train loss: 0.1578 took: 2.10s  Val. loss: 0.1561\n",
      "Epoch 31, 100% \t Train loss: 0.1579 took: 1.54s  Val. loss: 0.1604\n",
      "Epoch 32, 100% \t Train loss: 0.1551 took: 1.56s  Val. loss: 0.1566\n",
      "Epoch 33, 100% \t Train loss: 0.1541 took: 1.58s  Val. loss: 0.1542\n",
      "Epoch 34, 100% \t Train loss: 0.1545 took: 1.58s  Val. loss: 0.1584\n",
      "Epoch 35, 100% \t Train loss: 0.1562 took: 1.59s  Val. loss: 0.1535\n",
      "Epoch 36, 100% \t Train loss: 0.1532 took: 1.58s  Val. loss: 0.1518\n",
      "Epoch 37, 100% \t Train loss: 0.1517 took: 1.58s  Val. loss: 0.1522\n",
      "Epoch 38, 100% \t Train loss: 0.1527 took: 1.59s  Val. loss: 0.1507\n",
      "Epoch 39, 100% \t Train loss: 0.1520 took: 1.61s  Val. loss: 0.1562\n",
      "Epoch 40, 100% \t Train loss: 0.1532 took: 1.61s  Val. loss: 0.1522\n",
      "Epoch 41, 100% \t Train loss: 0.1518 took: 1.63s  Val. loss: 0.1519\n",
      "Epoch 42, 100% \t Train loss: 0.1503 took: 1.62s  Val. loss: 0.1543\n",
      "Epoch 43, 100% \t Train loss: 0.1509 took: 1.64s  Val. loss: 0.1535\n",
      "Epoch 44, 100% \t Train loss: 0.1501 took: 1.65s  Val. loss: 0.1511\n",
      "Epoch 45, 100% \t Train loss: 0.1495 took: 1.64s  Val. loss: 0.1533\n",
      "Epoch 46, 100% \t Train loss: 0.1498 took: 1.63s  Val. loss: 0.1515\n",
      "Epoch 47, 100% \t Train loss: 0.1489 took: 1.64s  Val. loss: 0.1508\n",
      "Epoch 48, 100% \t Train loss: 0.1488 took: 1.67s  Val. loss: 0.1505\n",
      "Epoch 49, 100% \t Train loss: 0.1493 took: 1.71s  Val. loss: 0.1499\n",
      "Epoch 50, 100% \t Train loss: 0.1502 took: 1.76s  Val. loss: 0.1544\n",
      "Training finished, took 105.97s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  64  - prob: 0.33\n",
      "\tinfo_channels :  6  - prob: 0.33\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  2  - prob: 0.25\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.739532\n",
      "lambda: 0.0010 - V: 0.744364\n",
      "lambda: 0.0005 - V: 0.809957\n",
      "Average V: 0.764618\n",
      "Time elapsed: 396.47 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2567 took: 1.64s  Val. loss: 0.2623\n",
      "Epoch 2, 100% \t Train loss: 0.2544 took: 1.66s  Val. loss: 0.2501\n",
      "Epoch 3, 100% \t Train loss: 0.1970 took: 1.66s  Val. loss: 0.1756\n",
      "Epoch 4, 100% \t Train loss: 0.1610 took: 1.65s  Val. loss: 0.1696\n",
      "Epoch 5, 100% \t Train loss: 0.1556 took: 1.64s  Val. loss: 0.1665\n",
      "Epoch 6, 100% \t Train loss: 0.1519 took: 1.65s  Val. loss: 0.1635\n",
      "Epoch 7, 100% \t Train loss: 0.1491 took: 1.66s  Val. loss: 0.1605\n",
      "Epoch 8, 100% \t Train loss: 0.1484 took: 1.66s  Val. loss: 0.1620\n",
      "Epoch 9, 100% \t Train loss: 0.1472 took: 1.66s  Val. loss: 0.1616\n",
      "Epoch 10, 100% \t Train loss: 0.1467 took: 1.66s  Val. loss: 0.1608\n",
      "Epoch 11, 100% \t Train loss: 0.1456 took: 1.69s  Val. loss: 0.1624\n",
      "Epoch 12, 100% \t Train loss: 0.1455 took: 1.65s  Val. loss: 0.1601\n",
      "Epoch 13, 100% \t Train loss: 0.1452 took: 1.65s  Val. loss: 0.1635\n",
      "Epoch 14, 100% \t Train loss: 0.1444 took: 1.65s  Val. loss: 0.1642\n",
      "Epoch 15, 100% \t Train loss: 0.1445 took: 1.66s  Val. loss: 0.1633\n",
      "Epoch 16, 100% \t Train loss: 0.1436 took: 1.64s  Val. loss: 0.1656\n",
      "Epoch 17, 100% \t Train loss: 0.1429 took: 1.66s  Val. loss: 0.1631\n",
      "Epoch 18, 100% \t Train loss: 0.1424 took: 1.65s  Val. loss: 0.1636\n",
      "Epoch 19, 100% \t Train loss: 0.1422 took: 1.65s  Val. loss: 0.1661\n",
      "Epoch 20, 100% \t Train loss: 0.1419 took: 1.67s  Val. loss: 0.1646\n",
      "Epoch 21, 100% \t Train loss: 0.1411 took: 1.66s  Val. loss: 0.1643\n",
      "Epoch 22, 100% \t Train loss: 0.1411 took: 1.65s  Val. loss: 0.1639\n",
      "Epoch 23, 100% \t Train loss: 0.1407 took: 1.10s  Val. loss: 0.1641\n",
      "Epoch 24, 100% \t Train loss: 0.1399 took: 0.94s  Val. loss: 0.1659\n",
      "Epoch 25, 100% \t Train loss: 0.1389 took: 0.94s  Val. loss: 0.1622\n",
      "Epoch 26, 100% \t Train loss: 0.1377 took: 0.94s  Val. loss: 0.1628\n",
      "Epoch 27, 100% \t Train loss: 0.1372 took: 0.95s  Val. loss: 0.1634\n",
      "Epoch 28, 100% \t Train loss: 0.1350 took: 0.94s  Val. loss: 0.1603\n",
      "Epoch 29, 100% \t Train loss: 0.1326 took: 0.95s  Val. loss: 0.1606\n",
      "Epoch 30, 100% \t Train loss: 0.1314 took: 0.95s  Val. loss: 0.1562\n",
      "Epoch 31, 100% \t Train loss: 0.1286 took: 0.96s  Val. loss: 0.1550\n",
      "Epoch 32, 100% \t Train loss: 0.1274 took: 1.00s  Val. loss: 0.1534\n",
      "Epoch 33, 100% \t Train loss: 0.1252 took: 1.08s  Val. loss: 0.1541\n",
      "Epoch 34, 100% \t Train loss: 0.1238 took: 1.10s  Val. loss: 0.1480\n",
      "Epoch 35, 100% \t Train loss: 0.1216 took: 1.09s  Val. loss: 0.1441\n",
      "Epoch 36, 100% \t Train loss: 0.1185 took: 1.09s  Val. loss: 0.1449\n",
      "Epoch 37, 100% \t Train loss: 0.1154 took: 1.11s  Val. loss: 0.1392\n",
      "Epoch 38, 100% \t Train loss: 0.1118 took: 1.10s  Val. loss: 0.1354\n",
      "Epoch 39, 100% \t Train loss: 0.1080 took: 1.11s  Val. loss: 0.1293\n",
      "Epoch 40, 100% \t Train loss: 0.1041 took: 1.12s  Val. loss: 0.1279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, 100% \t Train loss: 0.1016 took: 1.13s  Val. loss: 0.1248\n",
      "Epoch 42, 100% \t Train loss: 0.0981 took: 1.15s  Val. loss: 0.1219\n",
      "Epoch 43, 100% \t Train loss: 0.0957 took: 1.16s  Val. loss: 0.1185\n",
      "Epoch 44, 100% \t Train loss: 0.0938 took: 1.15s  Val. loss: 0.1181\n",
      "Epoch 45, 100% \t Train loss: 0.0920 took: 1.16s  Val. loss: 0.1166\n",
      "Epoch 46, 100% \t Train loss: 0.0897 took: 1.16s  Val. loss: 0.1133\n",
      "Epoch 47, 100% \t Train loss: 0.0888 took: 1.17s  Val. loss: 0.1146\n",
      "Epoch 48, 100% \t Train loss: 0.0880 took: 1.17s  Val. loss: 0.1104\n",
      "Epoch 49, 100% \t Train loss: 0.0860 took: 1.19s  Val. loss: 0.1112\n",
      "Epoch 50, 100% \t Train loss: 0.0852 took: 1.20s  Val. loss: 0.1081\n",
      "Training finished, took 76.17s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2568 took: 1.67s  Val. loss: 0.2564\n",
      "Epoch 2, 100% \t Train loss: 0.2557 took: 1.67s  Val. loss: 0.2576\n",
      "Epoch 3, 100% \t Train loss: 0.2557 took: 1.66s  Val. loss: 0.2564\n",
      "Epoch 4, 100% \t Train loss: 0.2556 took: 1.65s  Val. loss: 0.2568\n",
      "Epoch 5, 100% \t Train loss: 0.2548 took: 1.66s  Val. loss: 0.2550\n",
      "Epoch 6, 100% \t Train loss: 0.2412 took: 1.66s  Val. loss: 0.2300\n",
      "Epoch 7, 100% \t Train loss: 0.2054 took: 1.65s  Val. loss: 0.1993\n",
      "Epoch 8, 100% \t Train loss: 0.1786 took: 1.65s  Val. loss: 0.1854\n",
      "Epoch 9, 100% \t Train loss: 0.1670 took: 1.68s  Val. loss: 0.1818\n",
      "Epoch 10, 100% \t Train loss: 0.1622 took: 1.65s  Val. loss: 0.1758\n",
      "Epoch 11, 100% \t Train loss: 0.1574 took: 1.66s  Val. loss: 0.1755\n",
      "Epoch 12, 100% \t Train loss: 0.1553 took: 1.67s  Val. loss: 0.1745\n",
      "Epoch 13, 100% \t Train loss: 0.1534 took: 1.68s  Val. loss: 0.1728\n",
      "Epoch 14, 100% \t Train loss: 0.1516 took: 1.66s  Val. loss: 0.1717\n",
      "Epoch 15, 100% \t Train loss: 0.1512 took: 1.67s  Val. loss: 0.1738\n",
      "Epoch 16, 100% \t Train loss: 0.1508 took: 1.66s  Val. loss: 0.1725\n",
      "Epoch 17, 100% \t Train loss: 0.1495 took: 1.67s  Val. loss: 0.1718\n",
      "Epoch 18, 100% \t Train loss: 0.1485 took: 1.66s  Val. loss: 0.1720\n",
      "Epoch 19, 100% \t Train loss: 0.1479 took: 1.66s  Val. loss: 0.1717\n",
      "Epoch 20, 100% \t Train loss: 0.1469 took: 1.68s  Val. loss: 0.1713\n",
      "Epoch 21, 100% \t Train loss: 0.1465 took: 1.69s  Val. loss: 0.1727\n",
      "Epoch 22, 100% \t Train loss: 0.1461 took: 1.66s  Val. loss: 0.1706\n",
      "Epoch 23, 100% \t Train loss: 0.1466 took: 1.65s  Val. loss: 0.1710\n",
      "Epoch 24, 100% \t Train loss: 0.1464 took: 1.67s  Val. loss: 0.1724\n",
      "Epoch 25, 100% \t Train loss: 0.1448 took: 1.65s  Val. loss: 0.1702\n",
      "Epoch 26, 100% \t Train loss: 0.1458 took: 1.65s  Val. loss: 0.1724\n",
      "Epoch 27, 100% \t Train loss: 0.1446 took: 1.64s  Val. loss: 0.1731\n",
      "Epoch 28, 100% \t Train loss: 0.1446 took: 1.66s  Val. loss: 0.1687\n",
      "Epoch 29, 100% \t Train loss: 0.1442 took: 1.68s  Val. loss: 0.1694\n",
      "Epoch 30, 100% \t Train loss: 0.1440 took: 1.67s  Val. loss: 0.1703\n",
      "Epoch 31, 100% \t Train loss: 0.1432 took: 1.65s  Val. loss: 0.1711\n",
      "Epoch 32, 100% \t Train loss: 0.1434 took: 1.55s  Val. loss: 0.1727\n",
      "Epoch 33, 100% \t Train loss: 0.1437 took: 1.67s  Val. loss: 0.1699\n",
      "Epoch 34, 100% \t Train loss: 0.1429 took: 1.67s  Val. loss: 0.1704\n",
      "Epoch 35, 100% \t Train loss: 0.1423 took: 1.67s  Val. loss: 0.1705\n",
      "Epoch 36, 100% \t Train loss: 0.1429 took: 1.68s  Val. loss: 0.1730\n",
      "Epoch 37, 100% \t Train loss: 0.1429 took: 1.70s  Val. loss: 0.1709\n",
      "Epoch 38, 100% \t Train loss: 0.1422 took: 1.69s  Val. loss: 0.1702\n",
      "Epoch 39, 100% \t Train loss: 0.1425 took: 1.69s  Val. loss: 0.1713\n",
      "Epoch 40, 100% \t Train loss: 0.1420 took: 1.70s  Val. loss: 0.1727\n",
      "Epoch 41, 100% \t Train loss: 0.1418 took: 1.71s  Val. loss: 0.1708\n",
      "Epoch 42, 100% \t Train loss: 0.1413 took: 1.36s  Val. loss: 0.1712\n",
      "Epoch 43, 100% \t Train loss: 0.1409 took: 0.97s  Val. loss: 0.1722\n",
      "Epoch 44, 100% \t Train loss: 0.1405 took: 0.96s  Val. loss: 0.1729\n",
      "Epoch 45, 100% \t Train loss: 0.1405 took: 0.97s  Val. loss: 0.1710\n",
      "Epoch 46, 100% \t Train loss: 0.1402 took: 0.97s  Val. loss: 0.1727\n",
      "Epoch 47, 100% \t Train loss: 0.1402 took: 0.98s  Val. loss: 0.1753\n",
      "Epoch 48, 100% \t Train loss: 0.1404 took: 0.98s  Val. loss: 0.1724\n",
      "Epoch 49, 100% \t Train loss: 0.1400 took: 0.98s  Val. loss: 0.1714\n",
      "Epoch 50, 100% \t Train loss: 0.1396 took: 0.98s  Val. loss: 0.1718\n",
      "Training finished, took 88.53s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2559 took: 1.64s  Val. loss: 0.2591\n",
      "Epoch 2, 100% \t Train loss: 0.2557 took: 1.65s  Val. loss: 0.2588\n",
      "Epoch 3, 100% \t Train loss: 0.2557 took: 1.66s  Val. loss: 0.2589\n",
      "Epoch 4, 100% \t Train loss: 0.2557 took: 1.64s  Val. loss: 0.2584\n",
      "Epoch 5, 100% \t Train loss: 0.2557 took: 1.66s  Val. loss: 0.2578\n",
      "Epoch 6, 100% \t Train loss: 0.2557 took: 1.65s  Val. loss: 0.2589\n",
      "Epoch 7, 100% \t Train loss: 0.2556 took: 1.66s  Val. loss: 0.2590\n",
      "Epoch 8, 100% \t Train loss: 0.2556 took: 1.68s  Val. loss: 0.2590\n",
      "Epoch 9, 100% \t Train loss: 0.2556 took: 1.64s  Val. loss: 0.2589\n",
      "Epoch 10, 100% \t Train loss: 0.2557 took: 1.66s  Val. loss: 0.2583\n",
      "Epoch 11, 100% \t Train loss: 0.2557 took: 1.65s  Val. loss: 0.2587\n",
      "Epoch 12, 100% \t Train loss: 0.2557 took: 1.65s  Val. loss: 0.2591\n",
      "Epoch 13, 100% \t Train loss: 0.2556 took: 0.95s  Val. loss: 0.2589\n",
      "Epoch 14, 100% \t Train loss: 0.2556 took: 0.94s  Val. loss: 0.2583\n",
      "Epoch 15, 100% \t Train loss: 0.2556 took: 0.94s  Val. loss: 0.2585\n",
      "Epoch 16, 100% \t Train loss: 0.2556 took: 0.94s  Val. loss: 0.2592\n",
      "Epoch 17, 100% \t Train loss: 0.2556 took: 0.94s  Val. loss: 0.2579\n",
      "Epoch 18, 100% \t Train loss: 0.2556 took: 0.94s  Val. loss: 0.2587\n",
      "Epoch 19, 100% \t Train loss: 0.2555 took: 1.33s  Val. loss: 0.2591\n",
      "Epoch 20, 100% \t Train loss: 0.2554 took: 1.68s  Val. loss: 0.2577\n",
      "Epoch 21, 100% \t Train loss: 0.2552 took: 1.66s  Val. loss: 0.2584\n",
      "Epoch 22, 100% \t Train loss: 0.2546 took: 1.62s  Val. loss: 0.2564\n",
      "Epoch 23, 100% \t Train loss: 0.2531 took: 1.66s  Val. loss: 0.2531\n",
      "Epoch 24, 100% \t Train loss: 0.2425 took: 1.67s  Val. loss: 0.2346\n",
      "Epoch 25, 100% \t Train loss: 0.2270 took: 0.93s  Val. loss: 0.2245\n",
      "Epoch 26, 100% \t Train loss: 0.2155 took: 0.94s  Val. loss: 0.2106\n",
      "Epoch 27, 100% \t Train loss: 0.2041 took: 0.94s  Val. loss: 0.2009\n",
      "Epoch 28, 100% \t Train loss: 0.1951 took: 0.94s  Val. loss: 0.1969\n",
      "Epoch 29, 100% \t Train loss: 0.1889 took: 0.95s  Val. loss: 0.1874\n",
      "Epoch 30, 100% \t Train loss: 0.1830 took: 0.96s  Val. loss: 0.1850\n",
      "Epoch 31, 100% \t Train loss: 0.1796 took: 0.97s  Val. loss: 0.1841\n",
      "Epoch 32, 100% \t Train loss: 0.1777 took: 0.98s  Val. loss: 0.1801\n",
      "Epoch 33, 100% \t Train loss: 0.1754 took: 0.98s  Val. loss: 0.1803\n",
      "Epoch 34, 100% \t Train loss: 0.1740 took: 0.98s  Val. loss: 0.1798\n",
      "Epoch 35, 100% \t Train loss: 0.1743 took: 0.98s  Val. loss: 0.1766\n",
      "Epoch 36, 100% \t Train loss: 0.1732 took: 0.97s  Val. loss: 0.1768\n",
      "Epoch 37, 100% \t Train loss: 0.1719 took: 0.97s  Val. loss: 0.1763\n",
      "Epoch 38, 100% \t Train loss: 0.1713 took: 0.97s  Val. loss: 0.1766\n",
      "Epoch 39, 100% \t Train loss: 0.1697 took: 0.97s  Val. loss: 0.1756\n",
      "Epoch 40, 100% \t Train loss: 0.1690 took: 0.97s  Val. loss: 0.1759\n",
      "Epoch 41, 100% \t Train loss: 0.1676 took: 0.97s  Val. loss: 0.1740\n",
      "Epoch 42, 100% \t Train loss: 0.1674 took: 0.98s  Val. loss: 0.1752\n",
      "Epoch 43, 100% \t Train loss: 0.1669 took: 0.98s  Val. loss: 0.1740\n",
      "Epoch 44, 100% \t Train loss: 0.1668 took: 0.98s  Val. loss: 0.1764\n",
      "Epoch 45, 100% \t Train loss: 0.1671 took: 0.98s  Val. loss: 0.1744\n",
      "Epoch 46, 100% \t Train loss: 0.1658 took: 0.98s  Val. loss: 0.1739\n",
      "Epoch 47, 100% \t Train loss: 0.1654 took: 0.99s  Val. loss: 0.1744\n",
      "Epoch 48, 100% \t Train loss: 0.1654 took: 0.99s  Val. loss: 0.1742\n",
      "Epoch 49, 100% \t Train loss: 0.1639 took: 1.00s  Val. loss: 0.1775\n",
      "Epoch 50, 100% \t Train loss: 0.1638 took: 1.00s  Val. loss: 0.1767\n",
      "Training finished, took 68.64s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  2  - prob: 0.35\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.846368\n",
      "lambda: 0.0010 - V: 0.817451\n",
      "lambda: 0.0005 - V: 0.781726\n",
      "Average V: 0.815182\n",
      "Time elapsed: 236.78 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2554 took: 1.80s  Val. loss: 0.2524\n",
      "Epoch 2, 100% \t Train loss: 0.1905 took: 1.80s  Val. loss: 0.1776\n",
      "Epoch 3, 100% \t Train loss: 0.1618 took: 1.02s  Val. loss: 0.1673\n",
      "Epoch 4, 100% \t Train loss: 0.1561 took: 1.02s  Val. loss: 0.1616\n",
      "Epoch 5, 100% \t Train loss: 0.1521 took: 1.02s  Val. loss: 0.1599\n",
      "Epoch 6, 100% \t Train loss: 0.1506 took: 1.02s  Val. loss: 0.1579\n",
      "Epoch 7, 100% \t Train loss: 0.1505 took: 1.03s  Val. loss: 0.1577\n",
      "Epoch 8, 100% \t Train loss: 0.1490 took: 1.03s  Val. loss: 0.1610\n",
      "Epoch 9, 100% \t Train loss: 0.1484 took: 1.02s  Val. loss: 0.1603\n",
      "Epoch 10, 100% \t Train loss: 0.1487 took: 1.02s  Val. loss: 0.1646\n",
      "Epoch 11, 100% \t Train loss: 0.1478 took: 1.04s  Val. loss: 0.1589\n",
      "Epoch 12, 100% \t Train loss: 0.1474 took: 1.02s  Val. loss: 0.1588\n",
      "Epoch 13, 100% \t Train loss: 0.1467 took: 1.02s  Val. loss: 0.1583\n",
      "Epoch 14, 100% \t Train loss: 0.1466 took: 1.03s  Val. loss: 0.1592\n",
      "Epoch 15, 100% \t Train loss: 0.1469 took: 1.03s  Val. loss: 0.1585\n",
      "Epoch 16, 100% \t Train loss: 0.1458 took: 1.37s  Val. loss: 0.1575\n",
      "Epoch 17, 100% \t Train loss: 0.1454 took: 1.79s  Val. loss: 0.1584\n",
      "Epoch 18, 100% \t Train loss: 0.1454 took: 1.80s  Val. loss: 0.1597\n",
      "Epoch 19, 100% \t Train loss: 0.1461 took: 1.80s  Val. loss: 0.1609\n",
      "Epoch 20, 100% \t Train loss: 0.1449 took: 1.80s  Val. loss: 0.1559\n",
      "Epoch 21, 100% \t Train loss: 0.1451 took: 1.78s  Val. loss: 0.1571\n",
      "Epoch 22, 100% \t Train loss: 0.1446 took: 1.81s  Val. loss: 0.1576\n",
      "Epoch 23, 100% \t Train loss: 0.1448 took: 1.03s  Val. loss: 0.1598\n",
      "Epoch 24, 100% \t Train loss: 0.1437 took: 1.03s  Val. loss: 0.1577\n",
      "Epoch 25, 100% \t Train loss: 0.1420 took: 1.03s  Val. loss: 0.1555\n",
      "Epoch 26, 100% \t Train loss: 0.1418 took: 1.03s  Val. loss: 0.1551\n",
      "Epoch 27, 100% \t Train loss: 0.1401 took: 1.04s  Val. loss: 0.1557\n",
      "Epoch 28, 100% \t Train loss: 0.1376 took: 1.10s  Val. loss: 0.1542\n",
      "Epoch 29, 100% \t Train loss: 0.1350 took: 1.04s  Val. loss: 0.1496\n",
      "Epoch 30, 100% \t Train loss: 0.1335 took: 1.05s  Val. loss: 0.1524\n",
      "Epoch 31, 100% \t Train loss: 0.1314 took: 1.09s  Val. loss: 0.1491\n",
      "Epoch 32, 100% \t Train loss: 0.1309 took: 1.29s  Val. loss: 0.1469\n",
      "Epoch 33, 100% \t Train loss: 0.1293 took: 1.49s  Val. loss: 0.1451\n",
      "Epoch 34, 100% \t Train loss: 0.1281 took: 1.56s  Val. loss: 0.1449\n",
      "Epoch 35, 100% \t Train loss: 0.1263 took: 1.57s  Val. loss: 0.1415\n",
      "Epoch 36, 100% \t Train loss: 0.1249 took: 1.60s  Val. loss: 0.1416\n",
      "Epoch 37, 100% \t Train loss: 0.1236 took: 1.59s  Val. loss: 0.1402\n",
      "Epoch 38, 100% \t Train loss: 0.1218 took: 1.60s  Val. loss: 0.1386\n",
      "Epoch 39, 100% \t Train loss: 0.1203 took: 1.60s  Val. loss: 0.1355\n",
      "Epoch 40, 100% \t Train loss: 0.1187 took: 1.63s  Val. loss: 0.1330\n",
      "Epoch 41, 100% \t Train loss: 0.1172 took: 1.67s  Val. loss: 0.1308\n",
      "Epoch 42, 100% \t Train loss: 0.1159 took: 2.43s  Val. loss: 0.1301\n",
      "Epoch 43, 100% \t Train loss: 0.1136 took: 2.47s  Val. loss: 0.1285\n",
      "Epoch 44, 100% \t Train loss: 0.1126 took: 2.47s  Val. loss: 0.1258\n",
      "Epoch 45, 100% \t Train loss: 0.1110 took: 2.45s  Val. loss: 0.1253\n",
      "Epoch 46, 100% \t Train loss: 0.1090 took: 2.46s  Val. loss: 0.1240\n",
      "Epoch 47, 100% \t Train loss: 0.1087 took: 2.45s  Val. loss: 0.1213\n",
      "Epoch 48, 100% \t Train loss: 0.1070 took: 2.43s  Val. loss: 0.1201\n",
      "Epoch 49, 100% \t Train loss: 0.1055 took: 2.44s  Val. loss: 0.1173\n",
      "Epoch 50, 100% \t Train loss: 0.1041 took: 2.43s  Val. loss: 0.1194\n",
      "Training finished, took 87.05s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2561 took: 1.04s  Val. loss: 0.2633\n",
      "Epoch 2, 100% \t Train loss: 0.2556 took: 1.03s  Val. loss: 0.2644\n",
      "Epoch 3, 100% \t Train loss: 0.2556 took: 1.03s  Val. loss: 0.2643\n",
      "Epoch 4, 100% \t Train loss: 0.2549 took: 1.03s  Val. loss: 0.2624\n",
      "Epoch 5, 100% \t Train loss: 0.2525 took: 1.03s  Val. loss: 0.2579\n",
      "Epoch 6, 100% \t Train loss: 0.2406 took: 1.04s  Val. loss: 0.2388\n",
      "Epoch 7, 100% \t Train loss: 0.2125 took: 1.04s  Val. loss: 0.2108\n",
      "Epoch 8, 100% \t Train loss: 0.1863 took: 1.03s  Val. loss: 0.1963\n",
      "Epoch 9, 100% \t Train loss: 0.1736 took: 1.03s  Val. loss: 0.1882\n",
      "Epoch 10, 100% \t Train loss: 0.1684 took: 1.02s  Val. loss: 0.1904\n",
      "Epoch 11, 100% \t Train loss: 0.1645 took: 1.03s  Val. loss: 0.1831\n",
      "Epoch 12, 100% \t Train loss: 0.1591 took: 1.03s  Val. loss: 0.1809\n",
      "Epoch 13, 100% \t Train loss: 0.1575 took: 1.03s  Val. loss: 0.1801\n",
      "Epoch 14, 100% \t Train loss: 0.1570 took: 1.03s  Val. loss: 0.1800\n",
      "Epoch 15, 100% \t Train loss: 0.1548 took: 1.03s  Val. loss: 0.1749\n",
      "Epoch 16, 100% \t Train loss: 0.1533 took: 1.03s  Val. loss: 0.1770\n",
      "Epoch 17, 100% \t Train loss: 0.1522 took: 1.03s  Val. loss: 0.1730\n",
      "Epoch 18, 100% \t Train loss: 0.1521 took: 1.03s  Val. loss: 0.1738\n",
      "Epoch 19, 100% \t Train loss: 0.1513 took: 1.03s  Val. loss: 0.1731\n",
      "Epoch 20, 100% \t Train loss: 0.1504 took: 1.03s  Val. loss: 0.1720\n",
      "Epoch 21, 100% \t Train loss: 0.1492 took: 1.03s  Val. loss: 0.1810\n",
      "Epoch 22, 100% \t Train loss: 0.1516 took: 1.03s  Val. loss: 0.1736\n",
      "Epoch 23, 100% \t Train loss: 0.1482 took: 1.03s  Val. loss: 0.1717\n",
      "Epoch 24, 100% \t Train loss: 0.1479 took: 1.03s  Val. loss: 0.1767\n",
      "Epoch 25, 100% \t Train loss: 0.1482 took: 1.03s  Val. loss: 0.1720\n",
      "Epoch 26, 100% \t Train loss: 0.1472 took: 1.04s  Val. loss: 0.1705\n",
      "Epoch 27, 100% \t Train loss: 0.1472 took: 1.04s  Val. loss: 0.1785\n",
      "Epoch 28, 100% \t Train loss: 0.1481 took: 1.05s  Val. loss: 0.1733\n",
      "Epoch 29, 100% \t Train loss: 0.1471 took: 1.07s  Val. loss: 0.1738\n",
      "Epoch 30, 100% \t Train loss: 0.1465 took: 1.09s  Val. loss: 0.1713\n",
      "Epoch 31, 100% \t Train loss: 0.1464 took: 1.12s  Val. loss: 0.1723\n",
      "Epoch 32, 100% \t Train loss: 0.1463 took: 1.20s  Val. loss: 0.1714\n",
      "Epoch 33, 100% \t Train loss: 0.1453 took: 1.21s  Val. loss: 0.1737\n",
      "Epoch 34, 100% \t Train loss: 0.1457 took: 1.22s  Val. loss: 0.1720\n",
      "Epoch 35, 100% \t Train loss: 0.1466 took: 1.25s  Val. loss: 0.1726\n",
      "Epoch 36, 100% \t Train loss: 0.1451 took: 1.25s  Val. loss: 0.1716\n",
      "Epoch 37, 100% \t Train loss: 0.1453 took: 1.23s  Val. loss: 0.1723\n",
      "Epoch 38, 100% \t Train loss: 0.1441 took: 1.26s  Val. loss: 0.1721\n",
      "Epoch 39, 100% \t Train loss: 0.1445 took: 1.28s  Val. loss: 0.1707\n",
      "Epoch 40, 100% \t Train loss: 0.1454 took: 1.27s  Val. loss: 0.1715\n",
      "Epoch 41, 100% \t Train loss: 0.1442 took: 1.31s  Val. loss: 0.1723\n",
      "Epoch 42, 100% \t Train loss: 0.1434 took: 1.39s  Val. loss: 0.1693\n",
      "Epoch 43, 100% \t Train loss: 0.1445 took: 2.09s  Val. loss: 0.1703\n",
      "Epoch 44, 100% \t Train loss: 0.1433 took: 1.36s  Val. loss: 0.1708\n",
      "Epoch 45, 100% \t Train loss: 0.1427 took: 1.32s  Val. loss: 0.1714\n",
      "Epoch 46, 100% \t Train loss: 0.1433 took: 1.16s  Val. loss: 0.1698\n",
      "Epoch 47, 100% \t Train loss: 0.1430 took: 1.16s  Val. loss: 0.1718\n",
      "Epoch 48, 100% \t Train loss: 0.1427 took: 1.14s  Val. loss: 0.1728\n",
      "Epoch 49, 100% \t Train loss: 0.1424 took: 1.15s  Val. loss: 0.1719\n",
      "Epoch 50, 100% \t Train loss: 0.1425 took: 1.15s  Val. loss: 0.1699\n",
      "Training finished, took 64.07s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2571 took: 1.03s  Val. loss: 0.2547\n",
      "Epoch 2, 100% \t Train loss: 0.2555 took: 1.03s  Val. loss: 0.2520\n",
      "Epoch 3, 100% \t Train loss: 0.2476 took: 1.03s  Val. loss: 0.2342\n",
      "Epoch 4, 100% \t Train loss: 0.2258 took: 1.03s  Val. loss: 0.2149\n",
      "Epoch 5, 100% \t Train loss: 0.2098 took: 1.04s  Val. loss: 0.1986\n",
      "Epoch 6, 100% \t Train loss: 0.1958 took: 1.10s  Val. loss: 0.1860\n",
      "Epoch 7, 100% \t Train loss: 0.1862 took: 1.03s  Val. loss: 0.1784\n",
      "Epoch 8, 100% \t Train loss: 0.1802 took: 1.03s  Val. loss: 0.1765\n",
      "Epoch 9, 100% \t Train loss: 0.1760 took: 1.03s  Val. loss: 0.1713\n",
      "Epoch 10, 100% \t Train loss: 0.1744 took: 1.03s  Val. loss: 0.1751\n",
      "Epoch 11, 100% \t Train loss: 0.1732 took: 1.03s  Val. loss: 0.1700\n",
      "Epoch 12, 100% \t Train loss: 0.1726 took: 1.03s  Val. loss: 0.1696\n",
      "Epoch 13, 100% \t Train loss: 0.1706 took: 1.03s  Val. loss: 0.1672\n",
      "Epoch 14, 100% \t Train loss: 0.1698 took: 1.03s  Val. loss: 0.1684\n",
      "Epoch 15, 100% \t Train loss: 0.1700 took: 1.03s  Val. loss: 0.1657\n",
      "Epoch 16, 100% \t Train loss: 0.1686 took: 1.03s  Val. loss: 0.1664\n",
      "Epoch 17, 100% \t Train loss: 0.1689 took: 1.03s  Val. loss: 0.1657\n",
      "Epoch 18, 100% \t Train loss: 0.1669 took: 1.03s  Val. loss: 0.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, 100% \t Train loss: 0.1659 took: 1.03s  Val. loss: 0.1649\n",
      "Epoch 20, 100% \t Train loss: 0.1649 took: 1.03s  Val. loss: 0.1622\n",
      "Epoch 21, 100% \t Train loss: 0.1632 took: 1.03s  Val. loss: 0.1640\n",
      "Epoch 22, 100% \t Train loss: 0.1633 took: 1.03s  Val. loss: 0.1643\n",
      "Epoch 23, 100% \t Train loss: 0.1624 took: 1.03s  Val. loss: 0.1688\n",
      "Epoch 24, 100% \t Train loss: 0.1643 took: 1.04s  Val. loss: 0.1619\n",
      "Epoch 25, 100% \t Train loss: 0.1621 took: 1.02s  Val. loss: 0.1598\n",
      "Epoch 26, 100% \t Train loss: 0.1611 took: 1.03s  Val. loss: 0.1601\n",
      "Epoch 27, 100% \t Train loss: 0.1610 took: 1.03s  Val. loss: 0.1587\n",
      "Epoch 28, 100% \t Train loss: 0.1595 took: 1.12s  Val. loss: 0.1656\n",
      "Epoch 29, 100% \t Train loss: 0.1592 took: 1.04s  Val. loss: 0.1599\n",
      "Epoch 30, 100% \t Train loss: 0.1586 took: 1.06s  Val. loss: 0.1660\n",
      "Epoch 31, 100% \t Train loss: 0.1606 took: 1.06s  Val. loss: 0.1628\n",
      "Epoch 32, 100% \t Train loss: 0.1587 took: 1.06s  Val. loss: 0.1617\n",
      "Epoch 33, 100% \t Train loss: 0.1581 took: 1.06s  Val. loss: 0.1590\n",
      "Epoch 34, 100% \t Train loss: 0.1574 took: 1.06s  Val. loss: 0.1580\n",
      "Epoch 35, 100% \t Train loss: 0.1579 took: 1.08s  Val. loss: 0.1607\n",
      "Epoch 36, 100% \t Train loss: 0.1580 took: 1.07s  Val. loss: 0.1578\n",
      "Epoch 37, 100% \t Train loss: 0.1577 took: 1.07s  Val. loss: 0.1590\n",
      "Epoch 38, 100% \t Train loss: 0.1566 took: 1.08s  Val. loss: 0.1593\n",
      "Epoch 39, 100% \t Train loss: 0.1577 took: 1.08s  Val. loss: 0.1583\n",
      "Epoch 40, 100% \t Train loss: 0.1566 took: 1.58s  Val. loss: 0.1580\n",
      "Epoch 41, 100% \t Train loss: 0.1561 took: 1.86s  Val. loss: 0.1576\n",
      "Epoch 42, 100% \t Train loss: 0.1563 took: 1.86s  Val. loss: 0.1589\n",
      "Epoch 43, 100% \t Train loss: 0.1561 took: 1.83s  Val. loss: 0.1592\n",
      "Epoch 44, 100% \t Train loss: 0.1559 took: 1.83s  Val. loss: 0.1566\n",
      "Epoch 45, 100% \t Train loss: 0.1551 took: 1.84s  Val. loss: 0.1558\n",
      "Epoch 46, 100% \t Train loss: 0.1552 took: 1.85s  Val. loss: 0.1567\n",
      "Epoch 47, 100% \t Train loss: 0.1546 took: 1.83s  Val. loss: 0.1570\n",
      "Epoch 48, 100% \t Train loss: 0.1543 took: 1.84s  Val. loss: 0.1561\n",
      "Epoch 49, 100% \t Train loss: 0.1542 took: 1.84s  Val. loss: 0.1583\n",
      "Epoch 50, 100% \t Train loss: 0.1543 took: 1.82s  Val. loss: 0.1614\n",
      "Training finished, took 68.75s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [8]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  32  - prob: 0.33\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.849596\n",
      "lambda: 0.0010 - V: 0.814445\n",
      "lambda: 0.0005 - V: 0.829822\n",
      "Average V: 0.831288\n",
      "Time elapsed: 223.25 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  8  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2597 took: 2.39s  Val. loss: 0.2570\n",
      "Epoch 2, 100% \t Train loss: 0.2591 took: 2.36s  Val. loss: 0.2579\n",
      "Epoch 3, 100% \t Train loss: 0.2593 took: 2.38s  Val. loss: 0.2576\n",
      "Epoch 4, 100% \t Train loss: 0.2592 took: 2.39s  Val. loss: 0.2571\n",
      "Epoch 5, 100% \t Train loss: 0.2593 took: 2.37s  Val. loss: 0.2565\n",
      "Epoch 6, 100% \t Train loss: 0.2591 took: 2.37s  Val. loss: 0.2575\n",
      "Epoch 7, 100% \t Train loss: 0.2592 took: 2.38s  Val. loss: 0.2585\n",
      "Epoch 8, 100% \t Train loss: 0.2591 took: 2.37s  Val. loss: 0.2571\n",
      "Epoch 9, 100% \t Train loss: 0.2591 took: 2.38s  Val. loss: 0.2589\n",
      "Epoch 10, 100% \t Train loss: 0.2592 took: 2.39s  Val. loss: 0.2567\n",
      "Epoch 11, 100% \t Train loss: 0.2591 took: 2.38s  Val. loss: 0.2578\n",
      "Epoch 12, 100% \t Train loss: 0.2591 took: 2.39s  Val. loss: 0.2577\n",
      "Epoch 13, 100% \t Train loss: 0.2591 took: 2.38s  Val. loss: 0.2582\n",
      "Epoch 14, 100% \t Train loss: 0.2591 took: 2.38s  Val. loss: 0.2574\n",
      "Epoch 15, 100% \t Train loss: 0.2591 took: 2.36s  Val. loss: 0.2572\n",
      "Epoch 16, 100% \t Train loss: 0.2591 took: 2.37s  Val. loss: 0.2581\n",
      "Epoch 17, 100% \t Train loss: 0.2591 took: 2.36s  Val. loss: 0.2574\n",
      "Epoch 18, 100% \t Train loss: 0.2591 took: 2.36s  Val. loss: 0.2578\n",
      "Epoch 19, 100% \t Train loss: 0.2591 took: 2.37s  Val. loss: 0.2570\n",
      "Epoch 20, 100% \t Train loss: 0.2591 took: 2.41s  Val. loss: 0.2578\n",
      "Epoch 21, 100% \t Train loss: 0.2591 took: 2.41s  Val. loss: 0.2582\n",
      "Epoch 22, 100% \t Train loss: 0.2591 took: 2.39s  Val. loss: 0.2580\n",
      "Epoch 23, 100% \t Train loss: 0.2591 took: 2.41s  Val. loss: 0.2575\n",
      "Epoch 24, 100% \t Train loss: 0.2591 took: 2.43s  Val. loss: 0.2579\n",
      "Epoch 25, 100% \t Train loss: 0.2591 took: 2.44s  Val. loss: 0.2579\n",
      "Epoch 26, 100% \t Train loss: 0.2591 took: 2.43s  Val. loss: 0.2568\n",
      "Epoch 27, 100% \t Train loss: 0.2591 took: 2.44s  Val. loss: 0.2581\n",
      "Epoch 28, 100% \t Train loss: 0.2591 took: 2.49s  Val. loss: 0.2571\n",
      "Epoch 29, 100% \t Train loss: 0.2591 took: 2.53s  Val. loss: 0.2567\n",
      "Epoch 30, 100% \t Train loss: 0.2590 took: 2.60s  Val. loss: 0.2575\n",
      "Epoch 31, 100% \t Train loss: 0.2590 took: 2.60s  Val. loss: 0.2578\n",
      "Epoch 32, 100% \t Train loss: 0.2591 took: 2.66s  Val. loss: 0.2577\n",
      "Epoch 33, 100% \t Train loss: 0.2591 took: 2.79s  Val. loss: 0.2578\n",
      "Epoch 34, 100% \t Train loss: 0.2591 took: 2.94s  Val. loss: 0.2581\n",
      "Epoch 35, 100% \t Train loss: 0.2591 took: 2.94s  Val. loss: 0.2573\n",
      "Epoch 36, 100% \t Train loss: 0.2591 took: 3.06s  Val. loss: 0.2583\n",
      "Epoch 37, 100% \t Train loss: 0.2590 took: 2.96s  Val. loss: 0.2581\n",
      "Epoch 38, 100% \t Train loss: 0.2591 took: 3.06s  Val. loss: 0.2580\n",
      "Epoch 39, 100% \t Train loss: 0.2590 took: 3.01s  Val. loss: 0.2577\n",
      "Epoch 40, 100% \t Train loss: 0.2591 took: 3.14s  Val. loss: 0.2581\n",
      "Epoch 41, 100% \t Train loss: 0.2591 took: 3.10s  Val. loss: 0.2578\n",
      "Epoch 42, 100% \t Train loss: 0.2590 took: 2.17s  Val. loss: 0.2571\n",
      "Epoch 43, 100% \t Train loss: 0.2590 took: 2.11s  Val. loss: 0.2586\n",
      "Epoch 44, 100% \t Train loss: 0.2590 took: 2.12s  Val. loss: 0.2584\n",
      "Epoch 45, 100% \t Train loss: 0.2590 took: 2.09s  Val. loss: 0.2582\n",
      "Epoch 46, 100% \t Train loss: 0.2591 took: 2.15s  Val. loss: 0.2576\n",
      "Epoch 47, 100% \t Train loss: 0.2590 took: 2.17s  Val. loss: 0.2585\n",
      "Epoch 48, 100% \t Train loss: 0.2590 took: 2.19s  Val. loss: 0.2580\n",
      "Epoch 49, 100% \t Train loss: 0.2590 took: 3.00s  Val. loss: 0.2578\n",
      "Epoch 50, 100% \t Train loss: 0.2591 took: 2.96s  Val. loss: 0.2570\n",
      "Training finished, took 139.26s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2571 took: 2.37s  Val. loss: 0.2525\n",
      "Epoch 2, 100% \t Train loss: 0.2570 took: 2.39s  Val. loss: 0.2523\n",
      "Epoch 3, 100% \t Train loss: 0.2570 took: 2.37s  Val. loss: 0.2530\n",
      "Epoch 4, 100% \t Train loss: 0.2570 took: 2.35s  Val. loss: 0.2523\n",
      "Epoch 5, 100% \t Train loss: 0.2569 took: 2.38s  Val. loss: 0.2536\n",
      "Epoch 6, 100% \t Train loss: 0.2570 took: 2.39s  Val. loss: 0.2525\n",
      "Epoch 7, 100% \t Train loss: 0.2570 took: 2.39s  Val. loss: 0.2531\n",
      "Epoch 8, 100% \t Train loss: 0.2569 took: 2.38s  Val. loss: 0.2520\n",
      "Epoch 9, 100% \t Train loss: 0.2570 took: 2.38s  Val. loss: 0.2523\n",
      "Epoch 10, 100% \t Train loss: 0.2570 took: 2.39s  Val. loss: 0.2525\n",
      "Epoch 11, 100% \t Train loss: 0.2569 took: 2.39s  Val. loss: 0.2526\n",
      "Epoch 12, 100% \t Train loss: 0.2570 took: 2.38s  Val. loss: 0.2524\n",
      "Epoch 13, 100% \t Train loss: 0.2569 took: 2.38s  Val. loss: 0.2526\n",
      "Epoch 14, 100% \t Train loss: 0.2569 took: 2.39s  Val. loss: 0.2527\n",
      "Epoch 15, 100% \t Train loss: 0.2570 took: 2.37s  Val. loss: 0.2525\n",
      "Epoch 16, 100% \t Train loss: 0.2570 took: 2.39s  Val. loss: 0.2529\n",
      "Epoch 17, 100% \t Train loss: 0.2569 took: 2.39s  Val. loss: 0.2531\n",
      "Epoch 18, 100% \t Train loss: 0.2570 took: 2.37s  Val. loss: 0.2524\n",
      "Epoch 19, 100% \t Train loss: 0.2570 took: 2.41s  Val. loss: 0.2536\n",
      "Epoch 20, 100% \t Train loss: 0.2570 took: 2.37s  Val. loss: 0.2521\n",
      "Epoch 21, 100% \t Train loss: 0.2570 took: 2.38s  Val. loss: 0.2528\n",
      "Epoch 22, 100% \t Train loss: 0.2570 took: 2.37s  Val. loss: 0.2517\n",
      "Epoch 23, 100% \t Train loss: 0.2570 took: 2.13s  Val. loss: 0.2522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, 100% \t Train loss: 0.2570 took: 1.43s  Val. loss: 0.2531\n",
      "Epoch 25, 100% \t Train loss: 0.2570 took: 1.43s  Val. loss: 0.2523\n",
      "Epoch 26, 100% \t Train loss: 0.2569 took: 1.44s  Val. loss: 0.2532\n",
      "Epoch 27, 100% \t Train loss: 0.2569 took: 1.44s  Val. loss: 0.2524\n",
      "Epoch 28, 100% \t Train loss: 0.2570 took: 1.45s  Val. loss: 0.2529\n",
      "Epoch 29, 100% \t Train loss: 0.2570 took: 1.45s  Val. loss: 0.2518\n",
      "Epoch 30, 100% \t Train loss: 0.2569 took: 1.47s  Val. loss: 0.2523\n",
      "Epoch 31, 100% \t Train loss: 0.2570 took: 1.46s  Val. loss: 0.2533\n",
      "Epoch 32, 100% \t Train loss: 0.2570 took: 1.47s  Val. loss: 0.2527\n",
      "Epoch 33, 100% \t Train loss: 0.2569 took: 1.48s  Val. loss: 0.2531\n",
      "Epoch 34, 100% \t Train loss: 0.2569 took: 2.41s  Val. loss: 0.2528\n",
      "Epoch 35, 100% \t Train loss: 0.2570 took: 2.45s  Val. loss: 0.2525\n",
      "Epoch 36, 100% \t Train loss: 0.2570 took: 2.42s  Val. loss: 0.2524\n",
      "Epoch 37, 100% \t Train loss: 0.2570 took: 2.42s  Val. loss: 0.2525\n",
      "Epoch 38, 100% \t Train loss: 0.2570 took: 2.43s  Val. loss: 0.2534\n",
      "Epoch 39, 100% \t Train loss: 0.2570 took: 2.41s  Val. loss: 0.2529\n",
      "Epoch 40, 100% \t Train loss: 0.2570 took: 1.45s  Val. loss: 0.2525\n",
      "Epoch 41, 100% \t Train loss: 0.2569 took: 1.46s  Val. loss: 0.2523\n",
      "Epoch 42, 100% \t Train loss: 0.2569 took: 1.46s  Val. loss: 0.2519\n",
      "Epoch 43, 100% \t Train loss: 0.2569 took: 1.46s  Val. loss: 0.2526\n",
      "Epoch 44, 100% \t Train loss: 0.2570 took: 1.48s  Val. loss: 0.2530\n",
      "Epoch 45, 100% \t Train loss: 0.2569 took: 1.46s  Val. loss: 0.2526\n",
      "Epoch 46, 100% \t Train loss: 0.2569 took: 1.51s  Val. loss: 0.2527\n",
      "Epoch 47, 100% \t Train loss: 0.2569 took: 1.57s  Val. loss: 0.2524\n",
      "Epoch 48, 100% \t Train loss: 0.2570 took: 1.63s  Val. loss: 0.2527\n",
      "Epoch 49, 100% \t Train loss: 0.2569 took: 1.67s  Val. loss: 0.2524\n",
      "Epoch 50, 100% \t Train loss: 0.2570 took: 1.61s  Val. loss: 0.2524\n",
      "Training finished, took 110.96s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2594 took: 2.34s  Val. loss: 0.2628\n",
      "Epoch 2, 100% \t Train loss: 0.2585 took: 1.42s  Val. loss: 0.2621\n",
      "Epoch 3, 100% \t Train loss: 0.2585 took: 1.42s  Val. loss: 0.2620\n",
      "Epoch 4, 100% \t Train loss: 0.2585 took: 1.41s  Val. loss: 0.2609\n",
      "Epoch 5, 100% \t Train loss: 0.2585 took: 1.42s  Val. loss: 0.2620\n",
      "Epoch 6, 100% \t Train loss: 0.2585 took: 1.42s  Val. loss: 0.2617\n",
      "Epoch 7, 100% \t Train loss: 0.2585 took: 1.42s  Val. loss: 0.2615\n",
      "Epoch 8, 100% \t Train loss: 0.2585 took: 1.42s  Val. loss: 0.2618\n",
      "Epoch 9, 100% \t Train loss: 0.2585 took: 1.42s  Val. loss: 0.2615\n",
      "Epoch 10, 100% \t Train loss: 0.2585 took: 1.52s  Val. loss: 0.2622\n",
      "Epoch 11, 100% \t Train loss: 0.2585 took: 1.97s  Val. loss: 0.2619\n",
      "Epoch 12, 100% \t Train loss: 0.2585 took: 2.39s  Val. loss: 0.2617\n",
      "Epoch 13, 100% \t Train loss: 0.2585 took: 2.38s  Val. loss: 0.2619\n",
      "Epoch 14, 100% \t Train loss: 0.2585 took: 2.39s  Val. loss: 0.2614\n",
      "Epoch 15, 100% \t Train loss: 0.2585 took: 2.38s  Val. loss: 0.2616\n",
      "Epoch 16, 100% \t Train loss: 0.2585 took: 2.41s  Val. loss: 0.2618\n",
      "Epoch 17, 100% \t Train loss: 0.2585 took: 2.47s  Val. loss: 0.2614\n",
      "Epoch 18, 100% \t Train loss: 0.2585 took: 2.62s  Val. loss: 0.2608\n",
      "Epoch 19, 100% \t Train loss: 0.2585 took: 2.29s  Val. loss: 0.2613\n",
      "Epoch 20, 100% \t Train loss: 0.2585 took: 2.34s  Val. loss: 0.2618\n",
      "Epoch 21, 100% \t Train loss: 0.2585 took: 2.61s  Val. loss: 0.2616\n",
      "Epoch 22, 100% \t Train loss: 0.2585 took: 2.57s  Val. loss: 0.2621\n",
      "Epoch 23, 100% \t Train loss: 0.2584 took: 2.62s  Val. loss: 0.2610\n",
      "Epoch 24, 100% \t Train loss: 0.2585 took: 2.49s  Val. loss: 0.2618\n",
      "Epoch 25, 100% \t Train loss: 0.2585 took: 2.45s  Val. loss: 0.2619\n",
      "Epoch 26, 100% \t Train loss: 0.2585 took: 2.50s  Val. loss: 0.2619\n",
      "Epoch 27, 100% \t Train loss: 0.2585 took: 1.73s  Val. loss: 0.2619\n",
      "Epoch 28, 100% \t Train loss: 0.2585 took: 1.44s  Val. loss: 0.2620\n",
      "Epoch 29, 100% \t Train loss: 0.2585 took: 1.44s  Val. loss: 0.2620\n",
      "Epoch 30, 100% \t Train loss: 0.2585 took: 1.45s  Val. loss: 0.2617\n",
      "Epoch 31, 100% \t Train loss: 0.2585 took: 1.45s  Val. loss: 0.2613\n",
      "Epoch 32, 100% \t Train loss: 0.2585 took: 1.46s  Val. loss: 0.2615\n",
      "Epoch 33, 100% \t Train loss: 0.2585 took: 1.46s  Val. loss: 0.2616\n",
      "Epoch 34, 100% \t Train loss: 0.2585 took: 1.45s  Val. loss: 0.2620\n",
      "Epoch 35, 100% \t Train loss: 0.2585 took: 1.46s  Val. loss: 0.2617\n",
      "Epoch 36, 100% \t Train loss: 0.2585 took: 1.46s  Val. loss: 0.2618\n",
      "Epoch 37, 100% \t Train loss: 0.2585 took: 1.46s  Val. loss: 0.2621\n",
      "Epoch 38, 100% \t Train loss: 0.2585 took: 1.48s  Val. loss: 0.2614\n",
      "Epoch 39, 100% \t Train loss: 0.2585 took: 1.49s  Val. loss: 0.2617\n",
      "Epoch 40, 100% \t Train loss: 0.2585 took: 1.49s  Val. loss: 0.2614\n",
      "Epoch 41, 100% \t Train loss: 0.2585 took: 1.51s  Val. loss: 0.2619\n",
      "Epoch 42, 100% \t Train loss: 0.2585 took: 2.41s  Val. loss: 0.2619\n",
      "Epoch 43, 100% \t Train loss: 0.2585 took: 2.42s  Val. loss: 0.2617\n",
      "Epoch 44, 100% \t Train loss: 0.2585 took: 2.43s  Val. loss: 0.2618\n",
      "Epoch 45, 100% \t Train loss: 0.2585 took: 2.45s  Val. loss: 0.2622\n",
      "Epoch 46, 100% \t Train loss: 0.2585 took: 2.45s  Val. loss: 0.2616\n",
      "Epoch 47, 100% \t Train loss: 0.2585 took: 1.50s  Val. loss: 0.2616\n",
      "Epoch 48, 100% \t Train loss: 0.2585 took: 1.49s  Val. loss: 0.2623\n",
      "Epoch 49, 100% \t Train loss: 0.2585 took: 1.49s  Val. loss: 0.2612\n",
      "Epoch 50, 100% \t Train loss: 0.2585 took: 1.49s  Val. loss: 0.2617\n",
      "Training finished, took 104.93s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6, 12]  - prob: 0.24\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  16  - prob: 0.33\n",
      "\tinfo_channels :  4  - prob: 0.32\n",
      "\tmask_channels :  8  - prob: 0.34\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.742303\n",
      "lambda: 0.0010 - V: 0.747390\n",
      "lambda: 0.0005 - V: 0.738269\n",
      "Average V: 0.742654\n",
      "Time elapsed: 358.51 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2610 took: 1.93s  Val. loss: 0.2624\n",
      "Epoch 2, 100% \t Train loss: 0.2608 took: 1.93s  Val. loss: 0.2629\n",
      "Epoch 3, 100% \t Train loss: 0.2603 took: 1.94s  Val. loss: 0.2617\n",
      "Epoch 4, 100% \t Train loss: 0.2468 took: 1.96s  Val. loss: 0.2262\n",
      "Epoch 5, 100% \t Train loss: 0.2093 took: 1.95s  Val. loss: 0.2050\n",
      "Epoch 6, 100% \t Train loss: 0.2022 took: 1.92s  Val. loss: 0.2001\n",
      "Epoch 7, 100% \t Train loss: 0.1984 took: 1.95s  Val. loss: 0.2001\n",
      "Epoch 8, 100% \t Train loss: 0.1977 took: 1.94s  Val. loss: 0.1978\n",
      "Epoch 9, 100% \t Train loss: 0.1958 took: 1.95s  Val. loss: 0.1967\n",
      "Epoch 10, 100% \t Train loss: 0.1933 took: 1.93s  Val. loss: 0.1948\n",
      "Epoch 11, 100% \t Train loss: 0.1919 took: 1.95s  Val. loss: 0.1927\n",
      "Epoch 12, 100% \t Train loss: 0.1894 took: 1.95s  Val. loss: 0.1896\n",
      "Epoch 13, 100% \t Train loss: 0.1879 took: 1.94s  Val. loss: 0.1867\n",
      "Epoch 14, 100% \t Train loss: 0.1850 took: 1.94s  Val. loss: 0.1853\n",
      "Epoch 15, 100% \t Train loss: 0.1835 took: 1.94s  Val. loss: 0.1848\n",
      "Epoch 16, 100% \t Train loss: 0.1816 took: 1.97s  Val. loss: 0.1804\n",
      "Epoch 17, 100% \t Train loss: 0.1791 took: 1.93s  Val. loss: 0.1803\n",
      "Epoch 18, 100% \t Train loss: 0.1784 took: 1.93s  Val. loss: 0.1769\n",
      "Epoch 19, 100% \t Train loss: 0.1741 took: 1.91s  Val. loss: 0.1752\n",
      "Epoch 20, 100% \t Train loss: 0.1713 took: 1.94s  Val. loss: 0.1722\n",
      "Epoch 21, 100% \t Train loss: 0.1698 took: 1.92s  Val. loss: 0.1759\n",
      "Epoch 22, 100% \t Train loss: 0.1685 took: 1.93s  Val. loss: 0.1700\n",
      "Epoch 23, 100% \t Train loss: 0.1666 took: 1.93s  Val. loss: 0.1726\n",
      "Epoch 24, 100% \t Train loss: 0.1639 took: 1.92s  Val. loss: 0.1627\n",
      "Epoch 25, 100% \t Train loss: 0.1628 took: 1.93s  Val. loss: 0.1676\n",
      "Epoch 26, 100% \t Train loss: 0.1615 took: 1.94s  Val. loss: 0.1643\n",
      "Epoch 27, 100% \t Train loss: 0.1590 took: 1.93s  Val. loss: 0.1655\n",
      "Epoch 28, 100% \t Train loss: 0.1593 took: 1.97s  Val. loss: 0.1657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, 100% \t Train loss: 0.1588 took: 1.93s  Val. loss: 0.1636\n",
      "Epoch 30, 100% \t Train loss: 0.1561 took: 1.95s  Val. loss: 0.1602\n",
      "Epoch 31, 100% \t Train loss: 0.1568 took: 1.96s  Val. loss: 0.1595\n",
      "Epoch 32, 100% \t Train loss: 0.1560 took: 2.04s  Val. loss: 0.1585\n",
      "Epoch 33, 100% \t Train loss: 0.1540 took: 2.18s  Val. loss: 0.1610\n",
      "Epoch 34, 100% \t Train loss: 0.1533 took: 2.19s  Val. loss: 0.1545\n",
      "Epoch 35, 100% \t Train loss: 0.1524 took: 2.19s  Val. loss: 0.1590\n",
      "Epoch 36, 100% \t Train loss: 0.1538 took: 2.20s  Val. loss: 0.1571\n",
      "Epoch 37, 100% \t Train loss: 0.1516 took: 2.23s  Val. loss: 0.1544\n",
      "Epoch 38, 100% \t Train loss: 0.1528 took: 2.25s  Val. loss: 0.1542\n",
      "Epoch 39, 100% \t Train loss: 0.1509 took: 2.25s  Val. loss: 0.1512\n",
      "Epoch 40, 100% \t Train loss: 0.1502 took: 2.26s  Val. loss: 0.1539\n",
      "Epoch 41, 100% \t Train loss: 0.1501 took: 2.27s  Val. loss: 0.1563\n",
      "Epoch 42, 100% \t Train loss: 0.1496 took: 2.27s  Val. loss: 0.1548\n",
      "Epoch 43, 100% \t Train loss: 0.1500 took: 2.27s  Val. loss: 0.1518\n",
      "Epoch 44, 100% \t Train loss: 0.1486 took: 2.28s  Val. loss: 0.1496\n",
      "Epoch 45, 100% \t Train loss: 0.1490 took: 2.27s  Val. loss: 0.1578\n",
      "Epoch 46, 100% \t Train loss: 0.1465 took: 2.27s  Val. loss: 0.1500\n",
      "Epoch 47, 100% \t Train loss: 0.1465 took: 2.28s  Val. loss: 0.1474\n",
      "Epoch 48, 100% \t Train loss: 0.1451 took: 2.29s  Val. loss: 0.1523\n",
      "Epoch 49, 100% \t Train loss: 0.1457 took: 2.29s  Val. loss: 0.1468\n",
      "Epoch 50, 100% \t Train loss: 0.1443 took: 2.30s  Val. loss: 0.1521\n",
      "Training finished, took 116.41s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2556 took: 1.94s  Val. loss: 0.2629\n",
      "Epoch 2, 100% \t Train loss: 0.2553 took: 1.94s  Val. loss: 0.2617\n",
      "Epoch 3, 100% \t Train loss: 0.2553 took: 1.92s  Val. loss: 0.2634\n",
      "Epoch 4, 100% \t Train loss: 0.2550 took: 1.91s  Val. loss: 0.2635\n",
      "Epoch 5, 100% \t Train loss: 0.2544 took: 1.94s  Val. loss: 0.2613\n",
      "Epoch 6, 100% \t Train loss: 0.2518 took: 1.92s  Val. loss: 0.2612\n",
      "Epoch 7, 100% \t Train loss: 0.2414 took: 1.13s  Val. loss: 0.2484\n",
      "Epoch 8, 100% \t Train loss: 0.2240 took: 1.14s  Val. loss: 0.2404\n",
      "Epoch 9, 100% \t Train loss: 0.2188 took: 1.14s  Val. loss: 0.2361\n",
      "Epoch 10, 100% \t Train loss: 0.2150 took: 1.14s  Val. loss: 0.2338\n",
      "Epoch 11, 100% \t Train loss: 0.2054 took: 1.14s  Val. loss: 0.2221\n",
      "Epoch 12, 100% \t Train loss: 0.1954 took: 1.14s  Val. loss: 0.2174\n",
      "Epoch 13, 100% \t Train loss: 0.1922 took: 1.14s  Val. loss: 0.2138\n",
      "Epoch 14, 100% \t Train loss: 0.1900 took: 1.13s  Val. loss: 0.2126\n",
      "Epoch 15, 100% \t Train loss: 0.1888 took: 1.14s  Val. loss: 0.2098\n",
      "Epoch 16, 100% \t Train loss: 0.1870 took: 1.14s  Val. loss: 0.2074\n",
      "Epoch 17, 100% \t Train loss: 0.1867 took: 1.14s  Val. loss: 0.2098\n",
      "Epoch 18, 100% \t Train loss: 0.1877 took: 1.13s  Val. loss: 0.2088\n",
      "Epoch 19, 100% \t Train loss: 0.1865 took: 1.14s  Val. loss: 0.2071\n",
      "Epoch 20, 100% \t Train loss: 0.1853 took: 1.14s  Val. loss: 0.2061\n",
      "Epoch 21, 100% \t Train loss: 0.1845 took: 1.13s  Val. loss: 0.2081\n",
      "Epoch 22, 100% \t Train loss: 0.1838 took: 1.14s  Val. loss: 0.2130\n",
      "Epoch 23, 100% \t Train loss: 0.1851 took: 1.14s  Val. loss: 0.2100\n",
      "Epoch 24, 100% \t Train loss: 0.1834 took: 1.14s  Val. loss: 0.2083\n",
      "Epoch 25, 100% \t Train loss: 0.1828 took: 1.14s  Val. loss: 0.2058\n",
      "Epoch 26, 100% \t Train loss: 0.1825 took: 1.14s  Val. loss: 0.2166\n",
      "Epoch 27, 100% \t Train loss: 0.1828 took: 1.14s  Val. loss: 0.2039\n",
      "Epoch 28, 100% \t Train loss: 0.1806 took: 1.18s  Val. loss: 0.2033\n",
      "Epoch 29, 100% \t Train loss: 0.1801 took: 1.95s  Val. loss: 0.2039\n",
      "Epoch 30, 100% \t Train loss: 0.1813 took: 1.93s  Val. loss: 0.2130\n",
      "Epoch 31, 100% \t Train loss: 0.1797 took: 1.94s  Val. loss: 0.2026\n",
      "Epoch 32, 100% \t Train loss: 0.1798 took: 1.97s  Val. loss: 0.2090\n",
      "Epoch 33, 100% \t Train loss: 0.1786 took: 1.94s  Val. loss: 0.2036\n",
      "Epoch 34, 100% \t Train loss: 0.1790 took: 1.94s  Val. loss: 0.2039\n",
      "Epoch 35, 100% \t Train loss: 0.1788 took: 1.95s  Val. loss: 0.2017\n",
      "Epoch 36, 100% \t Train loss: 0.1761 took: 1.93s  Val. loss: 0.2007\n",
      "Epoch 37, 100% \t Train loss: 0.1750 took: 1.96s  Val. loss: 0.1999\n",
      "Epoch 38, 100% \t Train loss: 0.1754 took: 1.93s  Val. loss: 0.2016\n",
      "Epoch 39, 100% \t Train loss: 0.1757 took: 1.93s  Val. loss: 0.2035\n",
      "Epoch 40, 100% \t Train loss: 0.1746 took: 1.92s  Val. loss: 0.1971\n",
      "Epoch 41, 100% \t Train loss: 0.1741 took: 1.96s  Val. loss: 0.1990\n",
      "Epoch 42, 100% \t Train loss: 0.1724 took: 1.97s  Val. loss: 0.1925\n",
      "Epoch 43, 100% \t Train loss: 0.1712 took: 1.95s  Val. loss: 0.1930\n",
      "Epoch 44, 100% \t Train loss: 0.1702 took: 1.94s  Val. loss: 0.1929\n",
      "Epoch 45, 100% \t Train loss: 0.1673 took: 1.94s  Val. loss: 0.1906\n",
      "Epoch 46, 100% \t Train loss: 0.1675 took: 1.96s  Val. loss: 0.1909\n",
      "Epoch 47, 100% \t Train loss: 0.1659 took: 1.95s  Val. loss: 0.1877\n",
      "Epoch 48, 100% \t Train loss: 0.1661 took: 1.92s  Val. loss: 0.1916\n",
      "Epoch 49, 100% \t Train loss: 0.1650 took: 1.94s  Val. loss: 0.1892\n",
      "Epoch 50, 100% \t Train loss: 0.1635 took: 1.94s  Val. loss: 0.1860\n",
      "Training finished, took 89.77s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2566 took: 1.93s  Val. loss: 0.2610\n",
      "Epoch 2, 100% \t Train loss: 0.2558 took: 1.91s  Val. loss: 0.2609\n",
      "Epoch 3, 100% \t Train loss: 0.2543 took: 1.95s  Val. loss: 0.2596\n",
      "Epoch 4, 100% \t Train loss: 0.2473 took: 1.92s  Val. loss: 0.2468\n",
      "Epoch 5, 100% \t Train loss: 0.2283 took: 1.93s  Val. loss: 0.2288\n",
      "Epoch 6, 100% \t Train loss: 0.2117 took: 1.93s  Val. loss: 0.2174\n",
      "Epoch 7, 100% \t Train loss: 0.2008 took: 1.93s  Val. loss: 0.2086\n",
      "Epoch 8, 100% \t Train loss: 0.1957 took: 1.94s  Val. loss: 0.2056\n",
      "Epoch 9, 100% \t Train loss: 0.1924 took: 1.93s  Val. loss: 0.2020\n",
      "Epoch 10, 100% \t Train loss: 0.1909 took: 1.95s  Val. loss: 0.2017\n",
      "Epoch 11, 100% \t Train loss: 0.1901 took: 1.97s  Val. loss: 0.2003\n",
      "Epoch 12, 100% \t Train loss: 0.1891 took: 1.94s  Val. loss: 0.1998\n",
      "Epoch 13, 100% \t Train loss: 0.1886 took: 1.94s  Val. loss: 0.1987\n",
      "Epoch 14, 100% \t Train loss: 0.1876 took: 1.93s  Val. loss: 0.1973\n",
      "Epoch 15, 100% \t Train loss: 0.1871 took: 1.93s  Val. loss: 0.1986\n",
      "Epoch 16, 100% \t Train loss: 0.1870 took: 1.94s  Val. loss: 0.1957\n",
      "Epoch 17, 100% \t Train loss: 0.1864 took: 1.90s  Val. loss: 0.1961\n",
      "Epoch 18, 100% \t Train loss: 0.1858 took: 1.93s  Val. loss: 0.1949\n",
      "Epoch 19, 100% \t Train loss: 0.1862 took: 1.92s  Val. loss: 0.1963\n",
      "Epoch 20, 100% \t Train loss: 0.1851 took: 1.92s  Val. loss: 0.1949\n",
      "Epoch 21, 100% \t Train loss: 0.1847 took: 1.92s  Val. loss: 0.1965\n",
      "Epoch 22, 100% \t Train loss: 0.1849 took: 1.92s  Val. loss: 0.1936\n",
      "Epoch 23, 100% \t Train loss: 0.1846 took: 1.94s  Val. loss: 0.1935\n",
      "Epoch 24, 100% \t Train loss: 0.1840 took: 1.94s  Val. loss: 0.1937\n",
      "Epoch 25, 100% \t Train loss: 0.1851 took: 1.93s  Val. loss: 0.1958\n",
      "Epoch 26, 100% \t Train loss: 0.1840 took: 1.93s  Val. loss: 0.1940\n",
      "Epoch 27, 100% \t Train loss: 0.1841 took: 1.16s  Val. loss: 0.1932\n",
      "Epoch 28, 100% \t Train loss: 0.1834 took: 1.14s  Val. loss: 0.1924\n",
      "Epoch 29, 100% \t Train loss: 0.1828 took: 1.14s  Val. loss: 0.1937\n",
      "Epoch 30, 100% \t Train loss: 0.1835 took: 1.14s  Val. loss: 0.1929\n",
      "Epoch 31, 100% \t Train loss: 0.1831 took: 1.14s  Val. loss: 0.1918\n",
      "Epoch 32, 100% \t Train loss: 0.1827 took: 1.16s  Val. loss: 0.1901\n",
      "Epoch 33, 100% \t Train loss: 0.1822 took: 1.15s  Val. loss: 0.1930\n",
      "Epoch 34, 100% \t Train loss: 0.1823 took: 1.15s  Val. loss: 0.1927\n",
      "Epoch 35, 100% \t Train loss: 0.1818 took: 1.16s  Val. loss: 0.1921\n",
      "Epoch 36, 100% \t Train loss: 0.1819 took: 1.16s  Val. loss: 0.1934\n",
      "Epoch 37, 100% \t Train loss: 0.1820 took: 1.84s  Val. loss: 0.1935\n",
      "Epoch 38, 100% \t Train loss: 0.1817 took: 1.97s  Val. loss: 0.1904\n",
      "Epoch 39, 100% \t Train loss: 0.1814 took: 1.96s  Val. loss: 0.1914\n",
      "Epoch 40, 100% \t Train loss: 0.1810 took: 1.99s  Val. loss: 0.1911\n",
      "Epoch 41, 100% \t Train loss: 0.1803 took: 1.97s  Val. loss: 0.1899\n",
      "Epoch 42, 100% \t Train loss: 0.1805 took: 1.95s  Val. loss: 0.1910\n",
      "Epoch 43, 100% \t Train loss: 0.1808 took: 1.95s  Val. loss: 0.1897\n",
      "Epoch 44, 100% \t Train loss: 0.1797 took: 1.95s  Val. loss: 0.1915\n",
      "Epoch 45, 100% \t Train loss: 0.1795 took: 1.95s  Val. loss: 0.1902\n",
      "Epoch 46, 100% \t Train loss: 0.1795 took: 1.95s  Val. loss: 0.1926\n",
      "Epoch 47, 100% \t Train loss: 0.1811 took: 1.97s  Val. loss: 0.1935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, 100% \t Train loss: 0.1796 took: 1.95s  Val. loss: 0.1901\n",
      "Epoch 49, 100% \t Train loss: 0.1793 took: 1.15s  Val. loss: 0.1901\n",
      "Epoch 50, 100% \t Train loss: 0.1792 took: 1.16s  Val. loss: 0.1909\n",
      "Training finished, took 98.86s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [6]  - prob: 0.25\n",
      "\tmax_pool_size :  4  - prob: 0.32\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  8  - prob: 0.34\n",
      "\thidden_channels :  12  - prob: 0.33\n",
      "\tresidual_hidden_dim :  16  - prob: 0.33\n",
      "\tn_residual_layers :  3  - prob: 0.26\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.824358\n",
      "lambda: 0.0010 - V: 0.786590\n",
      "lambda: 0.0005 - V: 0.799329\n",
      "Average V: 0.803426\n",
      "Time elapsed: 308.60 s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2553 took: 0.99s  Val. loss: 0.2250\n",
      "Epoch 2, 100% \t Train loss: 0.1861 took: 0.97s  Val. loss: 0.1724\n",
      "Epoch 3, 100% \t Train loss: 0.1663 took: 0.98s  Val. loss: 0.1647\n",
      "Epoch 4, 100% \t Train loss: 0.1603 took: 0.98s  Val. loss: 0.1707\n",
      "Epoch 5, 100% \t Train loss: 0.1581 took: 0.98s  Val. loss: 0.1646\n",
      "Epoch 6, 100% \t Train loss: 0.1560 took: 0.97s  Val. loss: 0.1621\n",
      "Epoch 7, 100% \t Train loss: 0.1558 took: 0.98s  Val. loss: 0.1647\n",
      "Epoch 8, 100% \t Train loss: 0.1551 took: 0.97s  Val. loss: 0.1613\n",
      "Epoch 9, 100% \t Train loss: 0.1546 took: 0.97s  Val. loss: 0.1639\n",
      "Epoch 10, 100% \t Train loss: 0.1544 took: 0.97s  Val. loss: 0.1620\n",
      "Epoch 11, 100% \t Train loss: 0.1527 took: 0.98s  Val. loss: 0.1613\n",
      "Epoch 12, 100% \t Train loss: 0.1519 took: 1.21s  Val. loss: 0.1606\n",
      "Epoch 13, 100% \t Train loss: 0.1518 took: 1.72s  Val. loss: 0.1618\n",
      "Epoch 14, 100% \t Train loss: 0.1508 took: 1.70s  Val. loss: 0.1613\n",
      "Epoch 15, 100% \t Train loss: 0.1500 took: 1.71s  Val. loss: 0.1618\n",
      "Epoch 16, 100% \t Train loss: 0.1496 took: 1.70s  Val. loss: 0.1624\n",
      "Epoch 17, 100% \t Train loss: 0.1492 took: 1.71s  Val. loss: 0.1597\n",
      "Epoch 18, 100% \t Train loss: 0.1477 took: 1.72s  Val. loss: 0.1589\n",
      "Epoch 19, 100% \t Train loss: 0.1461 took: 1.70s  Val. loss: 0.1598\n",
      "Epoch 20, 100% \t Train loss: 0.1438 took: 1.71s  Val. loss: 0.1547\n",
      "Epoch 21, 100% \t Train loss: 0.1377 took: 1.69s  Val. loss: 0.1439\n",
      "Epoch 22, 100% \t Train loss: 0.1243 took: 1.70s  Val. loss: 0.1282\n",
      "Epoch 23, 100% \t Train loss: 0.1092 took: 1.70s  Val. loss: 0.1120\n",
      "Epoch 24, 100% \t Train loss: 0.0982 took: 1.71s  Val. loss: 0.1036\n",
      "Epoch 25, 100% \t Train loss: 0.0930 took: 1.70s  Val. loss: 0.0990\n",
      "Epoch 26, 100% \t Train loss: 0.0888 took: 1.71s  Val. loss: 0.0983\n",
      "Epoch 27, 100% \t Train loss: 0.0867 took: 1.70s  Val. loss: 0.0953\n",
      "Epoch 28, 100% \t Train loss: 0.0848 took: 1.70s  Val. loss: 0.0924\n",
      "Epoch 29, 100% \t Train loss: 0.0838 took: 1.71s  Val. loss: 0.0939\n",
      "Epoch 30, 100% \t Train loss: 0.0823 took: 1.71s  Val. loss: 0.0933\n",
      "Epoch 31, 100% \t Train loss: 0.0815 took: 1.70s  Val. loss: 0.0918\n",
      "Epoch 32, 100% \t Train loss: 0.0806 took: 1.73s  Val. loss: 0.0912\n",
      "Epoch 33, 100% \t Train loss: 0.0804 took: 1.74s  Val. loss: 0.0944\n",
      "Epoch 34, 100% \t Train loss: 0.0802 took: 1.74s  Val. loss: 0.0913\n",
      "Epoch 35, 100% \t Train loss: 0.0784 took: 1.74s  Val. loss: 0.0931\n",
      "Epoch 36, 100% \t Train loss: 0.0786 took: 1.75s  Val. loss: 0.0892\n",
      "Epoch 37, 100% \t Train loss: 0.0780 took: 1.74s  Val. loss: 0.0912\n",
      "Epoch 38, 100% \t Train loss: 0.0779 took: 1.75s  Val. loss: 0.0898\n",
      "Epoch 39, 100% \t Train loss: 0.0763 took: 1.74s  Val. loss: 0.0906\n",
      "Epoch 40, 100% \t Train loss: 0.0774 took: 1.74s  Val. loss: 0.0947\n",
      "Epoch 41, 100% \t Train loss: 0.0769 took: 1.74s  Val. loss: 0.0895\n",
      "Epoch 42, 100% \t Train loss: 0.0759 took: 1.73s  Val. loss: 0.0903\n",
      "Epoch 43, 100% \t Train loss: 0.0755 took: 1.76s  Val. loss: 0.0940\n",
      "Epoch 44, 100% \t Train loss: 0.0750 took: 1.73s  Val. loss: 0.0892\n",
      "Epoch 45, 100% \t Train loss: 0.0747 took: 1.73s  Val. loss: 0.0898\n",
      "Epoch 46, 100% \t Train loss: 0.0743 took: 1.75s  Val. loss: 0.0902\n",
      "Epoch 47, 100% \t Train loss: 0.0746 took: 1.76s  Val. loss: 0.0925\n",
      "Epoch 48, 100% \t Train loss: 0.0743 took: 1.74s  Val. loss: 0.0925\n",
      "Epoch 49, 100% \t Train loss: 0.0741 took: 1.74s  Val. loss: 0.0900\n",
      "Epoch 50, 100% \t Train loss: 0.0745 took: 1.71s  Val. loss: 0.0916\n",
      "Training finished, took 88.82s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2565 took: 1.71s  Val. loss: 0.2617\n",
      "Epoch 2, 100% \t Train loss: 0.2552 took: 1.69s  Val. loss: 0.2596\n",
      "Epoch 3, 100% \t Train loss: 0.2388 took: 1.73s  Val. loss: 0.2199\n",
      "Epoch 4, 100% \t Train loss: 0.1895 took: 1.69s  Val. loss: 0.1907\n",
      "Epoch 5, 100% \t Train loss: 0.1745 took: 1.70s  Val. loss: 0.1839\n",
      "Epoch 6, 100% \t Train loss: 0.1691 took: 1.72s  Val. loss: 0.1826\n",
      "Epoch 7, 100% \t Train loss: 0.1687 took: 1.71s  Val. loss: 0.1831\n",
      "Epoch 8, 100% \t Train loss: 0.1665 took: 1.70s  Val. loss: 0.1783\n",
      "Epoch 9, 100% \t Train loss: 0.1649 took: 1.71s  Val. loss: 0.1780\n",
      "Epoch 10, 100% \t Train loss: 0.1641 took: 1.71s  Val. loss: 0.1760\n",
      "Epoch 11, 100% \t Train loss: 0.1631 took: 1.71s  Val. loss: 0.1765\n",
      "Epoch 12, 100% \t Train loss: 0.1637 took: 1.70s  Val. loss: 0.1831\n",
      "Epoch 13, 100% \t Train loss: 0.1611 took: 1.71s  Val. loss: 0.1741\n",
      "Epoch 14, 100% \t Train loss: 0.1601 took: 1.29s  Val. loss: 0.1775\n",
      "Epoch 15, 100% \t Train loss: 0.1589 took: 1.70s  Val. loss: 0.1743\n",
      "Epoch 16, 100% \t Train loss: 0.1601 took: 1.73s  Val. loss: 0.1826\n",
      "Epoch 17, 100% \t Train loss: 0.1594 took: 1.70s  Val. loss: 0.1777\n",
      "Epoch 18, 100% \t Train loss: 0.1605 took: 1.70s  Val. loss: 0.1747\n",
      "Epoch 19, 100% \t Train loss: 0.1564 took: 1.70s  Val. loss: 0.1805\n",
      "Epoch 20, 100% \t Train loss: 0.1563 took: 1.71s  Val. loss: 0.1749\n",
      "Epoch 21, 100% \t Train loss: 0.1546 took: 1.70s  Val. loss: 0.1710\n",
      "Epoch 22, 100% \t Train loss: 0.1540 took: 1.70s  Val. loss: 0.1707\n",
      "Epoch 23, 100% \t Train loss: 0.1534 took: 1.71s  Val. loss: 0.1705\n",
      "Epoch 24, 100% \t Train loss: 0.1526 took: 1.18s  Val. loss: 0.1704\n",
      "Epoch 25, 100% \t Train loss: 0.1532 took: 0.98s  Val. loss: 0.1726\n",
      "Epoch 26, 100% \t Train loss: 0.1525 took: 0.98s  Val. loss: 0.1732\n",
      "Epoch 27, 100% \t Train loss: 0.1526 took: 0.98s  Val. loss: 0.1693\n",
      "Epoch 28, 100% \t Train loss: 0.1508 took: 0.99s  Val. loss: 0.1717\n",
      "Epoch 29, 100% \t Train loss: 0.1497 took: 0.98s  Val. loss: 0.1673\n",
      "Epoch 30, 100% \t Train loss: 0.1510 took: 0.99s  Val. loss: 0.1712\n",
      "Epoch 31, 100% \t Train loss: 0.1499 took: 0.99s  Val. loss: 0.1695\n",
      "Epoch 32, 100% \t Train loss: 0.1492 took: 0.99s  Val. loss: 0.1665\n",
      "Epoch 33, 100% \t Train loss: 0.1471 took: 0.98s  Val. loss: 0.1662\n",
      "Epoch 34, 100% \t Train loss: 0.1468 took: 0.98s  Val. loss: 0.1699\n",
      "Epoch 35, 100% \t Train loss: 0.1470 took: 0.98s  Val. loss: 0.1683\n",
      "Epoch 36, 100% \t Train loss: 0.1453 took: 1.14s  Val. loss: 0.1640\n",
      "Epoch 37, 100% \t Train loss: 0.1438 took: 1.71s  Val. loss: 0.1622\n",
      "Epoch 38, 100% \t Train loss: 0.1421 took: 1.72s  Val. loss: 0.1622\n",
      "Epoch 39, 100% \t Train loss: 0.1406 took: 1.74s  Val. loss: 0.1668\n",
      "Epoch 40, 100% \t Train loss: 0.1382 took: 1.74s  Val. loss: 0.1574\n",
      "Epoch 41, 100% \t Train loss: 0.1356 took: 1.75s  Val. loss: 0.1576\n",
      "Epoch 42, 100% \t Train loss: 0.1332 took: 1.76s  Val. loss: 0.1541\n",
      "Epoch 43, 100% \t Train loss: 0.1309 took: 1.76s  Val. loss: 0.1580\n",
      "Epoch 44, 100% \t Train loss: 0.1287 took: 1.75s  Val. loss: 0.1481\n",
      "Epoch 45, 100% \t Train loss: 0.1260 took: 1.76s  Val. loss: 0.1461\n",
      "Epoch 46, 100% \t Train loss: 0.1237 took: 1.77s  Val. loss: 0.1474\n",
      "Epoch 47, 100% \t Train loss: 0.1219 took: 1.76s  Val. loss: 0.1411\n",
      "Epoch 48, 100% \t Train loss: 0.1194 took: 1.72s  Val. loss: 0.1392\n",
      "Epoch 49, 100% \t Train loss: 0.1172 took: 1.72s  Val. loss: 0.1405\n",
      "Epoch 50, 100% \t Train loss: 0.1158 took: 1.73s  Val. loss: 0.1366\n",
      "Training finished, took 87.56s\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Training network...\n",
      "Verbose:  True\n",
      "Using cuda:  False\n",
      "Epoch 1, 100% \t Train loss: 0.2550 took: 1.71s  Val. loss: 0.2563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.2545 took: 1.70s  Val. loss: 0.2571\n",
      "Epoch 3, 100% \t Train loss: 0.2544 took: 1.70s  Val. loss: 0.2571\n",
      "Epoch 4, 100% \t Train loss: 0.2543 took: 1.70s  Val. loss: 0.2569\n",
      "Epoch 5, 100% \t Train loss: 0.2543 took: 1.70s  Val. loss: 0.2558\n",
      "Epoch 6, 100% \t Train loss: 0.2537 took: 1.70s  Val. loss: 0.2562\n",
      "Epoch 7, 100% \t Train loss: 0.2524 took: 1.70s  Val. loss: 0.2535\n",
      "Epoch 8, 100% \t Train loss: 0.2468 took: 1.73s  Val. loss: 0.2414\n",
      "Epoch 9, 100% \t Train loss: 0.2204 took: 1.70s  Val. loss: 0.2036\n",
      "Epoch 10, 100% \t Train loss: 0.1928 took: 1.72s  Val. loss: 0.1838\n",
      "Epoch 11, 100% \t Train loss: 0.1761 took: 1.71s  Val. loss: 0.1710\n",
      "Epoch 12, 100% \t Train loss: 0.1668 took: 1.73s  Val. loss: 0.1653\n",
      "Epoch 13, 100% \t Train loss: 0.1658 took: 1.70s  Val. loss: 0.1637\n",
      "Epoch 14, 100% \t Train loss: 0.1624 took: 1.71s  Val. loss: 0.1609\n",
      "Epoch 15, 100% \t Train loss: 0.1602 took: 1.72s  Val. loss: 0.1628\n",
      "Epoch 16, 100% \t Train loss: 0.1598 took: 1.72s  Val. loss: 0.1623\n",
      "Epoch 17, 100% \t Train loss: 0.1595 took: 1.70s  Val. loss: 0.1582\n",
      "Epoch 18, 100% \t Train loss: 0.1569 took: 1.71s  Val. loss: 0.1552\n",
      "Epoch 19, 100% \t Train loss: 0.1566 took: 1.70s  Val. loss: 0.1596\n",
      "Epoch 20, 100% \t Train loss: 0.1565 took: 1.70s  Val. loss: 0.1559\n",
      "Epoch 21, 100% \t Train loss: 0.1550 took: 1.71s  Val. loss: 0.1568\n",
      "Epoch 22, 100% \t Train loss: 0.1552 took: 1.71s  Val. loss: 0.1546\n",
      "Epoch 23, 100% \t Train loss: 0.1544 took: 1.71s  Val. loss: 0.1560\n",
      "Epoch 24, 100% \t Train loss: 0.1533 took: 1.71s  Val. loss: 0.1547\n",
      "Epoch 25, 100% \t Train loss: 0.1538 took: 1.73s  Val. loss: 0.1555\n",
      "Epoch 26, 100% \t Train loss: 0.1537 took: 1.71s  Val. loss: 0.1527\n",
      "Epoch 27, 100% \t Train loss: 0.1520 took: 1.70s  Val. loss: 0.1533\n",
      "Epoch 28, 100% \t Train loss: 0.1512 took: 1.73s  Val. loss: 0.1518\n",
      "Epoch 29, 100% \t Train loss: 0.1516 took: 1.74s  Val. loss: 0.1522\n",
      "Epoch 30, 100% \t Train loss: 0.1514 took: 1.71s  Val. loss: 0.1527\n",
      "Epoch 31, 100% \t Train loss: 0.1511 took: 1.71s  Val. loss: 0.1534\n",
      "Epoch 32, 100% \t Train loss: 0.1507 took: 1.71s  Val. loss: 0.1544\n",
      "Epoch 33, 100% \t Train loss: 0.1503 took: 1.72s  Val. loss: 0.1534\n",
      "Epoch 34, 100% \t Train loss: 0.1528 took: 1.70s  Val. loss: 0.1593\n",
      "Epoch 35, 100% \t Train loss: 0.1510 took: 1.71s  Val. loss: 0.1519\n",
      "Epoch 36, 100% \t Train loss: 0.1501 took: 1.73s  Val. loss: 0.1502\n",
      "Epoch 37, 100% \t Train loss: 0.1504 took: 1.72s  Val. loss: 0.1508\n",
      "Epoch 38, 100% \t Train loss: 0.1493 took: 1.73s  Val. loss: 0.1518\n",
      "Epoch 39, 100% \t Train loss: 0.1493 took: 1.73s  Val. loss: 0.1515\n",
      "Epoch 40, 100% \t Train loss: 0.1495 took: 1.73s  Val. loss: 0.1512\n",
      "Epoch 41, 100% \t Train loss: 0.1487 took: 1.74s  Val. loss: 0.1509\n",
      "Epoch 42, 100% \t Train loss: 0.1494 took: 1.74s  Val. loss: 0.1506\n",
      "Epoch 43, 100% \t Train loss: 0.1486 took: 1.74s  Val. loss: 0.1522\n",
      "Epoch 44, 100% \t Train loss: 0.1489 took: 1.73s  Val. loss: 0.1507\n",
      "Epoch 45, 100% \t Train loss: 0.1483 took: 1.71s  Val. loss: 0.1523\n",
      "Epoch 46, 100% \t Train loss: 0.1483 took: 1.72s  Val. loss: 0.1503\n",
      "Epoch 47, 100% \t Train loss: 0.1477 took: 1.73s  Val. loss: 0.1512\n",
      "Epoch 48, 100% \t Train loss: 0.1482 took: 1.70s  Val. loss: 0.1509\n",
      "Epoch 49, 100% \t Train loss: 0.1476 took: 1.71s  Val. loss: 0.1499\n",
      "Epoch 50, 100% \t Train loss: 0.1475 took: 1.71s  Val. loss: 0.1500\n",
      "Training finished, took 98.08s\n",
      "\n",
      "========================================\n",
      "Configuration sampled: \n",
      "\tout_channels :  [12]  - prob: 0.26\n",
      "\tmax_pool_size :  3  - prob: 0.33\n",
      "\tn_features :  32  - prob: 0.34\n",
      "\tinfo_channels :  8  - prob: 0.35\n",
      "\tmask_channels :  4  - prob: 0.32\n",
      "\thidden_channels :  6  - prob: 0.34\n",
      "\tresidual_hidden_dim :  32  - prob: 0.33\n",
      "\tn_residual_layers :  1  - prob: 0.23\n",
      "========================================\n",
      "lambda: 0.0050 - V: 0.875991\n",
      "lambda: 0.0010 - V: 0.827623\n",
      "lambda: 0.0005 - V: 0.827724\n",
      "Average V: 0.843779\n",
      "Time elapsed: 278.01 s\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    bayes_HP_tuning.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPs = bayes_HP_tuning.return_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_channels': [12],\n",
       " 'max_pool_size': 2,\n",
       " 'n_features': 32,\n",
       " 'info_channels': 8,\n",
       " 'mask_channels': 8,\n",
       " 'hidden_channels': 6,\n",
       " 'residual_hidden_dim': 64,\n",
       " 'n_residual_layers': 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Param: out_channels\n",
      "Values:  [[6], [8], [12], [6, 12]]\n",
      "Probs:  [0.25266946 0.25565142 0.25581348 0.23586564]\n",
      "\n",
      "Param: max_pool_size\n",
      "Values:  [2, 3, 4]\n",
      "Probs:  [0.34545893 0.33361748 0.32092358]\n",
      "\n",
      "Param: n_features\n",
      "Values:  [16, 32, 64]\n",
      "Probs:  [0.32978766 0.33626912 0.33394322]\n",
      "\n",
      "Param: info_channels\n",
      "Values:  [4, 6, 8]\n",
      "Probs:  [0.31929414 0.33470014 0.34600572]\n",
      "\n",
      "Param: mask_channels\n",
      "Values:  [4, 6, 8]\n",
      "Probs:  [0.32431845 0.33287537 0.34280617]\n",
      "\n",
      "Param: hidden_channels\n",
      "Values:  [6, 12, 32]\n",
      "Probs:  [0.33557636 0.33308941 0.33133423]\n",
      "\n",
      "Param: residual_hidden_dim\n",
      "Values:  [16, 32, 64]\n",
      "Probs:  [0.33089575 0.33217632 0.33692793]\n",
      "\n",
      "Param: n_residual_layers\n",
      "Values:  [1, 2, 3, 4]\n",
      "Probs:  [0.23319344 0.25338094 0.25857873 0.2548469 ]\n"
     ]
    }
   ],
   "source": [
    "for k in HPs:\n",
    "    values, probs = bayes_HP_tuning.return_param_probs(k)\n",
    "    print(\"\\nParam: \"+k)\n",
    "    print(\"Values: \", values)\n",
    "    print(\"Probs: \", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save at Results/Sandbox/Supervised/HP_tuning__S_bayesian_CAWN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/m/work/modules/automatic/anaconda/envs/aalto-ubuntu1804-generic/software/anaconda/2020-01-tf2/5a34a04a/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MultiplicativeActor. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "save = True\n",
    "keywords = ['bayesian'] # example\n",
    "\n",
    "if save:\n",
    "    save_dir = 'Results/Sandbox/Supervised/'\n",
    "    ID = ''.join([random.choice(string.ascii_letters) for _ in range(4)])\n",
    "    ID = ID.upper()\n",
    "    keywords.append(ID)\n",
    "    filename = '_'.join(keywords)\n",
    "    filename = 'S_'+filename\n",
    "    print(\"Save at \"+save_dir+\"HP_tuning__\"+filename)\n",
    "    torch.save(bayes_HP_tuning, save_dir+\"HP_tuning_\"+filename)\n",
    "else:\n",
    "    print(\"Nothing saved\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
