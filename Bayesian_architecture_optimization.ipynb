{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to develop:\n",
    "1. parameters dictionary -> class on its own\n",
    "\n",
    "```python\n",
    "'key':{'values','prior','prior_sample_weight',0:{'V_lambda','V','freq'}, 1:...}\n",
    "    \n",
    "value_priors_dict = {'param_1':(values_1, priors_1), ..., 'param_m':(values_m, priors_m)}\n",
    "\n",
    "```\n",
    "\n",
    "2. Methods: init, sample_params, sample_key, update_params, update_key, evaluate_params\n",
    "\n",
    "3. Evaluation instance is a class that has a method evaluate_params and is passed already instantiated to the BayesianHPTuning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesHPTuning():\n",
    "    \n",
    "    def __init__(self, value_priors_dict, evaluation_instance, N=2, lambdas=[5e-3,1e-3,5e-4]):\n",
    "        \n",
    "        self.params = {}\n",
    "        for param in value_priors_dict.keys():\n",
    "            self.params[param] = BayesParam(*value_priors_dict[param], prior_sample_weight=N)\n",
    "            \n",
    "        self.eval = evaluation_instance\n",
    "        self.lambdas = lambdas\n",
    "        self.history = []\n",
    "    \n",
    "    def step(self):\n",
    "        HPs = self.sample_params()\n",
    "        V, V_lambda = self.evaluate_params(HPs)\n",
    "        self.update_params(V, V_lambda)\n",
    "        # here can be implemented conditions for logging, saving and stopping the whole thing\n",
    "        return\n",
    "    \n",
    "    def sample_params(self):\n",
    "        HPs = {}\n",
    "        for param in self.params:\n",
    "            value = self.params[param].sample()\n",
    "            HPs[param] = value\n",
    "        return HPs\n",
    "    \n",
    "    def evaluate_params(self, HPs):\n",
    "        # both of shape (len(lambdas), n_epochs)\n",
    "        train_V_lambda, val_V_lambda = self.eval.evaluate_params(HPs, self.lambdas)\n",
    "        \n",
    "        d = dict(HPs=HPs, lambdas=self.lambdas, train_V_lambda=train_V_lambda, val_V_lambda=val_V_lambda)\n",
    "        self.history.append(d)\n",
    "        \n",
    "        V = val_V_lambda.mean()\n",
    "        V_lambda = val_V_lambda.mean(axis=1)\n",
    "        \n",
    "        return V, V_lambda\n",
    "    \n",
    "    def update_params(self, V, V_lambda):\n",
    "        for param in value_priors_dict.keys():\n",
    "            self.params[param].update_stat(V, V_lambda)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesParam():\n",
    "    def __init__(self, values, priors, prior_sample_weight):\n",
    "        self.values = values\n",
    "        self.priors = priors\n",
    "        self.N = prior_sample_weight\n",
    "        self.global_V = []\n",
    "        self.last_sampled = None\n",
    "        self.stat = {}\n",
    "        for idx in range(len(values)):\n",
    "            self.stat[idx] = {'V_lambda':[], 'V':[], 'freq':0}\n",
    "            \n",
    "    def sample(self):\n",
    "        probs = self.get_updated_sampling_probs()\n",
    "        idx = np.random.choice(np.arange(len(self.values)), p=probs)\n",
    "        value = self.values[idx]\n",
    "        self.last_sampled = idx\n",
    "        return value\n",
    "        \n",
    "    def get_updated_sampling_probs(self):\n",
    "        expected_global_V = np.mean(self.global_V)\n",
    "        advantages = []\n",
    "        for idx in self.stat:\n",
    "            if self.stat['freq'] != 0:\n",
    "                expected_Vj = np.mean(self.stat[i]['V'])\n",
    "                adv_j = expected_Vj - expected_global_V\n",
    "            else:\n",
    "                adv_j = 0 # every value would do\n",
    "            biased_adv_j = (self.N*self.priors[idx]+self.stat['freq']*adv_j)/(self.N+self.stat['freq'])\n",
    "            advantages.append(biased_adv_j)\n",
    "        # sampling probs are the softmax of the biased advantages \n",
    "        advantages = np.array(advantages)\n",
    "        probs = np.exp(advantages)/np.exp(advantages).sum()\n",
    "        return probs\n",
    "    \n",
    "    def update_stat(self, V, V_lambda):\n",
    "        idx = self.last_sampled\n",
    "        self.stat[idx]['V'].append(V)\n",
    "        self.stat[idx]['V_lambda'].append(V_lambda)\n",
    "        self.stat[idx]['freq'] += 1\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
