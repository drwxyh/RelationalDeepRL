{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian optimization of architecture parameters\n",
    "\n",
    "**Idea:** given an optimization task and an architecture, find the best set of parameters in a given set.\n",
    "\n",
    "**Why Bayesian?** Because it is an adaptive optimization procedure, that starts sampling the parameters to try from some initial distributions (priors) provided by the user and then uses experience to update the sampling distribution, in order to maximize the expected performance on the task.\n",
    "\n",
    "Notation:\n",
    "- $\\overline{\\theta} = (\\theta_1, \\ldots, \\theta_m)$ is a set of parameters;\n",
    "- $\\theta_{-i}$ is a set of parameters excluding $\\theta_i$;\n",
    "- $\\theta_{ij}$ is the j-th possible value of the i-th parameter; \n",
    "- $V(\\overline{\\theta};\\lambda)$ is the value (performance) achieved in the task from that set of parameters and learning rate $\\lambda$;\n",
    "- $V(\\overline{\\theta})$ is the average value achieved by a set of parameters for different learning rates;\n",
    "- $V(\\overline{\\theta})=\\sum_{i=1}^m v_i(\\theta_i)$ is the value decomposition that for semplicity we assume (independent contribution from different parameters, neglecting interactions between them);\n",
    "\n",
    "I estimate $v_{ij} = v_i(\\theta_{ij})$ as follows:\n",
    "$$v_{ij} = \\underset{\\{\\theta_{-i}\\}}E[V(\\theta_{-i},\\theta_{ij}] - \\underset{\\{\\overline{\\theta}\\}}E[V(\\overline{\\theta})]$$\n",
    "Basically is the difference between the expected value marginal to having selected $\\theta_i = \\theta_{ij}$ w.r.t. the global expected value.\n",
    "\n",
    "I define a prior $\\Pi_i = (\\pi_1, \\ldots, \\pi_{n_i})$ for each parameter $\\theta_i$ and a number of samples $N$ associated to that prior (e.g. $N=2$); this basically tells me how much my prior will weight in the final probability distribution.\n",
    "\n",
    "**Probability distribution update:** After we try out a particular parameter configuration, we want to update the probability of sampling each parameter using the information that we gained (i.e. the value achieved by this particular configuration). To do so, first we compute the values $v_{ij}$ with the formula introduced above, then we compute the advantage in choosing $v_{ij}$ as $a_{ij} = \\frac{v_{ij} - \\overline{v_i}}{\\overline{v_i}}$; Now we compute the biased advantages $a^{(b)}_{ij}$ as a weighted sum between the prior and the real advantage, with weights $N$ and $f_{ij}$ and finally we take a softmax to get the probability distribution $p_{ij}$.\n",
    "\n",
    "Actually here the greatest problem is that the advantages and the prior have different scales at the moment, which means that our update won't be as effective as it should. The first thing that we need to solve is that we choose the prior using our intuition of what those probabilities mean, but we need to convert it in relative advantages if we want to compare it with the real advantages that we computed. One way of doing so is to consider the prior as a result of a softmax and to invert the operation:\n",
    "$$\\pi_{ij} = \\frac{exp(q_{ij})}{\\sum_k exp(q_{ik})}$$\n",
    "This yields $q_{ij} = log(\\pi_{ij}) + C_i$, with $C_i$ a constant that we can choose. Since the advantages $a_{ij}$ have zero average, we can choose $C_i$ so that even the $q_{ij}$ have zero average. In other words we cannot decide the range of values that $q_{ij}$ span, but only the center of that interval.\n",
    "So $C_i = - \\frac{1}{n_i}\\sum_k log(\\pi_{ik})$ and finally $$q_{ij} = log(\\pi_{ij}) - \\frac{1}{n_i}\\sum_k log(\\pi_{ik})$$\n",
    "So then \n",
    "$$a^{(b)}_{ij} = \\frac{Nq_{ij}+f_{ij}a_{ij}}{N+f_{ij}}$$\n",
    "and \n",
    "$$p_{ij} = \\frac{exp(a^{(b)}_{ij})}{\\sum_k exp(a^{(b)}_{ik})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesHPTuning():\n",
    "    \n",
    "    def __init__(self, value_priors_dict, evaluation_instance, N=2, lambdas=[5e-3,1e-3,5e-4]):\n",
    "        \n",
    "        self.params = {}\n",
    "        for param in value_priors_dict.keys():\n",
    "            self.params[param] = BayesParam(*value_priors_dict[param], prior_sample_weight=N)\n",
    "            \n",
    "        self.eval = evaluation_instance\n",
    "        self.lambdas = lambdas\n",
    "        self.history = []\n",
    "    \n",
    "    def step(self):\n",
    "        start = time.time()\n",
    "        \n",
    "        HPs, HPs_probs = self.sample_params()\n",
    "        print(\"\\n\"+\"=\"*40)\n",
    "        print(\"Configuration sampled: \")\n",
    "        for p in HPs:\n",
    "            print('\\t'+p+' : ',HPs[p], ' - prob: %.2f'%HPs_probs[p])\n",
    "        print(\"=\"*40)\n",
    "        V, V_lambda = self.evaluate_params(HPs)\n",
    "        self.update_params(V, V_lambda)\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        # here can be implemented conditions for logging, saving and stopping the whole thing\n",
    "        self.print_step(HPs, HPs_probs, V, V_lambda, elapsed)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def sample_params(self):\n",
    "        HPs = {}\n",
    "        HPs_probs = {}\n",
    "        for param in self.params:\n",
    "            value, prob = self.params[param].sample()\n",
    "            HPs[param] = value\n",
    "            HPs_probs[param] = prob\n",
    "        return HPs, HPs_probs\n",
    "    \n",
    "    def evaluate_params(self, HPs):\n",
    "        # both of shape (len(lambdas), n_epochs)\n",
    "        train_V_lambda, val_V_lambda = self.eval.evaluate_params(HPs, self.lambdas)\n",
    "        \n",
    "        d = dict(HPs=HPs, lambdas=self.lambdas, train_V_lambda=train_V_lambda, val_V_lambda=val_V_lambda)\n",
    "        self.history.append(d)\n",
    "        \n",
    "        V = val_V_lambda.mean()\n",
    "        V_lambda = val_V_lambda.mean(axis=1)\n",
    "        \n",
    "        return V, V_lambda\n",
    "    \n",
    "    def update_params(self, V, V_lambda):\n",
    "        for param in self.params:\n",
    "            self.params[param].update_stat(V, V_lambda)\n",
    "        return\n",
    "    \n",
    "    def print_step(self, HPs, HPs_probs, V, V_lambda, elapsed):\n",
    "        print(\"\\n\"+\"=\"*40)\n",
    "        print(\"Configuration sampled: \")\n",
    "        for p in HPs:\n",
    "            print('\\t'+p+' : ',HPs[p], ' - prob: %.2f'%HPs_probs[p])\n",
    "        print(\"=\"*40)\n",
    "        for i, l in enumerate(self.lambdas):\n",
    "            print(\"lambda: %.4f - V: %4f\"%(self.lambdas[i],V_lambda[i]))\n",
    "        print(\"Average V: %4f\"%V)\n",
    "        print(\"Time elapsed: %.2f s\"%(elapsed))\n",
    "        return\n",
    "    \n",
    "    def return_best_model(self):\n",
    "        HPs = {}\n",
    "        for param in self.params:\n",
    "            probs = self.params[param].get_updated_sampling_probs()\n",
    "            idx = np.argmax(probs)\n",
    "            v = self.params[param].values[idx]\n",
    "            HPs[param] = v\n",
    "        return HPs\n",
    "    \n",
    "    def return_param_probs(self, param_name):\n",
    "        values = self.params[param_name].values\n",
    "        probs = self.params[param_name].get_updated_sampling_probs()\n",
    "        return values, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesParam():\n",
    "    def __init__(self, values, priors, prior_sample_weight):\n",
    "        self.values = values\n",
    "        self.priors = priors\n",
    "        self.N = prior_sample_weight\n",
    "        self.global_V = []\n",
    "        self.last_sampled = None\n",
    "        self.stat = {}\n",
    "        for idx in range(len(values)):\n",
    "            self.stat[idx] = {'V_lambda':[], 'V':[], 'freq':0}\n",
    "            \n",
    "    def sample(self):\n",
    "        probs = self.get_updated_sampling_probs()\n",
    "        idx = np.random.choice(np.arange(len(self.values)), p=probs)\n",
    "        value = self.values[idx]\n",
    "        self.last_sampled = idx\n",
    "        return value\n",
    "        \n",
    "    def get_updated_sampling_probs(self):\n",
    "        expected_global_V = np.mean(self.global_V)\n",
    "        advantages = []\n",
    "        for idx in self.stat:\n",
    "            if self.stat['freq'] != 0:\n",
    "                expected_Vj = np.mean(self.stat[i]['V'])\n",
    "                adv_j = expected_Vj - expected_global_V\n",
    "            else:\n",
    "                adv_j = 0 # every value would do\n",
    "            biased_adv_j = (self.N*self.priors[idx]+self.stat['freq']*adv_j)/(self.N+self.stat['freq'])\n",
    "            advantages.append(biased_adv_j)\n",
    "        # sampling probs are the softmax of the biased advantages \n",
    "        advantages = np.array(advantages)\n",
    "        probs = np.exp(advantages)/np.exp(advantages).sum()\n",
    "        return probs\n",
    "    \n",
    "    def update_stat(self, V, V_lambda):\n",
    "        idx = self.last_sampled\n",
    "        self.stat[idx]['V'].append(V)\n",
    "        self.stat[idx]['V_lambda'].append(V_lambda)\n",
    "        self.stat[idx]['freq'] += 1\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
