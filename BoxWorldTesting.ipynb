{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "R9EYGzHsgtK6",
    "outputId": "b8434c21-12f3-4b79-e71b-07e5cf0864ef"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    !git clone https://github.com/deepmind/pycolab.git\n",
    "    !git clone https://github.com/nicoladainese96/RelationalModule.git\n",
    "    !pip install pycolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhQ0STsMfTkc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from RelationalModule import ActorCritic, ControlActorCritic\n",
    "from RelationalModule import train_agent as train\n",
    "from RelationalModule import utils\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6iwtqRC6fTkx",
    "outputId": "35629e0e-d823-4c64-a249-975db24775f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.train_agent' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/train_agent.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bec0WsZRfTlG"
   },
   "outputs": [],
   "source": [
    "GRID_SIZE = 7\n",
    "game_params = dict(grid_size=GRID_SIZE,\n",
    "                solution_length=[0],\n",
    "                num_forward = [0], # number of distractors\n",
    "                num_backward=[0], # just set to 0 for now\n",
    "                branch_length=1, # length of forward distractors\n",
    "                max_num_steps = 120\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HDHaeLwhfTlT",
    "outputId": "cd556298-557f-4d17-e299-37ac9f9432f0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "========== A2C HyperParameters ==========\n",
      "Discount factor:  0.99\n",
      "Learning rate:  0.003\n",
      "Action space:  4\n",
      "Temporal Difference learning:  True\n",
      "Twin networks:  True\n",
      "Update critic target factor:  0.2\n",
      "n_steps for TD:  40\n",
      "Device used:  cpu\n",
      "\n",
      "\n",
      "========== A2C Architecture ==========\n",
      "Actor architecture: \n",
      " ControlActor(\n",
      "  (control_net): ControlNet(\n",
      "    (embed): Embedding(117, 3)\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=243, out_features=768, bias=True)\n",
      "      (1): ResidualLayer(\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (w1): Linear(in_features=768, out_features=256, bias=True)\n",
      "        (w2): Linear(in_features=256, out_features=768, bias=True)\n",
      "      )\n",
      "      (2): Linear(in_features=768, out_features=256, bias=True)\n",
      "      (3): ResidualLayer(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n",
      "Critic architecture: \n",
      " ControlCritic(\n",
      "  (net1): ControlBasicCritic(\n",
      "    (control_net): ControlNet(\n",
      "      (embed): Embedding(117, 3)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=243, out_features=768, bias=True)\n",
      "        (1): ResidualLayer(\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (w1): Linear(in_features=768, out_features=256, bias=True)\n",
      "          (w2): Linear(in_features=256, out_features=768, bias=True)\n",
      "        )\n",
      "        (2): Linear(in_features=768, out_features=256, bias=True)\n",
      "        (3): ResidualLayer(\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (net2): ControlBasicCritic(\n",
      "    (control_net): ControlNet(\n",
      "      (embed): Embedding(117, 3)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=243, out_features=768, bias=True)\n",
      "        (1): ResidualLayer(\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (w1): Linear(in_features=768, out_features=256, bias=True)\n",
      "          (w2): Linear(in_features=256, out_features=768, bias=True)\n",
      "        )\n",
      "        (2): Linear(in_features=768, out_features=256, bias=True)\n",
      "        (3): ResidualLayer(\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Critic target architecture: \n",
      "ControlCritic(\n",
      "  (net1): ControlBasicCritic(\n",
      "    (control_net): ControlNet(\n",
      "      (embed): Embedding(117, 3)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=243, out_features=768, bias=True)\n",
      "        (1): ResidualLayer(\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (w1): Linear(in_features=768, out_features=256, bias=True)\n",
      "          (w2): Linear(in_features=256, out_features=768, bias=True)\n",
      "        )\n",
      "        (2): Linear(in_features=768, out_features=256, bias=True)\n",
      "        (3): ResidualLayer(\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (net2): ControlBasicCritic(\n",
      "    (control_net): ControlNet(\n",
      "      (embed): Embedding(117, 3)\n",
      "      (net): Sequential(\n",
      "        (0): Linear(in_features=243, out_features=768, bias=True)\n",
      "        (1): ResidualLayer(\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (w1): Linear(in_features=768, out_features=256, bias=True)\n",
      "          (w2): Linear(in_features=256, out_features=768, bias=True)\n",
      "        )\n",
      "        (2): Linear(in_features=768, out_features=256, bias=True)\n",
      "        (3): ResidualLayer(\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "HPs = dict(action_space=4, lr=0.003, gamma=0.99, TD=True, twin=True, tau=0.2, n_steps=40,\n",
    "           n_kernels=96, vocab_size = 117, n_dim=12, n_features=64, n_heads=4, n_attn_modules=2, \n",
    "           n_linears=4, max_pool=False, linear_size=GRID_SIZE+2)\n",
    "if colab:\n",
    "    HPs['device'] = 'cuda'\n",
    "else:\n",
    "    HPs['device'] = 'cpu'\n",
    "\n",
    "print('device: ', HPs['device'])  \n",
    "\n",
    "# Relational Agent\n",
    "agent = ActorCritic.BoxWorldA2C(**HPs)\n",
    "\n",
    "control_HPs = dict(action_space=4, lr=0.003, gamma=0.99, TD=True, twin=True, tau=0.2, n_steps=40, linear_size=GRID_SIZE+2)\n",
    "           \n",
    "# Control Agent\n",
    "control_agent = ControlActorCritic.ControlA2C(**control_HPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgCA3SMwxpcz"
   },
   "outputs": [],
   "source": [
    "# Random Agent\n",
    "\n",
    "class RandomAgent():\n",
    "    def __init__(self, n_actions):\n",
    "        self.n_actions = n_actions\n",
    "    \n",
    "    def get_action(self,state, *args, **kwargs):\n",
    "        a = np.random.choice(self.n_actions)\n",
    "        log_prob = np.log(1./self.n_actions) # just because it's the standard output of the other agent\n",
    "        return a, log_prob\n",
    "    \n",
    "    def update(self, *args):\n",
    "        return\n",
    "\n",
    "rnd_agent = RandomAgent(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "id": "Kf30nk3RqdHb",
    "outputId": "badd17e9-341e-4354-f224-7fc1a15eb529",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (77,)\n",
      "rewards.shape:  (77,)\n",
      "n_step_rewards:  [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          6.75729049  6.82554595  6.89449086  6.96413218  7.03447695\n",
      "  7.10553227  7.17730533  7.24980336  7.3230337   7.39700373  7.47172094\n",
      "  7.54719287  7.62342714  7.70043146  7.77821359  7.85678141  7.93614284\n",
      "  8.0163059   8.09727868  8.17906938  8.26168624  8.34513761  8.42943193\n",
      "  8.51457771  8.60058355  8.68745813  8.77521023  8.86384872  8.95338254\n",
      "  9.04382075  9.13517247  9.22744694  9.32065348  9.41480149  9.5099005\n",
      "  9.6059601   9.70299     9.801       9.9        10.        ]\n",
      "rewards:  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0. 10.]\n",
      "done.shape: (before n_steps) (77,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True]\n",
      "done.shape: (after n_steps) (77,)\n",
      "Gamma_V.shape:  (77,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.67572905 0.6825546  0.68944909 0.69641322\n",
      " 0.70344769 0.71055323 0.71773053 0.72498034 0.73230337 0.73970037\n",
      " 0.74717209 0.75471929 0.76234271 0.77004315 0.77782136 0.78567814\n",
      " 0.79361428 0.80163059 0.80972787 0.81790694 0.82616862 0.83451376\n",
      " 0.84294319 0.85145777 0.86005835 0.86874581 0.87752102 0.88638487\n",
      " 0.89533825 0.90438208 0.91351725 0.92274469 0.93206535 0.94148015\n",
      " 0.95099005 0.96059601 0.970299   0.9801     0.99      ]\n",
      "old_states.shape:  torch.Size([77, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([77, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([77])\n",
      "V_trg.shape (after sum):  torch.Size([77])\n",
      "V_trg.shape (after squeeze):  torch.Size([77])\n",
      "V_trg.shape:  torch.Size([77])\n",
      "V_pred.shape:  torch.Size([77])\n",
      "A.shape:  torch.Size([77])\n",
      "policy_gradient.shape:  torch.Size([77])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (4,)\n",
      "rewards.shape:  (4,)\n",
      "n_step_rewards:  [ 9.70299  9.801    9.9     10.     ]\n",
      "rewards:  [ 0.  0.  0. 10.]\n",
      "done.shape: (before n_steps) (4,)\n",
      "done: (before n_steps) [False False False  True]\n",
      "done.shape: (after n_steps) (4,)\n",
      "Gamma_V.shape:  (4,)\n",
      "done: (after n_steps) [ True  True  True  True]\n",
      "Gamma_V:  [0.96059601 0.970299   0.9801     0.99      ]\n",
      "old_states.shape:  torch.Size([4, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([4, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([4])\n",
      "V_trg.shape (after sum):  torch.Size([4])\n",
      "V_trg.shape (after squeeze):  torch.Size([4])\n",
      "V_trg.shape:  torch.Size([4])\n",
      "V_pred.shape:  torch.Size([4])\n",
      "A.shape:  torch.Size([4])\n",
      "policy_gradient.shape:  torch.Size([4])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (4,)\n",
      "rewards.shape:  (4,)\n",
      "n_step_rewards:  [ 9.70299  9.801    9.9     10.     ]\n",
      "rewards:  [ 0.  0.  0. 10.]\n",
      "done.shape: (before n_steps) (4,)\n",
      "done: (before n_steps) [False False False  True]\n",
      "done.shape: (after n_steps) (4,)\n",
      "Gamma_V.shape:  (4,)\n",
      "done: (after n_steps) [ True  True  True  True]\n",
      "Gamma_V:  [0.96059601 0.970299   0.9801     0.99      ]\n",
      "old_states.shape:  torch.Size([4, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([4, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([4])\n",
      "V_trg.shape (after sum):  torch.Size([4])\n",
      "V_trg.shape (after squeeze):  torch.Size([4])\n",
      "V_trg.shape:  torch.Size([4])\n",
      "V_pred.shape:  torch.Size([4])\n",
      "A.shape:  torch.Size([4])\n",
      "policy_gradient.shape:  torch.Size([4])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (2,)\n",
      "rewards.shape:  (2,)\n",
      "n_step_rewards:  [ 9.9 10. ]\n",
      "rewards:  [ 0. 10.]\n",
      "done.shape: (before n_steps) (2,)\n",
      "done: (before n_steps) [False  True]\n",
      "done.shape: (after n_steps) (2,)\n",
      "Gamma_V.shape:  (2,)\n",
      "done: (after n_steps) [ True  True]\n",
      "Gamma_V:  [0.9801 0.99  ]\n",
      "old_states.shape:  torch.Size([2, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([2, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([2])\n",
      "V_trg.shape (after sum):  torch.Size([2])\n",
      "V_trg.shape (after squeeze):  torch.Size([2])\n",
      "V_trg.shape:  torch.Size([2])\n",
      "V_pred.shape:  torch.Size([2])\n",
      "A.shape:  torch.Size([2])\n",
      "policy_gradient.shape:  torch.Size([2])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (2,)\n",
      "rewards.shape:  (2,)\n",
      "n_step_rewards:  [ 9.9 10. ]\n",
      "rewards:  [ 0. 10.]\n",
      "done.shape: (before n_steps) (2,)\n",
      "done: (before n_steps) [False  True]\n",
      "done.shape: (after n_steps) (2,)\n",
      "Gamma_V.shape:  (2,)\n",
      "done: (after n_steps) [ True  True]\n",
      "Gamma_V:  [0.9801 0.99  ]\n",
      "old_states.shape:  torch.Size([2, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([2, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([2])\n",
      "V_trg.shape (after sum):  torch.Size([2])\n",
      "V_trg.shape (after squeeze):  torch.Size([2])\n",
      "V_trg.shape:  torch.Size([2])\n",
      "V_pred.shape:  torch.Size([2])\n",
      "A.shape:  torch.Size([2])\n",
      "policy_gradient.shape:  torch.Size([2])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (3,)\n",
      "rewards.shape:  (3,)\n",
      "n_step_rewards:  [ 9.801  9.9   10.   ]\n",
      "rewards:  [ 0.  0. 10.]\n",
      "done.shape: (before n_steps) (3,)\n",
      "done: (before n_steps) [False False  True]\n",
      "done.shape: (after n_steps) (3,)\n",
      "Gamma_V.shape:  (3,)\n",
      "done: (after n_steps) [ True  True  True]\n",
      "Gamma_V:  [0.970299 0.9801   0.99    ]\n",
      "old_states.shape:  torch.Size([3, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([3, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([3])\n",
      "V_trg.shape (after sum):  torch.Size([3])\n",
      "V_trg.shape (after squeeze):  torch.Size([3])\n",
      "V_trg.shape:  torch.Size([3])\n",
      "V_pred.shape:  torch.Size([3])\n",
      "A.shape:  torch.Size([3])\n",
      "policy_gradient.shape:  torch.Size([3])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (3,)\n",
      "rewards.shape:  (3,)\n",
      "n_step_rewards:  [ 9.801  9.9   10.   ]\n",
      "rewards:  [ 0.  0. 10.]\n",
      "done.shape: (before n_steps) (3,)\n",
      "done: (before n_steps) [False False  True]\n",
      "done.shape: (after n_steps) (3,)\n",
      "Gamma_V.shape:  (3,)\n",
      "done: (after n_steps) [ True  True  True]\n",
      "Gamma_V:  [0.970299 0.9801   0.99    ]\n",
      "old_states.shape:  torch.Size([3, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([3, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([3])\n",
      "V_trg.shape (after sum):  torch.Size([3])\n",
      "V_trg.shape (after squeeze):  torch.Size([3])\n",
      "V_trg.shape:  torch.Size([3])\n",
      "V_pred.shape:  torch.Size([3])\n",
      "A.shape:  torch.Size([3])\n",
      "policy_gradient.shape:  torch.Size([3])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (1,)\n",
      "rewards.shape:  (1,)\n",
      "n_step_rewards:  [10.]\n",
      "rewards:  [10.]\n",
      "done.shape: (before n_steps) (1,)\n",
      "done: (before n_steps) [ True]\n",
      "done.shape: (after n_steps) (1,)\n",
      "Gamma_V.shape:  (1,)\n",
      "done: (after n_steps) [ True]\n",
      "Gamma_V:  [0.99]\n",
      "old_states.shape:  torch.Size([1, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([1, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([])\n",
      "V_trg.shape (after sum):  torch.Size([1])\n",
      "V_trg.shape (after squeeze):  torch.Size([])\n",
      "V_trg.shape:  torch.Size([1])\n",
      "V_pred.shape:  torch.Size([])\n",
      "A.shape:  torch.Size([1])\n",
      "policy_gradient.shape:  torch.Size([1])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (3,)\n",
      "rewards.shape:  (3,)\n",
      "n_step_rewards:  [ 9.801  9.9   10.   ]\n",
      "rewards:  [ 0.  0. 10.]\n",
      "done.shape: (before n_steps) (3,)\n",
      "done: (before n_steps) [False False  True]\n",
      "done.shape: (after n_steps) (3,)\n",
      "Gamma_V.shape:  (3,)\n",
      "done: (after n_steps) [ True  True  True]\n",
      "Gamma_V:  [0.970299 0.9801   0.99    ]\n",
      "old_states.shape:  torch.Size([3, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([3, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([3])\n",
      "V_trg.shape (after sum):  torch.Size([3])\n",
      "V_trg.shape (after squeeze):  torch.Size([3])\n",
      "V_trg.shape:  torch.Size([3])\n",
      "V_pred.shape:  torch.Size([3])\n",
      "A.shape:  torch.Size([3])\n",
      "policy_gradient.shape:  torch.Size([3])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (4,)\n",
      "rewards.shape:  (4,)\n",
      "n_step_rewards:  [ 9.70299  9.801    9.9     10.     ]\n",
      "rewards:  [ 0.  0.  0. 10.]\n",
      "done.shape: (before n_steps) (4,)\n",
      "done: (before n_steps) [False False False  True]\n",
      "done.shape: (after n_steps) (4,)\n",
      "Gamma_V.shape:  (4,)\n",
      "done: (after n_steps) [ True  True  True  True]\n",
      "Gamma_V:  [0.96059601 0.970299   0.9801     0.99      ]\n",
      "old_states.shape:  torch.Size([4, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([4, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([4])\n",
      "V_trg.shape (after sum):  torch.Size([4])\n",
      "V_trg.shape (after squeeze):  torch.Size([4])\n",
      "V_trg.shape:  torch.Size([4])\n",
      "V_pred.shape:  torch.Size([4])\n",
      "A.shape:  torch.Size([4])\n",
      "policy_gradient.shape:  torch.Size([4])\n",
      "n_step_rewards.shape:  (1,)\n",
      "rewards.shape:  (1,)\n",
      "n_step_rewards:  [10.]\n",
      "rewards:  [10.]\n",
      "done.shape: (before n_steps) (1,)\n",
      "done: (before n_steps) [ True]\n",
      "done.shape: (after n_steps) (1,)\n",
      "Gamma_V.shape:  (1,)\n",
      "done: (after n_steps) [ True]\n",
      "Gamma_V:  [0.99]\n",
      "old_states.shape:  torch.Size([1, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([1, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([])\n",
      "V_trg.shape (after sum):  torch.Size([1])\n",
      "V_trg.shape (after squeeze):  torch.Size([])\n",
      "V_trg.shape:  torch.Size([1])\n",
      "V_pred.shape:  torch.Size([])\n",
      "A.shape:  torch.Size([1])\n",
      "policy_gradient.shape:  torch.Size([1])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "Episode 100 - reward: 1.20\n",
      "n_step_rewards.shape:  (2,)\n",
      "rewards.shape:  (2,)\n",
      "n_step_rewards:  [ 9.9 10. ]\n",
      "rewards:  [ 0. 10.]\n",
      "done.shape: (before n_steps) (2,)\n",
      "done: (before n_steps) [False  True]\n",
      "done.shape: (after n_steps) (2,)\n",
      "Gamma_V.shape:  (2,)\n",
      "done: (after n_steps) [ True  True]\n",
      "Gamma_V:  [0.9801 0.99  ]\n",
      "old_states.shape:  torch.Size([2, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([2, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([2])\n",
      "V_trg.shape (after sum):  torch.Size([2])\n",
      "V_trg.shape (after squeeze):  torch.Size([2])\n",
      "V_trg.shape:  torch.Size([2])\n",
      "V_pred.shape:  torch.Size([2])\n",
      "A.shape:  torch.Size([2])\n",
      "policy_gradient.shape:  torch.Size([2])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n",
      "n_step_rewards.shape:  (121,)\n",
      "rewards.shape:  (121,)\n",
      "n_step_rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "rewards:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "done.shape: (before n_steps) (121,)\n",
      "done: (before n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "done.shape: (after n_steps) (121,)\n",
      "Gamma_V.shape:  (121,)\n",
      "done: (after n_steps) [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Gamma_V:  [0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176 0.66897176\n",
      " 0.66897176 0.66897176 0.66897176 0.66897176 0.67572905 0.6825546\n",
      " 0.68944909 0.69641322 0.70344769 0.71055323 0.71773053 0.72498034\n",
      " 0.73230337 0.73970037 0.74717209 0.75471929 0.76234271 0.77004315\n",
      " 0.77782136 0.78567814 0.79361428 0.80163059 0.80972787 0.81790694\n",
      " 0.82616862 0.83451376 0.84294319 0.85145777 0.86005835 0.86874581\n",
      " 0.87752102 0.88638487 0.89533825 0.90438208 0.91351725 0.92274469\n",
      " 0.93206535 0.94148015 0.95099005 0.96059601 0.970299   0.9801\n",
      " 0.99      ]\n",
      "old_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "new_states.shape:  torch.Size([121, 1, 9, 9])\n",
      "V_trg.shape (after critic):  torch.Size([121])\n",
      "V_trg.shape (after sum):  torch.Size([121])\n",
      "V_trg.shape (after squeeze):  torch.Size([121])\n",
      "V_trg.shape:  torch.Size([121])\n",
      "V_pred.shape:  torch.Size([121])\n",
      "A.shape:  torch.Size([121])\n",
      "policy_gradient.shape:  torch.Size([121])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/train_agent.py\u001b[0m in \u001b[0;36mtrain_boxworld\u001b[0;34m(agent, game_params, n_episodes, max_steps, return_agent, mask)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgame_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m#print(\"Time playing the episode: %.2f s\"%(t1-t0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/train_agent.py\u001b[0m in \u001b[0;36mplay_episode\u001b[0;34m(agent, game, max_steps, mask)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Start the episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mits_showtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/train_agent.py\u001b[0m in \u001b[0;36mget_state\u001b[0;34m(observation, mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#print(\"board (masked): \", board)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mgrid_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mboard\u001b[0m \u001b[0;31m#/MAX_PIXEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = train.train_boxworld(control_agent, game_params, n_episodes=5000, \n",
    "                               max_steps=game_params['max_num_steps'], return_agent=True, mask=True)\n",
    "score, asymptotic_score, asymptotic_std, trained_agent, time_profile = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkdAxrzyfTmG"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "n_epochs = np.arange(100, len(score))\n",
    "average_score = np.array([np.mean(score[i:i+100]) for i in range(len(score)-100)])\n",
    "plt.plot(n_epochs, average_score, alpha=0.9)\n",
    "plt.title(\"Performance\", fontsize=16)\n",
    "plt.xlabel(\"Number of epochs\", fontsize=16)\n",
    "plt.ylabel(\"Total reward\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRZNea0rKVE_"
   },
   "outputs": [],
   "source": [
    "save = False\n",
    "keywords = ['relational', 'residual','unboxed_gem',str(len(control_score))+\"-episodes\",\"50-steps\"] # example\n",
    "\n",
    "if colab and save:\n",
    "    %cd ~\n",
    "    parent_dir = \"/content/gdrive/My Drive/Colab Notebooks/\"\n",
    "    save_dir  = \"RelationalTrained/\"\n",
    "    %cd \"{parent_dir}\"\n",
    "    !mkdir \"{save_dir}\"\n",
    "    ID = utils.save_session(save_dir, keywords, game_params, HPs, score)\n",
    "    torch.save(trained_agent, save_dir+\"agent_\"+ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dluPwuvZcAkI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BoxWorldTesting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
