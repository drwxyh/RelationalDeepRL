{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "R9EYGzHsgtK6",
    "outputId": "972e0c17-ed98-4a0c-cdfa-66d2bf38eef6"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "\n",
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    !git clone https://github.com/deepmind/pycolab.git\n",
    "    !git clone https://github.com/nicoladainese96/RelationalModule.git\n",
    "    !pip install pycolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhQ0STsMfTkc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from RelationalModule import ActorCritic, ControlActorCritic\n",
    "from RelationalModule import train_agent as train\n",
    "from RelationalModule import utils\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6iwtqRC6fTkx",
    "outputId": "49c6b6e7-33d1-4478-cf15-4bdcfaa8e0ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.train_agent' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/train_agent.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bec0WsZRfTlG"
   },
   "outputs": [],
   "source": [
    "game_params = dict(grid_size=12,\n",
    "                solution_length=[0],\n",
    "                num_forward = [0], # number of distractors\n",
    "                num_backward=[0], # just set to 0 for now\n",
    "                branch_length=1, # length of forward distractors\n",
    "                max_num_steps = 50\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HDHaeLwhfTlT",
    "outputId": "dc95807b-6c0c-4262-ea1a-d74668166ae7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "Sequential(\n",
      "  (0): ExtractEntities(\n",
      "    (embed): Embedding(117, 3)\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 12, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(12, 24, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): RelationalModule(\n",
      "    (net): Sequential(\n",
      "      (0): PositionalEncoding(\n",
      "        (projection): Linear(in_features=26, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): FeaturewiseMaxPool()\n",
      "  (3): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (4): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (5): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (6): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): ExtractEntities(\n",
      "    (embed): Embedding(117, 3)\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 12, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(12, 24, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): RelationalModule(\n",
      "    (net): Sequential(\n",
      "      (0): PositionalEncoding(\n",
      "        (projection): Linear(in_features=26, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): FeaturewiseMaxPool()\n",
      "  (3): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (4): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (5): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (6): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): ExtractEntities(\n",
      "    (embed): Embedding(117, 3)\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 12, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(12, 24, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): RelationalModule(\n",
      "    (net): Sequential(\n",
      "      (0): PositionalEncoding(\n",
      "        (projection): Linear(in_features=26, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): FeaturewiseMaxPool()\n",
      "  (3): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (4): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (5): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (6): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): ExtractEntities(\n",
      "    (embed): Embedding(117, 3)\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 12, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(12, 24, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): RelationalModule(\n",
      "    (net): Sequential(\n",
      "      (0): PositionalEncoding(\n",
      "        (projection): Linear(in_features=26, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): FeaturewiseMaxPool()\n",
      "  (3): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (4): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (5): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (6): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): ExtractEntities(\n",
      "    (embed): Embedding(117, 3)\n",
      "    (net): Sequential(\n",
      "      (0): Conv2d(3, 12, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(12, 24, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): RelationalModule(\n",
      "    (net): Sequential(\n",
      "      (0): PositionalEncoding(\n",
      "        (projection): Linear(in_features=26, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AttentionBlock(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (ff): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): FeaturewiseMaxPool()\n",
      "  (3): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (4): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (5): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (6): ResidualLayer(\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (w1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (w2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "HPs = dict(action_space=4,\n",
    "           lr=1e-3,\n",
    "           gamma=0.99,\n",
    "           TD=True,\n",
    "           twin=True,\n",
    "           tau=0.2,\n",
    "           n_steps=10\n",
    "           )\n",
    "if colab:\n",
    "    HPs['device'] = 'cuda'\n",
    "else:\n",
    "    HPs['device'] = 'cpu'\n",
    "\n",
    "print('device: ', HPs['device'])  \n",
    "\n",
    "# Relational Agent\n",
    "agent = ActorCritic.BoxWorldA2C(**HPs)\n",
    "\n",
    "# Control Agent\n",
    "control_agent = ControlActorCritic.ControlA2C(**HPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgCA3SMwxpcz"
   },
   "outputs": [],
   "source": [
    "# Random Agent\n",
    "\n",
    "class RandomAgent():\n",
    "    def __init__(self, n_actions):\n",
    "        self.n_actions = n_actions\n",
    "    \n",
    "    def get_action(self,state, *args, **kwargs):\n",
    "        a = np.random.choice(self.n_actions)\n",
    "        log_prob = np.log(1./self.n_actions) # just because it's the standard output of the other agent\n",
    "        return a, log_prob\n",
    "    \n",
    "    def update(self, *args):\n",
    "        return\n",
    "\n",
    "rnd_agent = RandomAgent(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "Kf30nk3RqdHb",
    "outputId": "7560a1b1-99be-44d4-f6ae-03965f065c28",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicola/anaconda3/envs/torch/lib/python3.7/site-packages/pycolab/ascii_art.py:318: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  art = np.vstack(np.fromstring(line, dtype=np.uint8) for line in art)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([1, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([1, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([1, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 1, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 1, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([1, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([1, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([51, 1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([51, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([51, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([51, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 51, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 51, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([51, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([51, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([51, 1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([51, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([51, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([51, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 51, 256])\n",
      "x.shape (RelationalModule):  torch.Size([144, 51, 256])\n",
      "x.shape (FeaturewiseMaxPool):  torch.Size([51, 256])\n",
      "x.shape (BoxWorldNet):  torch.Size([51, 256])\n",
      "x.shape (before ExtractEntities):  torch.Size([51, 1, 14, 14])\n",
      "x.shape (ExtractEntities):  torch.Size([51, 24, 12, 12])\n",
      "x.shape (After encoding):  torch.Size([51, 26, 12, 12])\n",
      "x.shape (Before transposing and projection):  torch.Size([51, 26, 144])\n",
      "x.shape (PositionalEncoding):  torch.Size([144, 51, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/train_agent.py\u001b[0m in \u001b[0;36mtrain_boxworld\u001b[0;34m(agent, game_params, n_episodes, max_steps, return_agent)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m#print(\"Episode %d - reward: %.0f\"%(e+1, performance[-1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m#print(\"Time updating the agent: %.2f s\"%(t2-t1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/ActorCritic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mcritic_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_TD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mcritic_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_MC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/ActorCritic.py\u001b[0m in \u001b[0;36mupdate_TD\u001b[0;34m(self, rewards, log_probs, states, done, bootstrap)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m### Update critic and then actor ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_critic_TD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_step_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma_V\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_actor_TD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_step_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma_V\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/ActorCritic.py\u001b[0m in \u001b[0;36mupdate_critic_TD\u001b[0;34m(self, n_step_rewards, new_states, old_states, done, Gamma_V)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mV1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"V1.shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/AC_networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/AC_networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/RelationalNetworks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x.shape (BoxWorldNet): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/RelationalNetworks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;34m\"\"\"Expects an input of shape (batch_size, n_pixels, n_kernels)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x.shape (RelationalModule): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/RelationalNetworks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# MHA step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mx_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add and norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_norm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# FF step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   3355\u001b[0m                                                device=key_padding_mask.device)], dim=1)\n\u001b[1;32m   3356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3357\u001b[0;31m     \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3358\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = train.train_boxworld(agent, game_params, n_episodes=100, \n",
    "                               max_steps=game_params['max_num_steps'], return_agent=True)\n",
    "score, asymptotic_score, asymptotic_std, trained_agent, time_profile = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSND18K4fTmD"
   },
   "source": [
    "On my PC:\n",
    "\n",
    " Average time for playing an episode: 1.97428691 <br>\n",
    " Average time for updating the agent: 26.46678982\n",
    "\n",
    " On Colab notebook:\n",
    "\n",
    " Average time for playing an episode:  1.11658633 <br>\n",
    " Average time for updating the agent: 18.63836179\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxejRxWmjv9v"
   },
   "source": [
    "With GPU\n",
    "\n",
    "Average time for playing an episode: 0.43020332 <br>\n",
    "Average time for updating the agent: 0.64481306\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "rkdAxrzyfTmG",
    "outputId": "b4ba3529-b2f7-4609-e6d1-217953d63db8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-abee58e12768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maverage_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performance\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "n_epochs = np.arange(100, len(score))\n",
    "average_score = np.array([np.mean(score[i:i+100]) for i in range(len(score)-100)])\n",
    "plt.plot(n_epochs, average_score, alpha=0.9)\n",
    "plt.title(\"Performance\", fontsize=16)\n",
    "plt.xlabel(\"Number of epochs\", fontsize=16)\n",
    "plt.ylabel(\"Total reward\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRZNea0rKVE_"
   },
   "outputs": [],
   "source": [
    "save = False\n",
    "keywords = ['control','unboxed_gem',str(len(control_score))+\"-episodes\"] # example\n",
    "\n",
    "if colab and save:\n",
    "    %cd ~\n",
    "    parent_dir = \"/content/gdrive/My Drive/Colab Notebooks/\"\n",
    "    save_dir  = \"RelationalTrained/\"\n",
    "    %cd \"{parent_dir}\"\n",
    "    !mkdir \"{save_dir}\"\n",
    "    ID = utils.save_session(save_dir, keywords, game_params, HPs, score)\n",
    "    torch.save(trained_agent, save_dir+\"agent_\"+ID)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BoxWorldTesting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
