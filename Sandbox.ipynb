{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import test_env\n",
    "from RelationalModule import ControlNetworks as cnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.ControlNetworks' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/ControlNetworks.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(test_env)\n",
    "reload(cnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_start(X=10, Y=10):\n",
    "    s1, s2 = np.random.choice(X*Y, 2, replace=False)\n",
    "    initial = [s1//X, s1%X]\n",
    "    goal = [s2//X, s2%X]\n",
    "    return initial, goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable parameters\n",
    "X = 10\n",
    "Y = 10\n",
    "initial, goal = random_start(X, Y)\n",
    "\n",
    "# All game parameters\n",
    "game_params = dict(x=X, y=Y, initial=initial, goal=goal, max_steps=100, greyscale_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = test_env.Sandbox(**game_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(state.reshape(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using One Hot Encoding for the state representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "colors = [1,2,3]\n",
    "ohe_state = np.full((3,)+state.shape[1:], 0).astype(float)\n",
    "print(ohe_state.shape)\n",
    "for i, c in enumerate(colors):\n",
    "    mask = (state[0,:,:] == c)\n",
    "    ohe_state[i][mask] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 32\n",
    "map_size = 10\n",
    "hidden_dim = 128\n",
    "n_residuals = 4\n",
    "\n",
    "OHE_conv = cnet.Convolution(k_in=3, k_out=24)\n",
    "pos_enc = cnet.PositionalEncoding(n_kernels=24, n_features=n_features)\n",
    "\n",
    "pixel_res_layer = cnet.ResidualLayer(map_size**2, hidden_dim)\n",
    "pixel_res_layers = cnet.clones(pixel_res_layer, n_residuals)\n",
    "pixel_res_block = nn.Sequential(*pixel_res_layers)\n",
    "\n",
    "maxpool = cnet.FeaturewiseMaxPool(pixel_axis=2)\n",
    "\n",
    "feature_res_layer = cnet.ResidualLayer(n_features, n_features)\n",
    "feature_res_layers = cnet.clones(feature_res_layer, n_residuals)\n",
    "feature_res_block = nn.Sequential(*feature_res_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([3, 12, 12])\n",
      "conv_state.shape:  torch.Size([1, 24, 10, 10])\n",
      "After positional enc + projection:  torch.Size([100, 1, 32])\n",
      "x.shape:  torch.Size([1, 32, 100])\n",
      "x.shape:  torch.Size([1, 32, 100])\n",
      "x.shape:  torch.Size([1, 32])\n",
      "x.shape:  torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(ohe_state).float()\n",
    "print(\"Input shape: \", x.shape)\n",
    "x = OHE_conv(x)\n",
    "print(\"conv_state.shape: \", x.shape)\n",
    "x = pos_enc(x)\n",
    "print(\"After positional enc + projection: \", x.shape)\n",
    "x = x.permute(1,2,0)\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = pixel_res_block(x) # Interaction between pixels feature-wise\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = maxpool(x) # Feature-wise maxpooling\n",
    "print(\"x.shape: \", x.shape)\n",
    "x = feature_res_block(x) # Interaction between features -> final representation\n",
    "print(\"x.shape: \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RelationalModule.ControlNetworks' from '/home/nicola/Nicola_unipd/MasterThesis/RelationalDeepRL/RelationalModule/ControlNetworks.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(cnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohenet = cnet.OheNet(map_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(ohe_state).float()\n",
    "y = ohenet(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 4\n",
    "n_dim = 3\n",
    "d_model = 16\n",
    "n_heads = 2\n",
    "linear_size = 12\n",
    "\n",
    "embed = nn.Embedding(vocab_size, n_dim, padding_idx=0)\n",
    "pos_enc = cnet.PositionalEncoding(n_dim, d_model)\n",
    "relational = cnet.AttentionBlock(d_model, n_heads)\n",
    "projection = nn.Linear(linear_size**2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(state)\n",
    "if len(x.shape) <= 3:\n",
    "    x = x.unsqueeze(0)\n",
    "x = embed(x)\n",
    "x = x.permute(0,1,4,2,3)\n",
    "x = x.reshape(x.shape[:1]+(-1,)+x.shape[3:])\n",
    "x = pos_enc(x)\n",
    "x = relational(x)\n",
    "x = x.permute(1,2,0)\n",
    "x = projection(x)\n",
    "x = x.reshape(x.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPs = dict( vocab_size = 4,\n",
    "            n_dim = 3,\n",
    "            n_features = 16,\n",
    "            n_heads = 2,\n",
    "            linear_size = X+2)\n",
    "\n",
    "control_net = cnet.ControlNet(**HPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(state)\n",
    "y = control_net(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving env with just coordinates\n",
    "State = [x_agent, y_agent, x_goal, y_goal] <br>\n",
    "All coordinates rescaled in [0,1] dividing for the linear size of the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_start(X=10, Y=10):\n",
    "    s1, s2 = np.random.choice(X*Y, 2, replace=False)\n",
    "    initial = [s1//X, s1%X]\n",
    "    goal = [s2//X, s2%X]\n",
    "    return initial, goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable parameters\n",
    "X = 10\n",
    "Y = 10\n",
    "initial, goal = random_start(X, Y)\n",
    "\n",
    "# All game parameters\n",
    "game_params = dict(x=X, y=Y, initial=initial, goal=goal, max_steps=100, \n",
    "                   greyscale_state=False, return_coord=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = test_env.Sandbox(**game_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Agent initial coordinates: \", initial)\n",
    "print(\"Goal coordinates: \", goal)\n",
    "print(\"Linear dimension: \", X)\n",
    "print(\"Initial state: \", state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RelationalModule import MLP_AC_networks as MLP_nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_HPs = dict(observation_space=5, action_space=4, hiddens=[32,16])\n",
    "actor = MLP_nets.Actor(**actor_HPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(state).unsqueeze(0).float()\n",
    "print(x.shape)\n",
    "log_probs = actor(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.exp(log_probs)\n",
    "p.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
