{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import time\n",
    "import copy \n",
    "from AC_modules.Networks import *\n",
    "from AC_modules.AdvantageActorCritic import SharedAC, IndependentAC\n",
    "\n",
    "from Utils import test_env\n",
    "\n",
    "debug = False\n",
    "queue = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_AC(model_dict): # works\n",
    "    if model_dict['shared']:\n",
    "        return SharedAC(model_dict['model'], *model_dict['args'], **model_dict['kwargs'])\n",
    "    else:\n",
    "        return IndependentAC(model_dict['model'], *model_dict['args'], **model_dict['kwargs'])\n",
    "        \n",
    "def play_episode(agent, env, max_steps):\n",
    "\n",
    "    # Start the episode\n",
    "    state = env.reset()\n",
    "    if debug: print(\"state.shape: \", state.shape)\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "    distributions = []\n",
    "    states = [state]\n",
    "    done = []\n",
    "    bootstrap = []\n",
    "        \n",
    "    steps = 0\n",
    "    while True:\n",
    "     \n",
    "        action, log_prob, distrib = agent.get_action(state, return_log = True)\n",
    "        new_state, reward, terminal, info = env.step(action)\n",
    "        if debug: print(\"state.shape: \", new_state.shape)\n",
    "        rewards.append(reward)\n",
    "        log_probs.append(log_prob)\n",
    "        distributions.append(distrib)\n",
    "        states.append(new_state)\n",
    "        done.append(terminal)\n",
    "        \n",
    "        # Still unclear how to retrieve max steps from the game itself\n",
    "        if terminal is True and steps == max_steps:\n",
    "            bootstrap.append(True)\n",
    "        else:\n",
    "            bootstrap.append(False) \n",
    "        \n",
    "        if terminal is True:\n",
    "            #print(\"steps: \", steps)\n",
    "            #print(\"Bootstrap needed: \", bootstrap[-1])\n",
    "            break\n",
    "            \n",
    "        state = new_state\n",
    "        steps += 1\n",
    "        \n",
    "    rewards = np.array(rewards)\n",
    "    states = np.array(states)\n",
    "    if debug: print(\"states.shape: \", states.shape)\n",
    "    done = np.array(done)\n",
    "    bootstrap = np.array(bootstrap)\n",
    "\n",
    "    return rewards, log_probs, distributions, np.array(states), done, bootstrap\n",
    "\n",
    "def random_start(X=10, Y=10):\n",
    "    s1, s2 = np.random.choice(X*Y, 2, replace=False)\n",
    "    initial = [s1//X, s1%X]\n",
    "    goal = [s2//X, s2%X]\n",
    "    return initial, goal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_thread(global_model, model_dict, game_params, learning_rate, n_episodes, max_steps, random_init, rank):\n",
    "    print(\"Entered process %d\"%rank)\n",
    "    #local_model = model_constructor.generate_model()\n",
    "    #print(\"Constructed local model \")\n",
    "    #print(\"model_dict: \", model_dict)\n",
    "    #local_model = build_AC(model_dict)\n",
    "    local_model = copy.deepcopy(global_model)\n",
    "    print(\"Constructed local model \")\n",
    "    local_model.load_state_dict(global_model.state_dict())\n",
    "    print(\"Loaded state dictionary\")\n",
    "    optimizer = torch.optim.Adam(global_model.parameters(), lr=learning_rate)\n",
    "    print(\"created optim\")\n",
    "    \n",
    "    print(\"Process %d started\"%rank)\n",
    "    \n",
    "    performance = []\n",
    "    steps_to_solve = []\n",
    "    for e in range(n_episodes):\n",
    "        \n",
    "        if random_init:\n",
    "            # Change game params\n",
    "            initial, goal = random_start(game_params[\"x\"], game_params[\"y\"])\n",
    "\n",
    "            # All game parameters\n",
    "            game_params[\"initial\"] = initial\n",
    "            game_params[\"goal\"] = goal\n",
    "\n",
    "        env = test_env.Sandbox(**game_params)\n",
    "        rewards, log_probs, distributions, states, done, bootstrap = play_episode(local_model, env, max_steps)\n",
    "        global_model.env_steps += len(rewards) # hope it works asynchronously - TO CHECK\n",
    "        \n",
    "        performance.append(np.sum(rewards))\n",
    "        steps_to_solve.append(len(rewards))\n",
    "        \n",
    "        #if (e+1)%10 == 0:\n",
    "        #    print(\"Episode %d of process %d - reward: %.2f - steps to solve: %.2f\"%(e+1, rank, np.mean(performance[-10:]), np.mean(steps_to_solve[-10:])))\n",
    "        print(\"Episode %d of process %d - reward: %.2f - steps to solve: %.2f\"%(e+1, rank, performance[-1], steps_to_solve[-10:]))\n",
    "        \n",
    "        critic_loss, actor_loss, entropy = local_model.compute_ac_loss(rewards, log_probs, distributions, states, done, bootstrap)\n",
    "        loss = critic_loss + actor_loss\n",
    "        \n",
    "        # Update global model and then copy back updated params to local model\n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        for global_param, local_param in zip(global_model.parameters(), local_model.parameters()):\n",
    "            global_param._grad = local_param.grad\n",
    "        optimizer.step()\n",
    "        global_model.optim_steps += 1 # hope it works asynchronously - TO CHECK\n",
    "        global_model.update_target()\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        \n",
    "    print(\"Training process {} reached maximum episode.\".format(rank))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_thread(global_model, game_params, tot_episodes, max_steps, random_init, Q=None, episodes_per_test=10, test_every=4):\n",
    "    print(\"Test process started\")\n",
    "    test_counter = 0\n",
    "    max_tests = tot_episodes // test_every\n",
    "    \n",
    "    performance = []\n",
    "    steps_to_solve = []\n",
    "    critic_losses = [] \n",
    "    actor_losses = []\n",
    "    entropies = []\n",
    "    while True:\n",
    "        if global_model.optim_steps > test_counter*test_every:\n",
    "            test_counter +=1\n",
    "            episode_reward = []\n",
    "            episode_steps = []\n",
    "            for e in range(episodes_per_test):\n",
    "                if random_init:\n",
    "                    # Change game params\n",
    "                    initial, goal = random_start(game_params[\"x\"], game_params[\"y\"])\n",
    "\n",
    "                    # All game parameters\n",
    "                    game_params[\"initial\"] = initial\n",
    "                    game_params[\"goal\"] = goal\n",
    "\n",
    "                env = test_env.Sandbox(**game_params)\n",
    "                rewards, log_probs, distributions, states, done, bootstrap = play_episode(agent, env, max_steps)\n",
    "                episode_reward.append(np.sum(rewards))\n",
    "                episode_steps.append(len(rewards))\n",
    "                \n",
    "                if e == 0:\n",
    "                    critic_loss, actor_loss, entropy = agent.compute_ac_loss(rewards, log_probs, distributions, states, done, bootstrap)\n",
    "            performance.append(np.mean(episode_reward))\n",
    "            steps_to_solve.append(np.mean(episode_steps))\n",
    "            print(\"Test %d - reward %.2f - steps to solve %.2f\"%(test_counter, performance[-1], steps_to_solve[-1]))\n",
    "            critic_losses.append(critic_loss)\n",
    "            actor_losses.append(actor_loss)\n",
    "            entropies.append(entropy)\n",
    "        else:\n",
    "            #time.sleep(1) # wait 1 sec\n",
    "            pass\n",
    "        if test_counter == max_tests:\n",
    "            break\n",
    "    #if queue:\n",
    "    #    Q.put(performance, steps_to_solve, critic_losses, actor_losses, entropies) # TO CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sandbox(agent_constructor, learning_rate, game_params, n_training_threads=3, n_episodes=1000,\n",
    "                  max_steps=120, return_agent=False, random_init=True):\n",
    "    \n",
    "    global_model = agent_constructor.generate_model()\n",
    "    global_model.share_memory()\n",
    "    \n",
    "    model_dict = dict(model=agent_constructor.model,\n",
    "                      shared=agent_constructor.shared,\n",
    "                      args=agent_constructor.args,\n",
    "                      kwargs=agent_constructor.kwargs)\n",
    "    processes = []\n",
    "    for rank in range(1, n_training_threads + 1):  # + 1 for test process\n",
    "        if rank == 0:\n",
    "            p = mp.Process(target=test_thread, args=(global_model, game_params, n_episodes*n_training_threads, \n",
    "                                                     max_steps, random_init,))\n",
    "        else:\n",
    "            #local_model = agent_constructor.generate_model()\n",
    "            p = mp.Process(target=training_thread, args=(global_model, model_dict, game_params, \n",
    "                                                         learning_rate, n_episodes, max_steps, random_init, rank),)\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    print(\"All processes started\")\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    print(\"All processes finished\")\n",
    "\n",
    "    if return_agent:\n",
    "        return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AC_modules.Constructor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_kernels': 36,\n",
       " 'n_features': 256,\n",
       " 'n_heads': 1,\n",
       " 'n_attn_modules': 2,\n",
       " 'feature_hidden_dim': 16,\n",
       " 'feature_n_residuals': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relational_HPs = torch.load(\"Results/Sandbox/Supervised/best_HP_S_chosen-residual_UMUT\")\n",
    "relational_HPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "Model:  <class 'AC_modules.Networks.GatedBoxWorldNet'>\n",
      "self.model:  <class 'AC_modules.Networks.GatedBoxWorldNet'>\n",
      "self.shared:  True\n",
      "self.args:  (4,)\n",
      "self.kwargs:  {'gamma': 0.99, 'tau': 0.3, 'n_steps': 5, 'H': 0.001, 'n_kernels': 36, 'n_features': 256, 'n_heads': 1, 'n_attn_modules': 2, 'feature_hidden_dim': 16, 'feature_n_residuals': 1, 'device': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "name = \"GatedBoxWorldNet\"\n",
    "action_space = 4\n",
    "#n_features = 16\n",
    "\n",
    "HPs = dict(gamma=0.99, tau=0.3, n_steps=5, H=1e-3, **relational_HPs)\n",
    "learning_rate = 1e-4\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    HPs['device'] = 'cuda'\n",
    "else:\n",
    "    HPs['device'] = 'cpu'\n",
    "    \n",
    "print(\"Using device \"+HPs['device'])\n",
    "agent_constructor = ActorCriticConstructor(name, True, action_space, **HPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable parameters\n",
    "X = 5\n",
    "Y = 5\n",
    "initial = [0,0]\n",
    "goal = [4,4]\n",
    "MAX_STEPS = 20\n",
    "\n",
    "game_params = dict(x=X, y=Y, initial=initial, goal=goal, max_steps=MAX_STEPS, \n",
    "                   greyscale_state=True, return_ohe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  <class 'AC_modules.Networks.GatedBoxWorldNet'>\n",
      "action_space:  4\n",
      "n_features:  256\n",
      "HPs:  {'n_kernels': 36, 'n_heads': 1, 'n_attn_modules': 2, 'feature_hidden_dim': 16, 'feature_n_residuals': 1}\n",
      "device:  cpu\n",
      "params and buffers check\n",
      "[Parameter containing:\n",
      "tensor([[[[ 0.0628, -0.2637],\n",
      "          [ 0.1979, -0.2660]],\n",
      "\n",
      "         [[-0.0814,  0.1895],\n",
      "          [ 0.2067, -0.1509]],\n",
      "\n",
      "         [[-0.2547, -0.1768],\n",
      "          [ 0.1381,  0.0704]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0357, -0.1480],\n",
      "          [ 0.1125, -0.0944]],\n",
      "\n",
      "         [[-0.2850, -0.2019],\n",
      "          [ 0.1650, -0.2126]],\n",
      "\n",
      "         [[-0.0084,  0.0121],\n",
      "          [ 0.1339,  0.1854]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2623, -0.1416],\n",
      "          [ 0.2881, -0.2124]],\n",
      "\n",
      "         [[ 0.0634, -0.0315],\n",
      "          [ 0.2399,  0.0823]],\n",
      "\n",
      "         [[ 0.1186,  0.0663],\n",
      "          [-0.1900,  0.0279]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1644,  0.0489],\n",
      "          [ 0.0829, -0.1409]],\n",
      "\n",
      "         [[ 0.1766,  0.0492],\n",
      "          [-0.1040,  0.1378]],\n",
      "\n",
      "         [[-0.1267, -0.2113],\n",
      "          [-0.1801, -0.0423]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0515, -0.2855],\n",
      "          [-0.1063, -0.0977]],\n",
      "\n",
      "         [[-0.1061, -0.1033],\n",
      "          [ 0.1603, -0.1636]],\n",
      "\n",
      "         [[-0.2595,  0.2057],\n",
      "          [-0.1135,  0.1432]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0915,  0.1866],\n",
      "          [-0.1328, -0.0041]],\n",
      "\n",
      "         [[ 0.1094,  0.2213],\n",
      "          [-0.1571,  0.2559]],\n",
      "\n",
      "         [[ 0.0812,  0.2739],\n",
      "          [-0.2623, -0.2489]]],\n",
      "\n",
      "\n",
      "        [[[-0.1618, -0.0980],\n",
      "          [ 0.1243,  0.1689]],\n",
      "\n",
      "         [[ 0.1183, -0.0541],\n",
      "          [-0.0384, -0.1413]],\n",
      "\n",
      "         [[ 0.0228, -0.1861],\n",
      "          [-0.2171,  0.2466]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1166, -0.0340],\n",
      "          [ 0.1995,  0.2149]],\n",
      "\n",
      "         [[ 0.1226, -0.2702],\n",
      "          [ 0.0494,  0.2523]],\n",
      "\n",
      "         [[ 0.1572, -0.2508],\n",
      "          [ 0.1935, -0.1241]]],\n",
      "\n",
      "\n",
      "        [[[-0.0077, -0.0550],\n",
      "          [ 0.1002,  0.1921]],\n",
      "\n",
      "         [[-0.1336,  0.2102],\n",
      "          [ 0.1235,  0.0256]],\n",
      "\n",
      "         [[ 0.2511, -0.0751],\n",
      "          [-0.1046, -0.0288]]],\n",
      "\n",
      "\n",
      "        [[[-0.0081,  0.0601],\n",
      "          [-0.0659, -0.0402]],\n",
      "\n",
      "         [[-0.2316, -0.0864],\n",
      "          [ 0.0259, -0.1692]],\n",
      "\n",
      "         [[-0.0796, -0.0044],\n",
      "          [ 0.1256,  0.1103]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1393, -0.1675],\n",
      "          [-0.1723, -0.0136]],\n",
      "\n",
      "         [[-0.1585,  0.0300],\n",
      "          [-0.2854, -0.1188]],\n",
      "\n",
      "         [[-0.2479,  0.1345],\n",
      "          [ 0.2085,  0.2576]]],\n",
      "\n",
      "\n",
      "        [[[-0.0096, -0.0579],\n",
      "          [ 0.0336,  0.1794]],\n",
      "\n",
      "         [[ 0.2202, -0.2746],\n",
      "          [ 0.0285,  0.2536]],\n",
      "\n",
      "         [[ 0.0545, -0.2433],\n",
      "          [ 0.2431, -0.0476]]],\n",
      "\n",
      "\n",
      "        [[[-0.1875,  0.2221],\n",
      "          [-0.1697, -0.0927]],\n",
      "\n",
      "         [[-0.2006, -0.0530],\n",
      "          [ 0.1253, -0.1439]],\n",
      "\n",
      "         [[-0.1534, -0.1716],\n",
      "          [-0.1441, -0.1962]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0786, -0.0644],\n",
      "          [-0.0008, -0.1914]],\n",
      "\n",
      "         [[-0.0176, -0.2416],\n",
      "          [ 0.1017, -0.2421]],\n",
      "\n",
      "         [[ 0.2259,  0.0281],\n",
      "          [ 0.2673,  0.0457]]],\n",
      "\n",
      "\n",
      "        [[[-0.2611,  0.0050],\n",
      "          [-0.1864,  0.2622]],\n",
      "\n",
      "         [[-0.2115, -0.1682],\n",
      "          [ 0.0956, -0.2447]],\n",
      "\n",
      "         [[-0.2655, -0.1310],\n",
      "          [-0.0398, -0.0164]]],\n",
      "\n",
      "\n",
      "        [[[-0.0151,  0.0322],\n",
      "          [ 0.1276,  0.1771]],\n",
      "\n",
      "         [[ 0.2528, -0.0705],\n",
      "          [ 0.1509, -0.2551]],\n",
      "\n",
      "         [[-0.0854, -0.2655],\n",
      "          [-0.2233, -0.1002]]],\n",
      "\n",
      "\n",
      "        [[[-0.0621,  0.1971],\n",
      "          [-0.0245, -0.0562]],\n",
      "\n",
      "         [[-0.0299, -0.0441],\n",
      "          [-0.1467,  0.0133]],\n",
      "\n",
      "         [[-0.0115, -0.2298],\n",
      "          [ 0.1583, -0.2253]]],\n",
      "\n",
      "\n",
      "        [[[-0.2640, -0.2736],\n",
      "          [-0.0905,  0.0168]],\n",
      "\n",
      "         [[-0.2075, -0.1642],\n",
      "          [-0.2435, -0.1100]],\n",
      "\n",
      "         [[ 0.2835,  0.0411],\n",
      "          [ 0.1882, -0.0951]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1830, -0.1833,  0.1920,  0.1293,  0.2561,  0.1492,  0.2718, -0.0446,\n",
      "        -0.1549, -0.0285, -0.1649,  0.1066, -0.1943,  0.0804, -0.1145, -0.2800,\n",
      "        -0.0010, -0.2063], requires_grad=True), Parameter containing:\n",
      "tensor([[[[-0.0596, -0.0417],\n",
      "          [-0.0292,  0.0424]],\n",
      "\n",
      "         [[-0.0468, -0.0531],\n",
      "          [-0.1053, -0.0346]],\n",
      "\n",
      "         [[-0.0900,  0.1163],\n",
      "          [ 0.0492, -0.0857]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0868, -0.1118],\n",
      "          [ 0.0824,  0.0281]],\n",
      "\n",
      "         [[-0.0988,  0.1177],\n",
      "          [ 0.1083, -0.0520]],\n",
      "\n",
      "         [[-0.0473, -0.0211],\n",
      "          [ 0.0559, -0.0924]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0149, -0.0601],\n",
      "          [-0.0505, -0.0090]],\n",
      "\n",
      "         [[ 0.0929,  0.0062],\n",
      "          [ 0.0843,  0.0194]],\n",
      "\n",
      "         [[ 0.0580,  0.0725],\n",
      "          [-0.0017,  0.1060]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0119, -0.0074],\n",
      "          [-0.0532,  0.0381]],\n",
      "\n",
      "         [[-0.0416, -0.0248],\n",
      "          [ 0.0674,  0.0058]],\n",
      "\n",
      "         [[ 0.0876,  0.0192],\n",
      "          [ 0.0361,  0.1061]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0997,  0.0226],\n",
      "          [ 0.0421,  0.1148]],\n",
      "\n",
      "         [[ 0.0154,  0.1171],\n",
      "          [ 0.0686,  0.0131]],\n",
      "\n",
      "         [[ 0.0640, -0.0233],\n",
      "          [ 0.0309, -0.0410]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0601, -0.0537],\n",
      "          [-0.0375,  0.0551]],\n",
      "\n",
      "         [[ 0.0329,  0.0662],\n",
      "          [ 0.0838, -0.0708]],\n",
      "\n",
      "         [[-0.0931, -0.0471],\n",
      "          [-0.0583, -0.0005]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0801, -0.0032],\n",
      "          [ 0.0828, -0.0663]],\n",
      "\n",
      "         [[-0.1132, -0.0461],\n",
      "          [-0.0317, -0.1089]],\n",
      "\n",
      "         [[ 0.0106,  0.1090],\n",
      "          [ 0.0156, -0.0531]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0432,  0.0307],\n",
      "          [ 0.0466, -0.0149]],\n",
      "\n",
      "         [[-0.0648, -0.0178],\n",
      "          [ 0.0367,  0.0070]],\n",
      "\n",
      "         [[-0.0742,  0.0561],\n",
      "          [ 0.0252, -0.0606]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0795,  0.0903],\n",
      "          [ 0.0347,  0.0684]],\n",
      "\n",
      "         [[ 0.0769,  0.0081],\n",
      "          [ 0.0596,  0.0689]],\n",
      "\n",
      "         [[ 0.0689,  0.0351],\n",
      "          [ 0.0595, -0.0951]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0598,  0.1013],\n",
      "          [-0.0140,  0.1165]],\n",
      "\n",
      "         [[-0.0299,  0.0858],\n",
      "          [ 0.0615,  0.0858]],\n",
      "\n",
      "         [[ 0.0232, -0.0493],\n",
      "          [-0.0541, -0.0993]]],\n",
      "\n",
      "\n",
      "        [[[-0.0340, -0.0548],\n",
      "          [ 0.0897, -0.0699]],\n",
      "\n",
      "         [[-0.0984, -0.0529],\n",
      "          [ 0.0022,  0.0405]],\n",
      "\n",
      "         [[ 0.0993, -0.0801],\n",
      "          [-0.1017, -0.0957]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1151, -0.0286],\n",
      "          [-0.0679, -0.0350]],\n",
      "\n",
      "         [[ 0.0722, -0.0856],\n",
      "          [ 0.0247,  0.0230]],\n",
      "\n",
      "         [[-0.0965,  0.0487],\n",
      "          [-0.0090,  0.0444]]]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0114, -0.0979,  0.0024, -0.0879, -0.0919, -0.1018, -0.0213,  0.0821,\n",
      "        -0.0182,  0.0087, -0.0515, -0.0268, -0.1003,  0.0551,  0.0890,  0.0430,\n",
      "         0.0936,  0.0831, -0.1025, -0.0513, -0.0517, -0.0366,  0.0280,  0.0877,\n",
      "         0.0294,  0.0334, -0.0589,  0.0669, -0.0277,  0.0811,  0.0352,  0.0926,\n",
      "        -0.0364, -0.0697,  0.0492,  0.0223], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0131,  0.0763, -0.1035,  ..., -0.0717, -0.0174, -0.1532],\n",
      "        [-0.1121, -0.0460,  0.0010,  ...,  0.0758, -0.1065,  0.0986],\n",
      "        [ 0.1342, -0.1406,  0.0242,  ..., -0.0253,  0.0534, -0.1195],\n",
      "        ...,\n",
      "        [-0.0043, -0.0174,  0.1034,  ...,  0.0216, -0.0558, -0.0784],\n",
      "        [ 0.0495,  0.1397, -0.0272,  ...,  0.0431, -0.1166,  0.0181],\n",
      "        [ 0.0307, -0.0074,  0.1609,  ..., -0.1226, -0.0566, -0.0590]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1151, -0.0472,  0.0488,  0.0585,  0.0950, -0.1199,  0.0254, -0.0897,\n",
      "         0.1372,  0.1192,  0.0072,  0.0189, -0.1532,  0.1582, -0.0752, -0.0430,\n",
      "         0.1189,  0.0721, -0.0342,  0.0415, -0.0138,  0.1191, -0.0554, -0.1486,\n",
      "         0.0279, -0.0983,  0.1425,  0.0608,  0.1520,  0.1401,  0.0558,  0.1477,\n",
      "        -0.0869, -0.1600,  0.0027, -0.1221, -0.0847, -0.0175, -0.0072,  0.0111,\n",
      "         0.1170,  0.0530, -0.0952, -0.0988, -0.0439, -0.0410, -0.0700, -0.0884,\n",
      "         0.1190,  0.1020,  0.1139,  0.1416,  0.0808,  0.1229, -0.1193,  0.1439,\n",
      "         0.1257, -0.0057,  0.0212, -0.1487,  0.0064, -0.0356,  0.1280, -0.0737,\n",
      "         0.1145,  0.1085, -0.0227,  0.1378, -0.0555,  0.1139,  0.1220, -0.1616,\n",
      "        -0.1512, -0.1591, -0.1116,  0.0092,  0.0813, -0.0608,  0.1257, -0.0255,\n",
      "         0.1395, -0.1059, -0.0937,  0.0249, -0.0153,  0.1100,  0.1340, -0.0906,\n",
      "        -0.0405, -0.1475, -0.0337, -0.0070, -0.0173, -0.1380, -0.1219, -0.1296,\n",
      "         0.0681,  0.1128,  0.1427,  0.0476, -0.0578, -0.0154, -0.0972,  0.1441,\n",
      "        -0.1005,  0.1352, -0.0344,  0.0461, -0.0003, -0.1135,  0.0933, -0.0816,\n",
      "         0.0697,  0.1047,  0.0047, -0.0064,  0.0662, -0.0235,  0.1062,  0.0633,\n",
      "         0.1388, -0.0129,  0.0697,  0.0326, -0.0123, -0.1498, -0.0745,  0.1272,\n",
      "        -0.1266,  0.0560,  0.0088,  0.0189, -0.1057,  0.0934,  0.0717, -0.0342,\n",
      "        -0.1202,  0.0630,  0.0472, -0.1085, -0.0515, -0.0407,  0.1461,  0.1063,\n",
      "         0.1073,  0.1238, -0.0808,  0.0431, -0.1598,  0.1495, -0.1445, -0.0529,\n",
      "         0.1369,  0.0081, -0.1534,  0.0635, -0.1088, -0.0760, -0.1545, -0.0540,\n",
      "        -0.0328, -0.1536,  0.0572, -0.0982,  0.1031, -0.0097,  0.0973, -0.0211,\n",
      "         0.0173,  0.0423, -0.1359, -0.0459, -0.1201,  0.0456,  0.1212,  0.1090,\n",
      "        -0.1241, -0.0487, -0.0289, -0.0886,  0.0390, -0.0046,  0.0847, -0.1269,\n",
      "         0.1259, -0.1145,  0.0247, -0.1159, -0.0570, -0.0367, -0.0065,  0.1228,\n",
      "         0.0443,  0.1270, -0.1547,  0.0181, -0.0871,  0.0034, -0.0223, -0.1004,\n",
      "         0.1210,  0.0899, -0.0918,  0.1595,  0.0033,  0.0598, -0.1207, -0.0145,\n",
      "        -0.0628,  0.0166, -0.1408,  0.0459, -0.1357, -0.0744,  0.1123, -0.0888,\n",
      "         0.1194, -0.0004, -0.1160,  0.1400, -0.0212,  0.0009, -0.0637,  0.0570,\n",
      "        -0.0598,  0.0703, -0.0591,  0.0828, -0.0311,  0.0915, -0.1598, -0.0976,\n",
      "        -0.0213, -0.1338, -0.0805,  0.0328,  0.1439, -0.0603, -0.1395, -0.0878,\n",
      "        -0.1587,  0.0786, -0.0767,  0.0349,  0.0361,  0.1224,  0.0308, -0.1009,\n",
      "         0.0046,  0.0686, -0.0106, -0.0466,  0.0860,  0.1024, -0.1506,  0.1068],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0049,  0.0596,  0.0193,  ...,  0.0733,  0.0458, -0.0440],\n",
      "        [-0.0351,  0.0267, -0.0549,  ...,  0.0712, -0.0608, -0.0340],\n",
      "        [-0.0490, -0.0584,  0.0687,  ...,  0.0300, -0.0577,  0.0096],\n",
      "        ...,\n",
      "        [ 0.0137,  0.0440, -0.0550,  ..., -0.0525,  0.0205,  0.0576],\n",
      "        [-0.0742,  0.0523, -0.0091,  ..., -0.0330, -0.0371,  0.0551],\n",
      "        [ 0.0358,  0.0723,  0.0223,  ...,  0.0230,  0.0287,  0.0604]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0182,  0.0457, -0.0142,  ..., -0.0434, -0.0284, -0.0310],\n",
      "        [-0.0528,  0.0602,  0.0231,  ..., -0.0532,  0.0069, -0.0542],\n",
      "        [ 0.0458, -0.0252, -0.0408,  ...,  0.0404, -0.0514, -0.0051],\n",
      "        ...,\n",
      "        [ 0.0366, -0.0392, -0.0041,  ...,  0.0561, -0.0026,  0.0461],\n",
      "        [ 0.0038,  0.0548, -0.0484,  ...,  0.0266, -0.0034,  0.0438],\n",
      "        [ 0.0572, -0.0502, -0.0406,  ...,  0.0185,  0.0159,  0.0052]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0385, -0.0105, -0.0159,  ...,  0.0208,  0.0380,  0.0030],\n",
      "        [-0.0333, -0.0169, -0.0191,  ...,  0.0333, -0.0020, -0.0033],\n",
      "        [-0.0331,  0.0219,  0.0440,  ..., -0.0126,  0.0233,  0.0304],\n",
      "        ...,\n",
      "        [ 0.0278,  0.0259, -0.0238,  ...,  0.0405,  0.0283,  0.0347],\n",
      "        [ 0.0061,  0.0352,  0.0413,  ...,  0.0331, -0.0134, -0.0349],\n",
      "        [-0.0431,  0.0106, -0.0146,  ..., -0.0438, -0.0174,  0.0407]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0360, -0.0312, -0.0421,  ..., -0.0379,  0.0436,  0.0437],\n",
      "        [-0.0140, -0.0012, -0.0173,  ..., -0.0373, -0.0274,  0.0330],\n",
      "        [ 0.0052, -0.0377,  0.0431,  ...,  0.0373,  0.0406, -0.0358],\n",
      "        ...,\n",
      "        [-0.0218, -0.0424,  0.0108,  ..., -0.0214, -0.0164,  0.0396],\n",
      "        [ 0.0204, -0.0109,  0.0076,  ...,  0.0415,  0.0194,  0.0412],\n",
      "        [ 0.0173,  0.0195,  0.0237,  ...,  0.0255, -0.0375, -0.0271]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0375,  0.0354,  0.0330, -0.0417,  0.0171,  0.0232,  0.0079,  0.0295,\n",
      "        -0.0307, -0.0339,  0.0279,  0.0137, -0.0219,  0.0240, -0.0402, -0.0171,\n",
      "         0.0179,  0.0321,  0.0287, -0.0300, -0.0078,  0.0320, -0.0200, -0.0381,\n",
      "        -0.0398, -0.0115, -0.0439,  0.0013, -0.0348,  0.0158, -0.0345,  0.0090,\n",
      "         0.0352, -0.0147, -0.0229, -0.0180, -0.0306, -0.0162,  0.0428,  0.0163,\n",
      "        -0.0249, -0.0193,  0.0056,  0.0072,  0.0128, -0.0435, -0.0061,  0.0217,\n",
      "        -0.0192, -0.0234,  0.0212,  0.0288,  0.0053,  0.0088,  0.0017,  0.0327,\n",
      "        -0.0429, -0.0101,  0.0243, -0.0065,  0.0435, -0.0200,  0.0196,  0.0306,\n",
      "         0.0289, -0.0306,  0.0076, -0.0270, -0.0078, -0.0213,  0.0284,  0.0089,\n",
      "        -0.0297,  0.0075,  0.0124, -0.0435,  0.0205,  0.0091,  0.0378,  0.0201,\n",
      "         0.0086, -0.0188,  0.0337, -0.0405,  0.0018, -0.0263,  0.0179,  0.0308,\n",
      "        -0.0427,  0.0408,  0.0285, -0.0338,  0.0093, -0.0148, -0.0125,  0.0141,\n",
      "        -0.0210,  0.0161, -0.0223, -0.0186,  0.0440,  0.0141, -0.0160, -0.0437,\n",
      "         0.0105, -0.0373, -0.0167, -0.0180,  0.0225, -0.0411, -0.0388,  0.0073,\n",
      "         0.0403,  0.0162, -0.0373, -0.0401,  0.0253, -0.0132,  0.0157, -0.0229,\n",
      "         0.0409,  0.0400,  0.0151,  0.0267, -0.0404,  0.0026,  0.0117,  0.0001,\n",
      "        -0.0241, -0.0294, -0.0134,  0.0149,  0.0114,  0.0175,  0.0127,  0.0389,\n",
      "         0.0146, -0.0373,  0.0341,  0.0362,  0.0186,  0.0332, -0.0317, -0.0275,\n",
      "         0.0049,  0.0311,  0.0235,  0.0037,  0.0405, -0.0003,  0.0296, -0.0032,\n",
      "         0.0228, -0.0295,  0.0016, -0.0089,  0.0075,  0.0101, -0.0173, -0.0336,\n",
      "         0.0050,  0.0099, -0.0194,  0.0096, -0.0356,  0.0222,  0.0177, -0.0228,\n",
      "        -0.0052,  0.0089, -0.0210, -0.0094, -0.0384,  0.0339,  0.0012, -0.0043,\n",
      "        -0.0212,  0.0272, -0.0005,  0.0199, -0.0098,  0.0408,  0.0138,  0.0106,\n",
      "         0.0155,  0.0333, -0.0289,  0.0151,  0.0347, -0.0193,  0.0260,  0.0160,\n",
      "        -0.0210,  0.0410, -0.0133,  0.0261, -0.0360, -0.0145,  0.0067, -0.0161,\n",
      "        -0.0099,  0.0341, -0.0409, -0.0146, -0.0277, -0.0056,  0.0011,  0.0175,\n",
      "         0.0245, -0.0284,  0.0292, -0.0391,  0.0210,  0.0263, -0.0328, -0.0364,\n",
      "         0.0299,  0.0176,  0.0396, -0.0042, -0.0133, -0.0299, -0.0358,  0.0374,\n",
      "         0.0349,  0.0121,  0.0163, -0.0057,  0.0124,  0.0060,  0.0049, -0.0076,\n",
      "         0.0326, -0.0025, -0.0095, -0.0033, -0.0438,  0.0429, -0.0272,  0.0039,\n",
      "         0.0102, -0.0360,  0.0336,  0.0280,  0.0195, -0.0390,  0.0286, -0.0353,\n",
      "         0.0337, -0.0326,  0.0276, -0.0055, -0.0200,  0.0303,  0.0423,  0.0416],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-1.5771e-02,  3.5859e-02,  3.9502e-02,  ...,  2.0467e-02,\n",
      "         -9.1314e-03,  3.8594e-02],\n",
      "        [ 4.1005e-02,  3.5711e-02,  1.3737e-02,  ..., -2.5688e-02,\n",
      "          8.8130e-03,  3.0383e-02],\n",
      "        [-3.1333e-02,  3.2529e-02,  2.2825e-02,  ..., -2.1782e-02,\n",
      "          7.0695e-05, -2.9118e-02],\n",
      "        ...,\n",
      "        [ 2.0335e-02,  1.6294e-02, -3.8831e-02,  ...,  1.7245e-02,\n",
      "          3.6873e-02, -3.1885e-03],\n",
      "        [ 3.6355e-02,  1.3181e-02,  2.6968e-02,  ...,  7.0484e-03,\n",
      "         -2.2144e-03, -2.9589e-02],\n",
      "        [ 1.3234e-02,  2.8413e-02, -2.3170e-02,  ..., -2.2754e-02,\n",
      "          2.8533e-02,  4.1529e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0299,  0.0314, -0.0275,  ...,  0.0613,  0.0259,  0.0226],\n",
      "        [-0.0212, -0.0094,  0.0017,  ..., -0.0197,  0.0559, -0.0365],\n",
      "        [-0.0577,  0.0113,  0.0463,  ..., -0.0003, -0.0379, -0.0344],\n",
      "        ...,\n",
      "        [-0.0436, -0.0032,  0.0510,  ..., -0.0612, -0.0513,  0.0321],\n",
      "        [ 0.0147,  0.0171, -0.0226,  ...,  0.0014, -0.0409,  0.0379],\n",
      "        [ 0.0139, -0.0105, -0.0218,  ..., -0.0253,  0.0539,  0.0245]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0009, -0.0119, -0.0229, -0.0493,  0.0583, -0.0584,  0.0424, -0.0423,\n",
      "        -0.0076, -0.0249, -0.0449,  0.0131,  0.0500, -0.0042,  0.0169,  0.0466,\n",
      "         0.0538, -0.0562,  0.0381,  0.0410, -0.0211, -0.0220,  0.0112,  0.0095,\n",
      "        -0.0114,  0.0432,  0.0184, -0.0314,  0.0339, -0.0012, -0.0031,  0.0226,\n",
      "         0.0352,  0.0016,  0.0227,  0.0025,  0.0510,  0.0439, -0.0608,  0.0097,\n",
      "        -0.0520,  0.0352,  0.0523,  0.0496,  0.0198, -0.0567, -0.0040,  0.0567,\n",
      "        -0.0447,  0.0510, -0.0107,  0.0344, -0.0369,  0.0050, -0.0247, -0.0019,\n",
      "        -0.0221, -0.0288,  0.0235, -0.0383, -0.0470,  0.0086,  0.0325, -0.0027],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0389,  0.0044,  0.0604,  ..., -0.0073, -0.0539,  0.0590],\n",
      "        [ 0.0281,  0.0739, -0.0452,  ..., -0.0465, -0.0804, -0.0768],\n",
      "        [ 0.0470, -0.0308, -0.0087,  ..., -0.1089, -0.0020,  0.0236],\n",
      "        ...,\n",
      "        [-0.0464,  0.0015,  0.0341,  ...,  0.0843,  0.1129,  0.0387],\n",
      "        [ 0.0170,  0.1089,  0.0183,  ...,  0.0944, -0.0618, -0.0183],\n",
      "        [ 0.0872,  0.0232, -0.0335,  ...,  0.1009, -0.0071,  0.0658]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-9.8642e-02,  9.9350e-02,  6.4601e-02, -1.1628e-02, -8.1168e-02,\n",
      "        -2.8942e-02, -8.8918e-02, -3.3174e-02, -4.0735e-02,  8.9700e-02,\n",
      "         9.6922e-02,  7.8629e-02,  3.2482e-02, -1.1633e-01,  1.0060e-01,\n",
      "         1.2162e-01, -6.8403e-02, -8.0775e-02, -9.9935e-02, -1.8666e-02,\n",
      "         4.0532e-02, -3.4833e-02, -1.0466e-01, -9.3961e-02, -9.3559e-02,\n",
      "         9.6279e-02,  5.5017e-02, -8.1646e-02,  1.0928e-01, -1.5887e-02,\n",
      "         7.4111e-02, -8.9466e-02,  1.1008e-01, -4.6367e-02, -8.5303e-02,\n",
      "         1.0732e-01, -1.0851e-01,  1.7694e-02, -4.4360e-02,  2.7318e-02,\n",
      "        -1.0128e-01,  1.1456e-01,  9.7595e-03, -2.0046e-02,  8.2191e-03,\n",
      "         2.3127e-02, -8.5445e-03, -2.9183e-03, -6.7077e-02, -8.5069e-02,\n",
      "         1.0820e-01, -7.5638e-02,  2.2648e-02,  4.4339e-02,  3.3576e-02,\n",
      "        -3.2217e-02, -8.4408e-03, -1.1092e-01, -3.1982e-02,  1.9506e-02,\n",
      "         4.5729e-02,  3.1842e-02,  6.0962e-03, -8.6437e-02,  6.8761e-02,\n",
      "        -1.6992e-02, -2.0886e-02,  1.1016e-01, -5.8471e-02,  4.6212e-02,\n",
      "         1.5379e-02, -8.2225e-05, -3.9455e-02, -7.0571e-02,  1.1632e-01,\n",
      "        -8.6803e-02, -6.0005e-02,  8.0759e-02, -8.7689e-03,  6.4475e-02,\n",
      "        -6.2621e-02,  4.2574e-02,  1.0113e-01,  1.5904e-02,  8.9784e-02,\n",
      "        -5.8667e-02,  4.8540e-02, -7.6486e-02, -6.9782e-02,  8.8584e-02,\n",
      "        -1.0131e-01,  8.1230e-02, -5.6275e-02, -1.2489e-01,  1.2193e-02,\n",
      "         7.2291e-02,  5.8518e-02, -6.6271e-02,  1.1561e-01,  4.7621e-02,\n",
      "        -1.0754e-01,  9.8060e-02,  9.5880e-03,  2.6759e-03,  9.2774e-02,\n",
      "        -8.2661e-02,  2.8327e-05, -1.0293e-01, -1.0428e-01,  5.4201e-02,\n",
      "         5.8404e-02, -1.0582e-01, -1.4190e-02,  1.7176e-03,  1.0983e-01,\n",
      "         1.7968e-02,  2.4897e-02, -2.5943e-03,  1.1641e-01, -6.6418e-02,\n",
      "         6.3881e-02, -8.2696e-02, -3.9099e-02, -7.7772e-02, -4.1600e-03,\n",
      "         1.1481e-01, -7.4433e-02, -5.8996e-02,  9.0069e-02, -1.0390e-01,\n",
      "        -1.1296e-01, -9.1839e-02, -1.1062e-01, -5.8579e-02,  7.5922e-02,\n",
      "        -3.0539e-02,  1.1884e-01,  5.4558e-02,  1.1848e-01,  1.1444e-01,\n",
      "        -6.3385e-02,  2.7152e-02,  1.0936e-01,  1.1775e-01, -1.1557e-01,\n",
      "        -6.2377e-03,  5.4476e-02, -3.2914e-02,  1.6875e-02, -1.4645e-02,\n",
      "        -7.4045e-02, -1.0912e-01, -3.9750e-02, -9.2278e-03,  9.6168e-02,\n",
      "         9.4873e-02,  7.0902e-02,  6.5817e-02, -3.1217e-02,  4.9934e-02,\n",
      "         5.5079e-03,  5.0986e-02, -3.1937e-02, -2.8893e-02, -8.9113e-02,\n",
      "         9.1505e-02,  5.5833e-02, -1.2017e-01, -1.0556e-01,  1.0680e-01,\n",
      "         6.1184e-02,  1.6048e-02, -8.7206e-03,  1.0661e-03,  6.3697e-02,\n",
      "         1.8275e-02, -1.5568e-02, -6.0119e-02,  8.6084e-04,  7.3586e-02,\n",
      "        -1.0746e-01,  1.2452e-01, -8.9138e-02,  3.6648e-02,  6.7500e-02,\n",
      "         3.5203e-02, -6.9844e-02,  4.9699e-02, -2.7086e-02,  5.5185e-02,\n",
      "        -1.0681e-01,  1.9486e-02,  1.1881e-01,  7.7430e-02, -1.0072e-01,\n",
      "         4.7198e-02, -1.0916e-01, -1.0708e-01, -7.6535e-02, -8.4431e-02,\n",
      "         3.0104e-02, -5.3360e-02,  1.0387e-01, -6.8121e-02, -9.5326e-02,\n",
      "        -5.1350e-03,  4.4717e-02, -1.4044e-02, -5.0184e-02, -3.2022e-02,\n",
      "        -5.5169e-02, -1.1529e-01,  7.8366e-02,  1.1078e-01,  5.9474e-02,\n",
      "        -4.1764e-02,  2.6671e-02, -3.1681e-02, -1.8050e-02,  8.8473e-02,\n",
      "         2.7891e-03,  7.5970e-02,  8.4587e-02,  3.6315e-02,  2.8394e-02,\n",
      "         2.5682e-02, -5.0765e-02,  1.1415e-02,  1.0723e-01,  1.0884e-01,\n",
      "         6.8762e-02, -1.0893e-01, -3.2071e-02, -1.0788e-01, -3.2668e-02,\n",
      "         9.5525e-02, -5.2301e-02,  7.3256e-02, -1.1913e-01, -3.9101e-02,\n",
      "        -6.2883e-02,  8.6117e-02, -1.1462e-01,  4.6789e-02,  9.4500e-02,\n",
      "        -8.7464e-02, -9.3537e-02, -5.9581e-02,  5.9451e-02, -6.6704e-02,\n",
      "         7.3669e-02,  3.4128e-02,  1.9912e-02, -5.3712e-02,  7.9829e-02,\n",
      "        -9.9502e-02], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0198, -0.0387,  0.0383,  ..., -0.0297,  0.0086,  0.0061],\n",
      "        [ 0.0076, -0.0274, -0.0139,  ..., -0.0010,  0.0185,  0.0035],\n",
      "        [ 0.0177,  0.0314,  0.0399,  ..., -0.0085,  0.0255, -0.0068],\n",
      "        ...,\n",
      "        [-0.0078,  0.0226,  0.0143,  ..., -0.0390, -0.0273,  0.0021],\n",
      "        [-0.0024, -0.0308, -0.0408,  ..., -0.0322, -0.0293, -0.0106],\n",
      "        [ 0.0068,  0.0059,  0.0101,  ..., -0.0067,  0.0360,  0.0287]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0049, -0.0057,  0.0025,  ...,  0.0182, -0.0192, -0.0309],\n",
      "        [ 0.0131,  0.0058,  0.0080,  ...,  0.0347, -0.0397, -0.0068],\n",
      "        [ 0.0159,  0.0079, -0.0034,  ..., -0.0362, -0.0044,  0.0288],\n",
      "        ...,\n",
      "        [-0.0122, -0.0198, -0.0018,  ...,  0.0145, -0.0226, -0.0130],\n",
      "        [-0.0371,  0.0161, -0.0335,  ...,  0.0101,  0.0214, -0.0266],\n",
      "        [ 0.0154,  0.0442, -0.0008,  ..., -0.0171,  0.0090, -0.0226]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-3.8855e-02,  4.2652e-02, -6.3493e-03,  3.9602e-02, -8.1748e-03,\n",
      "         1.1971e-02, -2.3663e-02, -1.6971e-02,  2.5360e-02,  9.5699e-03,\n",
      "        -3.4453e-02,  1.8599e-02, -1.3514e-02, -2.0195e-02,  2.0479e-03,\n",
      "        -4.9620e-03,  9.2806e-04,  7.5088e-03,  1.8400e-02, -1.0734e-02,\n",
      "         4.3847e-02,  2.2153e-02,  1.1363e-02,  2.8663e-02,  2.9763e-02,\n",
      "        -4.0708e-02, -1.6564e-02,  1.4468e-02,  1.5074e-02,  3.1854e-03,\n",
      "         9.6975e-03,  3.1716e-03,  1.4358e-02,  2.4275e-02, -3.2364e-02,\n",
      "         3.5001e-02, -2.4569e-02, -1.1383e-03, -1.4755e-02,  2.9255e-02,\n",
      "         3.7234e-02, -2.8476e-02, -1.6221e-02, -1.5884e-02, -1.2747e-03,\n",
      "        -1.2245e-02, -5.6260e-03,  4.8987e-04, -2.7847e-02,  4.1592e-02,\n",
      "         4.0181e-02, -4.2503e-02, -2.7895e-02,  3.9952e-02,  3.8896e-02,\n",
      "        -1.9761e-02, -9.6064e-04, -3.2354e-02, -1.6732e-03, -2.1739e-02,\n",
      "         2.9548e-02, -1.2857e-02, -5.3444e-03, -2.9369e-02, -4.1237e-02,\n",
      "        -1.2045e-02,  1.8631e-02, -2.8117e-02, -2.6557e-02,  2.2529e-02,\n",
      "        -1.0840e-02, -2.8862e-02, -1.0199e-02, -2.5925e-02, -2.4329e-02,\n",
      "         1.8194e-02,  4.1563e-02, -4.1258e-02,  7.2724e-03, -1.2101e-02,\n",
      "        -3.6007e-02, -2.3826e-02,  7.6768e-03, -1.5262e-02, -2.2908e-02,\n",
      "         1.1499e-02, -2.9557e-02,  3.1298e-02,  3.8815e-02,  3.9533e-02,\n",
      "        -1.6451e-02, -1.9997e-02, -4.7562e-03, -3.0801e-02, -9.3787e-03,\n",
      "        -4.2650e-02, -3.9298e-02, -8.9465e-03,  1.4769e-02,  1.5827e-02,\n",
      "        -1.9556e-02,  3.9394e-02,  4.5264e-03,  3.0362e-03,  3.3627e-02,\n",
      "         1.7636e-02,  9.8851e-03,  3.5524e-02, -9.4140e-03,  2.9526e-02,\n",
      "        -8.5574e-03,  4.1663e-02, -3.4179e-02, -1.4314e-03,  5.6868e-03,\n",
      "        -2.5845e-03,  2.7766e-02, -4.1237e-02,  2.8893e-02, -3.8945e-02,\n",
      "        -1.4971e-02, -3.1096e-03, -5.1731e-03, -3.3735e-02,  2.6033e-02,\n",
      "         2.3988e-02,  4.3382e-02,  2.5977e-02,  3.4183e-02, -3.9713e-02,\n",
      "         3.2115e-02, -3.3842e-02,  8.0209e-03,  1.3054e-02, -2.5243e-03,\n",
      "         1.0768e-02,  2.9017e-02, -3.7508e-03,  3.3428e-03,  1.4214e-02,\n",
      "        -5.2108e-03, -2.0891e-02,  3.7385e-02,  3.7065e-02,  6.8003e-04,\n",
      "        -2.1275e-02, -2.0591e-02, -4.2969e-02, -1.5966e-02,  7.8438e-03,\n",
      "        -2.3256e-02, -1.0545e-02, -2.4562e-02, -8.5801e-03, -4.3617e-02,\n",
      "         4.3263e-03,  3.4098e-02,  1.8697e-02, -1.5533e-02,  1.9457e-02,\n",
      "         8.9967e-03,  5.0092e-03,  2.4138e-02, -1.8352e-02, -3.6700e-02,\n",
      "         4.0849e-02,  1.3534e-02, -2.2864e-02, -3.5433e-02,  3.9368e-03,\n",
      "         1.2448e-02,  2.2416e-02, -2.4798e-02,  6.1203e-03, -6.6535e-03,\n",
      "        -2.2099e-02, -2.0370e-02,  8.6648e-04, -2.1246e-02, -3.1217e-02,\n",
      "         2.3495e-02,  4.3385e-02, -1.0157e-02,  4.1737e-02,  3.2297e-02,\n",
      "        -9.6685e-04, -1.8810e-02,  7.3085e-03,  1.9288e-02,  3.5573e-03,\n",
      "        -2.1418e-02,  2.1973e-02, -3.7285e-02,  3.7585e-03,  6.3473e-03,\n",
      "         1.1502e-02,  1.3056e-02, -2.8040e-02, -4.1266e-02, -2.4288e-03,\n",
      "        -9.6125e-03,  1.7428e-02,  1.9393e-02,  2.0022e-02,  2.4074e-02,\n",
      "         3.2230e-02,  5.2971e-03,  1.1363e-02, -1.3535e-02, -4.2354e-03,\n",
      "        -1.0712e-02, -3.9627e-03,  3.0365e-02, -1.8850e-02,  2.2404e-02,\n",
      "         3.0375e-02,  3.5214e-02, -1.4104e-02, -8.8801e-03, -2.9337e-02,\n",
      "        -1.9755e-02, -4.1299e-02, -3.6311e-02, -3.9002e-02, -3.7965e-02,\n",
      "        -3.0448e-02,  4.1031e-02,  3.7472e-02,  3.1112e-02, -9.4069e-03,\n",
      "         1.6227e-03,  1.1036e-02,  7.5922e-03, -7.0197e-04, -2.8743e-02,\n",
      "         1.3923e-02,  3.6534e-02, -3.7578e-02, -1.5580e-02, -4.9107e-03,\n",
      "        -1.9816e-02,  9.3153e-03,  4.8724e-03,  1.4643e-02,  2.0478e-02,\n",
      "         1.0296e-02,  1.9863e-02, -2.0387e-02,  3.9937e-02,  1.2469e-02,\n",
      "         2.3759e-02, -1.3236e-02, -2.9295e-02, -6.4615e-05,  4.2259e-02,\n",
      "        -1.3266e-02], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0332,  0.0224,  0.0350,  ...,  0.0279,  0.0327, -0.0368],\n",
      "        [ 0.0334,  0.0425,  0.0416,  ..., -0.0261,  0.0308,  0.0392],\n",
      "        [-0.0289, -0.0434,  0.0380,  ..., -0.0233,  0.0441,  0.0388],\n",
      "        ...,\n",
      "        [ 0.0241,  0.0428,  0.0044,  ..., -0.0224, -0.0130,  0.0349],\n",
      "        [ 0.0224,  0.0010, -0.0278,  ...,  0.0256, -0.0203, -0.0397],\n",
      "        [-0.0404, -0.0273,  0.0186,  ..., -0.0148,  0.0356, -0.0114]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True), Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0604, -0.0478,  0.0246,  ...,  0.0321,  0.0134, -0.0367],\n",
      "        [-0.0004, -0.0173, -0.0485,  ...,  0.0236, -0.0021, -0.0540],\n",
      "        [-0.0461, -0.0154,  0.0624,  ..., -0.0500, -0.0376, -0.0608],\n",
      "        ...,\n",
      "        [ 0.0070,  0.0160,  0.0226,  ...,  0.0114, -0.0331,  0.0028],\n",
      "        [-0.0266, -0.0597, -0.0103,  ...,  0.0577, -0.0359, -0.0148],\n",
      "        [-0.0008, -0.0131, -0.0573,  ...,  0.0085, -0.0539, -0.0241]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 3.7776e-02,  5.3624e-02,  4.8816e-05,  5.5236e-02,  2.2774e-02,\n",
      "        -7.9068e-03,  3.6831e-02, -5.3541e-02, -6.0995e-02,  7.0271e-03,\n",
      "        -7.1465e-03,  5.9820e-02, -5.1317e-02,  1.4876e-02,  5.8723e-02,\n",
      "         5.2762e-02], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1778,  0.2401,  0.2231,  ...,  0.2481,  0.0318,  0.2379],\n",
      "        [ 0.0214, -0.1399,  0.1502,  ..., -0.0142,  0.1732,  0.1729],\n",
      "        [-0.1188, -0.0477,  0.0149,  ...,  0.0457, -0.2000, -0.0140],\n",
      "        ...,\n",
      "        [ 0.0793, -0.0960,  0.0997,  ..., -0.1553, -0.0152,  0.1258],\n",
      "        [-0.0640, -0.1713,  0.2049,  ..., -0.2106, -0.1148,  0.0225],\n",
      "        [-0.2199,  0.0819, -0.1361,  ..., -0.0373, -0.1212,  0.2296]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1720, -0.2077, -0.1866,  0.0637,  0.0425, -0.0290,  0.0931, -0.0470,\n",
      "        -0.1775,  0.0891,  0.0532,  0.0619, -0.0414, -0.0690, -0.0874, -0.0661,\n",
      "        -0.0006, -0.1313,  0.1305, -0.0831, -0.2443,  0.0574,  0.0025, -0.0346,\n",
      "         0.1321,  0.1642, -0.0452, -0.0034,  0.0898,  0.0803,  0.2221,  0.0378,\n",
      "        -0.0257,  0.0302, -0.0501,  0.0958, -0.1730, -0.1845, -0.2464, -0.0593,\n",
      "         0.1308,  0.1294,  0.1056,  0.0469, -0.0125, -0.1845, -0.1255,  0.2434,\n",
      "         0.2367,  0.0182,  0.2041, -0.0037,  0.2157,  0.0256, -0.0559,  0.1952,\n",
      "         0.0057,  0.0043,  0.1525,  0.1449,  0.1278,  0.0783,  0.1868,  0.0842,\n",
      "         0.1791, -0.1809,  0.2080,  0.0265, -0.1698, -0.1308, -0.2287, -0.1395,\n",
      "        -0.1007, -0.0913, -0.0223,  0.1299, -0.0569, -0.1105,  0.0636, -0.0347,\n",
      "         0.2458, -0.1499, -0.1430, -0.2350,  0.1153,  0.1785, -0.0694,  0.1665,\n",
      "        -0.2354, -0.0831,  0.0490,  0.2162,  0.0286, -0.1314,  0.1655, -0.1524,\n",
      "        -0.1463, -0.0996, -0.1019, -0.1270, -0.1316,  0.0358,  0.2038,  0.0917,\n",
      "        -0.2404,  0.1247,  0.2485,  0.0170, -0.0685,  0.2323,  0.2352, -0.2344,\n",
      "         0.1350,  0.0446,  0.1443, -0.0172, -0.0399, -0.0583, -0.0173,  0.0488,\n",
      "        -0.1137, -0.0836, -0.1442, -0.2155, -0.1311,  0.1698, -0.2270,  0.0855,\n",
      "        -0.2245, -0.2180,  0.1376,  0.0629, -0.0376,  0.0236, -0.0125,  0.2338,\n",
      "        -0.1852, -0.2449, -0.2114,  0.0618, -0.0760, -0.0759, -0.0816, -0.1255,\n",
      "        -0.1815,  0.0200, -0.2449,  0.1745, -0.0583,  0.2435,  0.1524,  0.0559,\n",
      "         0.1885, -0.2064, -0.0036, -0.0951,  0.2354,  0.1060,  0.0336, -0.2126,\n",
      "        -0.1579, -0.1934,  0.1093,  0.2108, -0.0418, -0.0134,  0.2129, -0.2116,\n",
      "         0.0062,  0.1621, -0.1780, -0.1166, -0.2206,  0.1753, -0.1072,  0.0867,\n",
      "        -0.0438, -0.0129,  0.0539, -0.2198,  0.0864, -0.1385,  0.0247, -0.1747,\n",
      "        -0.1770,  0.1900, -0.0962,  0.0417,  0.2124, -0.1520,  0.2133,  0.1498,\n",
      "        -0.2302, -0.1692,  0.0088, -0.1722,  0.1330,  0.0437, -0.1085,  0.1064,\n",
      "         0.0349,  0.0319, -0.1004,  0.0934, -0.1991,  0.1600, -0.1815, -0.0696,\n",
      "         0.0763, -0.0677, -0.2103,  0.1676, -0.2156,  0.0607, -0.0550, -0.1831,\n",
      "         0.1296, -0.1688,  0.1505, -0.1558, -0.2268,  0.1517, -0.0046,  0.1546,\n",
      "        -0.2025, -0.2242, -0.2333, -0.0309,  0.0721, -0.1071, -0.1188, -0.2319,\n",
      "        -0.1613, -0.1165, -0.2173,  0.1903,  0.1665, -0.0605,  0.2457, -0.0236,\n",
      "         0.2352, -0.0326,  0.0956,  0.1652,  0.0059, -0.2098,  0.1833,  0.0972,\n",
      "        -0.1475,  0.2379,  0.1196, -0.1433, -0.1087,  0.2356, -0.0425, -0.2454],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0325, -0.0122, -0.0462, -0.0207, -0.0539,  0.0250, -0.0150, -0.0537,\n",
      "         -0.0356, -0.0306, -0.0009, -0.0144, -0.0232,  0.0097, -0.0041, -0.0370,\n",
      "          0.0004,  0.0262,  0.0126, -0.0568,  0.0457,  0.0170,  0.0404,  0.0171,\n",
      "         -0.0515,  0.0551,  0.0238, -0.0098, -0.0122,  0.0559, -0.0319, -0.0191,\n",
      "          0.0584,  0.0046, -0.0389, -0.0049, -0.0070,  0.0081, -0.0251,  0.0598,\n",
      "          0.0231,  0.0057,  0.0107, -0.0032, -0.0234,  0.0446, -0.0031, -0.0285,\n",
      "         -0.0153,  0.0413, -0.0125, -0.0492, -0.0469,  0.0474,  0.0349,  0.0240,\n",
      "          0.0129, -0.0299, -0.0506, -0.0373, -0.0275, -0.0561, -0.0186, -0.0545,\n",
      "         -0.0325, -0.0043, -0.0151, -0.0266, -0.0595, -0.0494,  0.0120,  0.0384,\n",
      "          0.0412,  0.0613,  0.0245, -0.0034,  0.0294, -0.0293,  0.0205, -0.0525,\n",
      "         -0.0520, -0.0044, -0.0512, -0.0003, -0.0132, -0.0318, -0.0463,  0.0314,\n",
      "         -0.0616,  0.0372, -0.0554,  0.0084,  0.0247, -0.0121, -0.0434, -0.0581,\n",
      "         -0.0204,  0.0057, -0.0218, -0.0256,  0.0078, -0.0363, -0.0364,  0.0174,\n",
      "         -0.0082, -0.0096,  0.0039,  0.0132,  0.0343, -0.0103,  0.0182,  0.0231,\n",
      "          0.0532, -0.0098,  0.0378,  0.0086, -0.0398,  0.0041,  0.0545,  0.0501,\n",
      "          0.0100,  0.0037,  0.0279,  0.0208,  0.0071,  0.0328, -0.0084, -0.0462,\n",
      "         -0.0052,  0.0584, -0.0037,  0.0488, -0.0539, -0.0382,  0.0495,  0.0237,\n",
      "         -0.0405,  0.0324,  0.0100, -0.0294,  0.0159, -0.0530,  0.0479, -0.0078,\n",
      "         -0.0592, -0.0558, -0.0273, -0.0184, -0.0404, -0.0416,  0.0418, -0.0129,\n",
      "          0.0088, -0.0276, -0.0617, -0.0293, -0.0011,  0.0143, -0.0347,  0.0466,\n",
      "         -0.0453,  0.0580, -0.0489, -0.0206, -0.0574,  0.0528, -0.0448,  0.0571,\n",
      "          0.0253, -0.0622,  0.0157,  0.0230, -0.0023,  0.0523,  0.0242, -0.0531,\n",
      "          0.0004, -0.0620, -0.0402, -0.0460, -0.0607,  0.0201,  0.0371, -0.0394,\n",
      "         -0.0579, -0.0156, -0.0532,  0.0158,  0.0621, -0.0086,  0.0206,  0.0056,\n",
      "          0.0275, -0.0436,  0.0459, -0.0195, -0.0043,  0.0014,  0.0089,  0.0202,\n",
      "          0.0598, -0.0565, -0.0437,  0.0434, -0.0516,  0.0540, -0.0604, -0.0292,\n",
      "         -0.0352, -0.0084,  0.0459, -0.0342,  0.0467,  0.0239,  0.0305, -0.0179,\n",
      "         -0.0402, -0.0152,  0.0153,  0.0269, -0.0137, -0.0088, -0.0057,  0.0439,\n",
      "         -0.0583,  0.0155,  0.0029, -0.0567, -0.0444,  0.0442,  0.0046,  0.0017,\n",
      "         -0.0525, -0.0579,  0.0536, -0.0238, -0.0493,  0.0224,  0.0280, -0.0465,\n",
      "         -0.0340,  0.0062, -0.0250,  0.0499, -0.0519,  0.0507, -0.0301,  0.0241,\n",
      "          0.0256,  0.0278, -0.0023,  0.0239,  0.0353,  0.0085, -0.0391,  0.0622]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0531], requires_grad=True)]\n",
      "architecture check\n",
      "========== A2C HyperParameters ==========\n",
      "Discount factor:  0.99\n",
      "Action space:  4\n",
      "Update critic target factor:  0.3\n",
      "n_steps for TD:  5\n",
      "Device used:  cpu\n",
      "\n",
      "\n",
      "========== A2C Architecture ==========\n",
      "Actor Critic architecture: \n",
      " SharedActorCritic(\n",
      "  (shared_architecture): GatedBoxWorldNet(\n",
      "    (net): Sequential(\n",
      "      (0): Convolution(\n",
      "        (net): Sequential(\n",
      "          (0): Conv2d(3, 18, kernel_size=(2, 2), stride=(1, 1))\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(18, 36, kernel_size=(2, 2), stride=(1, 1))\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): GatedRelationalModule(\n",
      "        (net): Sequential(\n",
      "          (0): PositionalEncoding(\n",
      "            (projection): Linear(in_features=38, out_features=256, bias=True)\n",
      "          )\n",
      "          (1): GatedTransformerBlock(\n",
      "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0, inplace=False)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (GRU_gate1): GRU_gating(\n",
      "              (Wr): Linear(in_features=512, out_features=256, bias=False)\n",
      "              (Wz): Linear(in_features=512, out_features=256, bias=True)\n",
      "              (Wg): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "            (ff): PositionwiseFeedForward(\n",
      "              (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "              (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (GRU_gate2): GRU_gating(\n",
      "              (Wr): Linear(in_features=512, out_features=256, bias=False)\n",
      "              (Wz): Linear(in_features=512, out_features=256, bias=True)\n",
      "              (Wg): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (2): GatedTransformerBlock(\n",
      "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0, inplace=False)\n",
      "            (attn): MultiheadAttention(\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (GRU_gate1): GRU_gating(\n",
      "              (Wr): Linear(in_features=512, out_features=256, bias=False)\n",
      "              (Wz): Linear(in_features=512, out_features=256, bias=True)\n",
      "              (Wg): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "            (ff): PositionwiseFeedForward(\n",
      "              (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "              (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "              (dropout): Dropout(p=0, inplace=False)\n",
      "            )\n",
      "            (GRU_gate2): GRU_gating(\n",
      "              (Wr): Linear(in_features=512, out_features=256, bias=False)\n",
      "              (Wz): Linear(in_features=512, out_features=256, bias=True)\n",
      "              (Wg): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): FeaturewiseMaxPool()\n",
      "      (3): ResidualLayer(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (w1): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (w2): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (actor): SharedActor(\n",
      "    (linear): Linear(in_features=256, out_features=4, bias=True)\n",
      "  )\n",
      "  (critic): SharedCritic(\n",
      "    (net): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (critic_target): BaseCritic(\n",
      "    (net): Sequential(\n",
      "      (0): GatedBoxWorldNet(\n",
      "        (net): Sequential(\n",
      "          (0): Convolution(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(3, 18, kernel_size=(2, 2), stride=(1, 1))\n",
      "              (1): ReLU()\n",
      "              (2): Conv2d(18, 36, kernel_size=(2, 2), stride=(1, 1))\n",
      "              (3): ReLU()\n",
      "            )\n",
      "          )\n",
      "          (1): GatedRelationalModule(\n",
      "            (net): Sequential(\n",
      "              (0): PositionalEncoding(\n",
      "                (projection): Linear(in_features=38, out_features=256, bias=True)\n",
      "              )\n",
      "              (1): GatedTransformerBlock(\n",
      "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0, inplace=False)\n",
      "                (attn): MultiheadAttention(\n",
      "                  (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "                (GRU_gate1): GRU_gating(\n",
      "                  (Wr): Linear(in_features=512, out_features=256, bias=False)\n",
      "                  (Wz): Linear(in_features=512, out_features=256, bias=True)\n",
      "                  (Wg): Linear(in_features=512, out_features=256, bias=False)\n",
      "                )\n",
      "                (ff): PositionwiseFeedForward(\n",
      "                  (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "                  (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0, inplace=False)\n",
      "                )\n",
      "                (GRU_gate2): GRU_gating(\n",
      "                  (Wr): Linear(in_features=512, out_features=256, bias=False)\n",
      "                  (Wz): Linear(in_features=512, out_features=256, bias=True)\n",
      "                  (Wg): Linear(in_features=512, out_features=256, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (2): GatedTransformerBlock(\n",
      "                (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0, inplace=False)\n",
      "                (attn): MultiheadAttention(\n",
      "                  (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                )\n",
      "                (GRU_gate1): GRU_gating(\n",
      "                  (Wr): Linear(in_features=512, out_features=256, bias=False)\n",
      "                  (Wz): Linear(in_features=512, out_features=256, bias=True)\n",
      "                  (Wg): Linear(in_features=512, out_features=256, bias=False)\n",
      "                )\n",
      "                (ff): PositionwiseFeedForward(\n",
      "                  (w_1): Linear(in_features=256, out_features=64, bias=True)\n",
      "                  (w_2): Linear(in_features=64, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0, inplace=False)\n",
      "                )\n",
      "                (GRU_gate2): GRU_gating(\n",
      "                  (Wr): Linear(in_features=512, out_features=256, bias=False)\n",
      "                  (Wz): Linear(in_features=512, out_features=256, bias=True)\n",
      "                  (Wg): Linear(in_features=512, out_features=256, bias=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): FeaturewiseMaxPool()\n",
      "          (3): ResidualLayer(\n",
      "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (w1): Linear(in_features=256, out_features=16, bias=True)\n",
      "            (w2): Linear(in_features=16, out_features=256, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered process 1\n",
      "Entered process 2\n",
      "All processes started\n",
      "Constructed local model \n",
      "Constructed local model \n",
      "Loaded state dictionary\n",
      "created optim\n",
      "Process 2 started\n",
      "Loaded state dictionary\n",
      "created optim\n",
      "state.shape:  (3, 7, 7)\n",
      "Process 1 started\n",
      "state.shape:  (3, 7, 7)\n",
      "state.shape:  (3, 7, 7)\n",
      "states.shape:  (2, 3, 7, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state.shape:  (3, 7, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nicola/anaconda3/envs/torch/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nicola/anaconda3/envs/torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states.shape:  (2, 3, 7, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-186c9a8d6d31>\", line 37, in training_thread\n",
      "    print(\"Episode %d of process %d - reward: %.2f - steps to solve: %.2f\"%(e+1, rank, performance[-1], steps_to_solve[-10:]))\n",
      "TypeError: must be real number, not list\n",
      "  File \"/home/nicola/anaconda3/envs/torch/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/nicola/anaconda3/envs/torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-3-186c9a8d6d31>\", line 37, in training_thread\n",
      "    print(\"Episode %d of process %d - reward: %.2f - steps to solve: %.2f\"%(e+1, rank, performance[-1], steps_to_solve[-10:]))\n",
      "TypeError: must be real number, not list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processes finished\n"
     ]
    }
   ],
   "source": [
    "model = train_sandbox(agent_constructor, learning_rate, game_params, n_training_threads=2, n_episodes=100,\n",
    "                  max_steps=MAX_STEPS, return_agent=True, random_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
